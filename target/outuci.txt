0 [main] INFO org.apache.spark.SparkContext  - Running Spark version 2.2.0
55 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory  - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
62 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory  - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
62 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory  - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
63 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl  - UgiMetrics, User and group related metrics
231 [main] DEBUG org.apache.hadoop.util.Shell  - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:326)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:351)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:273)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:261)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:791)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:761)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:634)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:58)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
279 [main] DEBUG org.apache.hadoop.util.Shell  - setsid is not available on this machine. So not using it.
279 [main] DEBUG org.apache.hadoop.util.Shell  - setsid exited with exit code 0
285 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName  - Kerberos krb5 configuration not found, setting default realm to empty
287 [main] DEBUG org.apache.hadoop.security.Groups  -  Creating new Groups object
288 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader  - Trying to load the custom-built native-hadoop library...
289 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader  - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
289 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader  - java.library.path=/Users/tomhanlon/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
289 [main] WARN org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
290 [main] DEBUG org.apache.hadoop.util.PerformanceAdvisory  - Falling back to shell based
290 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback  - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
361 [main] DEBUG org.apache.hadoop.security.Groups  - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
364 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - hadoop login
364 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - hadoop login commit
367 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - using local user:UnixPrincipal: tomhanlon
367 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - Using user: "UnixPrincipal: tomhanlon" with name tomhanlon
367 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - User entry: "tomhanlon"
368 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - UGI loginUser:tomhanlon (auth:SIMPLE)
412 [main] INFO org.apache.spark.SparkContext  - Submitted application: DL4J Spark RNN Example
429 [main] INFO org.apache.spark.SecurityManager  - Changing view acls to: tomhanlon
430 [main] INFO org.apache.spark.SecurityManager  - Changing modify acls to: tomhanlon
430 [main] INFO org.apache.spark.SecurityManager  - Changing view acls groups to: 
431 [main] INFO org.apache.spark.SecurityManager  - Changing modify acls groups to: 
431 [main] INFO org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomhanlon); groups with view permissions: Set(); users  with modify permissions: Set(tomhanlon); groups with modify permissions: Set()
440 [main] DEBUG org.apache.spark.SecurityManager  - Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
498 [main] DEBUG io.netty.util.internal.logging.InternalLoggerFactory  - Using SLF4J as the default logging framework
501 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.noUnsafe: false
503 [main] DEBUG io.netty.util.internal.PlatformDependent0  - java.nio.Buffer.address: available
503 [main] DEBUG io.netty.util.internal.PlatformDependent0  - sun.misc.Unsafe.theUnsafe: available
504 [main] DEBUG io.netty.util.internal.PlatformDependent0  - sun.misc.Unsafe.copyMemory: available
504 [main] DEBUG io.netty.util.internal.PlatformDependent0  - direct buffer constructor: available
505 [main] DEBUG io.netty.util.internal.PlatformDependent0  - java.nio.Bits.unaligned: available, true
505 [main] DEBUG io.netty.util.internal.PlatformDependent0  - java.nio.DirectByteBuffer.<init>(long, int): available
506 [main] DEBUG io.netty.util.internal.Cleaner0  - java.nio.ByteBuffer.cleaner(): available
506 [main] DEBUG io.netty.util.internal.PlatformDependent  - Java version: 8
506 [main] DEBUG io.netty.util.internal.PlatformDependent  - sun.misc.Unsafe: available
506 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.noJavassist: false
561 [main] DEBUG io.netty.util.internal.PlatformDependent  - Javassist: available
561 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.tmpdir: /var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T (java.io.tmpdir)
561 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.bitMode: 64 (sun.arch.data.model)
561 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.noPreferDirect: false
561 [main] DEBUG io.netty.util.internal.PlatformDependent  - io.netty.maxDirectMemory: 954728448 bytes
563 [main] DEBUG io.netty.util.internal.JavassistTypeParameterMatcherGenerator  - Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
566 [main] DEBUG io.netty.util.internal.JavassistTypeParameterMatcherGenerator  - Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
574 [main] DEBUG io.netty.channel.MultithreadEventLoopGroup  - -Dio.netty.eventLoopThreads: 16
590 [main] DEBUG io.netty.channel.nio.NioEventLoop  - -Dio.netty.noKeySetOptimization: false
590 [main] DEBUG io.netty.channel.nio.NioEventLoop  - -Dio.netty.selectorAutoRebuildThreshold: 512
593 [main] DEBUG io.netty.util.internal.PlatformDependent  - org.jctools-core.MpscChunkedArrayQueue: available
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.numHeapArenas: 9
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.numDirectArenas: 9
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.pageSize: 8192
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.maxOrder: 11
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.chunkSize: 16777216
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.tinyCacheSize: 512
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.smallCacheSize: 256
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.normalCacheSize: 64
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.cacheTrimInterval: 8192
615 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.useCacheForAllThreads
651 [main] DEBUG io.netty.util.internal.ThreadLocalRandom  - -Dio.netty.initialSeedUniquifier: 0x74c270571df766d2 (took 0 ms)
670 [main] DEBUG io.netty.buffer.ByteBufUtil  - -Dio.netty.allocator.type: unpooled
670 [main] DEBUG io.netty.buffer.ByteBufUtil  - -Dio.netty.threadLocalDirectBufferSize: 65536
671 [main] DEBUG io.netty.buffer.ByteBufUtil  - -Dio.netty.maxThreadLocalCharBufferSize: 16384
695 [main] DEBUG io.netty.util.NetUtil  - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
696 [main] DEBUG io.netty.util.NetUtil  - /proc/sys/net/core/somaxconn: 128 (non-existent)
706 [main] DEBUG org.apache.spark.network.server.TransportServer  - Shuffle server started on port: 59102
709 [main] INFO org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 59102.
710 [main] DEBUG org.apache.spark.SparkEnv  - Using serializer: class org.apache.spark.serializer.JavaSerializer
726 [main] INFO org.apache.spark.SparkEnv  - Registering MapOutputTracker
727 [main] DEBUG org.apache.spark.MapOutputTrackerMasterEndpoint  - init
744 [main] INFO org.apache.spark.SparkEnv  - Registering BlockManagerMaster
746 [main] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
746 [main] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
759 [main] INFO org.apache.spark.storage.DiskBlockManager  - Created local directory at /private/var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T/blockmgr-c8cc36b9-8043-47b5-a2f1-3b6f5aaf763b
760 [main] DEBUG org.apache.spark.storage.DiskBlockManager  - Adding shutdown hook
761 [main] DEBUG org.apache.spark.util.ShutdownHookManager  - Adding shutdown hook
778 [main] INFO org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 366.3 MB
813 [main] INFO org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
814 [main] DEBUG org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint  - init
827 [main] DEBUG org.apache.spark.SecurityManager  - Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
878 [main] DEBUG org.spark_project.jetty.util.log  - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
881 [main] INFO org.spark_project.jetty.util.log  - Logging initialized @1571ms
888 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72b16078
895 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@48c40605{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@54107f42,MANAGED}
899 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@54107f42 added {org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec@5241138b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
899 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@54107f42 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec,POJO}
900 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7a138fc5
900 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@379ab47b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@307765b4,MANAGED}
900 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@307765b4 added {org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf@cd5573a==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
901 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@307765b4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf,POJO}
901 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@44a2b17b
901 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@7a56812e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2a76b80a,MANAGED}
901 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2a76b80a added {org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12@5b1b43ba==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
902 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2a76b80a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12,POJO}
902 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2f4854d6
902 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@61d9efe0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7e70bd39,MANAGED}
902 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7e70bd39 added {org.apache.spark.ui.JettyUtils$$anon$3-e6516e@5ba3fb68==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
902 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7e70bd39 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-e6516e,POJO}
910 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5db99216
910 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@3ec11999{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5c1bd44c,MANAGED}
910 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5c1bd44c added {org.apache.spark.ui.JettyUtils$$anon$3-9f46d94@5326b624==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
910 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5c1bd44c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-9f46d94,POJO}
910 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@18cc679e
910 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@2e77b8cf{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2c4ca0f9,MANAGED}
910 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2c4ca0f9 added {org.apache.spark.ui.JettyUtils$$anon$3-67ef029@6707cca9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
911 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2c4ca0f9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-67ef029,POJO}
911 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6e57e95e
911 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@2755d705{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@56db847e,MANAGED}
911 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@56db847e added {org.apache.spark.ui.JettyUtils$$anon$3-740abb5@93e31bfb==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
911 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@56db847e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-740abb5,POJO}
911 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@560cbf1a
911 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@5fe8b721{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@551a20d6,MANAGED}
911 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@551a20d6 added {org.apache.spark.ui.JettyUtils$$anon$3-578524c3@c294fd7d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
911 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@551a20d6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-578524c3,POJO}
912 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e094740
912 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@7a11c4c7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4cc547a,MANAGED}
912 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@4cc547a added {org.apache.spark.ui.JettyUtils$$anon$3-7555b920@2382357f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
912 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@4cc547a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7555b920,POJO}
912 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4152d38d
912 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@3591009c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5398edd0,MANAGED}
912 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5398edd0 added {org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a@7b12c641==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
912 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5398edd0 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a,POJO}
915 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@660e9100
915 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@69f63d95{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@9cd25ff,MANAGED}
915 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@9cd25ff added {org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5@d78cb177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
915 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@9cd25ff added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5,POJO}
915 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3574e198
915 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@6db66836{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@db44aa2,MANAGED}
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@db44aa2 added {org.apache.spark.ui.JettyUtils$$anon$3-2de366bb@24199f4c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@db44aa2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2de366bb,POJO}
916 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@61a002b1
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@4eeea57d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@780ec4a5,MANAGED}
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@780ec4a5 added {org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0@1211d347==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@780ec4a5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0,POJO}
916 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6f70f32f
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@548e76f1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5aabbb29,MANAGED}
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5aabbb29 added {org.apache.spark.ui.JettyUtils$$anon$3-72c927f1@d370fb4d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
916 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5aabbb29 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-72c927f1,POJO}
917 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1ee4730
917 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@59a67c3a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5003041b,MANAGED}
917 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5003041b added {org.apache.spark.ui.JettyUtils$$anon$3-724bade8@8595000b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
917 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5003041b added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-724bade8,POJO}
918 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@16fb356
918 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@6bc248ed{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@23a9ba52,MANAGED}
918 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@23a9ba52 added {org.apache.spark.ui.JettyUtils$$anon$3-ca27722@f847cf48==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
918 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@23a9ba52 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-ca27722,POJO}
919 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@64f857e7
919 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@1095f122{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58c540cf,MANAGED}
919 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@58c540cf added {org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8@3bc4366d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
919 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@58c540cf added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8,POJO}
919 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1b822fcc
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@24a1c17f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@56102e1c,MANAGED}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@56102e1c added {org.apache.spark.ui.JettyUtils$$anon$3-73511076@b966f9a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@56102e1c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-73511076,POJO}
920 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@532721fd
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@410954b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7fb9f71f,MANAGED}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7fb9f71f added {org.apache.spark.ui.JettyUtils$$anon$3-3b366632@cd06473d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7fb9f71f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3b366632,POJO}
920 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@51f49060
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@514eedd8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@617fe9e1,MANAGED}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@617fe9e1 added {org.apache.spark.ui.JettyUtils$$anon$3-6970140a@9246d85c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@617fe9e1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6970140a,POJO}
920 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3af4e0bf
921 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@245a26e1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d63b624,MANAGED}
925 [main] DEBUG org.spark_project.jetty.http.PreEncodedHttpField  - HttpField encoders loaded: [org.spark_project.jetty.http.Http1FieldPreEncoder@46ab18da]
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@4d63b624 added {org.spark_project.jetty.servlet.DefaultServlet-5922ae77@bd6abff7==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@4d63b624 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-5922ae77,POJO}
931 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@71f67a79
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@3deb2326{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62d363ab,MANAGED}
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@62d363ab added {org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac@bbd4b3bf==org.apache.spark.ui.JettyUtils$$anon$4,-1,true,AUTO}
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@62d363ab added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac,POJO}
932 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@27cf3151
932 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@127e70c5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5910de75,MANAGED}
934 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5910de75 added {org.glassfish.jersey.servlet.ServletContainer-226f885f@d9ca3f8f==org.glassfish.jersey.servlet.ServletContainer,-1,false,AUTO}
934 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5910de75 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-226f885f,POJO}
935 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@681aad3b
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@1a6f2363{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2427e004,MANAGED}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2427e004 added {org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9@828053f2==org.apache.spark.ui.JettyUtils$$anon$4,-1,true,AUTO}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2427e004 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9,POJO}
935 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1b58ff9e
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@2f66e802{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@56b78e55,MANAGED}
936 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@56b78e55 added {org.apache.spark.ui.JettyUtils$$anon$4-76318a7d@48fd51fe==org.apache.spark.ui.JettyUtils$$anon$4,-1,true,AUTO}
936 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@56b78e55 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-76318a7d,POJO}
943 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@37fbe4a8 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
944 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@37fbe4a8 added {org.spark_project.jetty.server.handler.ErrorHandler@6d6bc158,AUTO}
945 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@37fbe4a8 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[],MANAGED}
946 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.Server@37fbe4a8
947 [main] INFO org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT
960 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.Server@37fbe4a8
960 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
961 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1651ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
961 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.ErrorHandler@6d6bc158
961 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.ErrorHandler@6d6bc158
961 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1651ms org.spark_project.jetty.server.handler.ErrorHandler@6d6bc158
961 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[]
961 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[]
961 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1651ms org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[]
961 [main] INFO org.spark_project.jetty.server.Server  - Started @1651ms
961 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1651ms org.spark_project.jetty.server.Server@37fbe4a8
966 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - HttpConnectionFactory@57f791c6[HTTP/1.1] added {HttpConfiguration@51650883{32768/8192,8192/8192,https://:0,[]},POJO}
971 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@37fbe4a8,UNMANAGED}
972 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
972 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@24f43aa3,AUTO}
972 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@63fd4873,POJO}
972 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@57f791c6[HTTP/1.1],AUTO}
972 [main] DEBUG org.spark_project.jetty.server.AbstractConnector  - ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@57f791c6[HTTP/1.1]
975 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17,MANAGED}
975 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
976 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
976 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@24f43aa3
977 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1667ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@24f43aa3
977 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting HttpConnectionFactory@57f791c6[HTTP/1.1]
977 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1667ms HttpConnectionFactory@57f791c6[HTTP/1.1]
977 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17
980 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17 added {org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=-1 selected=-1,AUTO}
980 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17 added {org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=-1 selected=-1,AUTO}
980 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17 added {org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=-1 selected=-1,AUTO}
980 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17 added {org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=-1 selected=-1,AUTO}
980 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=-1 selected=-1
980 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
980 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1671ms org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
980 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
980 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=-1 selected=-1
981 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@14e30b89 execute
981 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
981 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@14e30b89 produce enter
981 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@14e30b89 producing
981 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1671ms org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
981 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
981 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=-1 selected=-1
981 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
981 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@67a32ded execute
981 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
981 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@67a32ded produce enter
981 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@67a32ded producing
981 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
981 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1671ms org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
981 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
981 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=-1 selected=-1
981 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@172d01cb execute
981 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@172d01cb produce enter
981 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
981 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@172d01cb producing
981 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
981 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1672ms org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
981 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1672ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17
981 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
981 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 execute
981 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 produce enter
981 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 producing
981 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
982 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@7db0565c,POJO}
982 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue acceptor-0@7db0565c
982 [SparkUI-49] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run acceptor-0@7db0565c
982 [main] INFO org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
982 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1673ms ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
982 [main] INFO org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
982 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@37fbe4a8 added {Spark@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
997 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232 mime types IncludeExclude@30c0ccff{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@581d969c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@22db8f4}
997 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232 added {o.s.j.s.ServletContextHandler@48c40605{/jobs,null,null,@Spark},MANAGED}
997 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,UNMANAGED}
998 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,null,@Spark}]}]
998 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232
999 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232
999 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@48c40605{/jobs,null,null,@Spark}
1000 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@48c40605{/jobs,null,STARTING,@Spark}
1000 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@54107f42
1001 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec from default=false
1001 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1001 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1001 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1002 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec@5241138b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1002 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec=org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec@5241138b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1002 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@54107f42
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1693ms org.spark_project.jetty.servlet.ServletHandler@54107f42
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec@5241138b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1004 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1694ms org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec@5241138b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1005 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6e0ff644 for org.apache.spark.ui.JettyUtils$$anon$3-138fe6ec
1005 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}
1005 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1695ms o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}
1005 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1695ms org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232
1005 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5 mime types IncludeExclude@2a2bb0eb{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3c291aad,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2d0566ba}
1005 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5 added {o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,null,@Spark},MANAGED}
1005 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,UNMANAGED}
1006 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,null,@Spark}]}]
1006 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5
1006 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,null,@Spark}
1006 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,STARTING,@Spark}
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@307765b4
1006 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf from default=false
1006 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1006 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1006 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1006 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf@cd5573a==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1006 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf=org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf@cd5573a==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1006 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@307765b4
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1696ms org.spark_project.jetty.servlet.ServletHandler@307765b4
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf@cd5573a==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1696ms org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf@cd5573a==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1006 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7728643a for org.apache.spark.ui.JettyUtils$$anon$3-4a9e6faf
1006 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1697ms o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}
1006 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1697ms org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5
1006 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400 mime types IncludeExclude@5167268{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1cfd1875,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@28c0b664}
1007 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400 added {o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,null,@Spark},MANAGED}
1007 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,UNMANAGED}
1007 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1007 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,null,@Spark}]}]
1007 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1007 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400
1007 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400
1007 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,null,@Spark}
1007 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,STARTING,@Spark}
1007 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@2a76b80a
1007 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12 from default=false
1007 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1007 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1007 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1007 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12@5b1b43ba==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1007 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12=org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12@5b1b43ba==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1007 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@2a76b80a
1007 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1698ms org.spark_project.jetty.servlet.ServletHandler@2a76b80a
1007 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12@5b1b43ba==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1007 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1698ms org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12@5b1b43ba==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1007 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1af7f54a for org.apache.spark.ui.JettyUtils$$anon$3-7eb01b12
1008 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}
1008 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1698ms o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}
1008 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1698ms org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400
1008 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4 mime types IncludeExclude@4d157787{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@68ed96ca,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6d1310f6}
1008 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4 added {o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,null,@Spark},MANAGED}
1008 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,UNMANAGED}
1009 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1009 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1009 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,null,@Spark}]}]
1009 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4
1009 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,null,@Spark}
1009 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,STARTING,@Spark}
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@7e70bd39
1009 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-e6516e from default=false
1009 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1009 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1009 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1009 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-e6516e@5ba3fb68==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1009 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-e6516e=org.apache.spark.ui.JettyUtils$$anon$3-e6516e@5ba3fb68==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1009 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@7e70bd39
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1699ms org.spark_project.jetty.servlet.ServletHandler@7e70bd39
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-e6516e@5ba3fb68==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1700ms org.apache.spark.ui.JettyUtils$$anon$3-e6516e@5ba3fb68==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1009 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@54e7391d for org.apache.spark.ui.JettyUtils$$anon$3-e6516e
1009 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1700ms o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}
1009 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1700ms org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4
1010 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d mime types IncludeExclude@255990cc{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@51c929ae,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3c8bdd5b}
1010 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d added {o.s.j.s.ServletContextHandler@3ec11999{/stages,null,null,@Spark},MANAGED}
1010 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,UNMANAGED}
1010 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1010 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1010 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1010 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1010 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,null,@Spark}]}]
1010 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d
1010 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d
1010 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@3ec11999{/stages,null,null,@Spark}
1010 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@3ec11999{/stages,null,STARTING,@Spark}
1010 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@5c1bd44c
1010 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-9f46d94 from default=false
1010 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1010 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1010 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1010 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-9f46d94@5326b624==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1010 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-9f46d94=org.apache.spark.ui.JettyUtils$$anon$3-9f46d94@5326b624==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1011 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@5c1bd44c
1011 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1701ms org.spark_project.jetty.servlet.ServletHandler@5c1bd44c
1011 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-9f46d94@5326b624==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1011 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1701ms org.apache.spark.ui.JettyUtils$$anon$3-9f46d94@5326b624==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1011 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@40e4ea87 for org.apache.spark.ui.JettyUtils$$anon$3-9f46d94
1011 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}
1011 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1701ms o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}
1011 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1701ms org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d
1011 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c mime types IncludeExclude@3a7b503d{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@512d92b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@62c5bbdc}
1011 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c added {o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,null,@Spark},MANAGED}
1011 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,UNMANAGED}
1011 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1011 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1011 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1011 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,null,@Spark}]}]
1012 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1012 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c
1012 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,null,@Spark}
1012 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,STARTING,@Spark}
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@2c4ca0f9
1012 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-67ef029 from default=false
1012 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1012 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1012 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1012 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-67ef029@6707cca9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1012 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-67ef029=org.apache.spark.ui.JettyUtils$$anon$3-67ef029@6707cca9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1012 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@2c4ca0f9
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1702ms org.spark_project.jetty.servlet.ServletHandler@2c4ca0f9
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-67ef029@6707cca9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1702ms org.apache.spark.ui.JettyUtils$$anon$3-67ef029@6707cca9==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1012 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1bc53649 for org.apache.spark.ui.JettyUtils$$anon$3-67ef029
1012 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1703ms o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}
1012 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1703ms org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c
1013 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b mime types IncludeExclude@47d93e0d{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@475b7792,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@751e664e}
1013 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b added {o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,null,@Spark},MANAGED}
1013 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,UNMANAGED}
1013 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1013 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1013 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1013 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1013 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1013 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1013 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,null,@Spark}]}]
1013 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b
1013 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b
1013 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,null,@Spark}
1014 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,STARTING,@Spark}
1014 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@56db847e
1014 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-740abb5 from default=false
1014 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1014 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1014 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1014 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-740abb5@93e31bfb==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1014 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-740abb5=org.apache.spark.ui.JettyUtils$$anon$3-740abb5@93e31bfb==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1014 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@56db847e
1014 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1704ms org.spark_project.jetty.servlet.ServletHandler@56db847e
1014 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-740abb5@93e31bfb==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1014 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1705ms org.apache.spark.ui.JettyUtils$$anon$3-740abb5@93e31bfb==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1014 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@182b435b for org.apache.spark.ui.JettyUtils$$anon$3-740abb5
1014 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}
1014 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1705ms o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}
1014 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1705ms org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b
1015 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641 mime types IncludeExclude@3704122f{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3153ddfc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@60afd40d}
1015 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641 added {o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,null,@Spark},MANAGED}
1015 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,UNMANAGED}
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,null,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1016 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641
1016 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641
1016 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,null,@Spark}
1016 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,STARTING,@Spark}
1016 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@551a20d6
1016 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-578524c3 from default=false
1016 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1016 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1016 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1016 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-578524c3@c294fd7d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1016 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-578524c3=org.apache.spark.ui.JettyUtils$$anon$3-578524c3@c294fd7d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1016 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@551a20d6
1016 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1707ms org.spark_project.jetty.servlet.ServletHandler@551a20d6
1016 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-578524c3@c294fd7d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1017 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1707ms org.apache.spark.ui.JettyUtils$$anon$3-578524c3@c294fd7d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1017 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3f2049b6 for org.apache.spark.ui.JettyUtils$$anon$3-578524c3
1017 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}
1017 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1707ms o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}
1017 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1707ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641
1017 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93 mime types IncludeExclude@ea27e34{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@33a2499c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@e72dba7}
1017 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93 added {o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,null,@Spark},MANAGED}
1017 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,UNMANAGED}
1017 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1017 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1017 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1017 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1018 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1018 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1018 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1018 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1018 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,null,@Spark}]}]
1018 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93
1018 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93
1018 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,null,@Spark}
1018 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,STARTING,@Spark}
1018 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@4cc547a
1018 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7555b920 from default=false
1018 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1018 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1018 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1018 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-7555b920@2382357f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1018 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7555b920=org.apache.spark.ui.JettyUtils$$anon$3-7555b920@2382357f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1018 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@4cc547a
1018 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1709ms org.spark_project.jetty.servlet.ServletHandler@4cc547a
1018 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-7555b920@2382357f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1019 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1709ms org.apache.spark.ui.JettyUtils$$anon$3-7555b920@2382357f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1019 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1dfd5f51 for org.apache.spark.ui.JettyUtils$$anon$3-7555b920
1019 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}
1019 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1709ms o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}
1019 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1709ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93
1019 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb mime types IncludeExclude@24855019{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3abd581e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4d4d8fcf}
1019 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb added {o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,null,@Spark},MANAGED}
1019 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,UNMANAGED}
1019 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1019 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1019 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,null,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb
1020 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb
1020 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,null,@Spark}
1020 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,STARTING,@Spark}
1020 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@5398edd0
1020 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a from default=false
1020 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1020 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1020 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1020 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a@7b12c641==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1020 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a=org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a@7b12c641==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1020 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@5398edd0
1020 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1711ms org.spark_project.jetty.servlet.ServletHandler@5398edd0
1021 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a@7b12c641==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1021 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1711ms org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a@7b12c641==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1021 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6f0628de for org.apache.spark.ui.JettyUtils$$anon$3-b5cc23a
1021 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}
1021 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1711ms o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}
1021 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1711ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb
1021 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088 mime types IncludeExclude@1e392345{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@12f3afb5,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4ced35ed}
1021 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088 added {o.s.j.s.ServletContextHandler@69f63d95{/storage,null,null,@Spark},MANAGED}
1021 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,UNMANAGED}
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,null,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1022 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088
1022 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088
1022 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@69f63d95{/storage,null,null,@Spark}
1022 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@69f63d95{/storage,null,STARTING,@Spark}
1022 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@9cd25ff
1023 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5 from default=false
1023 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1023 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1023 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1023 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5@d78cb177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1023 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5=org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5@d78cb177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1023 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@9cd25ff
1023 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1713ms org.spark_project.jetty.servlet.ServletHandler@9cd25ff
1023 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5@d78cb177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1023 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1713ms org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5@d78cb177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1023 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7bd69e82 for org.apache.spark.ui.JettyUtils$$anon$3-27e0f2f5
1023 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}
1023 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1713ms o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}
1023 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1713ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088
1023 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a mime types IncludeExclude@51b01960{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6831d8fd,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@27dc79f7}
1023 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a added {o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,null,@Spark},MANAGED}
1023 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,UNMANAGED}
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,null,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1024 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a
1024 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a
1024 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,null,@Spark}
1024 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,STARTING,@Spark}
1024 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@db44aa2
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2de366bb from default=false
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1025 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2de366bb@24199f4c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1025 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2de366bb=org.apache.spark.ui.JettyUtils$$anon$3-2de366bb@24199f4c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1025 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@db44aa2
1025 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1715ms org.spark_project.jetty.servlet.ServletHandler@db44aa2
1025 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-2de366bb@24199f4c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1025 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1715ms org.apache.spark.ui.JettyUtils$$anon$3-2de366bb@24199f4c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1025 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3aaf4f07 for org.apache.spark.ui.JettyUtils$$anon$3-2de366bb
1025 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}
1025 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1715ms o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}
1025 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1715ms org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a
1025 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f mime types IncludeExclude@18e8473e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5a2f016d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1a38ba58}
1025 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f added {o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,null,@Spark},MANAGED}
1025 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,UNMANAGED}
1025 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1025 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,null,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f
1026 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,null,@Spark}
1026 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,STARTING,@Spark}
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@780ec4a5
1026 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0 from default=false
1026 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1026 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1026 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1026 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0@1211d347==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1026 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0=org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0@1211d347==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1026 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@780ec4a5
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1717ms org.spark_project.jetty.servlet.ServletHandler@780ec4a5
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0@1211d347==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1717ms org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0@1211d347==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1026 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6058e535 for org.apache.spark.ui.JettyUtils$$anon$3-e24ddd0
1026 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1717ms o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}
1026 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1717ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f
1027 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a mime types IncludeExclude@1deb2c43{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3bb9efbc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1cefc4b3}
1027 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a added {o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,null,@Spark},MANAGED}
1027 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,UNMANAGED}
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,null,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1027 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1028 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a
1028 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,null,@Spark}
1028 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,STARTING,@Spark}
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@5aabbb29
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-72c927f1 from default=false
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-72c927f1@d370fb4d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-72c927f1=org.apache.spark.ui.JettyUtils$$anon$3-72c927f1@d370fb4d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1028 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@5aabbb29
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1718ms org.spark_project.jetty.servlet.ServletHandler@5aabbb29
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-72c927f1@d370fb4d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1718ms org.apache.spark.ui.JettyUtils$$anon$3-72c927f1@d370fb4d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6f6a7463 for org.apache.spark.ui.JettyUtils$$anon$3-72c927f1
1028 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1718ms o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1718ms org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a
1028 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d mime types IncludeExclude@79f227a9{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6ca320ab,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@50d68830}
1028 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d added {o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,null,@Spark},MANAGED}
1028 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,UNMANAGED}
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,null,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d
1029 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d
1029 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,null,@Spark}
1029 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,STARTING,@Spark}
1029 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@5003041b
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-724bade8 from default=false
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-724bade8@8595000b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-724bade8=org.apache.spark.ui.JettyUtils$$anon$3-724bade8@8595000b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1030 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@5003041b
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1720ms org.spark_project.jetty.servlet.ServletHandler@5003041b
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-724bade8@8595000b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1720ms org.apache.spark.ui.JettyUtils$$anon$3-724bade8@8595000b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7674a051 for org.apache.spark.ui.JettyUtils$$anon$3-724bade8
1030 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1720ms o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1720ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d
1030 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c mime types IncludeExclude@6754ef00{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@619bd14c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@323e8306}
1030 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c added {o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,null,@Spark},MANAGED}
1030 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,UNMANAGED}
1030 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,null,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c
1031 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,null,@Spark}
1031 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,STARTING,@Spark}
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@23a9ba52
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-ca27722 from default=false
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-ca27722@f847cf48==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-ca27722=org.apache.spark.ui.JettyUtils$$anon$3-ca27722@f847cf48==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1031 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@23a9ba52
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1722ms org.spark_project.jetty.servlet.ServletHandler@23a9ba52
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-ca27722@f847cf48==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1722ms org.apache.spark.ui.JettyUtils$$anon$3-ca27722@f847cf48==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1032 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4acf72b6 for org.apache.spark.ui.JettyUtils$$anon$3-ca27722
1032 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1722ms o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1722ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c
1032 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12 mime types IncludeExclude@3301500b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@24b52d3e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@15deb1dc}
1032 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12 added {o.s.j.s.ServletContextHandler@1095f122{/executors,null,null,@Spark},MANAGED}
1032 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,UNMANAGED}
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1032 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,null,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12
1033 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@1095f122{/executors,null,null,@Spark}
1033 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@1095f122{/executors,null,STARTING,@Spark}
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@58c540cf
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8 from default=false
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8@3bc4366d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8=org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8@3bc4366d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1033 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@58c540cf
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1724ms org.spark_project.jetty.servlet.ServletHandler@58c540cf
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8@3bc4366d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1724ms org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8@3bc4366d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@57a4d5ee for org.apache.spark.ui.JettyUtils$$anon$3-3d6300e8
1033 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1724ms o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1724ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12
1034 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9 mime types IncludeExclude@3a45c42a{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@36dce7ed,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@47a64f7d}
1034 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9 added {o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,null,@Spark},MANAGED}
1034 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,UNMANAGED}
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,null,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9
1035 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,null,@Spark}
1035 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,STARTING,@Spark}
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@56102e1c
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-73511076 from default=false
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-73511076@b966f9a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-73511076=org.apache.spark.ui.JettyUtils$$anon$3-73511076@b966f9a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1035 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@56102e1c
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1726ms org.spark_project.jetty.servlet.ServletHandler@56102e1c
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-73511076@b966f9a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1726ms org.apache.spark.ui.JettyUtils$$anon$3-73511076@b966f9a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@27a0a5a2 for org.apache.spark.ui.JettyUtils$$anon$3-73511076
1035 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1726ms o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1726ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9
1036 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34 mime types IncludeExclude@33aa93c{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@32c0915e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@106faf11}
1036 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34 added {o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,null,@Spark},MANAGED}
1036 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,UNMANAGED}
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1037 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1037 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,null,@Spark}]}]
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34
1037 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,null,@Spark}
1037 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,STARTING,@Spark}
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@7fb9f71f
1037 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3b366632 from default=false
1037 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1037 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1037 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1037 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3b366632@cd06473d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1037 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3b366632=org.apache.spark.ui.JettyUtils$$anon$3-3b366632@cd06473d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1037 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@7fb9f71f
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1727ms org.spark_project.jetty.servlet.ServletHandler@7fb9f71f
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-3b366632@cd06473d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1727ms org.apache.spark.ui.JettyUtils$$anon$3-3b366632@cd06473d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1037 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@26d10f2e for org.apache.spark.ui.JettyUtils$$anon$3-3b366632
1037 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1727ms o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1727ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34
1037 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb mime types IncludeExclude@7dd712e8{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2c282004,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@22ee2d0}
1037 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb added {o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,null,@Spark},MANAGED}
1037 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,UNMANAGED}
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,[o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,null,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb
1038 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,null,@Spark}
1038 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,STARTING,@Spark}
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@617fe9e1
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6970140a from default=false
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6970140a@9246d85c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6970140a=org.apache.spark.ui.JettyUtils$$anon$3-6970140a@9246d85c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1038 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@617fe9e1
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1729ms org.spark_project.jetty.servlet.ServletHandler@617fe9e1
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-6970140a@9246d85c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1729ms org.apache.spark.ui.JettyUtils$$anon$3-6970140a@9246d85c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1039 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3e792ce3 for org.apache.spark.ui.JettyUtils$$anon$3-6970140a
1039 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1729ms o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1729ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb
1039 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328 mime types IncludeExclude@26f143ed{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3c1e3314,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4b770e40}
1039 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328 added {o.s.j.s.ServletContextHandler@245a26e1{/static,null,null,@Spark},MANAGED}
1039 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328,UNMANAGED}
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328,[o.s.j.s.ServletContextHandler@245a26e1{/static,null,null,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,[o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328
1041 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@245a26e1{/static,null,null,@Spark}
1041 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@245a26e1{/static,null,STARTING,@Spark}
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@4d63b624
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-5922ae77 from default=false
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-5922ae77@bd6abff7==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-5922ae77=org.spark_project.jetty.servlet.DefaultServlet-5922ae77@bd6abff7==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
1041 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@4d63b624
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1732ms org.spark_project.jetty.servlet.ServletHandler@4d63b624
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.DefaultServlet-5922ae77@bd6abff7==org.spark_project.jetty.servlet.DefaultServlet,-1,true
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1732ms org.spark_project.jetty.servlet.DefaultServlet-5922ae77@bd6abff7==org.spark_project.jetty.servlet.DefaultServlet,-1,true
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@54a3ab8f for org.spark_project.jetty.servlet.DefaultServlet-5922ae77
1047 [main] DEBUG org.spark_project.jetty.servlet.DefaultServlet  - resource base = jar:file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-core_2.11-2.2.0.jar!/org/apache/spark/ui/static
1047 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}
1047 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1737ms o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}
1047 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1737ms org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328
1047 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1 mime types IncludeExclude@61a5b4ae{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3a71c100,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5b69fd74}
1047 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1 added {o.s.j.s.ServletContextHandler@3deb2326{/,null,null,@Spark},MANAGED}
1047 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1,UNMANAGED}
1047 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1,[o.s.j.s.ServletContextHandler@3deb2326{/,null,null,@Spark}]}]
1047 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1047 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328,[o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,[o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1
1048 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1
1048 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@3deb2326{/,null,null,@Spark}
1048 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@3deb2326{/,null,STARTING,@Spark}
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@62d363ab
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac from default=false
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac@bbd4b3bf==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac=org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac@bbd4b3bf==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1049 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@62d363ab
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1739ms org.spark_project.jetty.servlet.ServletHandler@62d363ab
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac@bbd4b3bf==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1739ms org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac@bbd4b3bf==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@437e951d for org.apache.spark.ui.JettyUtils$$anon$4-7889a1ac
1049 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3deb2326{/,null,AVAILABLE,@Spark}
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1739ms o.s.j.s.ServletContextHandler@3deb2326{/,null,AVAILABLE,@Spark}
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1739ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1
1049 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3 mime types IncludeExclude@63a5e46c{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7e8e8651,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@49ef32e0}
1049 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3 added {o.s.j.s.ServletContextHandler@127e70c5{/api,null,null,@Spark},MANAGED}
1050 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1, org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3,UNMANAGED}
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1,[o.s.j.s.ServletContextHandler@3deb2326{/,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328,[o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,[o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3,[o.s.j.s.ServletContextHandler@127e70c5{/api,null,null,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3
1051 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@127e70c5{/api,null,null,@Spark}
1051 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@127e70c5{/api,null,STARTING,@Spark}
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@5910de75
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-226f885f from default=false
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-226f885f@d9ca3f8f==org.glassfish.jersey.servlet.ServletContainer,-1,false}
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-226f885f=org.glassfish.jersey.servlet.ServletContainer-226f885f@d9ca3f8f==org.glassfish.jersey.servlet.ServletContainer,-1,false}
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5910de75
1051 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5910de75 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713@e046ca34==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false,AUTO}
1051 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5910de75 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713,POJO}
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-226f885f from default=false
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713 from default=false
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-226f885f@d9ca3f8f==org.glassfish.jersey.servlet.ServletContainer,-1,false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713@e046ca34==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713@e046ca34==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false, org.glassfish.jersey.servlet.ServletContainer-226f885f=org.glassfish.jersey.servlet.ServletContainer-226f885f@d9ca3f8f==org.glassfish.jersey.servlet.ServletContainer,-1,false}
1051 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@5910de75
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1742ms org.spark_project.jetty.servlet.ServletHandler@5910de75
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.glassfish.jersey.servlet.ServletContainer-226f885f@d9ca3f8f==org.glassfish.jersey.servlet.ServletContainer,-1,false
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1742ms org.glassfish.jersey.servlet.ServletContainer-226f885f@d9ca3f8f==org.glassfish.jersey.servlet.ServletContainer,-1,false
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713@e046ca34==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1742ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-51abf713@e046ca34==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
1052 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@127e70c5{/api,null,AVAILABLE,@Spark}
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1742ms o.s.j.s.ServletContextHandler@127e70c5{/api,null,AVAILABLE,@Spark}
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1742ms org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3
1052 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6 mime types IncludeExclude@315df4bb{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3fc08eec,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@5cad8b7d}
1052 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6 added {o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,null,@Spark},MANAGED}
1052 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1, org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6,UNMANAGED}
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1,[o.s.j.s.ServletContextHandler@3deb2326{/,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328,[o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,[o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1052 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3,[o.s.j.s.ServletContextHandler@127e70c5{/api,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6,[o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,null,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6
1053 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,null,@Spark}
1053 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,STARTING,@Spark}
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@2427e004
1053 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9 from default=false
1053 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1053 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1053 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1053 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9@828053f2==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1053 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9=org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9@828053f2==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1053 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@2427e004
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1743ms org.spark_project.jetty.servlet.ServletHandler@2427e004
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9@828053f2==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1743ms org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9@828053f2==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1053 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@25243bc1 for org.apache.spark.ui.JettyUtils$$anon$4-5ebd56e9
1053 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,AVAILABLE,@Spark}
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1743ms o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,AVAILABLE,@Spark}
1053 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1743ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6
1053 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667 mime types IncludeExclude@2e6ee0bc{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4201a617,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@467f77a5}
1053 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667 added {o.s.j.s.ServletContextHandler@2f66e802{/stages/stage/kill,null,null,@Spark},MANAGED}
1053 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1, org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667,UNMANAGED}
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1,[o.s.j.s.ServletContextHandler@3deb2326{/,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3,[o.s.j.s.ServletContextHandler@127e70c5{/api,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328,[o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,[o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667,[o.s.j.s.ServletContextHandler@2f66e802{/stages/stage/kill,null,null,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6,[o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667
1054 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@2f66e802{/stages/stage/kill,null,null,@Spark}
1054 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@2f66e802{/stages/stage/kill,null,STARTING,@Spark}
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@56b78e55
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-76318a7d from default=false
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-76318a7d@48fd51fe==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-76318a7d=org.apache.spark.ui.JettyUtils$$anon$4-76318a7d@48fd51fe==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1054 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@56b78e55
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1745ms org.spark_project.jetty.servlet.ServletHandler@56b78e55
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$4-76318a7d@48fd51fe==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1745ms org.apache.spark.ui.JettyUtils$$anon$4-76318a7d@48fd51fe==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@420bc288 for org.apache.spark.ui.JettyUtils$$anon$4-76318a7d
1054 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2f66e802{/stages/stage/kill,null,AVAILABLE,@Spark}
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1745ms o.s.j.s.ServletContextHandler@2f66e802{/stages/stage/kill,null,AVAILABLE,@Spark}
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1745ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667
1057 [main] INFO org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040
1075 [main] INFO org.apache.spark.SparkContext  - Added JAR file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.1.4:59102/jars/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1512506453554
1242 [main] INFO org.apache.spark.SparkContext  - Added file file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/uci.zip at spark://192.168.1.4:59102/files/uci.zip with timestamp 1512506453721
1244 [main] INFO org.apache.spark.util.Utils  - Copying /Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/uci.zip to /private/var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T/spark-d18d2520-aa87-48bd-ab4e-784a2007b0a4/userFiles-22ea22d1-1611-4058-9703-980c46b08715/uci.zip
1343 [appclient-register-master-threadpool-0] INFO org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint  - Connecting to master spark://Toms-MacBook-Pro.local:7077...
1354 [netty-rpc-connection-0] DEBUG org.apache.spark.network.client.TransportClientFactory  - Creating new connection to Toms-MacBook-Pro.local/192.168.1.4:7077
1371 [rpc-client-1-1] DEBUG io.netty.buffer.AbstractByteBuf  - -Dio.netty.buffer.bytebuf.checkAccessible: true
1373 [rpc-client-1-1] DEBUG io.netty.util.ResourceLeakDetector  - -Dio.netty.leakDetection.level: simple
1373 [rpc-client-1-1] DEBUG io.netty.util.ResourceLeakDetector  - -Dio.netty.leakDetection.maxRecords: 4
1373 [rpc-client-1-1] DEBUG io.netty.util.ResourceLeakDetectorFactory  - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@561edc7
1378 [netty-rpc-connection-0] DEBUG org.apache.spark.network.client.TransportClientFactory  - Connection to Toms-MacBook-Pro.local/192.168.1.4:7077 successful, running bootstraps...
1378 [netty-rpc-connection-0] INFO org.apache.spark.network.client.TransportClientFactory  - Successfully created connection to Toms-MacBook-Pro.local/192.168.1.4:7077 after 23 ms (0 ms spent in bootstraps)
1382 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.maxCapacity.default: 32768
1382 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.maxSharedCapacityFactor: 2
1382 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.linkCapacity: 16
1382 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.ratio: 8
1440 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - Connected to Spark cluster with app ID app-20171205154053-0018
1442 [dispatcher-event-loop-3] INFO org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint  - Executor added: app-20171205154053-0018/0 on worker-20171205023234-192.168.1.4-63497 (192.168.1.4:63497) with 8 cores
1443 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - Granted executor ID app-20171205154053-0018/0 on hostPort 192.168.1.4:63497 with 8 cores, 1024.0 MB RAM
1445 [main] DEBUG org.apache.spark.network.server.TransportServer  - Shuffle server started on port: 59108
1445 [main] INFO org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59108.
1446 [main] INFO org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.1.4:59108
1448 [main] INFO org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
1450 [main] INFO org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.1.4, 59108, None)
1452 [dispatcher-event-loop-6] INFO org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint  - Executor updated: app-20171205154053-0018/0 is now RUNNING
1452 [dispatcher-event-loop-5] DEBUG org.apache.spark.storage.DefaultTopologyMapper  - Got a request for 192.168.1.4
1453 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.1.4:59108 with 366.3 MB RAM, BlockManagerId(driver, 192.168.1.4, 59108, None)
1457 [main] INFO org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.1.4, 59108, None)
1457 [main] INFO org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.1.4, 59108, None)
1576 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4f8b4bd0
1576 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@4e904fd5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@b18c4,MANAGED}
1576 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@b18c4 added {org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53@bca5a86f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
1576 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@b18c4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53,POJO}
1577 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1, org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667, o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,null,@Spark},UNMANAGED}
1577 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1,[o.s.j.s.ServletContextHandler@3deb2326{/,null,AVAILABLE,@Spark}]}]
1577 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f,[o.s.j.s.ServletContextHandler@4eeea57d{/storage/rdd,null,AVAILABLE,@Spark}]}]
1577 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088,[o.s.j.s.ServletContextHandler@69f63d95{/storage,null,AVAILABLE,@Spark}]}]
1577 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a,[o.s.j.s.ServletContextHandler@548e76f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1577 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3,[o.s.j.s.ServletContextHandler@127e70c5{/api,null,AVAILABLE,@Spark}]}]
1577 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb,[o.s.j.s.ServletContextHandler@3591009c{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1577 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93,[o.s.j.s.ServletContextHandler@7a11c4c7{/stages/pool,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5,[o.s.j.s.ServletContextHandler@379ab47b{/jobs/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328,[o.s.j.s.ServletContextHandler@245a26e1{/static,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9,[o.s.j.s.ServletContextHandler@24a1c17f{/executors/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641,[o.s.j.s.ServletContextHandler@5fe8b721{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb,[o.s.j.s.ServletContextHandler@514eedd8{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c,[o.s.j.s.ServletContextHandler@6bc248ed{/environment/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4,[o.s.j.s.ServletContextHandler@61d9efe0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232,[o.s.j.s.ServletContextHandler@48c40605{/jobs,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c,[o.s.j.s.ServletContextHandler@2e77b8cf{/stages/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b,[o.s.j.s.ServletContextHandler@2755d705{/stages/stage,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a,[o.s.j.s.ServletContextHandler@6db66836{/storage/json,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667,[o.s.j.s.ServletContextHandler@2f66e802{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400,[o.s.j.s.ServletContextHandler@7a56812e{/jobs/job,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d,[o.s.j.s.ServletContextHandler@59a67c3a{/environment,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d,[o.s.j.s.ServletContextHandler@3ec11999{/stages,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12,[o.s.j.s.ServletContextHandler@1095f122{/executors,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6,[o.s.j.s.ServletContextHandler@1a6f2363{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - metrics/json->[{o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,null,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34,[o.s.j.s.ServletContextHandler@410954b{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1578 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,null,@Spark}
1578 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,STARTING,@Spark}
1578 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@b18c4
1578 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53 from default=false
1578 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1578 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1578 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1578 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53@bca5a86f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1579 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53=org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53@bca5a86f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1579 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@b18c4
1579 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2269ms org.spark_project.jetty.servlet.ServletHandler@b18c4
1579 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53@bca5a86f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1579 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2269ms org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53@bca5a86f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1579 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@9d1a267 for org.apache.spark.ui.JettyUtils$$anon$3-4cbf4f53
1579 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,AVAILABLE,@Spark}
1579 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2269ms o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,AVAILABLE,@Spark}
1590 [main] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
1595 [main] DEBUG org.apache.spark.SparkContext  - Adding shutdown hook
name: uci/                 | size:      0 | compressed size:      0
name: uci/test/            | size:      0 | compressed size:      0
name: uci/test/features/   | size:      0 | compressed size:      0
name: uci/test/features/0.csv | size:    475 | compressed size:    239
name: uci/test/features/1.csv | size:    468 | compressed size:    224
name: uci/test/features/10.csv | size:    474 | compressed size:    225
name: uci/test/features/100.csv | size:    472 | compressed size:    230
name: uci/test/features/101.csv | size:    471 | compressed size:    226
name: uci/test/features/102.csv | size:    473 | compressed size:    231
name: uci/test/features/103.csv | size:    474 | compressed size:    224
name: uci/test/features/104.csv | size:    470 | compressed size:    225
name: uci/test/features/105.csv | size:    475 | compressed size:    229
name: uci/test/features/106.csv | size:    473 | compressed size:    236
name: uci/test/features/107.csv | size:    466 | compressed size:    222
name: uci/test/features/108.csv | size:    470 | compressed size:    234
name: uci/test/features/109.csv | size:    476 | compressed size:    234
name: uci/test/features/11.csv | size:    472 | compressed size:    222
name: uci/test/features/110.csv | size:    476 | compressed size:    229
name: uci/test/features/111.csv | size:    472 | compressed size:    227
name: uci/test/features/112.csv | size:    469 | compressed size:    233
name: uci/test/features/113.csv | size:    474 | compressed size:    228
name: uci/test/features/114.csv | size:    472 | compressed size:    224
name: uci/test/features/115.csv | size:    475 | compressed size:    230
name: uci/test/features/116.csv | size:    470 | compressed size:    237
name: uci/test/features/117.csv | size:    473 | compressed size:    227
name: uci/test/features/118.csv | size:    470 | compressed size:    223
name: uci/test/features/119.csv | size:    469 | compressed size:    236
name: uci/test/features/12.csv | size:    471 | compressed size:    228
name: uci/test/features/120.csv | size:    472 | compressed size:    236
name: uci/test/features/121.csv | size:    475 | compressed size:    224
name: uci/test/features/122.csv | size:    471 | compressed size:    237
name: uci/test/features/123.csv | size:    475 | compressed size:    233
name: uci/test/features/124.csv | size:    473 | compressed size:    242
name: uci/test/features/125.csv | size:    466 | compressed size:    216
name: uci/test/features/126.csv | size:    471 | compressed size:    220
name: uci/test/features/127.csv | size:    473 | compressed size:    227
name: uci/test/features/128.csv | size:    471 | compressed size:    225
name: uci/test/features/129.csv | size:    472 | compressed size:    240
name: uci/test/features/13.csv | size:    473 | compressed size:    231
name: uci/test/features/130.csv | size:    473 | compressed size:    228
name: uci/test/features/131.csv | size:    474 | compressed size:    224
name: uci/test/features/132.csv | size:    471 | compressed size:    236
name: uci/test/features/133.csv | size:    473 | compressed size:    232
name: uci/test/features/134.csv | size:    469 | compressed size:    227
name: uci/test/features/135.csv | size:    472 | compressed size:    231
name: uci/test/features/136.csv | size:    470 | compressed size:    220
name: uci/test/features/137.csv | size:    482 | compressed size:    243
name: uci/test/features/138.csv | size:    471 | compressed size:    225
name: uci/test/features/139.csv | size:    475 | compressed size:    227
name: uci/test/features/14.csv | size:    475 | compressed size:    227
name: uci/test/features/140.csv | size:    475 | compressed size:    243
name: uci/test/features/141.csv | size:    472 | compressed size:    224
name: uci/test/features/142.csv | size:    468 | compressed size:    226
name: uci/test/features/143.csv | size:    471 | compressed size:    227
name: uci/test/features/144.csv | size:    471 | compressed size:    229
name: uci/test/features/145.csv | size:    473 | compressed size:    232
name: uci/test/features/146.csv | size:    470 | compressed size:    237
name: uci/test/features/147.csv | size:    470 | compressed size:    220
name: uci/test/features/148.csv | size:    472 | compressed size:    234
name: uci/test/features/149.csv | size:    475 | compressed size:    231
name: uci/test/features/15.csv | size:    473 | compressed size:    224
name: uci/test/features/16.csv | size:    474 | compressed size:    237
name: uci/test/features/17.csv | size:    472 | compressed size:    230
name: uci/test/features/18.csv | size:    475 | compressed size:    233
name: uci/test/features/19.csv | size:    472 | compressed size:    231
name: uci/test/features/2.csv | size:    473 | compressed size:    233
name: uci/test/features/20.csv | size:    472 | compressed size:    229
name: uci/test/features/21.csv | size:    474 | compressed size:    228
name: uci/test/features/22.csv | size:    469 | compressed size:    231
name: uci/test/features/23.csv | size:    472 | compressed size:    234
name: uci/test/features/24.csv | size:    469 | compressed size:    229
name: uci/test/features/25.csv | size:    474 | compressed size:    240
name: uci/test/features/26.csv | size:    469 | compressed size:    232
name: uci/test/features/27.csv | size:    474 | compressed size:    238
name: uci/test/features/28.csv | size:    475 | compressed size:    228
name: uci/test/features/29.csv | size:    478 | compressed size:    238
name: uci/test/features/3.csv | size:    476 | compressed size:    227
name: uci/test/features/30.csv | size:    468 | compressed size:    233
name: uci/test/features/31.csv | size:    471 | compressed size:    239
name: uci/test/features/32.csv | size:    470 | compressed size:    229
name: uci/test/features/33.csv | size:    473 | compressed size:    237
name: uci/test/features/34.csv | size:    468 | compressed size:    221
name: uci/test/features/35.csv | size:    473 | compressed size:    224
name: uci/test/features/36.csv | size:    476 | compressed size:    234
name: uci/test/features/37.csv | size:    462 | compressed size:    226
name: uci/test/features/38.csv | size:    470 | compressed size:    233
name: uci/test/features/39.csv | size:    469 | compressed size:    219
name: uci/test/features/4.csv | size:    477 | compressed size:    234
name: uci/test/features/40.csv | size:    473 | compressed size:    236
name: uci/test/features/41.csv | size:    474 | compressed size:    239
name: uci/test/features/42.csv | size:    470 | compressed size:    233
name: uci/test/features/43.csv | size:    471 | compressed size:    234
name: uci/test/features/44.csv | size:    476 | compressed size:    233
name: uci/test/features/45.csv | size:    471 | compressed size:    226
name: uci/test/features/46.csv | size:    472 | compressed size:    231
name: uci/test/features/47.csv | size:    468 | compressed size:    228
name: uci/test/features/48.csv | size:    474 | compressed size:    228
name: uci/test/features/49.csv | size:    478 | compressed size:    238
name: uci/test/features/5.csv | size:    475 | compressed size:    232
name: uci/test/features/50.csv | size:    469 | compressed size:    232
name: uci/test/features/51.csv | size:    472 | compressed size:    226
name: uci/test/features/52.csv | size:    475 | compressed size:    229
name: uci/test/features/53.csv | size:    474 | compressed size:    232
name: uci/test/features/54.csv | size:    471 | compressed size:    236
name: uci/test/features/55.csv | size:    471 | compressed size:    242
name: uci/test/features/56.csv | size:    475 | compressed size:    231
name: uci/test/features/57.csv | size:    468 | compressed size:    225
name: uci/test/features/58.csv | size:    471 | compressed size:    235
name: uci/test/features/59.csv | size:    474 | compressed size:    233
name: uci/test/features/6.csv | size:    473 | compressed size:    232
name: uci/test/features/60.csv | size:    473 | compressed size:    223
name: uci/test/features/61.csv | size:    471 | compressed size:    230
name: uci/test/features/62.csv | size:    473 | compressed size:    220
name: uci/test/features/63.csv | size:    476 | compressed size:    224
name: uci/test/features/64.csv | size:    470 | compressed size:    230
name: uci/test/features/65.csv | size:    473 | compressed size:    231
name: uci/test/features/66.csv | size:    471 | compressed size:    228
name: uci/test/features/67.csv | size:    477 | compressed size:    234
name: uci/test/features/68.csv | size:    469 | compressed size:    230
name: uci/test/features/69.csv | size:    468 | compressed size:    219
name: uci/test/features/7.csv | size:    468 | compressed size:    237
name: uci/test/features/70.csv | size:    470 | compressed size:    221
name: uci/test/features/71.csv | size:    471 | compressed size:    224
name: uci/test/features/72.csv | size:    471 | compressed size:    228
name: uci/test/features/73.csv | size:    465 | compressed size:    231
name: uci/test/features/74.csv | size:    471 | compressed size:    221
name: uci/test/features/75.csv | size:    469 | compressed size:    234
name: uci/test/features/76.csv | size:    473 | compressed size:    234
name: uci/test/features/77.csv | size:    472 | compressed size:    232
name: uci/test/features/78.csv | size:    472 | compressed size:    226
name: uci/test/features/79.csv | size:    470 | compressed size:    227
name: uci/test/features/8.csv | size:    470 | compressed size:    226
name: uci/test/features/80.csv | size:    471 | compressed size:    228
name: uci/test/features/81.csv | size:    476 | compressed size:    238
name: uci/test/features/82.csv | size:    475 | compressed size:    234
name: uci/test/features/83.csv | size:    470 | compressed size:    222
name: uci/test/features/84.csv | size:    474 | compressed size:    230
name: uci/test/features/85.csv | size:    477 | compressed size:    241
name: uci/test/features/86.csv | size:    476 | compressed size:    232
name: uci/test/features/87.csv | size:    467 | compressed size:    228
name: uci/test/features/88.csv | size:    473 | compressed size:    230
name: uci/test/features/89.csv | size:    465 | compressed size:    227
name: uci/test/features/9.csv | size:    474 | compressed size:    224
name: uci/test/features/90.csv | size:    472 | compressed size:    230
name: uci/test/features/91.csv | size:    472 | compressed size:    235
name: uci/test/features/92.csv | size:    474 | compressed size:    241
name: uci/test/features/93.csv | size:    474 | compressed size:    233
name: uci/test/features/94.csv | size:    473 | compressed size:    232
name: uci/test/features/95.csv | size:    474 | compressed size:    231
name: uci/test/features/96.csv | size:    472 | compressed size:    231
name: uci/test/features/97.csv | size:    475 | compressed size:    229
name: uci/test/features/98.csv | size:    468 | compressed size:    236
name: uci/test/features/99.csv | size:    471 | compressed size:    231
name: uci/test/labels/     | size:      0 | compressed size:      0
name: uci/test/labels/0.csv | size:      1 | compressed size:      1
name: uci/test/labels/1.csv | size:      1 | compressed size:      1
name: uci/test/labels/10.csv | size:      1 | compressed size:      1
name: uci/test/labels/100.csv | size:      1 | compressed size:      1
name: uci/test/labels/101.csv | size:      1 | compressed size:      1
name: uci/test/labels/102.csv | size:      1 | compressed size:      1
name: uci/test/labels/103.csv | size:      1 | compressed size:      1
name: uci/test/labels/104.csv | size:      1 | compressed size:      1
name: uci/test/labels/105.csv | size:      1 | compressed size:      1
name: uci/test/labels/106.csv | size:      1 | compressed size:      1
name: uci/test/labels/107.csv | size:      1 | compressed size:      1
name: uci/test/labels/108.csv | size:      1 | compressed size:      1
name: uci/test/labels/109.csv | size:      1 | compressed size:      1
name: uci/test/labels/11.csv | size:      1 | compressed size:      1
name: uci/test/labels/110.csv | size:      1 | compressed size:      1
name: uci/test/labels/111.csv | size:      1 | compressed size:      1
name: uci/test/labels/112.csv | size:      1 | compressed size:      1
name: uci/test/labels/113.csv | size:      1 | compressed size:      1
name: uci/test/labels/114.csv | size:      1 | compressed size:      1
name: uci/test/labels/115.csv | size:      1 | compressed size:      1
name: uci/test/labels/116.csv | size:      1 | compressed size:      1
name: uci/test/labels/117.csv | size:      1 | compressed size:      1
name: uci/test/labels/118.csv | size:      1 | compressed size:      1
name: uci/test/labels/119.csv | size:      1 | compressed size:      1
name: uci/test/labels/12.csv | size:      1 | compressed size:      1
name: uci/test/labels/120.csv | size:      1 | compressed size:      1
name: uci/test/labels/121.csv | size:      1 | compressed size:      1
name: uci/test/labels/122.csv | size:      1 | compressed size:      1
name: uci/test/labels/123.csv | size:      1 | compressed size:      1
name: uci/test/labels/124.csv | size:      1 | compressed size:      1
name: uci/test/labels/125.csv | size:      1 | compressed size:      1
name: uci/test/labels/126.csv | size:      1 | compressed size:      1
name: uci/test/labels/127.csv | size:      1 | compressed size:      1
name: uci/test/labels/128.csv | size:      1 | compressed size:      1
name: uci/test/labels/129.csv | size:      1 | compressed size:      1
name: uci/test/labels/13.csv | size:      1 | compressed size:      1
name: uci/test/labels/130.csv | size:      1 | compressed size:      1
name: uci/test/labels/131.csv | size:      1 | compressed size:      1
name: uci/test/labels/132.csv | size:      1 | compressed size:      1
name: uci/test/labels/133.csv | size:      1 | compressed size:      1
name: uci/test/labels/134.csv | size:      1 | compressed size:      1
name: uci/test/labels/135.csv | size:      1 | compressed size:      1
name: uci/test/labels/136.csv | size:      1 | compressed size:      1
name: uci/test/labels/137.csv | size:      1 | compressed size:      1
name: uci/test/labels/138.csv | size:      1 | compressed size:      1
name: uci/test/labels/139.csv | size:      1 | compressed size:      1
name: uci/test/labels/14.csv | size:      1 | compressed size:      1
name: uci/test/labels/140.csv | size:      1 | compressed size:      1
name: uci/test/labels/141.csv | size:      1 | compressed size:      1
name: uci/test/labels/142.csv | size:      1 | compressed size:      1
name: uci/test/labels/143.csv | size:      1 | compressed size:      1
name: uci/test/labels/144.csv | size:      1 | compressed size:      1
name: uci/test/labels/145.csv | size:      1 | compressed size:      1
name: uci/test/labels/146.csv | size:      1 | compressed size:      1
name: uci/test/labels/147.csv | size:      1 | compressed size:      1
name: uci/test/labels/148.csv | size:      1 | compressed size:      1
name: uci/test/labels/149.csv | size:      1 | compressed size:      1
name: uci/test/labels/15.csv | size:      1 | compressed size:      1
name: uci/test/labels/16.csv | size:      1 | compressed size:      1
name: uci/test/labels/17.csv | size:      1 | compressed size:      1
name: uci/test/labels/18.csv | size:      1 | compressed size:      1
name: uci/test/labels/19.csv | size:      1 | compressed size:      1
name: uci/test/labels/2.csv | size:      1 | compressed size:      1
name: uci/test/labels/20.csv | size:      1 | compressed size:      1
name: uci/test/labels/21.csv | size:      1 | compressed size:      1
name: uci/test/labels/22.csv | size:      1 | compressed size:      1
name: uci/test/labels/23.csv | size:      1 | compressed size:      1
name: uci/test/labels/24.csv | size:      1 | compressed size:      1
name: uci/test/labels/25.csv | size:      1 | compressed size:      1
name: uci/test/labels/26.csv | size:      1 | compressed size:      1
name: uci/test/labels/27.csv | size:      1 | compressed size:      1
name: uci/test/labels/28.csv | size:      1 | compressed size:      1
name: uci/test/labels/29.csv | size:      1 | compressed size:      1
name: uci/test/labels/3.csv | size:      1 | compressed size:      1
name: uci/test/labels/30.csv | size:      1 | compressed size:      1
name: uci/test/labels/31.csv | size:      1 | compressed size:      1
name: uci/test/labels/32.csv | size:      1 | compressed size:      1
name: uci/test/labels/33.csv | size:      1 | compressed size:      1
name: uci/test/labels/34.csv | size:      1 | compressed size:      1
name: uci/test/labels/35.csv | size:      1 | compressed size:      1
name: uci/test/labels/36.csv | size:      1 | compressed size:      1
name: uci/test/labels/37.csv | size:      1 | compressed size:      1
name: uci/test/labels/38.csv | size:      1 | compressed size:      1
name: uci/test/labels/39.csv | size:      1 | compressed size:      1
name: uci/test/labels/4.csv | size:      1 | compressed size:      1
name: uci/test/labels/40.csv | size:      1 | compressed size:      1
name: uci/test/labels/41.csv | size:      1 | compressed size:      1
name: uci/test/labels/42.csv | size:      1 | compressed size:      1
name: uci/test/labels/43.csv | size:      1 | compressed size:      1
name: uci/test/labels/44.csv | size:      1 | compressed size:      1
name: uci/test/labels/45.csv | size:      1 | compressed size:      1
name: uci/test/labels/46.csv | size:      1 | compressed size:      1
name: uci/test/labels/47.csv | size:      1 | compressed size:      1
name: uci/test/labels/48.csv | size:      1 | compressed size:      1
name: uci/test/labels/49.csv | size:      1 | compressed size:      1
name: uci/test/labels/5.csv | size:      1 | compressed size:      1
name: uci/test/labels/50.csv | size:      1 | compressed size:      1
name: uci/test/labels/51.csv | size:      1 | compressed size:      1
name: uci/test/labels/52.csv | size:      1 | compressed size:      1
name: uci/test/labels/53.csv | size:      1 | compressed size:      1
name: uci/test/labels/54.csv | size:      1 | compressed size:      1
name: uci/test/labels/55.csv | size:      1 | compressed size:      1
name: uci/test/labels/56.csv | size:      1 | compressed size:      1
name: uci/test/labels/57.csv | size:      1 | compressed size:      1
name: uci/test/labels/58.csv | size:      1 | compressed size:      1
name: uci/test/labels/59.csv | size:      1 | compressed size:      1
name: uci/test/labels/6.csv | size:      1 | compressed size:      1
name: uci/test/labels/60.csv | size:      1 | compressed size:      1
name: uci/test/labels/61.csv | size:      1 | compressed size:      1
name: uci/test/labels/62.csv | size:      1 | compressed size:      1
name: uci/test/labels/63.csv | size:      1 | compressed size:      1
name: uci/test/labels/64.csv | size:      1 | compressed size:      1
name: uci/test/labels/65.csv | size:      1 | compressed size:      1
name: uci/test/labels/66.csv | size:      1 | compressed size:      1
name: uci/test/labels/67.csv | size:      1 | compressed size:      1
name: uci/test/labels/68.csv | size:      1 | compressed size:      1
name: uci/test/labels/69.csv | size:      1 | compressed size:      1
name: uci/test/labels/7.csv | size:      1 | compressed size:      1
name: uci/test/labels/70.csv | size:      1 | compressed size:      1
name: uci/test/labels/71.csv | size:      1 | compressed size:      1
name: uci/test/labels/72.csv | size:      1 | compressed size:      1
name: uci/test/labels/73.csv | size:      1 | compressed size:      1
name: uci/test/labels/74.csv | size:      1 | compressed size:      1
name: uci/test/labels/75.csv | size:      1 | compressed size:      1
name: uci/test/labels/76.csv | size:      1 | compressed size:      1
name: uci/test/labels/77.csv | size:      1 | compressed size:      1
name: uci/test/labels/78.csv | size:      1 | compressed size:      1
name: uci/test/labels/79.csv | size:      1 | compressed size:      1
name: uci/test/labels/8.csv | size:      1 | compressed size:      1
name: uci/test/labels/80.csv | size:      1 | compressed size:      1
name: uci/test/labels/81.csv | size:      1 | compressed size:      1
name: uci/test/labels/82.csv | size:      1 | compressed size:      1
name: uci/test/labels/83.csv | size:      1 | compressed size:      1
name: uci/test/labels/84.csv | size:      1 | compressed size:      1
name: uci/test/labels/85.csv | size:      1 | compressed size:      1
name: uci/test/labels/86.csv | size:      1 | compressed size:      1
name: uci/test/labels/87.csv | size:      1 | compressed size:      1
name: uci/test/labels/88.csv | size:      1 | compressed size:      1
name: uci/test/labels/89.csv | size:      1 | compressed size:      1
name: uci/test/labels/9.csv | size:      1 | compressed size:      1
name: uci/test/labels/90.csv | size:      1 | compressed size:      1
name: uci/test/labels/91.csv | size:      1 | compressed size:      1
name: uci/test/labels/92.csv | size:      1 | compressed size:      1
name: uci/test/labels/93.csv | size:      1 | compressed size:      1
name: uci/test/labels/94.csv | size:      1 | compressed size:      1
name: uci/test/labels/95.csv | size:      1 | compressed size:      1
name: uci/test/labels/96.csv | size:      1 | compressed size:      1
name: uci/test/labels/97.csv | size:      1 | compressed size:      1
name: uci/test/labels/98.csv | size:      1 | compressed size:      1
name: uci/test/labels/99.csv | size:      1 | compressed size:      1
name: uci/train/           | size:      0 | compressed size:      0
name: uci/train/features/  | size:      0 | compressed size:      0
name: uci/train/features/0.csv | size:    473 | compressed size:    227
name: uci/train/features/1.csv | size:    468 | compressed size:    224
name: uci/train/features/10.csv | size:    472 | compressed size:    226
name: uci/train/features/100.csv | size:    468 | compressed size:    228
name: uci/train/features/101.csv | size:    474 | compressed size:    227
name: uci/train/features/102.csv | size:    471 | compressed size:    231
name: uci/train/features/103.csv | size:    474 | compressed size:    229
name: uci/train/features/104.csv | size:    470 | compressed size:    229
name: uci/train/features/105.csv | size:    473 | compressed size:    234
name: uci/train/features/106.csv | size:    476 | compressed size:    226
name: uci/train/features/107.csv | size:    474 | compressed size:    242
name: uci/train/features/108.csv | size:    477 | compressed size:    236
name: uci/train/features/109.csv | size:    471 | compressed size:    236
name: uci/train/features/11.csv | size:    466 | compressed size:    220
name: uci/train/features/110.csv | size:    477 | compressed size:    233
name: uci/train/features/111.csv | size:    472 | compressed size:    227
name: uci/train/features/112.csv | size:    473 | compressed size:    228
name: uci/train/features/113.csv | size:    466 | compressed size:    217
name: uci/train/features/114.csv | size:    474 | compressed size:    230
name: uci/train/features/115.csv | size:    469 | compressed size:    226
name: uci/train/features/116.csv | size:    474 | compressed size:    234
name: uci/train/features/117.csv | size:    468 | compressed size:    229
name: uci/train/features/118.csv | size:    474 | compressed size:    225
name: uci/train/features/119.csv | size:    469 | compressed size:    226
name: uci/train/features/12.csv | size:    472 | compressed size:    230
name: uci/train/features/120.csv | size:    474 | compressed size:    235
name: uci/train/features/121.csv | size:    472 | compressed size:    228
name: uci/train/features/122.csv | size:    470 | compressed size:    219
name: uci/train/features/123.csv | size:    469 | compressed size:    226
name: uci/train/features/124.csv | size:    476 | compressed size:    227
name: uci/train/features/125.csv | size:    476 | compressed size:    233
name: uci/train/features/126.csv | size:    472 | compressed size:    233
name: uci/train/features/127.csv | size:    474 | compressed size:    229
name: uci/train/features/128.csv | size:    471 | compressed size:    226
name: uci/train/features/129.csv | size:    477 | compressed size:    222
name: uci/train/features/13.csv | size:    473 | compressed size:    222
name: uci/train/features/130.csv | size:    470 | compressed size:    225
name: uci/train/features/131.csv | size:    470 | compressed size:    227
name: uci/train/features/132.csv | size:    472 | compressed size:    229
name: uci/train/features/133.csv | size:    477 | compressed size:    229
name: uci/train/features/134.csv | size:    474 | compressed size:    237
name: uci/train/features/135.csv | size:    474 | compressed size:    229
name: uci/train/features/136.csv | size:    476 | compressed size:    226
name: uci/train/features/137.csv | size:    474 | compressed size:    232
name: uci/train/features/138.csv | size:    472 | compressed size:    222
name: uci/train/features/139.csv | size:    475 | compressed size:    230
name: uci/train/features/14.csv | size:    468 | compressed size:    231
name: uci/train/features/140.csv | size:    469 | compressed size:    232
name: uci/train/features/141.csv | size:    476 | compressed size:    233
name: uci/train/features/142.csv | size:    469 | compressed size:    232
name: uci/train/features/143.csv | size:    477 | compressed size:    234
name: uci/train/features/144.csv | size:    474 | compressed size:    233
name: uci/train/features/145.csv | size:    475 | compressed size:    239
name: uci/train/features/146.csv | size:    470 | compressed size:    230
name: uci/train/features/147.csv | size:    475 | compressed size:    235
name: uci/train/features/148.csv | size:    473 | compressed size:    233
name: uci/train/features/149.csv | size:    475 | compressed size:    233
name: uci/train/features/15.csv | size:    469 | compressed size:    225
name: uci/train/features/150.csv | size:    474 | compressed size:    229
name: uci/train/features/151.csv | size:    473 | compressed size:    229
name: uci/train/features/152.csv | size:    468 | compressed size:    238
name: uci/train/features/153.csv | size:    467 | compressed size:    236
name: uci/train/features/154.csv | size:    472 | compressed size:    227
name: uci/train/features/155.csv | size:    473 | compressed size:    227
name: uci/train/features/156.csv | size:    477 | compressed size:    243
name: uci/train/features/157.csv | size:    473 | compressed size:    224
name: uci/train/features/158.csv | size:    477 | compressed size:    240
name: uci/train/features/159.csv | size:    475 | compressed size:    235
name: uci/train/features/16.csv | size:    481 | compressed size:    242
name: uci/train/features/160.csv | size:    473 | compressed size:    241
name: uci/train/features/161.csv | size:    472 | compressed size:    228
name: uci/train/features/162.csv | size:    474 | compressed size:    224
name: uci/train/features/163.csv | size:    474 | compressed size:    228
name: uci/train/features/164.csv | size:    477 | compressed size:    236
name: uci/train/features/165.csv | size:    473 | compressed size:    230
name: uci/train/features/166.csv | size:    471 | compressed size:    231
name: uci/train/features/167.csv | size:    470 | compressed size:    226
name: uci/train/features/168.csv | size:    474 | compressed size:    232
name: uci/train/features/169.csv | size:    472 | compressed size:    235
name: uci/train/features/17.csv | size:    480 | compressed size:    241
name: uci/train/features/170.csv | size:    473 | compressed size:    228
name: uci/train/features/171.csv | size:    465 | compressed size:    222
name: uci/train/features/172.csv | size:    471 | compressed size:    225
name: uci/train/features/173.csv | size:    469 | compressed size:    228
name: uci/train/features/174.csv | size:    473 | compressed size:    224
name: uci/train/features/175.csv | size:    472 | compressed size:    225
name: uci/train/features/176.csv | size:    473 | compressed size:    234
name: uci/train/features/177.csv | size:    470 | compressed size:    229
name: uci/train/features/178.csv | size:    471 | compressed size:    222
name: uci/train/features/179.csv | size:    469 | compressed size:    226
name: uci/train/features/18.csv | size:    473 | compressed size:    223
name: uci/train/features/180.csv | size:    470 | compressed size:    226
name: uci/train/features/181.csv | size:    474 | compressed size:    233
name: uci/train/features/182.csv | size:    473 | compressed size:    230
name: uci/train/features/183.csv | size:    470 | compressed size:    233
name: uci/train/features/184.csv | size:    471 | compressed size:    227
name: uci/train/features/185.csv | size:    475 | compressed size:    231
name: uci/train/features/186.csv | size:    472 | compressed size:    237
name: uci/train/features/187.csv | size:    470 | compressed size:    231
name: uci/train/features/188.csv | size:    473 | compressed size:    221
name: uci/train/features/189.csv | size:    471 | compressed size:    230
name: uci/train/features/19.csv | size:    476 | compressed size:    243
name: uci/train/features/190.csv | size:    468 | compressed size:    222
name: uci/train/features/191.csv | size:    473 | compressed size:    222
name: uci/train/features/192.csv | size:    476 | compressed size:    232
name: uci/train/features/193.csv | size:    471 | compressed size:    229
name: uci/train/features/194.csv | size:    475 | compressed size:    237
name: uci/train/features/195.csv | size:    471 | compressed size:    230
name: uci/train/features/196.csv | size:    471 | compressed size:    237
name: uci/train/features/197.csv | size:    469 | compressed size:    222
name: uci/train/features/198.csv | size:    471 | compressed size:    233
name: uci/train/features/199.csv | size:    470 | compressed size:    227
name: uci/train/features/2.csv | size:    471 | compressed size:    241
name: uci/train/features/20.csv | size:    476 | compressed size:    227
name: uci/train/features/200.csv | size:    472 | compressed size:    229
name: uci/train/features/201.csv | size:    474 | compressed size:    223
name: uci/train/features/202.csv | size:    478 | compressed size:    233
name: uci/train/features/203.csv | size:    472 | compressed size:    227
name: uci/train/features/204.csv | size:    473 | compressed size:    235
name: uci/train/features/205.csv | size:    472 | compressed size:    238
name: uci/train/features/206.csv | size:    470 | compressed size:    218
name: uci/train/features/207.csv | size:    472 | compressed size:    222
name: uci/train/features/208.csv | size:    467 | compressed size:    232
name: uci/train/features/209.csv | size:    471 | compressed size:    226
name: uci/train/features/21.csv | size:    470 | compressed size:    233
name: uci/train/features/210.csv | size:    472 | compressed size:    237
name: uci/train/features/211.csv | size:    474 | compressed size:    233
name: uci/train/features/212.csv | size:    472 | compressed size:    230
name: uci/train/features/213.csv | size:    473 | compressed size:    230
name: uci/train/features/214.csv | size:    474 | compressed size:    233
name: uci/train/features/215.csv | size:    471 | compressed size:    237
name: uci/train/features/216.csv | size:    471 | compressed size:    230
name: uci/train/features/217.csv | size:    471 | compressed size:    230
name: uci/train/features/218.csv | size:    470 | compressed size:    230
name: uci/train/features/219.csv | size:    476 | compressed size:    224
name: uci/train/features/22.csv | size:    473 | compressed size:    233
name: uci/train/features/220.csv | size:    472 | compressed size:    226
name: uci/train/features/221.csv | size:    474 | compressed size:    234
name: uci/train/features/222.csv | size:    472 | compressed size:    217
name: uci/train/features/223.csv | size:    473 | compressed size:    225
name: uci/train/features/224.csv | size:    474 | compressed size:    242
name: uci/train/features/225.csv | size:    474 | compressed size:    229
name: uci/train/features/226.csv | size:    472 | compressed size:    226
name: uci/train/features/227.csv | size:    473 | compressed size:    236
name: uci/train/features/228.csv | size:    471 | compressed size:    238
name: uci/train/features/229.csv | size:    482 | compressed size:    241
name: uci/train/features/23.csv | size:    474 | compressed size:    224
name: uci/train/features/230.csv | size:    476 | compressed size:    234
name: uci/train/features/231.csv | size:    476 | compressed size:    232
name: uci/train/features/232.csv | size:    473 | compressed size:    218
name: uci/train/features/233.csv | size:    474 | compressed size:    221
name: uci/train/features/234.csv | size:    473 | compressed size:    240
name: uci/train/features/235.csv | size:    478 | compressed size:    225
name: uci/train/features/236.csv | size:    477 | compressed size:    235
name: uci/train/features/237.csv | size:    471 | compressed size:    230
name: uci/train/features/238.csv | size:    466 | compressed size:    229
name: uci/train/features/239.csv | size:    474 | compressed size:    234
name: uci/train/features/24.csv | size:    477 | compressed size:    241
name: uci/train/features/240.csv | size:    473 | compressed size:    226
name: uci/train/features/241.csv | size:    471 | compressed size:    224
name: uci/train/features/242.csv | size:    473 | compressed size:    224
name: uci/train/features/243.csv | size:    471 | compressed size:    225
name: uci/train/features/244.csv | size:    475 | compressed size:    226
name: uci/train/features/245.csv | size:    471 | compressed size:    226
name: uci/train/features/246.csv | size:    475 | compressed size:    233
name: uci/train/features/247.csv | size:    472 | compressed size:    238
name: uci/train/features/248.csv | size:    470 | compressed size:    219
name: uci/train/features/249.csv | size:    474 | compressed size:    235
name: uci/train/features/25.csv | size:    471 | compressed size:    233
name: uci/train/features/250.csv | size:    473 | compressed size:    231
name: uci/train/features/251.csv | size:    472 | compressed size:    229
name: uci/train/features/252.csv | size:    470 | compressed size:    228
name: uci/train/features/253.csv | size:    476 | compressed size:    237
name: uci/train/features/254.csv | size:    472 | compressed size:    229
name: uci/train/features/255.csv | size:    473 | compressed size:    235
name: uci/train/features/256.csv | size:    477 | compressed size:    241
name: uci/train/features/257.csv | size:    467 | compressed size:    224
name: uci/train/features/258.csv | size:    466 | compressed size:    224
name: uci/train/features/259.csv | size:    474 | compressed size:    226
name: uci/train/features/26.csv | size:    473 | compressed size:    239
name: uci/train/features/260.csv | size:    477 | compressed size:    231
name: uci/train/features/261.csv | size:    480 | compressed size:    240
name: uci/train/features/262.csv | size:    475 | compressed size:    235
name: uci/train/features/263.csv | size:    475 | compressed size:    235
name: uci/train/features/264.csv | size:    471 | compressed size:    236
name: uci/train/features/265.csv | size:    467 | compressed size:    225
name: uci/train/features/266.csv | size:    472 | compressed size:    231
name: uci/train/features/267.csv | size:    470 | compressed size:    227
name: uci/train/features/268.csv | size:    463 | compressed size:    220
name: uci/train/features/269.csv | size:    473 | compressed size:    223
name: uci/train/features/27.csv | size:    470 | compressed size:    225
name: uci/train/features/270.csv | size:    475 | compressed size:    224
name: uci/train/features/271.csv | size:    477 | compressed size:    243
name: uci/train/features/272.csv | size:    473 | compressed size:    229
name: uci/train/features/273.csv | size:    475 | compressed size:    239
name: uci/train/features/274.csv | size:    471 | compressed size:    229
name: uci/train/features/275.csv | size:    478 | compressed size:    237
name: uci/train/features/276.csv | size:    469 | compressed size:    229
name: uci/train/features/277.csv | size:    470 | compressed size:    227
name: uci/train/features/278.csv | size:    474 | compressed size:    231
name: uci/train/features/279.csv | size:    476 | compressed size:    232
name: uci/train/features/28.csv | size:    476 | compressed size:    229
name: uci/train/features/280.csv | size:    473 | compressed size:    230
name: uci/train/features/281.csv | size:    476 | compressed size:    230
name: uci/train/features/282.csv | size:    472 | compressed size:    218
name: uci/train/features/283.csv | size:    467 | compressed size:    226
name: uci/train/features/284.csv | size:    471 | compressed size:    230
name: uci/train/features/285.csv | size:    469 | compressed size:    227
name: uci/train/features/286.csv | size:    471 | compressed size:    225
name: uci/train/features/287.csv | size:    471 | compressed size:    227
name: uci/train/features/288.csv | size:    477 | compressed size:    226
name: uci/train/features/289.csv | size:    477 | compressed size:    232
name: uci/train/features/29.csv | size:    475 | compressed size:    227
name: uci/train/features/290.csv | size:    469 | compressed size:    223
name: uci/train/features/291.csv | size:    473 | compressed size:    235
name: uci/train/features/292.csv | size:    473 | compressed size:    231
name: uci/train/features/293.csv | size:    469 | compressed size:    231
name: uci/train/features/294.csv | size:    470 | compressed size:    232
name: uci/train/features/295.csv | size:    471 | compressed size:    227
name: uci/train/features/296.csv | size:    473 | compressed size:    234
name: uci/train/features/297.csv | size:    472 | compressed size:    234
name: uci/train/features/298.csv | size:    475 | compressed size:    239
name: uci/train/features/299.csv | size:    473 | compressed size:    228
name: uci/train/features/3.csv | size:    467 | compressed size:    224
name: uci/train/features/30.csv | size:    475 | compressed size:    234
name: uci/train/features/300.csv | size:    472 | compressed size:    237
name: uci/train/features/301.csv | size:    472 | compressed size:    237
name: uci/train/features/302.csv | size:    472 | compressed size:    228
name: uci/train/features/303.csv | size:    470 | compressed size:    237
name: uci/train/features/304.csv | size:    476 | compressed size:    230
name: uci/train/features/305.csv | size:    476 | compressed size:    227
name: uci/train/features/306.csv | size:    476 | compressed size:    233
name: uci/train/features/307.csv | size:    473 | compressed size:    233
name: uci/train/features/308.csv | size:    470 | compressed size:    217
name: uci/train/features/309.csv | size:    468 | compressed size:    228
name: uci/train/features/31.csv | size:    468 | compressed size:    228
name: uci/train/features/310.csv | size:    477 | compressed size:    236
name: uci/train/features/311.csv | size:    469 | compressed size:    228
name: uci/train/features/312.csv | size:    470 | compressed size:    239
name: uci/train/features/313.csv | size:    471 | compressed size:    230
name: uci/train/features/314.csv | size:    472 | compressed size:    228
name: uci/train/features/315.csv | size:    470 | compressed size:    235
name: uci/train/features/316.csv | size:    477 | compressed size:    233
name: uci/train/features/317.csv | size:    473 | compressed size:    231
name: uci/train/features/318.csv | size:    477 | compressed size:    232
name: uci/train/features/319.csv | size:    474 | compressed size:    224
name: uci/train/features/32.csv | size:    474 | compressed size:    238
name: uci/train/features/320.csv | size:    472 | compressed size:    231
name: uci/train/features/321.csv | size:    466 | compressed size:    230
name: uci/train/features/322.csv | size:    475 | compressed size:    240
name: uci/train/features/323.csv | size:    473 | compressed size:    232
name: uci/train/features/324.csv | size:    471 | compressed size:    225
name: uci/train/features/325.csv | size:    472 | compressed size:    228
name: uci/train/features/326.csv | size:    472 | compressed size:    242
name: uci/train/features/327.csv | size:    472 | compressed size:    231
name: uci/train/features/328.csv | size:    474 | compressed size:    229
name: uci/train/features/329.csv | size:    473 | compressed size:    237
name: uci/train/features/33.csv | size:    473 | compressed size:    230
name: uci/train/features/330.csv | size:    476 | compressed size:    230
name: uci/train/features/331.csv | size:    472 | compressed size:    238
name: uci/train/features/332.csv | size:    471 | compressed size:    235
name: uci/train/features/333.csv | size:    475 | compressed size:    226
name: uci/train/features/334.csv | size:    476 | compressed size:    226
name: uci/train/features/335.csv | size:    467 | compressed size:    235
name: uci/train/features/336.csv | size:    473 | compressed size:    235
name: uci/train/features/337.csv | size:    472 | compressed size:    225
name: uci/train/features/338.csv | size:    476 | compressed size:    236
name: uci/train/features/339.csv | size:    476 | compressed size:    235
name: uci/train/features/34.csv | size:    472 | compressed size:    237
name: uci/train/features/340.csv | size:    472 | compressed size:    224
name: uci/train/features/341.csv | size:    475 | compressed size:    228
name: uci/train/features/342.csv | size:    477 | compressed size:    231
name: uci/train/features/343.csv | size:    472 | compressed size:    236
name: uci/train/features/344.csv | size:    468 | compressed size:    224
name: uci/train/features/345.csv | size:    466 | compressed size:    236
name: uci/train/features/346.csv | size:    471 | compressed size:    236
name: uci/train/features/347.csv | size:    471 | compressed size:    229
name: uci/train/features/348.csv | size:    472 | compressed size:    227
name: uci/train/features/349.csv | size:    471 | compressed size:    231
name: uci/train/features/35.csv | size:    469 | compressed size:    220
name: uci/train/features/350.csv | size:    475 | compressed size:    225
name: uci/train/features/351.csv | size:    469 | compressed size:    224
name: uci/train/features/352.csv | size:    473 | compressed size:    239
name: uci/train/features/353.csv | size:    475 | compressed size:    225
name: uci/train/features/354.csv | size:    473 | compressed size:    222
name: uci/train/features/355.csv | size:    467 | compressed size:    223
name: uci/train/features/356.csv | size:    472 | compressed size:    232
name: uci/train/features/357.csv | size:    474 | compressed size:    224
name: uci/train/features/358.csv | size:    475 | compressed size:    233
name: uci/train/features/359.csv | size:    472 | compressed size:    238
name: uci/train/features/36.csv | size:    476 | compressed size:    230
name: uci/train/features/360.csv | size:    469 | compressed size:    231
name: uci/train/features/361.csv | size:    468 | compressed size:    224
name: uci/train/features/362.csv | size:    470 | compressed size:    224
name: uci/train/features/363.csv | size:    477 | compressed size:    237
name: uci/train/features/364.csv | size:    472 | compressed size:    225
name: uci/train/features/365.csv | size:    467 | compressed size:    226
name: uci/train/features/366.csv | size:    472 | compressed size:    234
name: uci/train/features/367.csv | size:    473 | compressed size:    242
name: uci/train/features/368.csv | size:    469 | compressed size:    225
name: uci/train/features/369.csv | size:    471 | compressed size:    224
name: uci/train/features/37.csv | size:    474 | compressed size:    220
name: uci/train/features/370.csv | size:    473 | compressed size:    231
name: uci/train/features/371.csv | size:    469 | compressed size:    220
name: uci/train/features/372.csv | size:    469 | compressed size:    229
name: uci/train/features/373.csv | size:    476 | compressed size:    240
name: uci/train/features/374.csv | size:    472 | compressed size:    227
name: uci/train/features/375.csv | size:    470 | compressed size:    232
name: uci/train/features/376.csv | size:    471 | compressed size:    235
name: uci/train/features/377.csv | size:    476 | compressed size:    227
name: uci/train/features/378.csv | size:    472 | compressed size:    228
name: uci/train/features/379.csv | size:    467 | compressed size:    233
name: uci/train/features/38.csv | size:    473 | compressed size:    222
name: uci/train/features/380.csv | size:    473 | compressed size:    237
name: uci/train/features/381.csv | size:    471 | compressed size:    229
name: uci/train/features/382.csv | size:    470 | compressed size:    231
name: uci/train/features/383.csv | size:    471 | compressed size:    231
name: uci/train/features/384.csv | size:    473 | compressed size:    232
name: uci/train/features/385.csv | size:    470 | compressed size:    226
name: uci/train/features/386.csv | size:    473 | compressed size:    234
name: uci/train/features/387.csv | size:    471 | compressed size:    232
name: uci/train/features/388.csv | size:    476 | compressed size:    230
name: uci/train/features/389.csv | size:    474 | compressed size:    227
name: uci/train/features/39.csv | size:    473 | compressed size:    230
name: uci/train/features/390.csv | size:    474 | compressed size:    232
name: uci/train/features/391.csv | size:    472 | compressed size:    233
name: uci/train/features/392.csv | size:    473 | compressed size:    230
name: uci/train/features/393.csv | size:    472 | compressed size:    228
name: uci/train/features/394.csv | size:    477 | compressed size:    238
name: uci/train/features/395.csv | size:    470 | compressed size:    236
name: uci/train/features/396.csv | size:    468 | compressed size:    224
name: uci/train/features/397.csv | size:    475 | compressed size:    227
name: uci/train/features/398.csv | size:    474 | compressed size:    233
name: uci/train/features/399.csv | size:    472 | compressed size:    231
name: uci/train/features/4.csv | size:    466 | compressed size:    226
name: uci/train/features/40.csv | size:    473 | compressed size:    231
name: uci/train/features/400.csv | size:    476 | compressed size:    225
name: uci/train/features/401.csv | size:    474 | compressed size:    229
name: uci/train/features/402.csv | size:    476 | compressed size:    222
name: uci/train/features/403.csv | size:    475 | compressed size:    239
name: uci/train/features/404.csv | size:    469 | compressed size:    229
name: uci/train/features/405.csv | size:    465 | compressed size:    227
name: uci/train/features/406.csv | size:    473 | compressed size:    232
name: uci/train/features/407.csv | size:    472 | compressed size:    223
name: uci/train/features/408.csv | size:    470 | compressed size:    229
name: uci/train/features/409.csv | size:    475 | compressed size:    234
name: uci/train/features/41.csv | size:    471 | compressed size:    239
name: uci/train/features/410.csv | size:    473 | compressed size:    232
name: uci/train/features/411.csv | size:    472 | compressed size:    235
name: uci/train/features/412.csv | size:    476 | compressed size:    231
name: uci/train/features/413.csv | size:    470 | compressed size:    224
name: uci/train/features/414.csv | size:    471 | compressed size:    225
name: uci/train/features/415.csv | size:    470 | compressed size:    236
name: uci/train/features/416.csv | size:    472 | compressed size:    231
name: uci/train/features/417.csv | size:    480 | compressed size:    241
name: uci/train/features/418.csv | size:    471 | compressed size:    231
name: uci/train/features/419.csv | size:    475 | compressed size:    227
name: uci/train/features/42.csv | size:    475 | compressed size:    238
name: uci/train/features/420.csv | size:    472 | compressed size:    230
name: uci/train/features/421.csv | size:    471 | compressed size:    229
name: uci/train/features/422.csv | size:    472 | compressed size:    225
name: uci/train/features/423.csv | size:    474 | compressed size:    231
name: uci/train/features/424.csv | size:    473 | compressed size:    237
name: uci/train/features/425.csv | size:    470 | compressed size:    222
name: uci/train/features/426.csv | size:    482 | compressed size:    237
name: uci/train/features/427.csv | size:    474 | compressed size:    237
name: uci/train/features/428.csv | size:    469 | compressed size:    224
name: uci/train/features/429.csv | size:    470 | compressed size:    231
name: uci/train/features/43.csv | size:    471 | compressed size:    226
name: uci/train/features/430.csv | size:    471 | compressed size:    227
name: uci/train/features/431.csv | size:    470 | compressed size:    229
name: uci/train/features/432.csv | size:    474 | compressed size:    241
name: uci/train/features/433.csv | size:    476 | compressed size:    231
name: uci/train/features/434.csv | size:    475 | compressed size:    228
name: uci/train/features/435.csv | size:    474 | compressed size:    230
name: uci/train/features/436.csv | size:    473 | compressed size:    218
name: uci/train/features/437.csv | size:    467 | compressed size:    241
name: uci/train/features/438.csv | size:    474 | compressed size:    238
name: uci/train/features/439.csv | size:    475 | compressed size:    226
name: uci/train/features/44.csv | size:    477 | compressed size:    231
name: uci/train/features/440.csv | size:    472 | compressed size:    236
name: uci/train/features/441.csv | size:    468 | compressed size:    232
name: uci/train/features/442.csv | size:    477 | compressed size:    235
name: uci/train/features/443.csv | size:    470 | compressed size:    227
name: uci/train/features/444.csv | size:    470 | compressed size:    221
name: uci/train/features/445.csv | size:    473 | compressed size:    222
name: uci/train/features/446.csv | size:    471 | compressed size:    234
name: uci/train/features/447.csv | size:    472 | compressed size:    234
name: uci/train/features/448.csv | size:    472 | compressed size:    221
name: uci/train/features/449.csv | size:    476 | compressed size:    228
name: uci/train/features/45.csv | size:    477 | compressed size:    231
name: uci/train/features/46.csv | size:    470 | compressed size:    234
name: uci/train/features/47.csv | size:    468 | compressed size:    215
name: uci/train/features/48.csv | size:    474 | compressed size:    240
name: uci/train/features/49.csv | size:    476 | compressed size:    231
name: uci/train/features/5.csv | size:    475 | compressed size:    219
name: uci/train/features/50.csv | size:    469 | compressed size:    228
name: uci/train/features/51.csv | size:    471 | compressed size:    220
name: uci/train/features/52.csv | size:    471 | compressed size:    228
name: uci/train/features/53.csv | size:    476 | compressed size:    226
name: uci/train/features/54.csv | size:    475 | compressed size:    230
name: uci/train/features/55.csv | size:    477 | compressed size:    231
name: uci/train/features/56.csv | size:    474 | compressed size:    239
name: uci/train/features/57.csv | size:    464 | compressed size:    223
name: uci/train/features/58.csv | size:    474 | compressed size:    226
name: uci/train/features/59.csv | size:    471 | compressed size:    222
name: uci/train/features/6.csv | size:    474 | compressed size:    222
name: uci/train/features/60.csv | size:    474 | compressed size:    231
name: uci/train/features/61.csv | size:    475 | compressed size:    222
name: uci/train/features/62.csv | size:    471 | compressed size:    231
name: uci/train/features/63.csv | size:    472 | compressed size:    232
name: uci/train/features/64.csv | size:    475 | compressed size:    231
name: uci/train/features/65.csv | size:    474 | compressed size:    230
name: uci/train/features/66.csv | size:    470 | compressed size:    239
name: uci/train/features/67.csv | size:    473 | compressed size:    229
name: uci/train/features/68.csv | size:    476 | compressed size:    234
name: uci/train/features/69.csv | size:    473 | compressed size:    228
name: uci/train/features/7.csv | size:    470 | compressed size:    224
name: uci/train/features/70.csv | size:    473 | compressed size:    238
name: uci/train/features/71.csv | size:    478 | compressed size:    230
name: uci/train/features/72.csv | size:    475 | compressed size:    241
name: uci/train/features/73.csv | size:    472 | compressed size:    231
name: uci/train/features/74.csv | size:    471 | compressed size:    237
name: uci/train/features/75.csv | size:    475 | compressed size:    221
name: uci/train/features/76.csv | size:    469 | compressed size:    226
name: uci/train/features/77.csv | size:    475 | compressed size:    239
name: uci/train/features/78.csv | size:    464 | compressed size:    230
name: uci/train/features/79.csv | size:    476 | compressed size:    234
name: uci/train/features/8.csv | size:    471 | compressed size:    235
name: uci/train/features/80.csv | size:    473 | compressed size:    223
name: uci/train/features/81.csv | size:    473 | compressed size:    229
name: uci/train/features/82.csv | size:    472 | compressed size:    222
name: uci/train/features/83.csv | size:    474 | compressed size:    235
name: uci/train/features/84.csv | size:    472 | compressed size:    220
name: uci/train/features/85.csv | size:    474 | compressed size:    233
name: uci/train/features/86.csv | size:    475 | compressed size:    229
name: uci/train/features/87.csv | size:    475 | compressed size:    233
name: uci/train/features/88.csv | size:    475 | compressed size:    228
name: uci/train/features/89.csv | size:    472 | compressed size:    219
name: uci/train/features/9.csv | size:    474 | compressed size:    230
name: uci/train/features/90.csv | size:    469 | compressed size:    236
name: uci/train/features/91.csv | size:    473 | compressed size:    221
name: uci/train/features/92.csv | size:    475 | compressed size:    231
name: uci/train/features/93.csv | size:    472 | compressed size:    232
name: uci/train/features/94.csv | size:    476 | compressed size:    237
name: uci/train/features/95.csv | size:    475 | compressed size:    226
name: uci/train/features/96.csv | size:    477 | compressed size:    238
name: uci/train/features/97.csv | size:    474 | compressed size:    230
name: uci/train/features/98.csv | size:    464 | compressed size:    221
name: uci/train/features/99.csv | size:    475 | compressed size:    233
name: uci/train/labels/    | size:      0 | compressed size:      0
name: uci/train/labels/0.csv | size:      1 | compressed size:      1
name: uci/train/labels/1.csv | size:      1 | compressed size:      1
name: uci/train/labels/10.csv | size:      1 | compressed size:      1
name: uci/train/labels/100.csv | size:      1 | compressed size:      1
name: uci/train/labels/101.csv | size:      1 | compressed size:      1
name: uci/train/labels/102.csv | size:      1 | compressed size:      1
name: uci/train/labels/103.csv | size:      1 | compressed size:      1
name: uci/train/labels/104.csv | size:      1 | compressed size:      1
name: uci/train/labels/105.csv | size:      1 | compressed size:      1
name: uci/train/labels/106.csv | size:      1 | compressed size:      1
name: uci/train/labels/107.csv | size:      1 | compressed size:      1
name: uci/train/labels/108.csv | size:      1 | compressed size:      1
name: uci/train/labels/109.csv | size:      1 | compressed size:      1
name: uci/train/labels/11.csv | size:      1 | compressed size:      1
name: uci/train/labels/110.csv | size:      1 | compressed size:      1
name: uci/train/labels/111.csv | size:      1 | compressed size:      1
name: uci/train/labels/112.csv | size:      1 | compressed size:      1
name: uci/train/labels/113.csv | size:      1 | compressed size:      1
name: uci/train/labels/114.csv | size:      1 | compressed size:      1
name: uci/train/labels/115.csv | size:      1 | compressed size:      1
name: uci/train/labels/116.csv | size:      1 | compressed size:      1
name: uci/train/labels/117.csv | size:      1 | compressed size:      1
name: uci/train/labels/118.csv | size:      1 | compressed size:      1
name: uci/train/labels/119.csv | size:      1 | compressed size:      1
name: uci/train/labels/12.csv | size:      1 | compressed size:      1
name: uci/train/labels/120.csv | size:      1 | compressed size:      1
name: uci/train/labels/121.csv | size:      1 | compressed size:      1
name: uci/train/labels/122.csv | size:      1 | compressed size:      1
name: uci/train/labels/123.csv | size:      1 | compressed size:      1
name: uci/train/labels/124.csv | size:      1 | compressed size:      1
name: uci/train/labels/125.csv | size:      1 | compressed size:      1
name: uci/train/labels/126.csv | size:      1 | compressed size:      1
name: uci/train/labels/127.csv | size:      1 | compressed size:      1
name: uci/train/labels/128.csv | size:      1 | compressed size:      1
name: uci/train/labels/129.csv | size:      1 | compressed size:      1
name: uci/train/labels/13.csv | size:      1 | compressed size:      1
name: uci/train/labels/130.csv | size:      1 | compressed size:      1
name: uci/train/labels/131.csv | size:      1 | compressed size:      1
name: uci/train/labels/132.csv | size:      1 | compressed size:      1
name: uci/train/labels/133.csv | size:      1 | compressed size:      1
name: uci/train/labels/134.csv | size:      1 | compressed size:      1
name: uci/train/labels/135.csv | size:      1 | compressed size:      1
name: uci/train/labels/136.csv | size:      1 | compressed size:      1
name: uci/train/labels/137.csv | size:      1 | compressed size:      1
name: uci/train/labels/138.csv | size:      1 | compressed size:      1
name: uci/train/labels/139.csv | size:      1 | compressed size:      1
name: uci/train/labels/14.csv | size:      1 | compressed size:      1
name: uci/train/labels/140.csv | size:      1 | compressed size:      1
name: uci/train/labels/141.csv | size:      1 | compressed size:      1
name: uci/train/labels/142.csv | size:      1 | compressed size:      1
name: uci/train/labels/143.csv | size:      1 | compressed size:      1
name: uci/train/labels/144.csv | size:      1 | compressed size:      1
name: uci/train/labels/145.csv | size:      1 | compressed size:      1
name: uci/train/labels/146.csv | size:      1 | compressed size:      1
name: uci/train/labels/147.csv | size:      1 | compressed size:      1
name: uci/train/labels/148.csv | size:      1 | compressed size:      1
name: uci/train/labels/149.csv | size:      1 | compressed size:      1
name: uci/train/labels/15.csv | size:      1 | compressed size:      1
name: uci/train/labels/150.csv | size:      1 | compressed size:      1
name: uci/train/labels/151.csv | size:      1 | compressed size:      1
name: uci/train/labels/152.csv | size:      1 | compressed size:      1
name: uci/train/labels/153.csv | size:      1 | compressed size:      1
name: uci/train/labels/154.csv | size:      1 | compressed size:      1
name: uci/train/labels/155.csv | size:      1 | compressed size:      1
name: uci/train/labels/156.csv | size:      1 | compressed size:      1
name: uci/train/labels/157.csv | size:      1 | compressed size:      1
name: uci/train/labels/158.csv | size:      1 | compressed size:      1
name: uci/train/labels/159.csv | size:      1 | compressed size:      1
name: uci/train/labels/16.csv | size:      1 | compressed size:      1
name: uci/train/labels/160.csv | size:      1 | compressed size:      1
name: uci/train/labels/161.csv | size:      1 | compressed size:      1
name: uci/train/labels/162.csv | size:      1 | compressed size:      1
name: uci/train/labels/163.csv | size:      1 | compressed size:      1
name: uci/train/labels/164.csv | size:      1 | compressed size:      1
name: uci/train/labels/165.csv | size:      1 | compressed size:      1
name: uci/train/labels/166.csv | size:      1 | compressed size:      1
name: uci/train/labels/167.csv | size:      1 | compressed size:      1
name: uci/train/labels/168.csv | size:      1 | compressed size:      1
name: uci/train/labels/169.csv | size:      1 | compressed size:      1
name: uci/train/labels/17.csv | size:      1 | compressed size:      1
name: uci/train/labels/170.csv | size:      1 | compressed size:      1
name: uci/train/labels/171.csv | size:      1 | compressed size:      1
name: uci/train/labels/172.csv | size:      1 | compressed size:      1
name: uci/train/labels/173.csv | size:      1 | compressed size:      1
name: uci/train/labels/174.csv | size:      1 | compressed size:      1
name: uci/train/labels/175.csv | size:      1 | compressed size:      1
name: uci/train/labels/176.csv | size:      1 | compressed size:      1
name: uci/train/labels/177.csv | size:      1 | compressed size:      1
name: uci/train/labels/178.csv | size:      1 | compressed size:      1
name: uci/train/labels/179.csv | size:      1 | compressed size:      1
name: uci/train/labels/18.csv | size:      1 | compressed size:      1
name: uci/train/labels/180.csv | size:      1 | compressed size:      1
name: uci/train/labels/181.csv | size:      1 | compressed size:      1
name: uci/train/labels/182.csv | size:      1 | compressed size:      1
name: uci/train/labels/183.csv | size:      1 | compressed size:      1
name: uci/train/labels/184.csv | size:      1 | compressed size:      1
name: uci/train/labels/185.csv | size:      1 | compressed size:      1
name: uci/train/labels/186.csv | size:      1 | compressed size:      1
name: uci/train/labels/187.csv | size:      1 | compressed size:      1
name: uci/train/labels/188.csv | size:      1 | compressed size:      1
name: uci/train/labels/189.csv | size:      1 | compressed size:      1
name: uci/train/labels/19.csv | size:      1 | compressed size:      1
name: uci/train/labels/190.csv | size:      1 | compressed size:      1
name: uci/train/labels/191.csv | size:      1 | compressed size:      1
name: uci/train/labels/192.csv | size:      1 | compressed size:      1
name: uci/train/labels/193.csv | size:      1 | compressed size:      1
name: uci/train/labels/194.csv | size:      1 | compressed size:      1
name: uci/train/labels/195.csv | size:      1 | compressed size:      1
name: uci/train/labels/196.csv | size:      1 | compressed size:      1
name: uci/train/labels/197.csv | size:      1 | compressed size:      1
name: uci/train/labels/198.csv | size:      1 | compressed size:      1
name: uci/train/labels/199.csv | size:      1 | compressed size:      1
name: uci/train/labels/2.csv | size:      1 | compressed size:      1
name: uci/train/labels/20.csv | size:      1 | compressed size:      1
name: uci/train/labels/200.csv | size:      1 | compressed size:      1
name: uci/train/labels/201.csv | size:      1 | compressed size:      1
name: uci/train/labels/202.csv | size:      1 | compressed size:      1
name: uci/train/labels/203.csv | size:      1 | compressed size:      1
name: uci/train/labels/204.csv | size:      1 | compressed size:      1
name: uci/train/labels/205.csv | size:      1 | compressed size:      1
name: uci/train/labels/206.csv | size:      1 | compressed size:      1
name: uci/train/labels/207.csv | size:      1 | compressed size:      1
name: uci/train/labels/208.csv | size:      1 | compressed size:      1
name: uci/train/labels/209.csv | size:      1 | compressed size:      1
name: uci/train/labels/21.csv | size:      1 | compressed size:      1
name: uci/train/labels/210.csv | size:      1 | compressed size:      1
name: uci/train/labels/211.csv | size:      1 | compressed size:      1
name: uci/train/labels/212.csv | size:      1 | compressed size:      1
name: uci/train/labels/213.csv | size:      1 | compressed size:      1
name: uci/train/labels/214.csv | size:      1 | compressed size:      1
name: uci/train/labels/215.csv | size:      1 | compressed size:      1
name: uci/train/labels/216.csv | size:      1 | compressed size:      1
name: uci/train/labels/217.csv | size:      1 | compressed size:      1
name: uci/train/labels/218.csv | size:      1 | compressed size:      1
name: uci/train/labels/219.csv | size:      1 | compressed size:      1
name: uci/train/labels/22.csv | size:      1 | compressed size:      1
name: uci/train/labels/220.csv | size:      1 | compressed size:      1
name: uci/train/labels/221.csv | size:      1 | compressed size:      1
name: uci/train/labels/222.csv | size:      1 | compressed size:      1
name: uci/train/labels/223.csv | size:      1 | compressed size:      1
name: uci/train/labels/224.csv | size:      1 | compressed size:      1
name: uci/train/labels/225.csv | size:      1 | compressed size:      1
name: uci/train/labels/226.csv | size:      1 | compressed size:      1
name: uci/train/labels/227.csv | size:      1 | compressed size:      1
name: uci/train/labels/228.csv | size:      1 | compressed size:      1
name: uci/train/labels/229.csv | size:      1 | compressed size:      1
name: uci/train/labels/23.csv | size:      1 | compressed size:      1
name: uci/train/labels/230.csv | size:      1 | compressed size:      1
name: uci/train/labels/231.csv | size:      1 | compressed size:      1
name: uci/train/labels/232.csv | size:      1 | compressed size:      1
name: uci/train/labels/233.csv | size:      1 | compressed size:      1
name: uci/train/labels/234.csv | size:      1 | compressed size:      1
name: uci/train/labels/235.csv | size:      1 | compressed size:      1
name: uci/train/labels/236.csv | size:      1 | compressed size:      1
name: uci/train/labels/237.csv | size:      1 | compressed size:      1
name: uci/train/labels/238.csv | size:      1 | compressed size:      1
name: uci/train/labels/239.csv | size:      1 | compressed size:      1
name: uci/train/labels/24.csv | size:      1 | compressed size:      1
name: uci/train/labels/240.csv | size:      1 | compressed size:      1
name: uci/train/labels/241.csv | size:      1 | compressed size:      1
name: uci/train/labels/242.csv | size:      1 | compressed size:      1
name: uci/train/labels/243.csv | size:      1 | compressed size:      1
name: uci/train/labels/244.csv | size:      1 | compressed size:      1
name: uci/train/labels/245.csv | size:      1 | compressed size:      1
name: uci/train/labels/246.csv | size:      1 | compressed size:      1
name: uci/train/labels/247.csv | size:      1 | compressed size:      1
name: uci/train/labels/248.csv | size:      1 | compressed size:      1
name: uci/train/labels/249.csv | size:      1 | compressed size:      1
name: uci/train/labels/25.csv | size:      1 | compressed size:      1
name: uci/train/labels/250.csv | size:      1 | compressed size:      1
name: uci/train/labels/251.csv | size:      1 | compressed size:      1
name: uci/train/labels/252.csv | size:      1 | compressed size:      1
name: uci/train/labels/253.csv | size:      1 | compressed size:      1
name: uci/train/labels/254.csv | size:      1 | compressed size:      1
name: uci/train/labels/255.csv | size:      1 | compressed size:      1
name: uci/train/labels/256.csv | size:      1 | compressed size:      1
name: uci/train/labels/257.csv | size:      1 | compressed size:      1
name: uci/train/labels/258.csv | size:      1 | compressed size:      1
name: uci/train/labels/259.csv | size:      1 | compressed size:      1
name: uci/train/labels/26.csv | size:      1 | compressed size:      1
name: uci/train/labels/260.csv | size:      1 | compressed size:      1
name: uci/train/labels/261.csv | size:      1 | compressed size:      1
name: uci/train/labels/262.csv | size:      1 | compressed size:      1
name: uci/train/labels/263.csv | size:      1 | compressed size:      1
name: uci/train/labels/264.csv | size:      1 | compressed size:      1
name: uci/train/labels/265.csv | size:      1 | compressed size:      1
name: uci/train/labels/266.csv | size:      1 | compressed size:      1
name: uci/train/labels/267.csv | size:      1 | compressed size:      1
name: uci/train/labels/268.csv | size:      1 | compressed size:      1
name: uci/train/labels/269.csv | size:      1 | compressed size:      1
name: uci/train/labels/27.csv | size:      1 | compressed size:      1
name: uci/train/labels/270.csv | size:      1 | compressed size:      1
name: uci/train/labels/271.csv | size:      1 | compressed size:      1
name: uci/train/labels/272.csv | size:      1 | compressed size:      1
name: uci/train/labels/273.csv | size:      1 | compressed size:      1
name: uci/train/labels/274.csv | size:      1 | compressed size:      1
name: uci/train/labels/275.csv | size:      1 | compressed size:      1
name: uci/train/labels/276.csv | size:      1 | compressed size:      1
name: uci/train/labels/277.csv | size:      1 | compressed size:      1
name: uci/train/labels/278.csv | size:      1 | compressed size:      1
name: uci/train/labels/279.csv | size:      1 | compressed size:      1
name: uci/train/labels/28.csv | size:      1 | compressed size:      1
name: uci/train/labels/280.csv | size:      1 | compressed size:      1
name: uci/train/labels/281.csv | size:      1 | compressed size:      1
name: uci/train/labels/282.csv | size:      1 | compressed size:      1
name: uci/train/labels/283.csv | size:      1 | compressed size:      1
name: uci/train/labels/284.csv | size:      1 | compressed size:      1
name: uci/train/labels/285.csv | size:      1 | compressed size:      1
name: uci/train/labels/286.csv | size:      1 | compressed size:      1
name: uci/train/labels/287.csv | size:      1 | compressed size:      1
name: uci/train/labels/288.csv | size:      1 | compressed size:      1
name: uci/train/labels/289.csv | size:      1 | compressed size:      1
name: uci/train/labels/29.csv | size:      1 | compressed size:      1
name: uci/train/labels/290.csv | size:      1 | compressed size:      1
name: uci/train/labels/291.csv | size:      1 | compressed size:      1
name: uci/train/labels/292.csv | size:      1 | compressed size:      1
name: uci/train/labels/293.csv | size:      1 | compressed size:      1
name: uci/train/labels/294.csv | size:      1 | compressed size:      1
name: uci/train/labels/295.csv | size:      1 | compressed size:      1
name: uci/train/labels/296.csv | size:      1 | compressed size:      1
name: uci/train/labels/297.csv | size:      1 | compressed size:      1
name: uci/train/labels/298.csv | size:      1 | compressed size:      1
name: uci/train/labels/299.csv | size:      1 | compressed size:      1
name: uci/train/labels/3.csv | size:      1 | compressed size:      1
name: uci/train/labels/30.csv | size:      1 | compressed size:      1
name: uci/train/labels/300.csv | size:      1 | compressed size:      1
name: uci/train/labels/301.csv | size:      1 | compressed size:      1
name: uci/train/labels/302.csv | size:      1 | compressed size:      1
name: uci/train/labels/303.csv | size:      1 | compressed size:      1
name: uci/train/labels/304.csv | size:      1 | compressed size:      1
name: uci/train/labels/305.csv | size:      1 | compressed size:      1
name: uci/train/labels/306.csv | size:      1 | compressed size:      1
name: uci/train/labels/307.csv | size:      1 | compressed size:      1
name: uci/train/labels/308.csv | size:      1 | compressed size:      1
name: uci/train/labels/309.csv | size:      1 | compressed size:      1
name: uci/train/labels/31.csv | size:      1 | compressed size:      1
name: uci/train/labels/310.csv | size:      1 | compressed size:      1
name: uci/train/labels/311.csv | size:      1 | compressed size:      1
name: uci/train/labels/312.csv | size:      1 | compressed size:      1
name: uci/train/labels/313.csv | size:      1 | compressed size:      1
name: uci/train/labels/314.csv | size:      1 | compressed size:      1
name: uci/train/labels/315.csv | size:      1 | compressed size:      1
name: uci/train/labels/316.csv | size:      1 | compressed size:      1
name: uci/train/labels/317.csv | size:      1 | compressed size:      1
name: uci/train/labels/318.csv | size:      1 | compressed size:      1
name: uci/train/labels/319.csv | size:      1 | compressed size:      1
name: uci/train/labels/32.csv | size:      1 | compressed size:      1
name: uci/train/labels/320.csv | size:      1 | compressed size:      1
name: uci/train/labels/321.csv | size:      1 | compressed size:      1
name: uci/train/labels/322.csv | size:      1 | compressed size:      1
name: uci/train/labels/323.csv | size:      1 | compressed size:      1
name: uci/train/labels/324.csv | size:      1 | compressed size:      1
name: uci/train/labels/325.csv | size:      1 | compressed size:      1
name: uci/train/labels/326.csv | size:      1 | compressed size:      1
name: uci/train/labels/327.csv | size:      1 | compressed size:      1
name: uci/train/labels/328.csv | size:      1 | compressed size:      1
name: uci/train/labels/329.csv | size:      1 | compressed size:      1
name: uci/train/labels/33.csv | size:      1 | compressed size:      1
name: uci/train/labels/330.csv | size:      1 | compressed size:      1
name: uci/train/labels/331.csv | size:      1 | compressed size:      1
name: uci/train/labels/332.csv | size:      1 | compressed size:      1
name: uci/train/labels/333.csv | size:      1 | compressed size:      1
name: uci/train/labels/334.csv | size:      1 | compressed size:      1
name: uci/train/labels/335.csv | size:      1 | compressed size:      1
name: uci/train/labels/336.csv | size:      1 | compressed size:      1
name: uci/train/labels/337.csv | size:      1 | compressed size:      1
name: uci/train/labels/338.csv | size:      1 | compressed size:      1
name: uci/train/labels/339.csv | size:      1 | compressed size:      1
name: uci/train/labels/34.csv | size:      1 | compressed size:      1
name: uci/train/labels/340.csv | size:      1 | compressed size:      1
name: uci/train/labels/341.csv | size:      1 | compressed size:      1
name: uci/train/labels/342.csv | size:      1 | compressed size:      1
name: uci/train/labels/343.csv | size:      1 | compressed size:      1
name: uci/train/labels/344.csv | size:      1 | compressed size:      1
name: uci/train/labels/345.csv | size:      1 | compressed size:      1
name: uci/train/labels/346.csv | size:      1 | compressed size:      1
name: uci/train/labels/347.csv | size:      1 | compressed size:      1
name: uci/train/labels/348.csv | size:      1 | compressed size:      1
name: uci/train/labels/349.csv | size:      1 | compressed size:      1
name: uci/train/labels/35.csv | size:      1 | compressed size:      1
name: uci/train/labels/350.csv | size:      1 | compressed size:      1
name: uci/train/labels/351.csv | size:      1 | compressed size:      1
name: uci/train/labels/352.csv | size:      1 | compressed size:      1
name: uci/train/labels/353.csv | size:      1 | compressed size:      1
name: uci/train/labels/354.csv | size:      1 | compressed size:      1
name: uci/train/labels/355.csv | size:      1 | compressed size:      1
name: uci/train/labels/356.csv | size:      1 | compressed size:      1
name: uci/train/labels/357.csv | size:      1 | compressed size:      1
name: uci/train/labels/358.csv | size:      1 | compressed size:      1
name: uci/train/labels/359.csv | size:      1 | compressed size:      1
name: uci/train/labels/36.csv | size:      1 | compressed size:      1
name: uci/train/labels/360.csv | size:      1 | compressed size:      1
name: uci/train/labels/361.csv | size:      1 | compressed size:      1
name: uci/train/labels/362.csv | size:      1 | compressed size:      1
name: uci/train/labels/363.csv | size:      1 | compressed size:      1
name: uci/train/labels/364.csv | size:      1 | compressed size:      1
name: uci/train/labels/365.csv | size:      1 | compressed size:      1
name: uci/train/labels/366.csv | size:      1 | compressed size:      1
name: uci/train/labels/367.csv | size:      1 | compressed size:      1
name: uci/train/labels/368.csv | size:      1 | compressed size:      1
name: uci/train/labels/369.csv | size:      1 | compressed size:      1
name: uci/train/labels/37.csv | size:      1 | compressed size:      1
name: uci/train/labels/370.csv | size:      1 | compressed size:      1
name: uci/train/labels/371.csv | size:      1 | compressed size:      1
name: uci/train/labels/372.csv | size:      1 | compressed size:      1
name: uci/train/labels/373.csv | size:      1 | compressed size:      1
name: uci/train/labels/374.csv | size:      1 | compressed size:      1
name: uci/train/labels/375.csv | size:      1 | compressed size:      1
name: uci/train/labels/376.csv | size:      1 | compressed size:      1
name: uci/train/labels/377.csv | size:      1 | compressed size:      1
name: uci/train/labels/378.csv | size:      1 | compressed size:      1
name: uci/train/labels/379.csv | size:      1 | compressed size:      1
name: uci/train/labels/38.csv | size:      1 | compressed size:      1
name: uci/train/labels/380.csv | size:      1 | compressed size:      1
name: uci/train/labels/381.csv | size:      1 | compressed size:      1
name: uci/train/labels/382.csv | size:      1 | compressed size:      1
name: uci/train/labels/383.csv | size:      1 | compressed size:      1
name: uci/train/labels/384.csv | size:      1 | compressed size:      1
name: uci/train/labels/385.csv | size:      1 | compressed size:      1
name: uci/train/labels/386.csv | size:      1 | compressed size:      1
name: uci/train/labels/387.csv | size:      1 | compressed size:      1
name: uci/train/labels/388.csv | size:      1 | compressed size:      1
name: uci/train/labels/389.csv | size:      1 | compressed size:      1
name: uci/train/labels/39.csv | size:      1 | compressed size:      1
name: uci/train/labels/390.csv | size:      1 | compressed size:      1
name: uci/train/labels/391.csv | size:      1 | compressed size:      1
name: uci/train/labels/392.csv | size:      1 | compressed size:      1
name: uci/train/labels/393.csv | size:      1 | compressed size:      1
name: uci/train/labels/394.csv | size:      1 | compressed size:      1
name: uci/train/labels/395.csv | size:      1 | compressed size:      1
name: uci/train/labels/396.csv | size:      1 | compressed size:      1
name: uci/train/labels/397.csv | size:      1 | compressed size:      1
name: uci/train/labels/398.csv | size:      1 | compressed size:      1
name: uci/train/labels/399.csv | size:      1 | compressed size:      1
name: uci/train/labels/4.csv | size:      1 | compressed size:      1
name: uci/train/labels/40.csv | size:      1 | compressed size:      1
name: uci/train/labels/400.csv | size:      1 | compressed size:      1
name: uci/train/labels/401.csv | size:      1 | compressed size:      1
name: uci/train/labels/402.csv | size:      1 | compressed size:      1
name: uci/train/labels/403.csv | size:      1 | compressed size:      1
name: uci/train/labels/404.csv | size:      1 | compressed size:      1
name: uci/train/labels/405.csv | size:      1 | compressed size:      1
name: uci/train/labels/406.csv | size:      1 | compressed size:      1
name: uci/train/labels/407.csv | size:      1 | compressed size:      1
name: uci/train/labels/408.csv | size:      1 | compressed size:      1
name: uci/train/labels/409.csv | size:      1 | compressed size:      1
name: uci/train/labels/41.csv | size:      1 | compressed size:      1
name: uci/train/labels/410.csv | size:      1 | compressed size:      1
name: uci/train/labels/411.csv | size:      1 | compressed size:      1
name: uci/train/labels/412.csv | size:      1 | compressed size:      1
name: uci/train/labels/413.csv | size:      1 | compressed size:      1
name: uci/train/labels/414.csv | size:      1 | compressed size:      1
name: uci/train/labels/415.csv | size:      1 | compressed size:      1
name: uci/train/labels/416.csv | size:      1 | compressed size:      1
name: uci/train/labels/417.csv | size:      1 | compressed size:      1
name: uci/train/labels/418.csv | size:      1 | compressed size:      1
name: uci/train/labels/419.csv | size:      1 | compressed size:      1
name: uci/train/labels/42.csv | size:      1 | compressed size:      1
name: uci/train/labels/420.csv | size:      1 | compressed size:      1
name: uci/train/labels/421.csv | size:      1 | compressed size:      1
name: uci/train/labels/422.csv | size:      1 | compressed size:      1
name: uci/train/labels/423.csv | size:      1 | compressed size:      1
name: uci/train/labels/424.csv | size:      1 | compressed size:      1
name: uci/train/labels/425.csv | size:      1 | compressed size:      1
name: uci/train/labels/426.csv | size:      1 | compressed size:      1
name: uci/train/labels/427.csv | size:      1 | compressed size:      1
name: uci/train/labels/428.csv | size:      1 | compressed size:      1
name: uci/train/labels/429.csv | size:      1 | compressed size:      1
name: uci/train/labels/43.csv | size:      1 | compressed size:      1
name: uci/train/labels/430.csv | size:      1 | compressed size:      1
name: uci/train/labels/431.csv | size:      1 | compressed size:      1
name: uci/train/labels/432.csv | size:      1 | compressed size:      1
name: uci/train/labels/433.csv | size:      1 | compressed size:      1
name: uci/train/labels/434.csv | size:      1 | compressed size:      1
name: uci/train/labels/435.csv | size:      1 | compressed size:      1
name: uci/train/labels/436.csv | size:      1 | compressed size:      1
name: uci/train/labels/437.csv | size:      1 | compressed size:      1
name: uci/train/labels/438.csv | size:      1 | compressed size:      1
name: uci/train/labels/439.csv | size:      1 | compressed size:      1
name: uci/train/labels/44.csv | size:      1 | compressed size:      1
name: uci/train/labels/440.csv | size:      1 | compressed size:      1
name: uci/train/labels/441.csv | size:      1 | compressed size:      1
name: uci/train/labels/442.csv | size:      1 | compressed size:      1
name: uci/train/labels/443.csv | size:      1 | compressed size:      1
name: uci/train/labels/444.csv | size:      1 | compressed size:      1
name: uci/train/labels/445.csv | size:      1 | compressed size:      1
name: uci/train/labels/446.csv | size:      1 | compressed size:      1
name: uci/train/labels/447.csv | size:      1 | compressed size:      1
name: uci/train/labels/448.csv | size:      1 | compressed size:      1
name: uci/train/labels/449.csv | size:      1 | compressed size:      1
name: uci/train/labels/45.csv | size:      1 | compressed size:      1
name: uci/train/labels/46.csv | size:      1 | compressed size:      1
name: uci/train/labels/47.csv | size:      1 | compressed size:      1
name: uci/train/labels/48.csv | size:      1 | compressed size:      1
name: uci/train/labels/49.csv | size:      1 | compressed size:      1
name: uci/train/labels/5.csv | size:      1 | compressed size:      1
name: uci/train/labels/50.csv | size:      1 | compressed size:      1
name: uci/train/labels/51.csv | size:      1 | compressed size:      1
name: uci/train/labels/52.csv | size:      1 | compressed size:      1
name: uci/train/labels/53.csv | size:      1 | compressed size:      1
name: uci/train/labels/54.csv | size:      1 | compressed size:      1
name: uci/train/labels/55.csv | size:      1 | compressed size:      1
name: uci/train/labels/56.csv | size:      1 | compressed size:      1
name: uci/train/labels/57.csv | size:      1 | compressed size:      1
name: uci/train/labels/58.csv | size:      1 | compressed size:      1
name: uci/train/labels/59.csv | size:      1 | compressed size:      1
name: uci/train/labels/6.csv | size:      1 | compressed size:      1
name: uci/train/labels/60.csv | size:      1 | compressed size:      1
name: uci/train/labels/61.csv | size:      1 | compressed size:      1
name: uci/train/labels/62.csv | size:      1 | compressed size:      1
name: uci/train/labels/63.csv | size:      1 | compressed size:      1
name: uci/train/labels/64.csv | size:      1 | compressed size:      1
name: uci/train/labels/65.csv | size:      1 | compressed size:      1
name: uci/train/labels/66.csv | size:      1 | compressed size:      1
name: uci/train/labels/67.csv | size:      1 | compressed size:      1
name: uci/train/labels/68.csv | size:      1 | compressed size:      1
name: uci/train/labels/69.csv | size:      1 | compressed size:      1
name: uci/train/labels/7.csv | size:      1 | compressed size:      1
name: uci/train/labels/70.csv | size:      1 | compressed size:      1
name: uci/train/labels/71.csv | size:      1 | compressed size:      1
name: uci/train/labels/72.csv | size:      1 | compressed size:      1
name: uci/train/labels/73.csv | size:      1 | compressed size:      1
name: uci/train/labels/74.csv | size:      1 | compressed size:      1
name: uci/train/labels/75.csv | size:      1 | compressed size:      1
name: uci/train/labels/76.csv | size:      1 | compressed size:      1
name: uci/train/labels/77.csv | size:      1 | compressed size:      1
name: uci/train/labels/78.csv | size:      1 | compressed size:      1
name: uci/train/labels/79.csv | size:      1 | compressed size:      1
name: uci/train/labels/8.csv | size:      1 | compressed size:      1
name: uci/train/labels/80.csv | size:      1 | compressed size:      1
name: uci/train/labels/81.csv | size:      1 | compressed size:      1
name: uci/train/labels/82.csv | size:      1 | compressed size:      1
name: uci/train/labels/83.csv | size:      1 | compressed size:      1
name: uci/train/labels/84.csv | size:      1 | compressed size:      1
name: uci/train/labels/85.csv | size:      1 | compressed size:      1
name: uci/train/labels/86.csv | size:      1 | compressed size:      1
name: uci/train/labels/87.csv | size:      1 | compressed size:      1
name: uci/train/labels/88.csv | size:      1 | compressed size:      1
name: uci/train/labels/89.csv | size:      1 | compressed size:      1
name: uci/train/labels/9.csv | size:      1 | compressed size:      1
name: uci/train/labels/90.csv | size:      1 | compressed size:      1
name: uci/train/labels/91.csv | size:      1 | compressed size:      1
name: uci/train/labels/92.csv | size:      1 | compressed size:      1
name: uci/train/labels/93.csv | size:      1 | compressed size:      1
name: uci/train/labels/94.csv | size:      1 | compressed size:      1
name: uci/train/labels/95.csv | size:      1 | compressed size:      1
name: uci/train/labels/96.csv | size:      1 | compressed size:      1
name: uci/train/labels/97.csv | size:      1 | compressed size:      1
name: uci/train/labels/98.csv | size:      1 | compressed size:      1
name: uci/train/labels/99.csv | size:      1 | compressed size:      1
1855 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend
1883 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ST4-4.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sketch_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/objenesis-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jline-2.12.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-xml_2.11-1.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsr305-1.3.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-collections-3.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/machinist_2.11-0.6.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-codec-1.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-metastore-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-yarn_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.ws.rs-api-2.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-rdbms-3.2.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/eigenbase-properties-1.1.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pyrolite-4.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-jackson-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-util-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill-java-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mesos-1.0.0-shaded-protobuf.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jaxb-api-2.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-encoding-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-log4j12-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-schema-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-shuffle_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scalap-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-annotations-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stream-2.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-server-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-kerberos-codec-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-mapper-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-all-4.0.43.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/py4j-0.10.4.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/zipfs.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-hdfs-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/oro-2.0.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-api-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/JavaEWAH-0.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-core_2.11-3.2.11.jar
file:/System/Library/Java/Extensions/j3dcore.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/zookeeper-3.4.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-jdbc-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-locator-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire_2.11-0.13.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/cldrdata.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/kryo-shaded-3.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-api-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-repackaged-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/compress-lzf-1.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib-local_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-media-jaxb-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-core-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/activation-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-2.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mesos_2.11-2.2.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/localedata.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-catalyst_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpcore-4.4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-jaxrs-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-utils-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-json-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-tags_2.11-2.2.0.jar
file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar
file:/System/Library/Java/Extensions/libJ3DAudio.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javolution-5.5.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.servlet-api-3.1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-api-jdo-3.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-scala_2.11-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jta-1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-net-2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bcprov-jdk15on-1.51.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jdo-api-3.0.1.jar
file:/System/Library/Java/Extensions/j3dutils.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-api-2.4.0-b34.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/sunec.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guava-14.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-java-1.1.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive-thriftserver_2.11-2.2.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/jaccess.jar
file:/System/Library/Java/Extensions/libJ3D.jnilib
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/jfxrt.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr4-runtime-4.5.3.jar
file:/System/Library/Java/Extensions/dns_sd.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-databind-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-common_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang-2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/janino-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-client-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-recipes-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-configuration-1.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-repl_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/shapeless_2.11-2.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-ast_2.11-3.2.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-core-3.2.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-dbcp-1.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-math3-3.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-guava-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-client-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-jackson_2.11-3.2.11.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/nashorn.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xbean-asm5-shaded-4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/RoaringBitmap-0.5.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-annotations-2.6.5.jar
file:/System/Library/Java/Extensions/vecmath.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stringtemplate-3.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-app-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-model-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/protobuf-java-2.5.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-column-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-bundle-1.6.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-graphite-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill_2.11-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze-macros_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-3.9.9.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-core-1.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-auth-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-runtime-3.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-core_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-cli-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libfb303-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javassist-3.18.1-GA.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-jvm-3.1.2.jar
file:/System/Library/Java/Extensions/mlibwrapper_jai.jar
file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-linq4j-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/joda-time-2.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/minlog-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compress-1.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/derby-10.12.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-io-2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-launcher_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-crypto-1.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-streaming_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/core-1.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-unsafe_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-format-2.3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/opencsv-2.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sql_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-core-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-common-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-avatica-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-exec-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mail-1.4.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jpam-1.1.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mx4j-3.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-graphx_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.annotation-api-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jcl-over-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-logging-1.1.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire-macros_2.11-0.13.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/validation-api-1.1.0.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/lz4-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/java-xmlbuilder-1.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/dnsns.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-pool-1.5.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsp-api-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xz-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-xc-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-compiler-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/htrace-core-3.1.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/univocity-parsers-2.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-framework-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-util-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpclient-4.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bonecp-0.8.0.RELEASE.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/conf/
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-i18n-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compiler-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-cli-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/paranamer-2.6.jar
file:/System/Library/Java/Extensions/jai_core.jar
file:/System/Library/Java/Extensions/libJ3DUtils.jnilib
file:/System/Library/Java/Extensions/AppleScriptEngine.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-core-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/macro-compat_2.11-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-1.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jul-to-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ivy-2.4.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-digester-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jodd-core-3.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libthrift-0.9.3.jar
file:/System/Library/Java/Extensions/libmlib_jai.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-mapred-1.7.7-hadoop2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/base64-2.3.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jets3t-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-library-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/leveldbjni-all-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-core-2.22.2.jar
file:/System/Library/Java/Extensions/jai_codec.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-reflect-2.11.8.jar
file:/usr/lib/java/libjdns_sd.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-beeline-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-paranamer-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/log4j-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/super-csv-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-common-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/osgi-resource-locator-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-servlet-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-ipc-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang3-3.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-httpclient-3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jtransforms-2.4.0.jar
file:/System/Library/Java/Extensions/j3daudio.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-parser-combinators_2.11-1.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/gson-2.2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-asn1-api-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xmlenc-0.52.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-web-proxy-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/arpack_combined_all-0.1.jar
file:/System/Library/Java/Extensions/MRJToolkit.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0-2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xercesImpl-2.9.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apache-log4j-extras-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-1.jar
2259 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DAudio.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2273 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3D.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2698 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2770 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DUtils.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2777 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libmlib_jai.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2796 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/lib/java/libjdns_sd.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2804 [main] INFO org.reflections.Reflections  - Reflections took 921 ms to scan 231 urls, producing 168762 keys and 188037 values 
3092 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 4
3093 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
jar:file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/
3379 [main] INFO org.reflections.Reflections  - Reflections took 286 ms to scan 1 urls, producing 31 keys and 227 values 
3436 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.4:59114) with ID 0
3491 [dispatcher-event-loop-4] DEBUG org.apache.spark.storage.DefaultTopologyMapper  - Got a request for 192.168.1.4
3491 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.1.4:59116 with 366.3 MB RAM, BlockManagerId(0, 192.168.1.4, 59116, None)
3548 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 4
3549 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Mac OS X]
3549 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [8]; Memory: [0.9GB];
3549 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]
3571 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
jar:file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/
3870 [main] INFO org.reflections.Reflections  - Reflections took 299 ms to scan 1 urls, producing 421 keys and 1666 values 
4567 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ST4-4.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sketch_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/objenesis-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jline-2.12.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-xml_2.11-1.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsr305-1.3.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-collections-3.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/machinist_2.11-0.6.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-codec-1.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-metastore-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-yarn_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.ws.rs-api-2.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-rdbms-3.2.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/eigenbase-properties-1.1.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pyrolite-4.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-jackson-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-util-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill-java-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mesos-1.0.0-shaded-protobuf.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jaxb-api-2.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-encoding-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-log4j12-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-schema-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-shuffle_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scalap-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-annotations-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stream-2.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-server-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-kerberos-codec-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-mapper-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-all-4.0.43.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/py4j-0.10.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-hdfs-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/oro-2.0.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-api-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/JavaEWAH-0.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-core_2.11-3.2.11.jar
file:/System/Library/Java/Extensions/j3dcore.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/zookeeper-3.4.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-jdbc-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-locator-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire_2.11-0.13.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/kryo-shaded-3.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-api-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-repackaged-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/compress-lzf-1.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib-local_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-media-jaxb-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-core-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/activation-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-2.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mesos_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-catalyst_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpcore-4.4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-jaxrs-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-utils-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-json-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-tags_2.11-2.2.0.jar
file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar
file:/System/Library/Java/Extensions/libJ3DAudio.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javolution-5.5.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.servlet-api-3.1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-api-jdo-3.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-scala_2.11-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jta-1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-net-2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bcprov-jdk15on-1.51.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jdo-api-3.0.1.jar
file:/System/Library/Java/Extensions/j3dutils.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-api-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guava-14.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-java-1.1.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive-thriftserver_2.11-2.2.0.jar
file:/System/Library/Java/Extensions/libJ3D.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr4-runtime-4.5.3.jar
file:/System/Library/Java/Extensions/dns_sd.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-databind-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-common_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang-2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/janino-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-client-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-recipes-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-configuration-1.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-repl_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/shapeless_2.11-2.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-ast_2.11-3.2.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-core-3.2.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-dbcp-1.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-math3-3.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-guava-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-client-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-jackson_2.11-3.2.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xbean-asm5-shaded-4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/RoaringBitmap-0.5.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-annotations-2.6.5.jar
file:/System/Library/Java/Extensions/vecmath.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stringtemplate-3.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-app-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-model-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/protobuf-java-2.5.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-column-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-bundle-1.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-graphite-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill_2.11-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze-macros_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-3.9.9.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-core-1.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-auth-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-runtime-3.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-core_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-cli-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libfb303-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javassist-3.18.1-GA.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-jvm-3.1.2.jar
file:/System/Library/Java/Extensions/mlibwrapper_jai.jar
file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-linq4j-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/joda-time-2.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/minlog-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compress-1.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/derby-10.12.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-io-2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-launcher_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-crypto-1.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-streaming_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/core-1.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-unsafe_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-format-2.3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/opencsv-2.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sql_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-core-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-common-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-avatica-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-exec-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mail-1.4.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jpam-1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mx4j-3.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-graphx_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.annotation-api-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jcl-over-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-logging-1.1.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire-macros_2.11-0.13.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/validation-api-1.1.0.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/lz4-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/java-xmlbuilder-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-pool-1.5.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsp-api-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xz-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-xc-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-compiler-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/htrace-core-3.1.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/univocity-parsers-2.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-framework-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-util-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpclient-4.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bonecp-0.8.0.RELEASE.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/conf/
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-i18n-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compiler-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-cli-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/paranamer-2.6.jar
file:/System/Library/Java/Extensions/jai_core.jar
file:/System/Library/Java/Extensions/libJ3DUtils.jnilib
file:/System/Library/Java/Extensions/AppleScriptEngine.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-core-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/macro-compat_2.11-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-1.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jul-to-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ivy-2.4.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-digester-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jodd-core-3.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libthrift-0.9.3.jar
file:/System/Library/Java/Extensions/libmlib_jai.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-mapred-1.7.7-hadoop2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/base64-2.3.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jets3t-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-library-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/leveldbjni-all-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-core-2.22.2.jar
file:/System/Library/Java/Extensions/jai_codec.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-reflect-2.11.8.jar
file:/usr/lib/java/libjdns_sd.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-beeline-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-paranamer-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/log4j-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/super-csv-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-common-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/osgi-resource-locator-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-servlet-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-ipc-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang3-3.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-httpclient-3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jtransforms-2.4.0.jar
file:/System/Library/Java/Extensions/j3daudio.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-parser-combinators_2.11-1.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/gson-2.2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-asn1-api-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xmlenc-0.52.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-web-proxy-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/arpack_combined_all-0.1.jar
file:/System/Library/Java/Extensions/MRJToolkit.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0-2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xercesImpl-2.9.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apache-log4j-extras-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-1.jar
9530 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DAudio.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
9802 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3D.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
10426 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
11621 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DUtils.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
11640 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libmlib_jai.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
12007 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/lib/java/libjdns_sd.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
12082 [main] INFO org.reflections.Reflections  - Reflections took 7515 ms to scan 221 urls, producing 7650 keys and 52161 values 
12127 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
12127 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
12127 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
12127 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer
12127 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor
12132 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
12132 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
12132 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
12132 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer
12132 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor
12174 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]
12250 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
12266 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
12267 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
12268 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
12268 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
12268 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
12269 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
12270 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
12270 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
12272 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
12276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
12276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
12277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
12279 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
12280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
12281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
12281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
12281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
12283 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
12294 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 0 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
12294 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 0 (count at ParameterAveragingTrainingMaster.java:325)
12295 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
12298 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
12303 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 0)
12304 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
12306 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
12306 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 0)
12389 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0 stored as values in memory (estimated size 1448.0 B, free 366.3 MB)
12391 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_0 locally took  56 ms
12392 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_0 without replication took  57 ms
12414 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.3 MB)
12416 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_0_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
12416 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_0_piece0
12417 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_0_piece0
12417 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_0_piece0 locally took  4 ms
12417 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_0_piece0 without replication took  4 ms
12418 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
12430 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
12431 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 0.0 with 8 tasks
12441 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 0.0: 0
12443 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
12445 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 0
12466 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
12467 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 0.0 (TID 0, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
12474 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 0.0 (TID 1, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
12477 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 0.0 (TID 2, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
12479 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 0.0 (TID 3, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
12481 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 0.0 (TID 4, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
12483 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 0.0 (TID 5, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
12485 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 0.0 (TID 6, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
12487 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 0.0 (TID 7, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
12490 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 0 on executor id: 0 hostname: 192.168.1.4.
12492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 1 on executor id: 0 hostname: 192.168.1.4.
12492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 2 on executor id: 0 hostname: 192.168.1.4.
12492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 3 on executor id: 0 hostname: 192.168.1.4.
12493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 4 on executor id: 0 hostname: 192.168.1.4.
12493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 5 on executor id: 0 hostname: 192.168.1.4.
12493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 6 on executor id: 0 hostname: 192.168.1.4.
12494 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 7 on executor id: 0 hostname: 192.168.1.4.
13322 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
14323 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
15327 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
16325 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
17322 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
18327 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
19322 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
20324 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
21325 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
22326 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
23324 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
24322 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
25325 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
26325 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
27327 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
28324 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
29327 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
30324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
31322 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
32325 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
33323 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
34322 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
35323 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
36325 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
37323 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
38327 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
39325 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
39990 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_0_piece0 as bytes
39992 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_0_piece0 is StorageLevel(disk, memory, 1 replicas)
40011 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_0_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 366.3 MB)
40163 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_3 in memory on 192.168.1.4:59116 (size: 114.7 KB, free: 366.2 MB)
40164 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_5 in memory on 192.168.1.4:59116 (size: 95.7 KB, free: 366.1 MB)
40164 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_6 in memory on 192.168.1.4:59116 (size: 114.7 KB, free: 366.0 MB)
40165 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_1 in memory on 192.168.1.4:59116 (size: 114.7 KB, free: 365.9 MB)
40166 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_2 in memory on 192.168.1.4:59116 (size: 95.7 KB, free: 365.8 MB)
40166 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_4 in memory on 192.168.1.4:59116 (size: 114.7 KB, free: 365.7 MB)
40168 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_0 in memory on 192.168.1.4:59116 (size: 95.7 KB, free: 365.6 MB)
40169 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_7 in memory on 192.168.1.4:59116 (size: 114.7 KB, free: 365.5 MB)
40218 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 7
40220 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
40221 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 6
40222 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 5
40222 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 4
40223 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 3
40223 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 2
40223 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 1
40224 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 0
40227 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 0.0 (TID 7) in 27741 ms on 192.168.1.4 (executor 0) (1/8)
40229 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 0.0 (TID 6) in 27746 ms on 192.168.1.4 (executor 0) (2/8)
40229 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 0.0 (TID 5) in 27748 ms on 192.168.1.4 (executor 0) (3/8)
40229 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 0.0 (TID 3) in 27752 ms on 192.168.1.4 (executor 0) (4/8)
40230 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 0.0 (TID 4) in 27751 ms on 192.168.1.4 (executor 0) (5/8)
40231 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 0.0 (TID 1) in 27762 ms on 192.168.1.4 (executor 0) (6/8)
40231 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 0.0 (TID 2) in 27757 ms on 192.168.1.4 (executor 0) (7/8)
40231 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 0.0 (TID 0) in 27784 ms on 192.168.1.4 (executor 0) (8/8)
40232 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 0.0, whose tasks have all completed, from pool 
40236 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 0 (count at ParameterAveragingTrainingMaster.java:325) finished in 27.792 s
40239 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 0, remaining stages = 0
40240 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 0 finished: count at ParameterAveragingTrainingMaster.java:325, took 27.958093 s
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40244 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40244 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40244 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
40247 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
40252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
40252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
40252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
40252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
40252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353
40252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
40254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
40254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
40255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353)
40255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
40256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
40256 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
40257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353
40258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
40258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
40258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
40258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353)
40258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
40258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40261 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40262 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40262 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40262 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
40262 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
40263 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 1 (collect at SparkUtils.java:353) with 8 output partitions
40263 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 1 (collect at SparkUtils.java:353)
40263 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
40265 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
40265 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 1)
40265 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
40265 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 1 (MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
40265 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 1)
40268 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1 stored as values in memory (estimated size 2.4 KB, free 366.3 MB)
40268 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_1 locally took  1 ms
40268 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_1 without replication took  1 ms
40269 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1571.0 B, free 366.3 MB)
40269 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_1_piece0 in memory on 192.168.1.4:59108 (size: 1571.0 B, free: 366.3 MB)
40270 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_1_piece0
40270 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_1_piece0
40270 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_1_piece0 locally took  1 ms
40270 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_1_piece0 without replication took  1 ms
40270 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
40270 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
40270 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 1.0 with 8 tasks
40271 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 1.0: 0
40273 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 1.0: PROCESS_LOCAL, NODE_LOCAL, ANY
40273 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 0
40275 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
40275 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 1.0 (TID 8, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
40277 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 1.0 (TID 9, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
40278 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 1.0 (TID 10, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
40279 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 1.0 (TID 11, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
40280 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 1.0 (TID 12, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
40282 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 1.0 (TID 13, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
40283 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 1.0 (TID 14, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
40285 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 1.0 (TID 15, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
40285 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 8 on executor id: 0 hostname: 192.168.1.4.
40286 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 9 on executor id: 0 hostname: 192.168.1.4.
40286 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 10 on executor id: 0 hostname: 192.168.1.4.
40286 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 11 on executor id: 0 hostname: 192.168.1.4.
40286 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 12 on executor id: 0 hostname: 192.168.1.4.
40286 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 13 on executor id: 0 hostname: 192.168.1.4.
40287 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 14 on executor id: 0 hostname: 192.168.1.4.
40287 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 15 on executor id: 0 hostname: 192.168.1.4.
40307 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_1_piece0 as bytes
40308 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_1_piece0 is StorageLevel(disk, memory, 1 replicas)
40311 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_1_piece0 in memory on 192.168.1.4:59116 (size: 1571.0 B, free: 365.5 MB)
40321 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 8
40333 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 7
40333 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
40334 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
40334 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 1.0 (TID 10) in 57 ms on 192.168.1.4 (executor 0) (1/8)
40334 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 6
40335 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 1.0 (TID 11) in 57 ms on 192.168.1.4 (executor 0) (2/8)
40335 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 5
40335 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 1.0 (TID 15) in 52 ms on 192.168.1.4 (executor 0) (3/8)
40336 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 4
40336 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 1.0 (TID 14) in 54 ms on 192.168.1.4 (executor 0) (4/8)
40337 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 3
40337 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 1.0 (TID 13) in 57 ms on 192.168.1.4 (executor 0) (5/8)
40337 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 2
40338 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 1.0 (TID 8) in 64 ms on 192.168.1.4 (executor 0) (6/8)
40339 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 1
40340 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 0
40340 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 1.0 (TID 9) in 65 ms on 192.168.1.4 (executor 0) (7/8)
40340 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 1.0 (TID 12) in 61 ms on 192.168.1.4 (executor 0) (8/8)
40340 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 1.0, whose tasks have all completed, from pool 
40341 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 1 (collect at SparkUtils.java:353) finished in 0.068 s
40341 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 1, remaining stages = 0
40341 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 1 finished: collect at SparkUtils.java:353, took 0.078769 s
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
40346 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
40348 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
40348 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 2 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
40348 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 2 (zipWithIndex at SparkUtils.java:391)
40348 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
40348 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
40349 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 2)
40349 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
40349 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 2 (MapPartitionsRDD[2] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
40349 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 2)
40350 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2 stored as values in memory (estimated size 2.2 KB, free 366.3 MB)
40351 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_2 locally took  1 ms
40351 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_2 without replication took  1 ms
40352 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.3 MB)
40352 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_2_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
40352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_2_piece0
40352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_2_piece0
40352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_2_piece0 locally took  1 ms
40352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_2_piece0 without replication took  1 ms
40353 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
40353 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 2 (MapPartitionsRDD[2] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
40353 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 2.0 with 7 tasks
40353 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 2.0: 0
40353 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 2.0: PROCESS_LOCAL, NODE_LOCAL, ANY
40354 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 0
40355 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 2 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
40355 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 2.0 (TID 16, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
40356 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 2.0 (TID 17, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
40357 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 2.0 (TID 18, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
40358 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 2.0 (TID 19, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
40360 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 2.0 (TID 20, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
40360 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 2.0 (TID 21, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
40362 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 2.0 (TID 22, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
40362 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
40362 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
40362 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 16 on executor id: 0 hostname: 192.168.1.4.
40362 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 17 on executor id: 0 hostname: 192.168.1.4.
40363 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 18 on executor id: 0 hostname: 192.168.1.4.
40363 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 19 on executor id: 0 hostname: 192.168.1.4.
40363 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 20 on executor id: 0 hostname: 192.168.1.4.
40363 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 21 on executor id: 0 hostname: 192.168.1.4.
40364 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 22 on executor id: 0 hostname: 192.168.1.4.
40376 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_2_piece0 as bytes
40376 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_2_piece0 is StorageLevel(disk, memory, 1 replicas)
40378 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_2_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.5 MB)
40388 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 6
40388 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 2.0 (TID 18) in 32 ms on 192.168.1.4 (executor 0) (1/7)
40388 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 5
40389 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 2.0 (TID 20) in 30 ms on 192.168.1.4 (executor 0) (2/7)
40390 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 4
40390 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 2.0 (TID 16) in 36 ms on 192.168.1.4 (executor 0) (3/7)
40391 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 3
40391 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 2.0 (TID 22) in 31 ms on 192.168.1.4 (executor 0) (4/7)
40391 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 2
40391 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 2.0 (TID 19) in 34 ms on 192.168.1.4 (executor 0) (5/7)
40392 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 1
40392 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 0
40392 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 2.0 (TID 17) in 37 ms on 192.168.1.4 (executor 0) (6/7)
40392 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 2.0 (TID 21) in 32 ms on 192.168.1.4 (executor 0) (7/7)
40392 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 2.0, whose tasks have all completed, from pool 
40393 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 2 (zipWithIndex at SparkUtils.java:391) finished in 0.039 s
40393 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 2, remaining stages = 0
40393 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 2 finished: zipWithIndex at SparkUtils.java:391, took 0.045637 s
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
40403 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40404 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
40425 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3 stored as values in memory (estimated size 33.0 KB, free 366.3 MB)
40426 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_3 locally took  13 ms
40426 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_3 without replication took  13 ms
40438 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.0 KB, free 366.3 MB)
40439 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_3_piece0 in memory on 192.168.1.4:59108 (size: 5.0 KB, free: 366.3 MB)
40439 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_3_piece0
40439 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_3_piece0
40439 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_3_piece0 locally took  1 ms
40439 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_3_piece0 without replication took  1 ms
40441 [main] INFO org.apache.spark.SparkContext  - Created broadcast 3 from broadcast at ParameterAveragingTrainingMaster.java:259
40444 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
40444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
40454 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40455 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
40456 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40457 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40459 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40460 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40460 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40460 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40460 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
40465 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40466 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40470 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40477 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40477 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40477 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
40478 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
40479 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
40479 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
40479 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
40479 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
40480 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
40483 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 0 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
40487 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 5 (mapToPair at SparkUtils.java:391)
40487 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 10 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
40487 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 3 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
40487 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 5 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
40487 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 4)
40488 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 4)
40488 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 5)
40488 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 4)
40488 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 4)
40488 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 3)
40488 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 3)
40489 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
40489 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 3 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:391), which has no missing parents
40489 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 3)
40494 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 366.2 MB)
40494 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_4 locally took  1 ms
40494 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_4 without replication took  1 ms
40495 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
40496 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_4_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
40496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_4_piece0
40496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_4_piece0
40496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_4_piece0 locally took  1 ms
40496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_4_piece0 without replication took  1 ms
40496 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
40498 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
40498 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 3.0 with 8 tasks
40498 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 3.0: 0
40498 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 3.0: PROCESS_LOCAL, NODE_LOCAL, ANY
40499 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 0
40500 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 3 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
40500 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 3.0 (TID 23, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
40501 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 3.0 (TID 24, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
40502 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 3.0 (TID 25, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
40503 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 3.0 (TID 26, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
40504 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 3.0 (TID 27, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
40505 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 3.0 (TID 28, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
40506 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 3.0 (TID 29, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
40507 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 3.0 (TID 30, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
40507 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 23 on executor id: 0 hostname: 192.168.1.4.
40507 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 24 on executor id: 0 hostname: 192.168.1.4.
40508 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 25 on executor id: 0 hostname: 192.168.1.4.
40508 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 26 on executor id: 0 hostname: 192.168.1.4.
40508 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 27 on executor id: 0 hostname: 192.168.1.4.
40508 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 28 on executor id: 0 hostname: 192.168.1.4.
40508 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 29 on executor id: 0 hostname: 192.168.1.4.
40510 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 30 on executor id: 0 hostname: 192.168.1.4.
40522 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_4_piece0 as bytes
40522 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_4_piece0 is StorageLevel(disk, memory, 1 replicas)
40525 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_4_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.5 MB)
40596 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 7
40596 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
40596 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
40596 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 6
40597 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 5
40597 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 4
40598 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 3
40598 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 3.0 (TID 29) in 93 ms on 192.168.1.4 (executor 0) (1/8)
40598 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 3.0 (TID 25) in 97 ms on 192.168.1.4 (executor 0) (2/8)
40598 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 3.0 (TID 30) in 92 ms on 192.168.1.4 (executor 0) (3/8)
40598 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 3.0 (TID 26) in 96 ms on 192.168.1.4 (executor 0) (4/8)
40599 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 2
40599 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 3.0 (TID 23) in 100 ms on 192.168.1.4 (executor 0) (5/8)
40599 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 3.0 (TID 24) in 99 ms on 192.168.1.4 (executor 0) (6/8)
40599 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 1
40599 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40599 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 3.0 (TID 27) in 96 ms on 192.168.1.4 (executor 0) (7/8)
40599 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 0
40600 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40600 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 3.0 (TID 28) in 96 ms on 192.168.1.4 (executor 0) (8/8)
40600 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 3.0, whose tasks have all completed, from pool 
40600 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40600 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40601 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40601 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40601 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40603 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
40603 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 3 (mapToPair at SparkUtils.java:391) finished in 0.105 s
40604 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
40604 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
40604 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 5, ShuffleMapStage 4)
40605 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
40606 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 1
40608 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 4)
40608 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
40608 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
40608 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 4)
40616 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5 stored as values in memory (estimated size 6.6 KB, free 366.2 MB)
40616 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_5 locally took  0 ms
40616 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_5 without replication took  0 ms
40617 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
40618 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_5_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.3 MB)
40618 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_5_piece0
40618 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_5_piece0
40618 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_5_piece0 locally took  1 ms
40618 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_5_piece0 without replication took  1 ms
40618 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
40619 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
40619 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 4.0 with 8 tasks
40619 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 4.0: 1
40620 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 4.0: NODE_LOCAL, ANY
40620 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 0
40621 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 4.0 (TID 31, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
40621 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 4.0 (TID 32, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
40621 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 4.0 (TID 33, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
40621 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 4.0 (TID 34, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
40621 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 4.0 (TID 35, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
40621 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 4.0 (TID 36, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
40622 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 4.0 (TID 37, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
40622 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 4.0 (TID 38, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
40622 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 31 on executor id: 0 hostname: 192.168.1.4.
40622 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 32 on executor id: 0 hostname: 192.168.1.4.
40622 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 33 on executor id: 0 hostname: 192.168.1.4.
40622 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 34 on executor id: 0 hostname: 192.168.1.4.
40622 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 35 on executor id: 0 hostname: 192.168.1.4.
40622 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 36 on executor id: 0 hostname: 192.168.1.4.
40623 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 37 on executor id: 0 hostname: 192.168.1.4.
40623 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 38 on executor id: 0 hostname: 192.168.1.4.
40632 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_5_piece0 as bytes
40632 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_5_piece0 is StorageLevel(disk, memory, 1 replicas)
40634 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_5_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.5 MB)
40682 [dispatcher-event-loop-1] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 1 to 192.168.1.4:59114
40683 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 1 to 192.168.1.4:59114
40684 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 1
40684 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 1
40686 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 1 is 186 bytes
40714 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_3_piece0 as bytes
40714 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_3_piece0 is StorageLevel(disk, memory, 1 replicas)
40716 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_3_piece0 in memory on 192.168.1.4:59116 (size: 5.0 KB, free: 365.4 MB)
41326 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
42326 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
43326 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
44322 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
45326 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
46325 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
47322 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
48321 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
49321 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
50321 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
51321 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
51404 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 7
51404 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
51405 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 4.0 (TID 35) in 10783 ms on 192.168.1.4 (executor 0) (1/8)
51405 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
52321 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 7
52574 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 6
52574 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 4.0 (TID 37) in 11953 ms on 192.168.1.4 (executor 0) (2/8)
52575 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
52658 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 5
52659 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 4.0 (TID 36) in 12037 ms on 192.168.1.4 (executor 0) (3/8)
52659 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
52726 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 4
52726 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 4.0 (TID 38) in 12104 ms on 192.168.1.4 (executor 0) (4/8)
52727 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
52886 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 3
52887 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 4.0 (TID 33) in 12265 ms on 192.168.1.4 (executor 0) (5/8)
52887 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
53041 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 2
53042 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 4.0 (TID 31) in 12421 ms on 192.168.1.4 (executor 0) (6/8)
53042 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
53052 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 1
53052 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 4.0 (TID 32) in 12431 ms on 192.168.1.4 (executor 0) (7/8)
53053 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
53062 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 0
53062 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 4.0 (TID 34) in 12441 ms on 192.168.1.4 (executor 0) (8/8)
53062 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 4.0, whose tasks have all completed, from pool 
53062 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
53063 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 4 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 12.442 s
53063 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
53063 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
53063 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 5)
53063 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
53063 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 2
53063 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 5)
53063 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
53063 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 5 (MapPartitionsRDD[12] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
53063 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 5)
53066 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
53066 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_6 locally took  1 ms
53066 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_6 without replication took  1 ms
53067 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
53067 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_6_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
53067 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_6_piece0
53067 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_6_piece0
53067 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_6_piece0 locally took  0 ms
53068 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_6_piece0 without replication took  0 ms
53068 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
53068 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
53068 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 5.0 with 2 tasks
53068 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 5.0: 2
53068 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 5.0: NODE_LOCAL, ANY
53069 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_5.0, runningTasks: 0
53069 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 5.0 (TID 39, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
53069 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 5.0 (TID 40, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
53069 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
53069 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 39 on executor id: 0 hostname: 192.168.1.4.
53069 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 40 on executor id: 0 hostname: 192.168.1.4.
53074 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_6_piece0 as bytes
53074 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_6_piece0 is StorageLevel(disk, memory, 1 replicas)
53077 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_6_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
53083 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 0 to 192.168.1.4:59114
53083 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 0 to 192.168.1.4:59114
53083 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 0
53083 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 0
53083 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 0 is 159 bytes
53130 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(2)
53131 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 2
53131 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 2
53136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 2
53136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 2
53140 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_2_piece0
53141 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2_piece0 of size 1460 dropped from memory (free 384023806)
53142 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_2_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
53142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_2_piece0
53142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_2_piece0
53142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_2
53142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2 of size 2216 dropped from memory (free 384026022)
53143 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 2, response is 0
53144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
53146 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_2_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
53150 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 2
53150 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(0)
53150 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 0
53150 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 0
53150 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 0
53150 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 0
53150 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_0_piece0
53150 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0_piece0 of size 1006 dropped from memory (free 384027028)
53151 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_0_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.3 MB)
53151 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_0_piece0
53151 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_0_piece0
53151 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_0
53151 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0 of size 1448 dropped from memory (free 384028476)
53151 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 0, response is 0
53151 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
53152 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_0_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
53153 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 0
53153 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(1)
53153 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 1
53153 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 1
53153 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 1
53153 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 1
53154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_1
53154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1 of size 2504 dropped from memory (free 384030980)
53154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_1_piece0
53154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1_piece0 of size 1571 dropped from memory (free 384032551)
53154 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_1_piece0 on 192.168.1.4:59108 in memory (size: 1571.0 B, free: 366.3 MB)
53154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_1_piece0
53154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_1_piece0
53154 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 1, response is 0
53154 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
53155 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_1_piece0 on 192.168.1.4:59116 in memory (size: 1571.0 B, free: 365.4 MB)
53156 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 1
53156 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(4)
53156 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 4
53156 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 4
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 4
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 4
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_4
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4 of size 3600 dropped from memory (free 384036151)
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_4_piece0
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4_piece0 of size 2195 dropped from memory (free 384038346)
53157 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_4_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_4_piece0
53157 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_4_piece0
53158 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 4, response is 0
53158 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
53158 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_4_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
53159 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 4
53159 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(5)
53159 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 5
53159 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 5
53160 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 5
53160 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 5
53160 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_5
53160 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5 of size 6712 dropped from memory (free 384045058)
53160 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_5_piece0
53160 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5_piece0 of size 3631 dropped from memory (free 384048689)
53161 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_5_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
53161 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_5_piece0
53161 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_5_piece0
53161 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 5, response is 0
53161 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
53161 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_5_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.5 MB)
53162 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 5
53179 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_5.0, runningTasks: 1
53179 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_5.0, runningTasks: 0
53182 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 5.0 (TID 39) in 113 ms on 192.168.1.4 (executor 0) (1/2)
53182 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 5.0 (TID 40) in 113 ms on 192.168.1.4 (executor 0) (2/2)
53182 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 5.0, whose tasks have all completed, from pool 
53182 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 5 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.114 s
53182 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 5, remaining stages = 2
53182 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 4, remaining stages = 1
53182 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 3, remaining stages = 0
53183 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 3 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 12.703727 s
53184 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
53285 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
53285 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_7 locally took  1 ms
53285 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_7 without replication took  1 ms
53286 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
53287 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_7_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
53287 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_7_piece0
53287 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_7_piece0
53287 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_7_piece0 locally took  1 ms
53287 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_7_piece0 without replication took  1 ms
53287 [main] INFO org.apache.spark.SparkContext  - Created broadcast 7 from broadcast at SparkDl4jMultiLayer.java:595
53290 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
53290 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_8 locally took  3 ms
53290 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_8 without replication took  3 ms
53291 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
53292 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_8_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
53292 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_8_piece0
53292 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_8_piece0
53292 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_8_piece0 locally took  1 ms
53292 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_8_piece0 without replication took  1 ms
53292 [main] INFO org.apache.spark.SparkContext  - Created broadcast 8 from broadcast at SparkDl4jMultiLayer.java:596
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53294 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53294 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53294 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53303 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53303 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53303 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53303 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
53303 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
53306 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
53311 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
53313 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
53316 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
53317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
53318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
53318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
53318 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
53318 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 2 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
53318 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 15 (treeAggregate at SparkDl4jMultiLayer.java:598)
53319 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 4 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
53319 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 7 (treeAggregate at SparkDl4jMultiLayer.java:598)
53319 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 6)
53319 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 6)
53319 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 7)
53319 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 6)
53319 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 6)
53319 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
53319 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
53319 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 6)
53321 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9 stored as values in memory (estimated size 8.9 KB, free 366.2 MB)
53321 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_9 locally took  0 ms
53322 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_9 without replication took  1 ms
53323 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.2 MB)
53323 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_9_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
53323 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_9_piece0
53323 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_9_piece0
53323 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_9_piece0 locally took  1 ms
53323 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_9_piece0 without replication took  1 ms
53324 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
53324 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
53324 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 6.0 with 8 tasks
53324 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 6.0: 2
53324 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 6.0: NO_PREF, ANY
53325 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 0
53325 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 6.0 (TID 41, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
53326 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 6.0 (TID 42, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
53326 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 6.0 (TID 43, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
53327 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 6.0 (TID 44, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
53327 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 6.0 (TID 45, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
53327 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 6.0 (TID 46, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
53328 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 6.0 (TID 47, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
53329 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 6.0 (TID 48, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
53329 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 41 on executor id: 0 hostname: 192.168.1.4.
53329 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 42 on executor id: 0 hostname: 192.168.1.4.
53330 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 43 on executor id: 0 hostname: 192.168.1.4.
53330 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 44 on executor id: 0 hostname: 192.168.1.4.
53330 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 45 on executor id: 0 hostname: 192.168.1.4.
53330 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 46 on executor id: 0 hostname: 192.168.1.4.
53330 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 47 on executor id: 0 hostname: 192.168.1.4.
53330 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 48 on executor id: 0 hostname: 192.168.1.4.
53339 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_9_piece0 as bytes
53340 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_9_piece0 is StorageLevel(disk, memory, 1 replicas)
53343 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_9_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
53376 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_8_piece0 as bytes
53376 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_8_piece0 is StorageLevel(disk, memory, 1 replicas)
53379 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_8_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
53422 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_7_piece0 as bytes
53423 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_7_piece0 is StorageLevel(disk, memory, 1 replicas)
53425 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_7_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
54183 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 7
54183 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
54184 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 6.0 (TID 46) in 857 ms on 192.168.1.4 (executor 0) (1/8)
54184 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54197 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 6
54197 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 6.0 (TID 43) in 871 ms on 192.168.1.4 (executor 0) (2/8)
54198 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54203 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 5
54203 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 6.0 (TID 48) in 875 ms on 192.168.1.4 (executor 0) (3/8)
54204 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54229 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 4
54230 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 6.0 (TID 44) in 904 ms on 192.168.1.4 (executor 0) (4/8)
54230 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 3
54231 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54231 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 6.0 (TID 47) in 903 ms on 192.168.1.4 (executor 0) (5/8)
54231 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54237 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 2
54237 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 6.0 (TID 45) in 910 ms on 192.168.1.4 (executor 0) (6/8)
54238 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54242 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 1
54242 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 6.0 (TID 42) in 917 ms on 192.168.1.4 (executor 0) (7/8)
54243 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54244 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 0
54244 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 6.0 (TID 41) in 919 ms on 192.168.1.4 (executor 0) (8/8)
54244 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 6.0, whose tasks have all completed, from pool 
54244 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54246 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 6 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.921 s
54246 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
54246 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
54246 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 7)
54246 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
54246 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 3
54246 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 7)
54246 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54246 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 7 (MapPartitionsRDD[17] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
54246 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 7)
54248 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
54248 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_10 locally took  1 ms
54248 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_10 without replication took  1 ms
54250 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
54250 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_10_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
54250 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_10_piece0
54250 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_10_piece0
54250 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_10_piece0 locally took  1 ms
54250 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_10_piece0 without replication took  1 ms
54250 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
54251 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
54251 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 7.0 with 2 tasks
54251 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 7.0: 3
54251 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 7.0: NODE_LOCAL, ANY
54251 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_7.0, runningTasks: 0
54252 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 7.0 (TID 49, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
54252 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 7.0 (TID 50, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
54252 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
54252 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 49 on executor id: 0 hostname: 192.168.1.4.
54252 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 50 on executor id: 0 hostname: 192.168.1.4.
54258 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_10_piece0 as bytes
54258 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_10_piece0 is StorageLevel(disk, memory, 1 replicas)
54260 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_10_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
54264 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 2 to 192.168.1.4:59114
54264 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 2 to 192.168.1.4:59114
54264 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 2
54264 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 2
54264 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 2 is 159 bytes
54273 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_7.0, runningTasks: 1
54275 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_7.0, runningTasks: 0
54280 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 7.0 (TID 49) in 29 ms on 192.168.1.4 (executor 0) (1/2)
54280 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 7.0 (TID 50) in 28 ms on 192.168.1.4 (executor 0) (2/2)
54280 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 7.0, whose tasks have all completed, from pool 
54280 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 7 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.029 s
54281 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 7, remaining stages = 1
54281 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 6, remaining stages = 0
54284 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 4 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.966710 s
54285 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 0: Accuracy = 0.00, F1 = NaN
54285 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 0
54285 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54286 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54287 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54288 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54288 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54288 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
54288 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
54288 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 5 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
54288 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 8 (count at ParameterAveragingTrainingMaster.java:325)
54288 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
54289 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
54289 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 8)
54289 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54289 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 8 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
54289 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 8)
54290 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
54290 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_11 locally took  0 ms
54290 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_11 without replication took  0 ms
54291 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
54292 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_11_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
54292 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_11_piece0
54292 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_11_piece0
54292 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_11_piece0 locally took  1 ms
54292 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_11_piece0 without replication took  1 ms
54292 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
54293 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 8 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
54293 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 8.0 with 8 tasks
54293 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 8.0: 3
54293 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 8.0: PROCESS_LOCAL, NODE_LOCAL, ANY
54293 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 0
54294 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 8 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
54294 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 8.0 (TID 51, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
54296 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 8.0 (TID 52, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
54297 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 8.0 (TID 53, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
54299 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 8.0 (TID 54, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
54300 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 8.0 (TID 55, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
54301 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 8.0 (TID 56, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
54302 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 8.0 (TID 57, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
54304 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 8.0 (TID 58, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
54304 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 51 on executor id: 0 hostname: 192.168.1.4.
54305 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 52 on executor id: 0 hostname: 192.168.1.4.
54305 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 53 on executor id: 0 hostname: 192.168.1.4.
54305 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 54 on executor id: 0 hostname: 192.168.1.4.
54305 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 55 on executor id: 0 hostname: 192.168.1.4.
54305 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 56 on executor id: 0 hostname: 192.168.1.4.
54306 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 57 on executor id: 0 hostname: 192.168.1.4.
54306 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 58 on executor id: 0 hostname: 192.168.1.4.
54313 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_11_piece0 as bytes
54313 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_11_piece0 is StorageLevel(disk, memory, 1 replicas)
54315 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_11_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
54321 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 8
54323 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 7
54323 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
54323 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
54323 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 8.0 (TID 54) in 26 ms on 192.168.1.4 (executor 0) (1/8)
54323 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 6
54323 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 8.0 (TID 52) in 29 ms on 192.168.1.4 (executor 0) (2/8)
54326 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 5
54326 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 8.0 (TID 57) in 25 ms on 192.168.1.4 (executor 0) (3/8)
54326 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 4
54327 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 8.0 (TID 56) in 26 ms on 192.168.1.4 (executor 0) (4/8)
54327 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 3
54327 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 8.0 (TID 53) in 31 ms on 192.168.1.4 (executor 0) (5/8)
54328 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 2
54328 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 1
54328 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 8.0 (TID 58) in 25 ms on 192.168.1.4 (executor 0) (6/8)
54328 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 8.0 (TID 55) in 29 ms on 192.168.1.4 (executor 0) (7/8)
54328 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 0
54328 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 8.0 (TID 51) in 35 ms on 192.168.1.4 (executor 0) (8/8)
54328 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 8.0, whose tasks have all completed, from pool 
54329 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 8 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.036 s
54329 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 8, remaining stages = 0
54329 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 5 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.041094 s
54329 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
54331 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
54333 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353
54334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
54335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
54335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
54335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353)
54335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
54336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353)
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
54337 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
54339 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
54339 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 6 (collect at SparkUtils.java:353) with 8 output partitions
54339 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 9 (collect at SparkUtils.java:353)
54339 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
54340 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
54340 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 9)
54340 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54340 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 9 (MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
54340 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 9)
54342 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
54342 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_12 locally took  1 ms
54342 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_12 without replication took  1 ms
54343 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
54343 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_12_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
54343 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_12_piece0
54343 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_12_piece0
54344 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_12_piece0 locally took  0 ms
54344 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_12_piece0 without replication took  1 ms
54344 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
54344 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 9 (MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
54344 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 9.0 with 8 tasks
54344 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 9.0: 3
54345 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 9.0: PROCESS_LOCAL, NODE_LOCAL, ANY
54345 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 0
54346 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 9 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
54346 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 9.0 (TID 59, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
54348 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 9.0 (TID 60, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
54349 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 9.0 (TID 61, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
54350 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 9.0 (TID 62, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
54352 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 9.0 (TID 63, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
54353 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 9.0 (TID 64, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
54355 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 9.0 (TID 65, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
54356 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 9.0 (TID 66, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
54356 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 59 on executor id: 0 hostname: 192.168.1.4.
54356 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 60 on executor id: 0 hostname: 192.168.1.4.
54356 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 61 on executor id: 0 hostname: 192.168.1.4.
54357 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 62 on executor id: 0 hostname: 192.168.1.4.
54357 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 63 on executor id: 0 hostname: 192.168.1.4.
54357 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 64 on executor id: 0 hostname: 192.168.1.4.
54357 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 65 on executor id: 0 hostname: 192.168.1.4.
54357 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 66 on executor id: 0 hostname: 192.168.1.4.
54366 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_12_piece0 as bytes
54366 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_12_piece0 is StorageLevel(disk, memory, 1 replicas)
54368 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_12_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
54376 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 7
54376 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
54376 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
54376 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 9.0 (TID 59) in 31 ms on 192.168.1.4 (executor 0) (1/8)
54377 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 6
54377 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 9.0 (TID 66) in 22 ms on 192.168.1.4 (executor 0) (2/8)
54378 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 5
54378 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 9.0 (TID 63) in 28 ms on 192.168.1.4 (executor 0) (3/8)
54379 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 4
54379 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 9.0 (TID 60) in 33 ms on 192.168.1.4 (executor 0) (4/8)
54380 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 3
54380 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 9.0 (TID 62) in 31 ms on 192.168.1.4 (executor 0) (5/8)
54380 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 2
54380 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 9.0 (TID 64) in 28 ms on 192.168.1.4 (executor 0) (6/8)
54381 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 1
54381 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 0
54381 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 9.0 (TID 61) in 33 ms on 192.168.1.4 (executor 0) (7/8)
54381 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 9.0 (TID 65) in 28 ms on 192.168.1.4 (executor 0) (8/8)
54381 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 9.0, whose tasks have all completed, from pool 
54381 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 9 (collect at SparkUtils.java:353) finished in 0.036 s
54381 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 9, remaining stages = 0
54381 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 6 finished: collect at SparkUtils.java:353, took 0.042563 s
54382 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54383 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54384 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
54385 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
54385 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 7 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
54385 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 10 (zipWithIndex at SparkUtils.java:391)
54385 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
54385 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
54385 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 10)
54385 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54385 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 10 (MapPartitionsRDD[18] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
54385 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 10)
54386 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
54387 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_13 locally took  1 ms
54387 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_13 without replication took  1 ms
54387 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
54388 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_13_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
54388 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_13_piece0
54388 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_13_piece0
54388 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_13_piece0 locally took  1 ms
54388 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_13_piece0 without replication took  1 ms
54388 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
54389 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 10 (MapPartitionsRDD[18] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
54389 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 10.0 with 7 tasks
54389 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 10.0: 3
54389 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 10.0: PROCESS_LOCAL, NODE_LOCAL, ANY
54389 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 0
54390 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 10 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
54390 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 10.0 (TID 67, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
54391 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 10.0 (TID 68, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
54392 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 10.0 (TID 69, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
54393 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 10.0 (TID 70, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
54394 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 10.0 (TID 71, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
54395 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 10.0 (TID 72, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
54396 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 10.0 (TID 73, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
54396 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
54396 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
54396 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 67 on executor id: 0 hostname: 192.168.1.4.
54397 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 68 on executor id: 0 hostname: 192.168.1.4.
54397 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 69 on executor id: 0 hostname: 192.168.1.4.
54397 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 70 on executor id: 0 hostname: 192.168.1.4.
54397 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 71 on executor id: 0 hostname: 192.168.1.4.
54397 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 72 on executor id: 0 hostname: 192.168.1.4.
54398 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 73 on executor id: 0 hostname: 192.168.1.4.
54405 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_13_piece0 as bytes
54405 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_13_piece0 is StorageLevel(disk, memory, 1 replicas)
54407 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_13_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
54414 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 6
54414 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 10.0 (TID 68) in 24 ms on 192.168.1.4 (executor 0) (1/7)
54414 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 5
54414 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 10.0 (TID 72) in 20 ms on 192.168.1.4 (executor 0) (2/7)
54414 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 4
54415 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 10.0 (TID 71) in 22 ms on 192.168.1.4 (executor 0) (3/7)
54417 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 3
54417 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 10.0 (TID 73) in 22 ms on 192.168.1.4 (executor 0) (4/7)
54417 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 2
54417 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 10.0 (TID 69) in 26 ms on 192.168.1.4 (executor 0) (5/7)
54418 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 1
54418 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 10.0 (TID 70) in 26 ms on 192.168.1.4 (executor 0) (6/7)
54419 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 0
54419 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 10.0 (TID 67) in 30 ms on 192.168.1.4 (executor 0) (7/7)
54419 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 10.0, whose tasks have all completed, from pool 
54419 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 10 (zipWithIndex at SparkUtils.java:391) finished in 0.030 s
54419 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 10, remaining stages = 0
54420 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 7 finished: zipWithIndex at SparkUtils.java:391, took 0.034900 s
54420 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
54420 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54421 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54422 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54423 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54423 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54423 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54423 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
54426 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14 stored as values in memory (estimated size 30.9 KB, free 366.2 MB)
54426 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_14 locally took  2 ms
54426 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_14 without replication took  2 ms
54428 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.2 MB)
54429 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_14_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.3 MB)
54429 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_14_piece0
54429 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_14_piece0
54429 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_14_piece0 locally took  1 ms
54429 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_14_piece0 without replication took  1 ms
54429 [main] INFO org.apache.spark.SparkContext  - Created broadcast 14 from broadcast at ParameterAveragingTrainingMaster.java:259
54429 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54430 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54431 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54431 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54431 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54432 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54433 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54434 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54434 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54434 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54434 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54434 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54435 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
54436 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54437 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54438 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54438 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54438 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54439 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54440 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54441 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54442 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54442 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54442 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54442 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54442 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54443 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54444 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54445 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54446 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54446 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54446 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54446 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
54446 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
54447 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 3 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
54447 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 21 (mapToPair at SparkUtils.java:391)
54447 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 26 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
54447 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 8 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
54447 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 13 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
54448 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 12)
54448 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 12)
54448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 13)
54448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 12)
54448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 12)
54448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 11)
54448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 11)
54448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54449 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 11 (MapPartitionsRDD[21] at mapToPair at SparkUtils.java:391), which has no missing parents
54449 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 11)
54450 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15 stored as values in memory (estimated size 3.5 KB, free 366.2 MB)
54451 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_15 locally took  1 ms
54451 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_15 without replication took  1 ms
54452 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
54452 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_15_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
54452 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_15_piece0
54452 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_15_piece0
54452 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_15_piece0 locally took  1 ms
54452 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_15_piece0 without replication took  1 ms
54452 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
54453 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[21] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
54453 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 11.0 with 8 tasks
54453 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 11.0: 3
54453 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 11.0: PROCESS_LOCAL, NODE_LOCAL, ANY
54453 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 0
54454 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 11 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
54455 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 11.0 (TID 74, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
54456 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 11.0 (TID 75, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
54457 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 11.0 (TID 76, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
54459 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 11.0 (TID 77, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
54460 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 11.0 (TID 78, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
54461 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 11.0 (TID 79, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
54462 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 11.0 (TID 80, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
54463 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 11.0 (TID 81, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
54463 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 74 on executor id: 0 hostname: 192.168.1.4.
54463 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 75 on executor id: 0 hostname: 192.168.1.4.
54463 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 76 on executor id: 0 hostname: 192.168.1.4.
54464 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 77 on executor id: 0 hostname: 192.168.1.4.
54464 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 78 on executor id: 0 hostname: 192.168.1.4.
54464 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 79 on executor id: 0 hostname: 192.168.1.4.
54464 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 80 on executor id: 0 hostname: 192.168.1.4.
54465 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 81 on executor id: 0 hostname: 192.168.1.4.
54471 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_15_piece0 as bytes
54472 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_15_piece0 is StorageLevel(disk, memory, 1 replicas)
54473 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_15_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
54485 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 7
54485 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
54486 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
54486 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 6
54486 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 11.0 (TID 78) in 27 ms on 192.168.1.4 (executor 0) (1/8)
54486 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 11.0 (TID 76) in 30 ms on 192.168.1.4 (executor 0) (2/8)
54486 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54486 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54487 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 5
54487 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 11.0 (TID 77) in 30 ms on 192.168.1.4 (executor 0) (3/8)
54487 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54488 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 4
54489 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 11.0 (TID 79) in 29 ms on 192.168.1.4 (executor 0) (4/8)
54489 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 3
54489 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54489 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 11.0 (TID 75) in 34 ms on 192.168.1.4 (executor 0) (5/8)
54489 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54489 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 2
54489 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 11.0 (TID 81) in 27 ms on 192.168.1.4 (executor 0) (6/8)
54490 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54493 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 1
54493 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 11.0 (TID 80) in 32 ms on 192.168.1.4 (executor 0) (7/8)
54493 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54495 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 0
54495 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 11.0 (TID 74) in 42 ms on 192.168.1.4 (executor 0) (8/8)
54495 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 11.0, whose tasks have all completed, from pool 
54495 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54496 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 11 (mapToPair at SparkUtils.java:391) finished in 0.043 s
54496 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
54496 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
54496 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 12, ResultStage 13)
54496 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
54496 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 4
54496 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 12)
54496 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54496 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 12 (MapPartitionsRDD[26] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
54496 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 12)
54498 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
54499 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_16 locally took  1 ms
54499 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_16 without replication took  1 ms
54500 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
54500 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_16_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.3 MB)
54500 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_16_piece0
54500 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_16_piece0
54500 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_16_piece0 locally took  1 ms
54500 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_16_piece0 without replication took  1 ms
54500 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
54501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[26] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
54501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 12.0 with 8 tasks
54501 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 12.0: 4
54501 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 12.0: NODE_LOCAL, ANY
54501 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 0
54502 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 12.0 (TID 82, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
54502 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 12.0 (TID 83, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
54502 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 12.0 (TID 84, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
54502 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 12.0 (TID 85, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
54502 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 12.0 (TID 86, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
54502 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 12.0 (TID 87, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
54503 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 12.0 (TID 88, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
54503 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 12.0 (TID 89, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
54503 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 82 on executor id: 0 hostname: 192.168.1.4.
54503 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 83 on executor id: 0 hostname: 192.168.1.4.
54503 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 84 on executor id: 0 hostname: 192.168.1.4.
54503 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 85 on executor id: 0 hostname: 192.168.1.4.
54503 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 86 on executor id: 0 hostname: 192.168.1.4.
54503 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 87 on executor id: 0 hostname: 192.168.1.4.
54504 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 88 on executor id: 0 hostname: 192.168.1.4.
54504 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 89 on executor id: 0 hostname: 192.168.1.4.
54509 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_16_piece0 as bytes
54509 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_16_piece0 is StorageLevel(disk, memory, 1 replicas)
54511 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_16_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
54515 [dispatcher-event-loop-3] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 4 to 192.168.1.4:59114
54515 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 4 to 192.168.1.4:59114
54515 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 4
54515 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 4
54515 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 4 is 186 bytes
54519 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_14_piece0 as bytes
54519 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_14_piece0 is StorageLevel(disk, memory, 1 replicas)
54522 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_14_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
55321 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 8
56321 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 8
56810 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 7
56810 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
56811 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 12.0 (TID 86) in 2309 ms on 192.168.1.4 (executor 0) (1/8)
56811 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
57323 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 7
58112 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 6
58112 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 12.0 (TID 87) in 3610 ms on 192.168.1.4 (executor 0) (2/8)
58113 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
58235 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 5
58235 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 12.0 (TID 88) in 3733 ms on 192.168.1.4 (executor 0) (3/8)
58236 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
58262 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 4
58262 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 12.0 (TID 89) in 3759 ms on 192.168.1.4 (executor 0) (4/8)
58263 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
58322 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 4
58671 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 3
58671 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 12.0 (TID 83) in 4169 ms on 192.168.1.4 (executor 0) (5/8)
58671 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
58675 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 2
58675 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 12.0 (TID 82) in 4174 ms on 192.168.1.4 (executor 0) (6/8)
58675 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
58706 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 1
58706 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 12.0 (TID 85) in 4204 ms on 192.168.1.4 (executor 0) (7/8)
58707 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
58713 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 0
58713 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 12.0 (TID 84) in 4211 ms on 192.168.1.4 (executor 0) (8/8)
58714 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 12.0, whose tasks have all completed, from pool 
58714 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
58714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 12 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.213 s
58714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
58714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
58714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 13)
58714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
58714 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 5
58714 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 13)
58714 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
58714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 13 (MapPartitionsRDD[28] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
58714 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 13)
58715 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
58716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_17 locally took  1 ms
58716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_17 without replication took  1 ms
58717 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
58717 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_17_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
58717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_17_piece0
58717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_17_piece0
58717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_17_piece0 locally took  1 ms
58717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_17_piece0 without replication took  1 ms
58717 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
58718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[28] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
58718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 13.0 with 2 tasks
58718 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 13.0: 5
58718 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 13.0: NODE_LOCAL, ANY
58718 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_13.0, runningTasks: 0
58718 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 13.0 (TID 90, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
58718 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 13.0 (TID 91, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
58718 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
58718 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 90 on executor id: 0 hostname: 192.168.1.4.
58719 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 91 on executor id: 0 hostname: 192.168.1.4.
58723 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_17_piece0 as bytes
58723 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_17_piece0 is StorageLevel(disk, memory, 1 replicas)
58725 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_17_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
58727 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 3 to 192.168.1.4:59114
58727 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 3 to 192.168.1.4:59114
58727 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 3
58727 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 3
58728 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 3 is 159 bytes
58754 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_13.0, runningTasks: 1
58754 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_13.0, runningTasks: 0
58754 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 13.0 (TID 91) in 36 ms on 192.168.1.4 (executor 0) (1/2)
58754 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 13.0 (TID 90) in 36 ms on 192.168.1.4 (executor 0) (2/2)
58754 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 13.0, whose tasks have all completed, from pool 
58755 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 13 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.037 s
58755 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 11, remaining stages = 2
58755 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 13, remaining stages = 1
58755 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 12, remaining stages = 0
58755 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 8 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.309163 s
58756 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
58758 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
58758 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_18 locally took  1 ms
58758 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_18 without replication took  1 ms
58759 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
58759 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_18_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
58759 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_18_piece0
58759 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_18_piece0
58759 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_18_piece0 locally took  0 ms
58760 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_18_piece0 without replication took  1 ms
58760 [main] INFO org.apache.spark.SparkContext  - Created broadcast 18 from broadcast at SparkDl4jMultiLayer.java:595
58761 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
58762 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_19 locally took  2 ms
58762 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_19 without replication took  2 ms
58763 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
58763 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_19_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
58763 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_19_piece0
58763 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_19_piece0
58763 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_19_piece0 locally took  0 ms
58763 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_19_piece0 without replication took  0 ms
58764 [main] INFO org.apache.spark.SparkContext  - Created broadcast 19 from broadcast at SparkDl4jMultiLayer.java:596
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
58767 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
58769 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
58769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
58769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
58772 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
58776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
58777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
58777 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
58777 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 5 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
58778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 31 (treeAggregate at SparkDl4jMultiLayer.java:598)
58778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 9 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
58778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 15 (treeAggregate at SparkDl4jMultiLayer.java:598)
58778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 14)
58778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 14)
58778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 15)
58778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 14)
58778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 14)
58778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
58778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 14 (MapPartitionsRDD[31] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
58778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 14)
58779 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20 stored as values in memory (estimated size 8.9 KB, free 366.1 MB)
58779 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_20 locally took  0 ms
58780 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_20 without replication took  1 ms
58780 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.1 MB)
58781 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_20_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
58781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_20_piece0
58781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_20_piece0
58781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_20_piece0 locally took  1 ms
58781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_20_piece0 without replication took  1 ms
58781 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
58781 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[31] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
58781 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 14.0 with 8 tasks
58782 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 14.0: 5
58782 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 14.0: NO_PREF, ANY
58782 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 0
58782 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 14.0 (TID 92, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
58783 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 14.0 (TID 93, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
58783 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 14.0 (TID 94, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
58783 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 14.0 (TID 95, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
58784 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 14.0 (TID 96, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
58784 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 14.0 (TID 97, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
58784 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 14.0 (TID 98, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
58785 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 14.0 (TID 99, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
58785 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 92 on executor id: 0 hostname: 192.168.1.4.
58785 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 93 on executor id: 0 hostname: 192.168.1.4.
58785 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 94 on executor id: 0 hostname: 192.168.1.4.
58785 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 95 on executor id: 0 hostname: 192.168.1.4.
58786 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 96 on executor id: 0 hostname: 192.168.1.4.
58786 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 97 on executor id: 0 hostname: 192.168.1.4.
58786 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 98 on executor id: 0 hostname: 192.168.1.4.
58786 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 99 on executor id: 0 hostname: 192.168.1.4.
58792 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_20_piece0 as bytes
58792 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_20_piece0 is StorageLevel(disk, memory, 1 replicas)
58794 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_20_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
58798 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_19_piece0 as bytes
58798 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_19_piece0 is StorageLevel(disk, memory, 1 replicas)
58800 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_19_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
58813 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_18_piece0 as bytes
58813 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_18_piece0 is StorageLevel(disk, memory, 1 replicas)
58815 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_18_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
59017 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 7
59017 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
59017 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 14.0 (TID 99) in 233 ms on 192.168.1.4 (executor 0) (1/8)
59017 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59149 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 6
59149 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 14.0 (TID 96) in 366 ms on 192.168.1.4 (executor 0) (2/8)
59149 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59152 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 5
59152 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 14.0 (TID 98) in 368 ms on 192.168.1.4 (executor 0) (3/8)
59152 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59154 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 4
59155 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 14.0 (TID 93) in 373 ms on 192.168.1.4 (executor 0) (4/8)
59155 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59166 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 3
59166 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 2
59166 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 14.0 (TID 95) in 383 ms on 192.168.1.4 (executor 0) (5/8)
59167 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 14.0 (TID 97) in 382 ms on 192.168.1.4 (executor 0) (6/8)
59167 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59167 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59171 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 1
59171 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 14.0 (TID 94) in 388 ms on 192.168.1.4 (executor 0) (7/8)
59171 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59196 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 0
59196 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 14.0 (TID 92) in 414 ms on 192.168.1.4 (executor 0) (8/8)
59196 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 14.0, whose tasks have all completed, from pool 
59196 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59196 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 14 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.414 s
59196 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
59196 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
59197 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 15)
59197 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
59197 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 6
59197 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 15)
59197 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
59197 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 15 (MapPartitionsRDD[33] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
59197 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 15)
59198 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
59198 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_21 locally took  1 ms
59198 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_21 without replication took  1 ms
59199 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
59199 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_21_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
59199 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_21_piece0
59199 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_21_piece0
59199 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_21_piece0 locally took  0 ms
59199 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_21_piece0 without replication took  0 ms
59200 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
59200 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
59200 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 15.0 with 2 tasks
59200 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 15.0: 6
59200 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 15.0: NODE_LOCAL, ANY
59201 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_15.0, runningTasks: 0
59201 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 15.0 (TID 100, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
59201 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 15.0 (TID 101, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
59201 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
59201 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 100 on executor id: 0 hostname: 192.168.1.4.
59201 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 101 on executor id: 0 hostname: 192.168.1.4.
59205 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_21_piece0 as bytes
59205 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_21_piece0 is StorageLevel(disk, memory, 1 replicas)
59207 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_21_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
59209 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 5 to 192.168.1.4:59114
59209 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 5 to 192.168.1.4:59114
59209 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 5
59209 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 5
59209 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 5 is 159 bytes
59214 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_15.0, runningTasks: 1
59214 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_15.0, runningTasks: 0
59215 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 15.0 (TID 101) in 14 ms on 192.168.1.4 (executor 0) (1/2)
59215 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 15.0 (TID 100) in 14 ms on 192.168.1.4 (executor 0) (2/2)
59216 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 15.0, whose tasks have all completed, from pool 
59216 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 15 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.016 s
59216 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 14, remaining stages = 1
59216 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 15, remaining stages = 0
59216 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 9 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.438883 s
59217 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 1: Accuracy = 0.00, F1 = NaN
59217 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 1
59217 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59218 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59219 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
59219 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
59220 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 10 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
59220 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 16 (count at ParameterAveragingTrainingMaster.java:325)
59220 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
59220 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
59221 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 16)
59221 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
59221 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 16 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
59221 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 16)
59222 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
59222 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_22 locally took  1 ms
59222 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_22 without replication took  1 ms
59223 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
59223 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_22_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
59223 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_22_piece0
59223 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_22_piece0
59223 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_22_piece0 locally took  0 ms
59223 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_22_piece0 without replication took  0 ms
59223 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
59224 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 16 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
59224 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 16.0 with 8 tasks
59224 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 16.0: 6
59224 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 16.0: PROCESS_LOCAL, NODE_LOCAL, ANY
59224 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 0
59225 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 16 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
59225 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 16.0 (TID 102, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
59226 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 16.0 (TID 103, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
59227 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 16.0 (TID 104, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
59227 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 16.0 (TID 105, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
59228 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 16.0 (TID 106, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
59229 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 16.0 (TID 107, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
59230 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 16.0 (TID 108, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
59231 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 16.0 (TID 109, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
59231 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 102 on executor id: 0 hostname: 192.168.1.4.
59231 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 103 on executor id: 0 hostname: 192.168.1.4.
59231 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 104 on executor id: 0 hostname: 192.168.1.4.
59231 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 105 on executor id: 0 hostname: 192.168.1.4.
59232 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 106 on executor id: 0 hostname: 192.168.1.4.
59232 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 107 on executor id: 0 hostname: 192.168.1.4.
59232 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 108 on executor id: 0 hostname: 192.168.1.4.
59232 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 109 on executor id: 0 hostname: 192.168.1.4.
59238 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_22_piece0 as bytes
59238 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_22_piece0 is StorageLevel(disk, memory, 1 replicas)
59240 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_22_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
59244 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 7
59244 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
59244 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
59245 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 6
59245 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 16.0 (TID 108) in 16 ms on 192.168.1.4 (executor 0) (1/8)
59245 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 5
59245 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 16.0 (TID 102) in 21 ms on 192.168.1.4 (executor 0) (2/8)
59245 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 16.0 (TID 109) in 15 ms on 192.168.1.4 (executor 0) (3/8)
59247 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 4
59247 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 16.0 (TID 107) in 19 ms on 192.168.1.4 (executor 0) (4/8)
59249 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 3
59249 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 16.0 (TID 105) in 22 ms on 192.168.1.4 (executor 0) (5/8)
59249 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 2
59249 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 16.0 (TID 106) in 22 ms on 192.168.1.4 (executor 0) (6/8)
59250 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 1
59250 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 16.0 (TID 103) in 25 ms on 192.168.1.4 (executor 0) (7/8)
59251 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 0
59251 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 16.0 (TID 104) in 25 ms on 192.168.1.4 (executor 0) (8/8)
59251 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 16.0, whose tasks have all completed, from pool 
59251 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 16 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.027 s
59251 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 16, remaining stages = 0
59251 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 10 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.031903 s
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
59253 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59254 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353
59255 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
59256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
59256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
59256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353)
59256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
59256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
59256 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353)
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
59257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59258 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
59258 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
59259 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 11 (collect at SparkUtils.java:353) with 8 output partitions
59259 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 17 (collect at SparkUtils.java:353)
59259 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
59259 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
59259 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 17)
59259 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
59259 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 17 (MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
59259 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 17)
59260 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
59260 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_23 locally took  0 ms
59260 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_23 without replication took  0 ms
59261 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.1 MB)
59261 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_23_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
59261 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_23_piece0
59261 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_23_piece0
59261 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_23_piece0 locally took  0 ms
59261 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_23_piece0 without replication took  0 ms
59261 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
59262 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 17 (MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
59262 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 17.0 with 8 tasks
59262 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 17.0: 6
59262 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 17.0: PROCESS_LOCAL, NODE_LOCAL, ANY
59262 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 0
59263 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 17 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
59263 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 17.0 (TID 110, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
59264 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 17.0 (TID 111, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
59264 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 17.0 (TID 112, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
59265 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 17.0 (TID 113, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
59266 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 17.0 (TID 114, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
59267 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 17.0 (TID 115, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
59268 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 17.0 (TID 116, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
59268 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 17.0 (TID 117, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
59269 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 110 on executor id: 0 hostname: 192.168.1.4.
59269 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 111 on executor id: 0 hostname: 192.168.1.4.
59269 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 112 on executor id: 0 hostname: 192.168.1.4.
59269 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 113 on executor id: 0 hostname: 192.168.1.4.
59270 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 114 on executor id: 0 hostname: 192.168.1.4.
59270 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 115 on executor id: 0 hostname: 192.168.1.4.
59270 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 116 on executor id: 0 hostname: 192.168.1.4.
59270 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 117 on executor id: 0 hostname: 192.168.1.4.
59277 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_23_piece0 as bytes
59277 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_23_piece0 is StorageLevel(disk, memory, 1 replicas)
59279 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_23_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
59284 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 7
59284 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
59284 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
59284 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 17.0 (TID 115) in 18 ms on 192.168.1.4 (executor 0) (1/8)
59286 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 6
59286 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 17.0 (TID 114) in 21 ms on 192.168.1.4 (executor 0) (2/8)
59287 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 5
59287 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 17.0 (TID 116) in 20 ms on 192.168.1.4 (executor 0) (3/8)
59289 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 4
59289 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 17.0 (TID 112) in 25 ms on 192.168.1.4 (executor 0) (4/8)
59290 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 3
59291 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 17.0 (TID 110) in 29 ms on 192.168.1.4 (executor 0) (5/8)
59291 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 2
59291 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 17.0 (TID 113) in 27 ms on 192.168.1.4 (executor 0) (6/8)
59294 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 1
59294 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 17.0 (TID 117) in 26 ms on 192.168.1.4 (executor 0) (7/8)
59295 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 0
59295 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 17.0 (TID 111) in 32 ms on 192.168.1.4 (executor 0) (8/8)
59296 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 17.0, whose tasks have all completed, from pool 
59296 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 17 (collect at SparkUtils.java:353) finished in 0.034 s
59296 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 17, remaining stages = 0
59296 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 11 finished: collect at SparkUtils.java:353, took 0.037491 s
59296 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59297 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59298 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59299 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59299 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59299 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59299 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
59299 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
59299 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 12 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
59299 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 18 (zipWithIndex at SparkUtils.java:391)
59299 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
59300 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
59300 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 18)
59300 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
59300 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 18 (MapPartitionsRDD[34] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
59300 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 18)
59301 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24 stored as values in memory (estimated size 2.2 KB, free 366.1 MB)
59301 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_24 locally took  0 ms
59301 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_24 without replication took  0 ms
59302 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.1 MB)
59302 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_24_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
59303 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_24_piece0
59303 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_24_piece0
59303 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_24_piece0 locally took  1 ms
59303 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_24_piece0 without replication took  1 ms
59303 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
59303 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 18 (MapPartitionsRDD[34] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
59303 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 18.0 with 7 tasks
59303 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 18.0: 6
59304 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 18.0: PROCESS_LOCAL, NODE_LOCAL, ANY
59304 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 0
59304 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 18 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
59305 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 18.0 (TID 118, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
59305 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 18.0 (TID 119, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
59306 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 18.0 (TID 120, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
59307 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 18.0 (TID 121, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
59308 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 18.0 (TID 122, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
59309 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 18.0 (TID 123, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
59309 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 18.0 (TID 124, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
59310 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
59310 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
59310 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 118 on executor id: 0 hostname: 192.168.1.4.
59310 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 119 on executor id: 0 hostname: 192.168.1.4.
59310 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 120 on executor id: 0 hostname: 192.168.1.4.
59311 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 121 on executor id: 0 hostname: 192.168.1.4.
59311 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 122 on executor id: 0 hostname: 192.168.1.4.
59311 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 123 on executor id: 0 hostname: 192.168.1.4.
59311 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 124 on executor id: 0 hostname: 192.168.1.4.
59316 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_24_piece0 as bytes
59316 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_24_piece0 is StorageLevel(disk, memory, 1 replicas)
59318 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_24_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
59324 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 7
59325 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 6
59325 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 18.0 (TID 123) in 17 ms on 192.168.1.4 (executor 0) (1/7)
59325 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 5
59325 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 18.0 (TID 122) in 18 ms on 192.168.1.4 (executor 0) (2/7)
59327 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 4
59327 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 18.0 (TID 120) in 22 ms on 192.168.1.4 (executor 0) (3/7)
59327 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 3
59327 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 18.0 (TID 118) in 23 ms on 192.168.1.4 (executor 0) (4/7)
59328 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 2
59329 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 18.0 (TID 124) in 19 ms on 192.168.1.4 (executor 0) (5/7)
59329 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 1
59329 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 18.0 (TID 121) in 23 ms on 192.168.1.4 (executor 0) (6/7)
59329 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 0
59329 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 18.0 (TID 119) in 24 ms on 192.168.1.4 (executor 0) (7/7)
59329 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 18.0, whose tasks have all completed, from pool 
59329 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 18 (zipWithIndex at SparkUtils.java:391) finished in 0.025 s
59329 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 18, remaining stages = 0
59330 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 12 finished: zipWithIndex at SparkUtils.java:391, took 0.030564 s
59330 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
59332 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
59332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
59332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
59332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
59335 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25 stored as values in memory (estimated size 31.4 KB, free 366.0 MB)
59335 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_25 locally took  2 ms
59335 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_25 without replication took  2 ms
59336 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.0 MB)
59336 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_25_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.2 MB)
59337 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_25_piece0
59337 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_25_piece0
59337 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_25_piece0 locally took  1 ms
59337 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_25_piece0 without replication took  1 ms
59337 [main] INFO org.apache.spark.SparkContext  - Created broadcast 25 from broadcast at ParameterAveragingTrainingMaster.java:259
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59337 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
59338 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59339 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59340 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59341 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59341 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59341 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59341 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
59341 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59342 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59343 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59344 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59347 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
59348 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
59349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
59349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
59349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
59349 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
59349 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 6 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
59349 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 37 (mapToPair at SparkUtils.java:391)
59349 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 42 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
59350 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 13 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
59350 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 21 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
59350 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 20)
59350 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 20)
59350 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 21)
59350 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 20)
59350 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 20)
59350 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 19)
59350 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 19)
59350 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
59350 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 19 (MapPartitionsRDD[37] at mapToPair at SparkUtils.java:391), which has no missing parents
59350 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 19)
59351 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
59351 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_26 locally took  0 ms
59351 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_26 without replication took  0 ms
59352 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
59352 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_26_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.2 MB)
59352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_26_piece0
59352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_26_piece0
59352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_26_piece0 locally took  0 ms
59352 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_26_piece0 without replication took  0 ms
59353 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
59353 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[37] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
59354 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 19.0 with 8 tasks
59354 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 19.0: 6
59354 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 19.0: PROCESS_LOCAL, NODE_LOCAL, ANY
59354 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 0
59355 [dispatcher-event-loop-1] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 19 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
59355 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 19.0 (TID 125, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
59356 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 19.0 (TID 126, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
59356 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 19.0 (TID 127, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
59357 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 19.0 (TID 128, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
59358 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 19.0 (TID 129, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
59359 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 19.0 (TID 130, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
59360 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 19.0 (TID 131, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
59360 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 19.0 (TID 132, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
59361 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 125 on executor id: 0 hostname: 192.168.1.4.
59361 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 126 on executor id: 0 hostname: 192.168.1.4.
59361 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 127 on executor id: 0 hostname: 192.168.1.4.
59362 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 128 on executor id: 0 hostname: 192.168.1.4.
59362 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 129 on executor id: 0 hostname: 192.168.1.4.
59362 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 130 on executor id: 0 hostname: 192.168.1.4.
59362 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 131 on executor id: 0 hostname: 192.168.1.4.
59362 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 132 on executor id: 0 hostname: 192.168.1.4.
59368 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_26_piece0 as bytes
59369 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_26_piece0 is StorageLevel(disk, memory, 1 replicas)
59370 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_26_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
59380 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 7
59380 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
59380 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
59380 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 19.0 (TID 127) in 24 ms on 192.168.1.4 (executor 0) (1/8)
59381 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59382 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 6
59382 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 19.0 (TID 132) in 22 ms on 192.168.1.4 (executor 0) (2/8)
59382 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 5
59382 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59382 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 4
59382 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 19.0 (TID 129) in 25 ms on 192.168.1.4 (executor 0) (3/8)
59382 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 19.0 (TID 131) in 23 ms on 192.168.1.4 (executor 0) (4/8)
59383 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59383 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59383 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 3
59383 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 19.0 (TID 130) in 25 ms on 192.168.1.4 (executor 0) (5/8)
59384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59387 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 2
59387 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 19.0 (TID 128) in 31 ms on 192.168.1.4 (executor 0) (6/8)
59387 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 1
59387 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59387 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 19.0 (TID 126) in 32 ms on 192.168.1.4 (executor 0) (7/8)
59388 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59389 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 0
59390 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 19.0 (TID 125) in 36 ms on 192.168.1.4 (executor 0) (8/8)
59390 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 19.0, whose tasks have all completed, from pool 
59390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59390 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 19 (mapToPair at SparkUtils.java:391) finished in 0.036 s
59390 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
59390 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
59390 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 20, ResultStage 21)
59390 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
59390 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 7
59390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 20)
59390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
59390 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 20 (MapPartitionsRDD[42] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
59390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 20)
59391 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27 stored as values in memory (estimated size 6.6 KB, free 366.0 MB)
59392 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_27 locally took  1 ms
59392 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_27 without replication took  1 ms
59400 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(18)
59400 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 18
59400 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 18
59401 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 18
59401 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 18
59401 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_18_piece0
59401 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.0 MB)
59401 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18_piece0 of size 1428 dropped from memory (free 383799343)
59401 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_27_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.2 MB)
59401 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_27_piece0
59401 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_27_piece0
59401 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_27_piece0 locally took  0 ms
59401 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_18_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.2 MB)
59402 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_27_piece0 without replication took  1 ms
59402 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_18_piece0
59402 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_18_piece0
59402 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_18
59402 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18 of size 8224 dropped from memory (free 383807567)
59402 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
59402 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 18, response is 0
59402 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[42] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
59402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 20.0 with 8 tasks
59403 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 20.0: 7
59403 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_18_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.4 MB)
59403 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 20.0: NODE_LOCAL, ANY
59403 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 0
59403 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 20.0 (TID 133, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
59404 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 20.0 (TID 134, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
59404 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 20.0 (TID 135, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
59404 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 20.0 (TID 136, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
59404 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 20.0 (TID 137, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
59404 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 20.0 (TID 138, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
59404 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 18
59404 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(11)
59404 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 11
59404 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 20.0 (TID 139, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
59404 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 11
59404 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 20.0 (TID 140, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
59404 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 133 on executor id: 0 hostname: 192.168.1.4.
59404 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 11
59404 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 11
59405 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 134 on executor id: 0 hostname: 192.168.1.4.
59405 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_11
59405 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 135 on executor id: 0 hostname: 192.168.1.4.
59405 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11 of size 1448 dropped from memory (free 383809015)
59405 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_11_piece0
59405 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 136 on executor id: 0 hostname: 192.168.1.4.
59405 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11_piece0 of size 1006 dropped from memory (free 383810021)
59405 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 137 on executor id: 0 hostname: 192.168.1.4.
59405 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 138 on executor id: 0 hostname: 192.168.1.4.
59405 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 139 on executor id: 0 hostname: 192.168.1.4.
59405 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_11_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.2 MB)
59405 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 140 on executor id: 0 hostname: 192.168.1.4.
59405 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_11_piece0
59405 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_11_piece0
59405 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 11, response is 0
59405 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59406 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_11_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
59409 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 11
59410 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(14)
59410 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 14
59410 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 14
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 14
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 14
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_14_piece0
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14_piece0 of size 5326 dropped from memory (free 383815347)
59410 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_14_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.2 MB)
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_14_piece0
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_14_piece0
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_14
59410 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14 of size 31656 dropped from memory (free 383847003)
59411 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 14, response is 0
59411 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59412 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_27_piece0 as bytes
59412 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_27_piece0 is StorageLevel(disk, memory, 1 replicas)
59412 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_14_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
59413 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 14
59413 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(22)
59413 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 22
59413 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 22
59413 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 22
59413 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 22
59414 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_22_piece0
59414 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22_piece0 of size 1006 dropped from memory (free 383848009)
59414 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_27_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
59414 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_22_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.3 MB)
59414 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_22_piece0
59414 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_22_piece0
59414 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_22
59414 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22 of size 1448 dropped from memory (free 383849457)
59414 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 22, response is 0
59415 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59415 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_22_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
59416 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 22
59416 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(1)
59417 [dispatcher-event-loop-4] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 7 to 192.168.1.4:59114
59417 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 1
59417 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 7 to 192.168.1.4:59114
59417 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 7
59417 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 7
59417 [map-output-dispatcher-6] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 7 is 186 bytes
59419 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 1
59420 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 1, response is true
59420 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
59420 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 1
59420 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(8)
59420 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 8
59420 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 8
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 8
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 8
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_8_piece0
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8_piece0 of size 2531 dropped from memory (free 383851988)
59421 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_8_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.3 MB)
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_8_piece0
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_8_piece0
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_8
59421 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8 of size 27528 dropped from memory (free 383879516)
59421 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 8, response is 0
59422 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59424 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_25_piece0 as bytes
59424 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_8_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
59424 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_25_piece0 is StorageLevel(disk, memory, 1 replicas)
59426 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_25_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
59426 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 8
59426 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(24)
59426 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 24
59426 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 24
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 24
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 24
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_24
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24 of size 2216 dropped from memory (free 383881732)
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_24_piece0
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24_piece0 of size 1460 dropped from memory (free 383883192)
59427 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_24_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_24_piece0
59427 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_24_piece0
59427 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 24, response is 0
59427 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59428 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_24_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
59429 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 24
59429 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(23)
59429 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 23
59429 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 23
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 23
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 23
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_23
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23 of size 2504 dropped from memory (free 383885696)
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_23_piece0
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23_piece0 of size 1570 dropped from memory (free 383887266)
59429 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_23_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.3 MB)
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_23_piece0
59429 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_23_piece0
59429 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 23, response is 0
59430 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59430 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_23_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.4 MB)
59431 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 23
59431 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(19)
59431 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 19
59431 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 19
59431 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 19
59431 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 19
59431 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_19_piece0
59431 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19_piece0 of size 2531 dropped from memory (free 383889797)
59432 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_19_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.3 MB)
59432 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_19_piece0
59432 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_19_piece0
59432 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_19
59432 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19 of size 27976 dropped from memory (free 383917773)
59432 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 19, response is 0
59432 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59432 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_19_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
59433 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 19
59433 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(13)
59433 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 13
59433 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 13
59433 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 13
59433 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 13
59433 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_13_piece0
59434 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13_piece0 of size 1460 dropped from memory (free 383919233)
59434 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_13_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
59434 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_13_piece0
59434 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_13_piece0
59434 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_13
59434 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13 of size 2216 dropped from memory (free 383921449)
59434 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 13, response is 0
59434 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59434 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_13_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
59435 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 13
59435 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(20)
59435 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 20
59435 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 20
59435 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 20
59435 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 20
59435 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_20
59436 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20 of size 9088 dropped from memory (free 383930537)
59436 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_20_piece0
59436 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20_piece0 of size 4134 dropped from memory (free 383934671)
59436 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_20_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.3 MB)
59436 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_20_piece0
59436 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_20_piece0
59436 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 20, response is 0
59436 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59437 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_20_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
59437 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 20
59437 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(3)
59437 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 3
59437 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 3
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 3
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 3
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_3_piece0
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3_piece0 of size 5149 dropped from memory (free 383939820)
59438 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_3_piece0 on 192.168.1.4:59108 in memory (size: 5.0 KB, free: 366.3 MB)
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_3_piece0
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_3_piece0
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_3
59438 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3 of size 33744 dropped from memory (free 383973564)
59438 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 3, response is 0
59438 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59439 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_3_piece0 on 192.168.1.4:59116 in memory (size: 5.0 KB, free: 365.4 MB)
59439 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 3
59439 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(17)
59439 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 17
59440 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 17
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 17
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 17
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_17_piece0
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17_piece0 of size 2135 dropped from memory (free 383975699)
59440 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_17_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_17_piece0
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_17_piece0
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_17
59440 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17 of size 3672 dropped from memory (free 383979371)
59440 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 17, response is 0
59440 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59441 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_17_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
59441 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 17
59442 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(7)
59442 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 7
59442 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 7
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 7
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 7
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_7
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7 of size 8224 dropped from memory (free 383987595)
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_7_piece0
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7_piece0 of size 1428 dropped from memory (free 383989023)
59442 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_7_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.3 MB)
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_7_piece0
59442 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_7_piece0
59442 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 7, response is 0
59442 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59443 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_7_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.4 MB)
59443 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 7
59443 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(16)
59443 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 16
59443 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 16
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 16
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 16
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_16_piece0
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16_piece0 of size 3632 dropped from memory (free 383992655)
59444 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_16_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_16_piece0
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_16_piece0
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_16
59444 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16 of size 6712 dropped from memory (free 383999367)
59444 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 16, response is 0
59444 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59445 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_16_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.4 MB)
59445 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 16
59445 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(5)
59446 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 5
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 5
59446 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 5
59446 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 5, response is true
59446 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(2)
59446 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 2
59446 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
59446 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 2
59446 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 2
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 2, response is true
59446 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(21)
59446 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 21
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
59446 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 21
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 21
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 21
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_21
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21 of size 3656 dropped from memory (free 384003023)
59446 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_21_piece0
59447 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21_piece0 of size 2122 dropped from memory (free 384005145)
59447 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_21_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
59447 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_21_piece0
59447 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_21_piece0
59447 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 21, response is 0
59447 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59447 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_21_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
59449 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 21
59449 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(3)
59449 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 3
59449 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 3
59449 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 3
59449 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 3, response is true
59449 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(15)
59449 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 15
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
59450 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 15
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 15
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 15
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_15
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15 of size 3600 dropped from memory (free 384008745)
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_15_piece0
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15_piece0 of size 2197 dropped from memory (free 384010942)
59450 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_15_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_15_piece0
59450 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_15_piece0
59450 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 15, response is 0
59451 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59451 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_15_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
59452 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 15
59452 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(0)
59452 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 0
59452 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 0
59452 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 0, response is true
59452 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 0
59452 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(9)
59452 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
59453 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 9
59453 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 9
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 9
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 9
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_9_piece0
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9_piece0 of size 4136 dropped from memory (free 384015078)
59453 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_9_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.3 MB)
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_9_piece0
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_9_piece0
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_9
59453 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9 of size 9088 dropped from memory (free 384024166)
59453 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 9, response is 0
59454 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59454 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_9_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
59455 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 9
59455 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(10)
59455 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 10
59455 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 10
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 10
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 10
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_10_piece0
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10_piece0 of size 2120 dropped from memory (free 384026286)
59456 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_10_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_10_piece0
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_10_piece0
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_10
59456 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10 of size 3656 dropped from memory (free 384029942)
59456 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 10, response is 0
59456 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59457 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_10_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
59458 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 10
59458 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(6)
59458 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 6
59458 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 6
59458 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 6
59458 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 6
59458 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_6
59458 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6 of size 3672 dropped from memory (free 384033614)
59458 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_6_piece0
59458 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6_piece0 of size 2134 dropped from memory (free 384035748)
59459 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_6_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
59459 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_6_piece0
59459 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_6_piece0
59459 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 6, response is 0
59459 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59459 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_6_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
59460 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 6
59460 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(12)
59460 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 12
59460 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 12
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 12
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 12
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_12
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12 of size 2504 dropped from memory (free 384038252)
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_12_piece0
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12_piece0 of size 1570 dropped from memory (free 384039822)
59461 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_12_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.3 MB)
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_12_piece0
59461 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_12_piece0
59461 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 12, response is 0
59461 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
59462 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_12_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.4 MB)
59462 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 12
59463 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(4)
59463 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 4
59463 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 4
59463 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 4
59463 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 4, response is true
59463 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
60321 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 8
61147 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 7
61147 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
61147 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 20.0 (TID 138) in 1743 ms on 192.168.1.4 (executor 0) (1/8)
61148 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61323 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 7
62325 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 7
62890 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 6
62890 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 20.0 (TID 139) in 3486 ms on 192.168.1.4 (executor 0) (2/8)
62891 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
62894 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 5
62894 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 20.0 (TID 140) in 3490 ms on 192.168.1.4 (executor 0) (3/8)
62894 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63325 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 5
63372 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 4
63373 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 20.0 (TID 135) in 3969 ms on 192.168.1.4 (executor 0) (4/8)
63373 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63382 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 3
63382 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 20.0 (TID 137) in 3978 ms on 192.168.1.4 (executor 0) (5/8)
63383 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63393 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 2
63393 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 20.0 (TID 134) in 3990 ms on 192.168.1.4 (executor 0) (6/8)
63394 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63401 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 1
63401 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 0
63402 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 20.0 (TID 136) in 3997 ms on 192.168.1.4 (executor 0) (7/8)
63402 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 20.0 (TID 133) in 3999 ms on 192.168.1.4 (executor 0) (8/8)
63402 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 20.0, whose tasks have all completed, from pool 
63402 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63402 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 20 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.999 s
63402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
63402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
63402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 21)
63402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
63402 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 8
63402 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 21)
63402 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
63402 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 21 (MapPartitionsRDD[44] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
63402 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 21)
63403 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
63403 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_28 locally took  0 ms
63403 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_28 without replication took  0 ms
63404 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
63404 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_28_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
63404 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_28_piece0
63404 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_28_piece0
63404 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_28_piece0 locally took  0 ms
63404 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_28_piece0 without replication took  0 ms
63405 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 28 from broadcast at DAGScheduler.scala:1006
63405 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[44] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
63405 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 21.0 with 2 tasks
63405 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 21.0: 8
63405 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 21.0: NODE_LOCAL, ANY
63406 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_21.0, runningTasks: 0
63406 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 21.0 (TID 141, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
63406 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 21.0 (TID 142, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
63406 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
63406 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 141 on executor id: 0 hostname: 192.168.1.4.
63406 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 142 on executor id: 0 hostname: 192.168.1.4.
63410 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_28_piece0 as bytes
63410 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_28_piece0 is StorageLevel(disk, memory, 1 replicas)
63411 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_28_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
63413 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 6 to 192.168.1.4:59114
63413 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 6 to 192.168.1.4:59114
63413 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 6
63413 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 6
63413 [map-output-dispatcher-7] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 6 is 159 bytes
63472 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_21.0, runningTasks: 1
63473 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_21.0, runningTasks: 0
63473 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 21.0 (TID 141) in 67 ms on 192.168.1.4 (executor 0) (1/2)
63473 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 21.0 (TID 142) in 67 ms on 192.168.1.4 (executor 0) (2/2)
63473 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 21.0, whose tasks have all completed, from pool 
63473 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 21 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.068 s
63474 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 20, remaining stages = 2
63474 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 19, remaining stages = 1
63474 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 21, remaining stages = 0
63474 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 13 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.125126 s
63475 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
63476 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
63476 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_29 locally took  0 ms
63476 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_29 without replication took  0 ms
63477 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
63477 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_29_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
63477 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_29_piece0
63477 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_29_piece0
63477 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_29_piece0 locally took  0 ms
63478 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_29_piece0 without replication took  1 ms
63478 [main] INFO org.apache.spark.SparkContext  - Created broadcast 29 from broadcast at SparkDl4jMultiLayer.java:595
63479 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
63479 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_30 locally took  1 ms
63479 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_30 without replication took  1 ms
63480 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
63480 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_30_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
63480 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_30_piece0
63480 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_30_piece0
63480 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_30_piece0 locally took  0 ms
63480 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_30_piece0 without replication took  0 ms
63481 [main] INFO org.apache.spark.SparkContext  - Created broadcast 30 from broadcast at SparkDl4jMultiLayer.java:596
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
63482 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63483 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63484 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63485 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63485 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63485 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
63485 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63486 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63487 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63488 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63489 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63490 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63490 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63490 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63490 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
63490 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
63491 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63492 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
63492 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
63493 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 8 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
63493 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 47 (treeAggregate at SparkDl4jMultiLayer.java:598)
63493 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 14 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
63493 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 23 (treeAggregate at SparkDl4jMultiLayer.java:598)
63493 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 22)
63493 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 22)
63493 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 23)
63493 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 22)
63493 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 22)
63493 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
63493 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 22 (MapPartitionsRDD[47] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
63493 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 22)
63495 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31 stored as values in memory (estimated size 8.9 KB, free 366.2 MB)
63495 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_31 locally took  1 ms
63495 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_31 without replication took  1 ms
63496 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.2 MB)
63496 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_31_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
63496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_31_piece0
63496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_31_piece0
63496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_31_piece0 locally took  0 ms
63496 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_31_piece0 without replication took  0 ms
63496 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 31 from broadcast at DAGScheduler.scala:1006
63497 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[47] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
63497 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 22.0 with 8 tasks
63497 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 22.0: 8
63497 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 22.0: NO_PREF, ANY
63497 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 0
63497 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 22.0 (TID 143, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
63498 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 22.0 (TID 144, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
63498 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 22.0 (TID 145, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
63498 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 22.0 (TID 146, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
63499 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 22.0 (TID 147, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
63499 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 22.0 (TID 148, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
63499 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 22.0 (TID 149, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
63500 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 22.0 (TID 150, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
63500 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 143 on executor id: 0 hostname: 192.168.1.4.
63500 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 144 on executor id: 0 hostname: 192.168.1.4.
63500 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 145 on executor id: 0 hostname: 192.168.1.4.
63500 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 146 on executor id: 0 hostname: 192.168.1.4.
63501 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 147 on executor id: 0 hostname: 192.168.1.4.
63501 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 148 on executor id: 0 hostname: 192.168.1.4.
63501 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 149 on executor id: 0 hostname: 192.168.1.4.
63501 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 150 on executor id: 0 hostname: 192.168.1.4.
63507 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_31_piece0 as bytes
63507 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_31_piece0 is StorageLevel(disk, memory, 1 replicas)
63508 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_31_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
63514 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_30_piece0 as bytes
63514 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_30_piece0 is StorageLevel(disk, memory, 1 replicas)
63516 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_30_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
63551 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_29_piece0 as bytes
63551 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_29_piece0 is StorageLevel(disk, memory, 1 replicas)
63552 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_29_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
63656 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 7
63657 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
63657 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 22.0 (TID 150) in 158 ms on 192.168.1.4 (executor 0) (1/8)
63657 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63738 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 6
63738 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 22.0 (TID 148) in 239 ms on 192.168.1.4 (executor 0) (2/8)
63738 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63757 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 5
63757 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 22.0 (TID 149) in 258 ms on 192.168.1.4 (executor 0) (3/8)
63758 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63796 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 4
63796 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 22.0 (TID 146) in 298 ms on 192.168.1.4 (executor 0) (4/8)
63796 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63809 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 3
63809 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 22.0 (TID 147) in 311 ms on 192.168.1.4 (executor 0) (5/8)
63809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63872 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 2
63873 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 22.0 (TID 145) in 374 ms on 192.168.1.4 (executor 0) (6/8)
63873 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63929 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 1
63929 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 22.0 (TID 144) in 432 ms on 192.168.1.4 (executor 0) (7/8)
63929 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63929 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 0
63930 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 22.0 (TID 143) in 433 ms on 192.168.1.4 (executor 0) (8/8)
63930 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 22.0, whose tasks have all completed, from pool 
63930 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
63930 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 22 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.433 s
63930 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
63930 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
63930 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 23)
63930 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
63930 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 9
63930 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 23)
63930 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
63930 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 23 (MapPartitionsRDD[49] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
63930 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 23)
63931 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
63931 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_32 locally took  0 ms
63931 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_32 without replication took  0 ms
63932 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
63932 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_32_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
63933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_32_piece0
63933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_32_piece0
63933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_32_piece0 locally took  1 ms
63933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_32_piece0 without replication took  1 ms
63933 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 32 from broadcast at DAGScheduler.scala:1006
63933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[49] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
63933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 23.0 with 2 tasks
63933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 23.0: 9
63933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 23.0: NODE_LOCAL, ANY
63933 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_23.0, runningTasks: 0
63934 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 23.0 (TID 151, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
63934 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 23.0 (TID 152, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
63934 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
63934 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 151 on executor id: 0 hostname: 192.168.1.4.
63934 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 152 on executor id: 0 hostname: 192.168.1.4.
63938 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_32_piece0 as bytes
63938 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_32_piece0 is StorageLevel(disk, memory, 1 replicas)
63939 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_32_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
63943 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 8 to 192.168.1.4:59114
63943 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 8 to 192.168.1.4:59114
63944 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 8
63944 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 8
63944 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 8 is 159 bytes
63948 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_23.0, runningTasks: 1
63948 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_23.0, runningTasks: 0
63948 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 23.0 (TID 152) in 14 ms on 192.168.1.4 (executor 0) (1/2)
63949 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 23.0 (TID 151) in 15 ms on 192.168.1.4 (executor 0) (2/2)
63949 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 23.0, whose tasks have all completed, from pool 
63949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 23 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.016 s
63949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 23, remaining stages = 1
63949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 22, remaining stages = 0
63949 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 14 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.457174 s
63950 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 2: Accuracy = 0.00, F1 = NaN
63950 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 2
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63950 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63951 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
63951 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
63952 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 15 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
63952 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 24 (count at ParameterAveragingTrainingMaster.java:325)
63952 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
63952 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
63952 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 24)
63952 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
63952 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 24 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
63952 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 24)
63953 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
63953 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_33 locally took  0 ms
63953 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_33 without replication took  0 ms
63954 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
63954 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_33_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
63954 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_33_piece0
63954 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_33_piece0
63954 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_33_piece0 locally took  0 ms
63954 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_33_piece0 without replication took  0 ms
63954 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 33 from broadcast at DAGScheduler.scala:1006
63954 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 24 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
63954 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 24.0 with 8 tasks
63955 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 24.0: 9
63955 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 24.0: PROCESS_LOCAL, NODE_LOCAL, ANY
63955 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 0
63956 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 24 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
63956 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 24.0 (TID 153, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
63956 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 24.0 (TID 154, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
63957 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 24.0 (TID 155, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
63958 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 24.0 (TID 156, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
63959 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 24.0 (TID 157, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
63960 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 24.0 (TID 158, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
63960 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 24.0 (TID 159, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
63961 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 24.0 (TID 160, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
63962 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 153 on executor id: 0 hostname: 192.168.1.4.
63962 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 154 on executor id: 0 hostname: 192.168.1.4.
63962 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 155 on executor id: 0 hostname: 192.168.1.4.
63962 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 156 on executor id: 0 hostname: 192.168.1.4.
63962 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 157 on executor id: 0 hostname: 192.168.1.4.
63963 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 158 on executor id: 0 hostname: 192.168.1.4.
63963 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 159 on executor id: 0 hostname: 192.168.1.4.
63963 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 160 on executor id: 0 hostname: 192.168.1.4.
63968 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_33_piece0 as bytes
63969 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_33_piece0 is StorageLevel(disk, memory, 1 replicas)
63970 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_33_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
63975 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 7
63975 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
63975 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
63975 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 6
63976 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 24.0 (TID 158) in 17 ms on 192.168.1.4 (executor 0) (1/8)
63976 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 24.0 (TID 156) in 19 ms on 192.168.1.4 (executor 0) (2/8)
63976 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 5
63976 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 24.0 (TID 157) in 18 ms on 192.168.1.4 (executor 0) (3/8)
63976 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 4
63976 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 24.0 (TID 160) in 16 ms on 192.168.1.4 (executor 0) (4/8)
63976 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 3
63976 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 24.0 (TID 159) in 16 ms on 192.168.1.4 (executor 0) (5/8)
63978 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 2
63978 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 24.0 (TID 153) in 23 ms on 192.168.1.4 (executor 0) (6/8)
63980 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 1
63980 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 24.0 (TID 155) in 23 ms on 192.168.1.4 (executor 0) (7/8)
63980 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 0
63980 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 24.0 (TID 154) in 24 ms on 192.168.1.4 (executor 0) (8/8)
63980 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 24.0, whose tasks have all completed, from pool 
63980 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 24 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.025 s
63980 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 24, remaining stages = 0
63980 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 15 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.028845 s
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63981 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
63982 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63982 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
63983 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
63984 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353)
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
63985 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353)
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
63986 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
63987 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
63987 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
63987 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
63987 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
63987 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
63987 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 16 (collect at SparkUtils.java:353) with 8 output partitions
63987 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 25 (collect at SparkUtils.java:353)
63987 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
63988 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
63988 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 25)
63988 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
63988 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 25 (MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
63988 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 25)
63989 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
63989 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_34 locally took  0 ms
63989 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_34 without replication took  0 ms
63990 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
63990 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_34_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
63990 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_34_piece0
63990 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_34_piece0
63990 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_34_piece0 locally took  0 ms
63990 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_34_piece0 without replication took  0 ms
63990 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 34 from broadcast at DAGScheduler.scala:1006
63991 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 25 (MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
63991 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 25.0 with 8 tasks
63991 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 25.0: 9
63991 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 25.0: PROCESS_LOCAL, NODE_LOCAL, ANY
63991 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 0
63992 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 25 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
63992 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 25.0 (TID 161, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
63993 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 25.0 (TID 162, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
63993 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 25.0 (TID 163, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
63994 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 25.0 (TID 164, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
63995 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 25.0 (TID 165, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
63996 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 25.0 (TID 166, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
63997 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 25.0 (TID 167, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
63997 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 25.0 (TID 168, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
63998 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 161 on executor id: 0 hostname: 192.168.1.4.
63998 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 162 on executor id: 0 hostname: 192.168.1.4.
63998 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 163 on executor id: 0 hostname: 192.168.1.4.
63998 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 164 on executor id: 0 hostname: 192.168.1.4.
63999 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 165 on executor id: 0 hostname: 192.168.1.4.
63999 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 166 on executor id: 0 hostname: 192.168.1.4.
63999 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 167 on executor id: 0 hostname: 192.168.1.4.
64000 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 168 on executor id: 0 hostname: 192.168.1.4.
64005 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_34_piece0 as bytes
64005 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_34_piece0 is StorageLevel(disk, memory, 1 replicas)
64007 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_34_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
64012 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 7
64012 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
64012 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
64013 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 6
64013 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 5
64013 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 25.0 (TID 164) in 20 ms on 192.168.1.4 (executor 0) (1/8)
64013 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 4
64014 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 3
64014 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 25.0 (TID 166) in 19 ms on 192.168.1.4 (executor 0) (2/8)
64014 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 25.0 (TID 167) in 18 ms on 192.168.1.4 (executor 0) (3/8)
64014 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 25.0 (TID 165) in 20 ms on 192.168.1.4 (executor 0) (4/8)
64014 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 25.0 (TID 168) in 17 ms on 192.168.1.4 (executor 0) (5/8)
64018 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 2
64018 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 25.0 (TID 161) in 27 ms on 192.168.1.4 (executor 0) (6/8)
64018 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 1
64019 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 25.0 (TID 162) in 27 ms on 192.168.1.4 (executor 0) (7/8)
64019 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 0
64019 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 25.0 (TID 163) in 26 ms on 192.168.1.4 (executor 0) (8/8)
64019 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 25.0, whose tasks have all completed, from pool 
64019 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 25 (collect at SparkUtils.java:353) finished in 0.028 s
64019 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 25, remaining stages = 0
64019 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 16 finished: collect at SparkUtils.java:353, took 0.032484 s
64020 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64021 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64022 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64023 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64023 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64023 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
64023 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
64023 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 17 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
64023 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 26 (zipWithIndex at SparkUtils.java:391)
64023 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
64024 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
64024 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 26)
64024 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
64024 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 26 (MapPartitionsRDD[50] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
64024 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 26)
64025 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
64025 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_35 locally took  1 ms
64025 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_35 without replication took  1 ms
64026 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
64026 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_35_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
64026 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_35_piece0
64026 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_35_piece0
64026 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_35_piece0 locally took  1 ms
64026 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_35_piece0 without replication took  1 ms
64026 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 35 from broadcast at DAGScheduler.scala:1006
64027 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 26 (MapPartitionsRDD[50] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
64027 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 26.0 with 7 tasks
64027 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 26.0: 9
64027 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 26.0: PROCESS_LOCAL, NODE_LOCAL, ANY
64027 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 0
64028 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 26 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
64028 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 26.0 (TID 169, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
64030 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 26.0 (TID 170, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
64031 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 26.0 (TID 171, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
64032 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 26.0 (TID 172, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
64033 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 26.0 (TID 173, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
64034 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 26.0 (TID 174, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
64035 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 26.0 (TID 175, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
64035 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
64036 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
64036 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 169 on executor id: 0 hostname: 192.168.1.4.
64036 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 170 on executor id: 0 hostname: 192.168.1.4.
64036 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 171 on executor id: 0 hostname: 192.168.1.4.
64036 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 172 on executor id: 0 hostname: 192.168.1.4.
64037 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 173 on executor id: 0 hostname: 192.168.1.4.
64037 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 174 on executor id: 0 hostname: 192.168.1.4.
64037 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 175 on executor id: 0 hostname: 192.168.1.4.
64043 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_35_piece0 as bytes
64043 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_35_piece0 is StorageLevel(disk, memory, 1 replicas)
64047 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_35_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
64051 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 6
64051 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 5
64051 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 26.0 (TID 173) in 19 ms on 192.168.1.4 (executor 0) (1/7)
64051 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 26.0 (TID 174) in 18 ms on 192.168.1.4 (executor 0) (2/7)
64051 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 4
64051 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 26.0 (TID 175) in 16 ms on 192.168.1.4 (executor 0) (3/7)
64057 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 3
64057 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 26.0 (TID 171) in 27 ms on 192.168.1.4 (executor 0) (4/7)
64058 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 2
64058 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 26.0 (TID 172) in 27 ms on 192.168.1.4 (executor 0) (5/7)
64058 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 1
64059 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 26.0 (TID 169) in 31 ms on 192.168.1.4 (executor 0) (6/7)
64062 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 0
64062 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 26.0 (TID 170) in 34 ms on 192.168.1.4 (executor 0) (7/7)
64062 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 26.0, whose tasks have all completed, from pool 
64062 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 26 (zipWithIndex at SparkUtils.java:391) finished in 0.035 s
64062 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 26, remaining stages = 0
64062 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 17 finished: zipWithIndex at SparkUtils.java:391, took 0.039538 s
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64063 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64064 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64064 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64064 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64064 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64065 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64066 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64066 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64066 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64066 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
64068 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36 stored as values in memory (estimated size 30.9 KB, free 366.1 MB)
64068 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_36 locally took  1 ms
64068 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_36 without replication took  1 ms
64069 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
64069 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_36_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.3 MB)
64069 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_36_piece0
64069 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_36_piece0
64069 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_36_piece0 locally took  0 ms
64069 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_36_piece0 without replication took  0 ms
64070 [main] INFO org.apache.spark.SparkContext  - Created broadcast 36 from broadcast at ParameterAveragingTrainingMaster.java:259
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
64074 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
64076 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64077 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64078 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64078 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64078 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
64078 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
64079 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64081 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64081 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64081 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
64083 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
64086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
64086 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
64087 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 9 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
64087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 53 (mapToPair at SparkUtils.java:391)
64087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 58 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
64087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 18 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
64087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 29 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
64087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 28)
64087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 28)
64087 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 29)
64087 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 28)
64087 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 28)
64087 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 27)
64087 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 27)
64088 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
64088 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 27 (MapPartitionsRDD[53] at mapToPair at SparkUtils.java:391), which has no missing parents
64088 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 27)
64089 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
64089 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_37 locally took  1 ms
64089 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_37 without replication took  1 ms
64090 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
64090 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_37_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
64090 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_37_piece0
64090 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_37_piece0
64090 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_37_piece0 locally took  1 ms
64090 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_37_piece0 without replication took  1 ms
64090 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 37 from broadcast at DAGScheduler.scala:1006
64090 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[53] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
64090 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 27.0 with 8 tasks
64091 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 27.0: 9
64091 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 27.0: PROCESS_LOCAL, NODE_LOCAL, ANY
64091 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 0
64092 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 27 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
64092 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 27.0 (TID 176, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
64092 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 27.0 (TID 177, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
64093 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 27.0 (TID 178, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
64095 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 27.0 (TID 179, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
64095 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 27.0 (TID 180, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
64097 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 27.0 (TID 181, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
64098 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 27.0 (TID 182, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
64099 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 27.0 (TID 183, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
64100 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 176 on executor id: 0 hostname: 192.168.1.4.
64100 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 177 on executor id: 0 hostname: 192.168.1.4.
64100 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 178 on executor id: 0 hostname: 192.168.1.4.
64100 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 179 on executor id: 0 hostname: 192.168.1.4.
64101 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 180 on executor id: 0 hostname: 192.168.1.4.
64101 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 181 on executor id: 0 hostname: 192.168.1.4.
64101 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 182 on executor id: 0 hostname: 192.168.1.4.
64101 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 183 on executor id: 0 hostname: 192.168.1.4.
64108 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_37_piece0 as bytes
64108 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_37_piece0 is StorageLevel(disk, memory, 1 replicas)
64109 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_37_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
64123 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 7
64123 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
64123 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
64123 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 6
64123 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 27.0 (TID 181) in 28 ms on 192.168.1.4 (executor 0) (1/8)
64123 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 27.0 (TID 183) in 25 ms on 192.168.1.4 (executor 0) (2/8)
64124 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 27.0 (TID 178) in 31 ms on 192.168.1.4 (executor 0) (3/8)
64124 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64124 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64124 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64124 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 5
64134 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 4
64134 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 27.0 (TID 180) in 39 ms on 192.168.1.4 (executor 0) (4/8)
64135 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 3
64135 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64135 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 27.0 (TID 182) in 38 ms on 192.168.1.4 (executor 0) (5/8)
64135 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64153 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 2
64154 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 27.0 (TID 177) in 62 ms on 192.168.1.4 (executor 0) (6/8)
64154 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64163 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 1
64163 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 27.0 (TID 176) in 72 ms on 192.168.1.4 (executor 0) (7/8)
64163 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64167 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 0
64167 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 27.0 (TID 179) in 74 ms on 192.168.1.4 (executor 0) (8/8)
64167 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 27.0, whose tasks have all completed, from pool 
64167 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64167 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 27 (mapToPair at SparkUtils.java:391) finished in 0.076 s
64167 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
64167 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
64167 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 28, ResultStage 29)
64167 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
64167 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 10
64167 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 28)
64168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
64168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 28 (MapPartitionsRDD[58] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
64168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 28)
64170 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
64170 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_38 locally took  1 ms
64170 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_38 without replication took  1 ms
64170 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
64171 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_38_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.3 MB)
64171 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_38_piece0
64171 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_38_piece0
64171 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_38_piece0 locally took  1 ms
64171 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_38_piece0 without replication took  1 ms
64171 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 38 from broadcast at DAGScheduler.scala:1006
64172 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[58] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
64172 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 28.0 with 8 tasks
64172 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 28.0: 10
64172 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 28.0: NODE_LOCAL, ANY
64172 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 0
64172 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 28.0 (TID 184, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
64172 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 28.0 (TID 185, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
64172 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 28.0 (TID 186, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
64172 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 28.0 (TID 187, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
64173 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 28.0 (TID 188, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
64173 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 28.0 (TID 189, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
64173 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 28.0 (TID 190, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
64173 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 28.0 (TID 191, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
64173 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 184 on executor id: 0 hostname: 192.168.1.4.
64173 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 185 on executor id: 0 hostname: 192.168.1.4.
64173 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 186 on executor id: 0 hostname: 192.168.1.4.
64173 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 187 on executor id: 0 hostname: 192.168.1.4.
64173 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 188 on executor id: 0 hostname: 192.168.1.4.
64174 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 189 on executor id: 0 hostname: 192.168.1.4.
64174 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 190 on executor id: 0 hostname: 192.168.1.4.
64174 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 191 on executor id: 0 hostname: 192.168.1.4.
64178 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_38_piece0 as bytes
64178 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_38_piece0 is StorageLevel(disk, memory, 1 replicas)
64180 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_38_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
64183 [dispatcher-event-loop-2] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 10 to 192.168.1.4:59114
64183 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 10 to 192.168.1.4:59114
64183 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 10
64183 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 10
64183 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 10 is 186 bytes
64187 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_36_piece0 as bytes
64187 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_36_piece0 is StorageLevel(disk, memory, 1 replicas)
64189 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_36_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
64321 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 8
65321 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 8
66070 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 7
66071 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
66071 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 28.0 (TID 191) in 1898 ms on 192.168.1.4 (executor 0) (1/8)
66071 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66321 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 7
67321 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 7
67638 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 6
67638 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 28.0 (TID 190) in 3465 ms on 192.168.1.4 (executor 0) (2/8)
67638 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
67656 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 5
67656 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 28.0 (TID 189) in 3483 ms on 192.168.1.4 (executor 0) (3/8)
67656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68144 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 4
68144 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 28.0 (TID 186) in 3972 ms on 192.168.1.4 (executor 0) (4/8)
68144 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 3
68144 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68145 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 28.0 (TID 187) in 3973 ms on 192.168.1.4 (executor 0) (5/8)
68145 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68153 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 2
68153 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 28.0 (TID 184) in 3981 ms on 192.168.1.4 (executor 0) (6/8)
68153 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68154 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 1
68154 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 28.0 (TID 185) in 3982 ms on 192.168.1.4 (executor 0) (7/8)
68154 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68178 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 0
68179 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 28.0 (TID 188) in 4007 ms on 192.168.1.4 (executor 0) (8/8)
68179 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 28.0, whose tasks have all completed, from pool 
68179 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68179 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 28 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.007 s
68179 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
68179 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
68179 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 29)
68179 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
68179 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 11
68179 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 29)
68179 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68179 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 29 (MapPartitionsRDD[60] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
68179 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 29)
68180 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
68180 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_39 locally took  0 ms
68180 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_39 without replication took  0 ms
68181 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
68181 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_39_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
68182 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_39_piece0
68182 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_39_piece0
68182 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_39_piece0 locally took  1 ms
68182 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_39_piece0 without replication took  1 ms
68182 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 39 from broadcast at DAGScheduler.scala:1006
68182 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 29 (MapPartitionsRDD[60] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
68182 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 29.0 with 2 tasks
68182 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 29.0: 11
68182 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 29.0: NODE_LOCAL, ANY
68183 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_29.0, runningTasks: 0
68183 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 29.0 (TID 192, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
68183 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 29.0 (TID 193, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
68183 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
68183 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 192 on executor id: 0 hostname: 192.168.1.4.
68183 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 193 on executor id: 0 hostname: 192.168.1.4.
68186 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_39_piece0 as bytes
68186 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_39_piece0 is StorageLevel(disk, memory, 1 replicas)
68188 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_39_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
68190 [dispatcher-event-loop-1] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 9 to 192.168.1.4:59114
68190 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 9 to 192.168.1.4:59114
68190 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 9
68190 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 9
68190 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 9 is 159 bytes
68265 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_29.0, runningTasks: 1
68265 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_29.0, runningTasks: 0
68266 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 29.0 (TID 193) in 83 ms on 192.168.1.4 (executor 0) (1/2)
68266 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 29.0 (TID 192) in 83 ms on 192.168.1.4 (executor 0) (2/2)
68266 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 29.0, whose tasks have all completed, from pool 
68266 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 29 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.083 s
68266 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 29, remaining stages = 2
68266 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 28, remaining stages = 1
68266 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 27, remaining stages = 0
68266 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 18 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.180184 s
68267 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
68269 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
68269 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_40 locally took  1 ms
68269 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_40 without replication took  1 ms
68270 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
68270 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_40_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
68270 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_40_piece0
68270 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_40_piece0
68270 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_40_piece0 locally took  1 ms
68270 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_40_piece0 without replication took  1 ms
68270 [main] INFO org.apache.spark.SparkContext  - Created broadcast 40 from broadcast at SparkDl4jMultiLayer.java:595
68271 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
68271 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_41 locally took  1 ms
68271 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_41 without replication took  1 ms
68272 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
68272 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_41_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
68272 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_41_piece0
68272 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_41_piece0
68272 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_41_piece0 locally took  0 ms
68272 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_41_piece0 without replication took  0 ms
68272 [main] INFO org.apache.spark.SparkContext  - Created broadcast 41 from broadcast at SparkDl4jMultiLayer.java:596
68272 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68273 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68274 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68275 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68276 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68277 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68278 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68279 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68280 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68281 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68282 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68283 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68283 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68283 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
68283 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
68283 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 11 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
68283 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 63 (treeAggregate at SparkDl4jMultiLayer.java:598)
68283 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 19 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
68283 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 31 (treeAggregate at SparkDl4jMultiLayer.java:598)
68283 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 30)
68283 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 30)
68283 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 31)
68283 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 30)
68283 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 30)
68284 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68284 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 30 (MapPartitionsRDD[63] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
68284 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 30)
68285 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42 stored as values in memory (estimated size 8.9 KB, free 366.1 MB)
68285 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_42 locally took  1 ms
68285 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_42 without replication took  1 ms
68286 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.1 MB)
68286 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_42_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
68286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_42_piece0
68286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_42_piece0
68286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_42_piece0 locally took  0 ms
68286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_42_piece0 without replication took  0 ms
68286 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 42 from broadcast at DAGScheduler.scala:1006
68287 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[63] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
68287 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 30.0 with 8 tasks
68287 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 30.0: 11
68287 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 30.0: NO_PREF, ANY
68287 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 0
68287 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 30.0 (TID 194, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
68288 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 30.0 (TID 195, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
68288 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 30.0 (TID 196, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
68288 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 30.0 (TID 197, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
68289 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 30.0 (TID 198, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
68289 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 30.0 (TID 199, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
68289 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 30.0 (TID 200, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
68290 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 30.0 (TID 201, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
68290 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 194 on executor id: 0 hostname: 192.168.1.4.
68290 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 195 on executor id: 0 hostname: 192.168.1.4.
68290 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 196 on executor id: 0 hostname: 192.168.1.4.
68290 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 197 on executor id: 0 hostname: 192.168.1.4.
68291 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 198 on executor id: 0 hostname: 192.168.1.4.
68291 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 199 on executor id: 0 hostname: 192.168.1.4.
68291 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 200 on executor id: 0 hostname: 192.168.1.4.
68291 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 201 on executor id: 0 hostname: 192.168.1.4.
68295 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_42_piece0 as bytes
68295 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_42_piece0 is StorageLevel(disk, memory, 1 replicas)
68297 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_42_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
68300 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_41_piece0 as bytes
68300 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_41_piece0 is StorageLevel(disk, memory, 1 replicas)
68301 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_41_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
68321 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 8
68344 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_40_piece0 as bytes
68344 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_40_piece0 is StorageLevel(disk, memory, 1 replicas)
68346 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_40_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
68493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 7
68493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
68493 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 30.0 (TID 201) in 204 ms on 192.168.1.4 (executor 0) (1/8)
68493 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68553 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 6
68553 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 30.0 (TID 199) in 264 ms on 192.168.1.4 (executor 0) (2/8)
68553 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68554 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 5
68555 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 30.0 (TID 200) in 266 ms on 192.168.1.4 (executor 0) (3/8)
68555 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68626 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 4
68627 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 30.0 (TID 197) in 338 ms on 192.168.1.4 (executor 0) (4/8)
68627 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68641 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 3
68642 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 30.0 (TID 194) in 355 ms on 192.168.1.4 (executor 0) (5/8)
68642 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68657 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 2
68657 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 30.0 (TID 198) in 369 ms on 192.168.1.4 (executor 0) (6/8)
68657 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68684 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 1
68684 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 30.0 (TID 196) in 396 ms on 192.168.1.4 (executor 0) (7/8)
68685 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68696 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 0
68696 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 30.0 (TID 195) in 409 ms on 192.168.1.4 (executor 0) (8/8)
68696 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 30.0, whose tasks have all completed, from pool 
68696 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68696 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 30 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.409 s
68696 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
68696 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
68696 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 31)
68696 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
68696 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 12
68696 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 31)
68696 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68696 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 31 (MapPartitionsRDD[65] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
68696 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 31)
68697 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
68697 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_43 locally took  0 ms
68697 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_43 without replication took  0 ms
68698 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
68698 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_43_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
68698 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_43_piece0
68698 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_43_piece0
68698 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_43_piece0 locally took  0 ms
68698 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_43_piece0 without replication took  0 ms
68699 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 43 from broadcast at DAGScheduler.scala:1006
68699 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[65] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
68699 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 31.0 with 2 tasks
68699 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 31.0: 12
68699 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 31.0: NODE_LOCAL, ANY
68699 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_31.0, runningTasks: 0
68699 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 31.0 (TID 202, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
68699 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 31.0 (TID 203, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
68699 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
68699 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 202 on executor id: 0 hostname: 192.168.1.4.
68700 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 203 on executor id: 0 hostname: 192.168.1.4.
68702 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_43_piece0 as bytes
68702 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_43_piece0 is StorageLevel(disk, memory, 1 replicas)
68704 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_43_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
68706 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 11 to 192.168.1.4:59114
68706 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 11 to 192.168.1.4:59114
68706 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 11
68706 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 11
68706 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 11 is 159 bytes
68710 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_31.0, runningTasks: 1
68710 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_31.0, runningTasks: 0
68711 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 31.0 (TID 202) in 12 ms on 192.168.1.4 (executor 0) (1/2)
68711 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 31.0 (TID 203) in 12 ms on 192.168.1.4 (executor 0) (2/2)
68711 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 31.0, whose tasks have all completed, from pool 
68711 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 31 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.012 s
68711 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 31, remaining stages = 1
68711 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 30, remaining stages = 0
68711 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 19 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.428459 s
68712 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 3: Accuracy = 0.00, F1 = NaN
68712 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 3
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68712 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
68714 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
68714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 20 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
68714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 32 (count at ParameterAveragingTrainingMaster.java:325)
68714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
68714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
68714 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 32)
68714 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68714 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 32 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
68714 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 32)
68715 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
68715 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_44 locally took  1 ms
68715 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_44 without replication took  1 ms
68715 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
68716 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_44_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
68716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_44_piece0
68716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_44_piece0
68716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_44_piece0 locally took  1 ms
68716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_44_piece0 without replication took  1 ms
68716 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 44 from broadcast at DAGScheduler.scala:1006
68716 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 32 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
68716 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 32.0 with 8 tasks
68716 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 32.0: 12
68716 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 32.0: PROCESS_LOCAL, NODE_LOCAL, ANY
68716 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 0
68717 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 32 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
68717 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 32.0 (TID 204, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
68718 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 32.0 (TID 205, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
68719 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 32.0 (TID 206, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
68720 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 32.0 (TID 207, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
68720 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 32.0 (TID 208, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
68721 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 32.0 (TID 209, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
68722 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 32.0 (TID 210, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
68723 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 32.0 (TID 211, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
68723 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 204 on executor id: 0 hostname: 192.168.1.4.
68723 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 205 on executor id: 0 hostname: 192.168.1.4.
68723 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 206 on executor id: 0 hostname: 192.168.1.4.
68724 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 207 on executor id: 0 hostname: 192.168.1.4.
68724 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 208 on executor id: 0 hostname: 192.168.1.4.
68724 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 209 on executor id: 0 hostname: 192.168.1.4.
68724 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 210 on executor id: 0 hostname: 192.168.1.4.
68724 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 211 on executor id: 0 hostname: 192.168.1.4.
68729 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_44_piece0 as bytes
68729 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_44_piece0 is StorageLevel(disk, memory, 1 replicas)
68730 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_44_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
68736 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 7
68736 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
68736 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
68736 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 6
68736 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 32.0 (TID 204) in 20 ms on 192.168.1.4 (executor 0) (1/8)
68736 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 32.0 (TID 211) in 14 ms on 192.168.1.4 (executor 0) (2/8)
68736 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 5
68736 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 4
68736 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 32.0 (TID 209) in 16 ms on 192.168.1.4 (executor 0) (3/8)
68736 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 32.0 (TID 210) in 15 ms on 192.168.1.4 (executor 0) (4/8)
68737 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 3
68737 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 32.0 (TID 206) in 19 ms on 192.168.1.4 (executor 0) (5/8)
68739 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 2
68739 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 32.0 (TID 205) in 22 ms on 192.168.1.4 (executor 0) (6/8)
68740 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 1
68740 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 32.0 (TID 207) in 21 ms on 192.168.1.4 (executor 0) (7/8)
68741 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 0
68741 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 32.0 (TID 208) in 21 ms on 192.168.1.4 (executor 0) (8/8)
68741 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 32.0, whose tasks have all completed, from pool 
68741 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 32 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.025 s
68741 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 32, remaining stages = 0
68741 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 20 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.027864 s
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68743 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68743 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68743 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
68743 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
68743 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68744 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353
68745 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68746 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
68746 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
68746 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
68746 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353)
68746 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
68746 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
68746 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353)
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
68747 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
68749 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
68749 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 21 (collect at SparkUtils.java:353) with 8 output partitions
68749 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 33 (collect at SparkUtils.java:353)
68749 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
68749 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
68749 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 33)
68749 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68749 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 33 (MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
68749 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 33)
68750 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
68750 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_45 locally took  0 ms
68750 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_45 without replication took  0 ms
68751 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.1 MB)
68751 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_45_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.2 MB)
68751 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_45_piece0
68751 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_45_piece0
68751 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_45_piece0 locally took  0 ms
68752 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_45_piece0 without replication took  0 ms
68752 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 45 from broadcast at DAGScheduler.scala:1006
68752 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 33 (MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
68752 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 33.0 with 8 tasks
68752 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 33.0: 12
68752 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 33.0: PROCESS_LOCAL, NODE_LOCAL, ANY
68752 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 0
68753 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 33 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
68753 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 33.0 (TID 212, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
68754 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 33.0 (TID 213, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
68755 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 33.0 (TID 214, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
68756 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 33.0 (TID 215, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
68756 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 33.0 (TID 216, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
68757 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 33.0 (TID 217, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
68758 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 33.0 (TID 218, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
68759 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 33.0 (TID 219, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
68759 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 212 on executor id: 0 hostname: 192.168.1.4.
68759 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 213 on executor id: 0 hostname: 192.168.1.4.
68760 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 214 on executor id: 0 hostname: 192.168.1.4.
68760 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 215 on executor id: 0 hostname: 192.168.1.4.
68760 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 216 on executor id: 0 hostname: 192.168.1.4.
68760 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 217 on executor id: 0 hostname: 192.168.1.4.
68760 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 218 on executor id: 0 hostname: 192.168.1.4.
68760 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 219 on executor id: 0 hostname: 192.168.1.4.
68765 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_45_piece0 as bytes
68765 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_45_piece0 is StorageLevel(disk, memory, 1 replicas)
68767 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_45_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
68771 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 7
68771 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
68771 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
68771 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 6
68771 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 33.0 (TID 214) in 17 ms on 192.168.1.4 (executor 0) (1/8)
68771 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 33.0 (TID 215) in 16 ms on 192.168.1.4 (executor 0) (2/8)
68772 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 5
68772 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 4
68772 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 33.0 (TID 217) in 16 ms on 192.168.1.4 (executor 0) (3/8)
68772 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 33.0 (TID 216) in 16 ms on 192.168.1.4 (executor 0) (4/8)
68773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 3
68773 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 33.0 (TID 218) in 16 ms on 192.168.1.4 (executor 0) (5/8)
68773 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 2
68773 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 33.0 (TID 219) in 15 ms on 192.168.1.4 (executor 0) (6/8)
68775 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 1
68775 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 33.0 (TID 213) in 22 ms on 192.168.1.4 (executor 0) (7/8)
68775 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 0
68775 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 33.0 (TID 212) in 23 ms on 192.168.1.4 (executor 0) (8/8)
68775 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 33.0, whose tasks have all completed, from pool 
68775 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 33 (collect at SparkUtils.java:353) finished in 0.023 s
68775 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 33, remaining stages = 0
68776 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 21 finished: collect at SparkUtils.java:353, took 0.026889 s
68776 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
68777 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
68778 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
68778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 22 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
68778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 34 (zipWithIndex at SparkUtils.java:391)
68778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
68779 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
68779 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 34)
68779 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68779 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 34 (MapPartitionsRDD[66] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
68779 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 34)
68780 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46 stored as values in memory (estimated size 2.2 KB, free 366.1 MB)
68780 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_46 locally took  0 ms
68780 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_46 without replication took  0 ms
68781 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.1 MB)
68781 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_46_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.2 MB)
68781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_46_piece0
68781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_46_piece0
68781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_46_piece0 locally took  0 ms
68781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_46_piece0 without replication took  0 ms
68781 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 46 from broadcast at DAGScheduler.scala:1006
68782 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 34 (MapPartitionsRDD[66] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
68782 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 34.0 with 7 tasks
68782 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 34.0: 12
68782 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 34.0: PROCESS_LOCAL, NODE_LOCAL, ANY
68782 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 0
68783 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 34 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
68783 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 34.0 (TID 220, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
68784 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 34.0 (TID 221, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
68785 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 34.0 (TID 222, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
68785 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 34.0 (TID 223, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
68786 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 34.0 (TID 224, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
68787 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 34.0 (TID 225, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
68788 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 34.0 (TID 226, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
68788 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
68788 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
68788 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 220 on executor id: 0 hostname: 192.168.1.4.
68788 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 221 on executor id: 0 hostname: 192.168.1.4.
68788 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 222 on executor id: 0 hostname: 192.168.1.4.
68788 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 223 on executor id: 0 hostname: 192.168.1.4.
68789 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 224 on executor id: 0 hostname: 192.168.1.4.
68789 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 225 on executor id: 0 hostname: 192.168.1.4.
68789 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 226 on executor id: 0 hostname: 192.168.1.4.
68794 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_46_piece0 as bytes
68794 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_46_piece0 is StorageLevel(disk, memory, 1 replicas)
68795 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_46_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
68799 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 6
68800 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 34.0 (TID 223) in 15 ms on 192.168.1.4 (executor 0) (1/7)
68800 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 5
68800 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 34.0 (TID 226) in 13 ms on 192.168.1.4 (executor 0) (2/7)
68801 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 4
68801 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 34.0 (TID 225) in 15 ms on 192.168.1.4 (executor 0) (3/7)
68801 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 3
68801 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 34.0 (TID 224) in 16 ms on 192.168.1.4 (executor 0) (4/7)
68801 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 2
68801 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 34.0 (TID 222) in 17 ms on 192.168.1.4 (executor 0) (5/7)
68803 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 1
68803 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 34.0 (TID 221) in 20 ms on 192.168.1.4 (executor 0) (6/7)
68803 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 0
68803 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 34.0 (TID 220) in 21 ms on 192.168.1.4 (executor 0) (7/7)
68803 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 34.0, whose tasks have all completed, from pool 
68803 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 34 (zipWithIndex at SparkUtils.java:391) finished in 0.021 s
68803 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 34, remaining stages = 0
68803 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 22 finished: zipWithIndex at SparkUtils.java:391, took 0.025146 s
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68806 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68806 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68806 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
68807 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47 stored as values in memory (estimated size 31.4 KB, free 366.0 MB)
68807 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_47 locally took  1 ms
68807 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_47 without replication took  1 ms
68808 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.0 MB)
68808 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_47_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.2 MB)
68808 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_47_piece0
68808 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_47_piece0
68808 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_47_piece0 locally took  1 ms
68808 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_47_piece0 without replication took  1 ms
68808 [main] INFO org.apache.spark.SparkContext  - Created broadcast 47 from broadcast at ParameterAveragingTrainingMaster.java:259
68808 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
68808 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
68809 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68810 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68811 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68812 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68813 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68814 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68815 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68816 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
68817 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
68817 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
68818 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 12 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
68818 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 69 (mapToPair at SparkUtils.java:391)
68818 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 74 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
68818 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 23 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
68818 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 37 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
68818 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 36)
68818 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 36)
68818 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 37)
68818 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 36)
68818 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 36)
68818 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 35)
68818 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 35)
68819 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68819 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 35 (MapPartitionsRDD[69] at mapToPair at SparkUtils.java:391), which has no missing parents
68819 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 35)
68819 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
68819 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_48 locally took  0 ms
68820 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_48 without replication took  1 ms
68820 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
68820 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_48_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.2 MB)
68821 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_48_piece0
68821 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_48_piece0
68821 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_48_piece0 locally took  1 ms
68821 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_48_piece0 without replication took  1 ms
68821 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 48 from broadcast at DAGScheduler.scala:1006
68821 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[69] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
68821 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 35.0 with 8 tasks
68821 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 35.0: 12
68821 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 35.0: PROCESS_LOCAL, NODE_LOCAL, ANY
68821 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 0
68822 [dispatcher-event-loop-6] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 35 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
68822 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 35.0 (TID 227, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
68823 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 35.0 (TID 228, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
68824 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 35.0 (TID 229, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
68825 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 35.0 (TID 230, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
68825 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 35.0 (TID 231, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
68826 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 35.0 (TID 232, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
68827 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 35.0 (TID 233, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
68828 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 35.0 (TID 234, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
68828 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 227 on executor id: 0 hostname: 192.168.1.4.
68829 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 228 on executor id: 0 hostname: 192.168.1.4.
68829 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 229 on executor id: 0 hostname: 192.168.1.4.
68829 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 230 on executor id: 0 hostname: 192.168.1.4.
68829 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 231 on executor id: 0 hostname: 192.168.1.4.
68829 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 232 on executor id: 0 hostname: 192.168.1.4.
68829 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 233 on executor id: 0 hostname: 192.168.1.4.
68829 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 234 on executor id: 0 hostname: 192.168.1.4.
68835 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_48_piece0 as bytes
68835 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_48_piece0 is StorageLevel(disk, memory, 1 replicas)
68836 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_48_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
68844 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 7
68844 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
68844 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
68845 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 6
68845 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 35.0 (TID 232) in 20 ms on 192.168.1.4 (executor 0) (1/8)
68845 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 35.0 (TID 233) in 19 ms on 192.168.1.4 (executor 0) (2/8)
68845 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 5
68845 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68845 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 35.0 (TID 231) in 20 ms on 192.168.1.4 (executor 0) (3/8)
68845 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68845 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68848 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 4
68848 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 35.0 (TID 229) in 25 ms on 192.168.1.4 (executor 0) (4/8)
68849 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68853 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 3
68854 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 35.0 (TID 234) in 27 ms on 192.168.1.4 (executor 0) (5/8)
68854 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68856 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 2
68856 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 35.0 (TID 230) in 32 ms on 192.168.1.4 (executor 0) (6/8)
68856 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68860 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 1
68860 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 35.0 (TID 227) in 39 ms on 192.168.1.4 (executor 0) (7/8)
68860 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68864 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 0
68864 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 35.0 (TID 228) in 42 ms on 192.168.1.4 (executor 0) (8/8)
68864 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 35.0, whose tasks have all completed, from pool 
68864 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
68864 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 35 (mapToPair at SparkUtils.java:391) finished in 0.043 s
68864 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
68864 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
68864 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 37, ShuffleMapStage 36)
68864 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
68864 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 13
68864 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 36)
68865 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
68865 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 36 (MapPartitionsRDD[74] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
68865 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 36)
68866 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49 stored as values in memory (estimated size 6.6 KB, free 366.0 MB)
68866 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_49 locally took  0 ms
68866 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_49 without replication took  0 ms
68867 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.0 MB)
68867 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_49_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.2 MB)
68868 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_49_piece0
68868 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_49_piece0
68868 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_49_piece0 locally took  1 ms
68868 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_49_piece0 without replication took  1 ms
68868 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 49 from broadcast at DAGScheduler.scala:1006
68868 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[74] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
68868 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 36.0 with 8 tasks
68868 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 36.0: 13
68868 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 36.0: NODE_LOCAL, ANY
68868 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 0
68868 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 36.0 (TID 235, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 36.0 (TID 236, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 36.0 (TID 237, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 36.0 (TID 238, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 36.0 (TID 239, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 36.0 (TID 240, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 36.0 (TID 241, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 36.0 (TID 242, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
68869 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 235 on executor id: 0 hostname: 192.168.1.4.
68869 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 236 on executor id: 0 hostname: 192.168.1.4.
68869 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 237 on executor id: 0 hostname: 192.168.1.4.
68869 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 238 on executor id: 0 hostname: 192.168.1.4.
68869 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 239 on executor id: 0 hostname: 192.168.1.4.
68869 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 240 on executor id: 0 hostname: 192.168.1.4.
68870 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 241 on executor id: 0 hostname: 192.168.1.4.
68870 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 242 on executor id: 0 hostname: 192.168.1.4.
68874 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_49_piece0 as bytes
68874 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_49_piece0 is StorageLevel(disk, memory, 1 replicas)
68876 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_49_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
68878 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 13 to 192.168.1.4:59114
68878 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 13 to 192.168.1.4:59114
68878 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 13
68878 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 13
68878 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 13 is 186 bytes
68882 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_47_piece0 as bytes
68882 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_47_piece0 is StorageLevel(disk, memory, 1 replicas)
68884 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_47_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
69324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 8
70323 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 8
70840 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 7
70840 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
70840 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 36.0 (TID 240) in 1971 ms on 192.168.1.4 (executor 0) (1/8)
70840 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71321 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 7
72056 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 6
72056 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 36.0 (TID 241) in 3187 ms on 192.168.1.4 (executor 0) (2/8)
72056 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72320 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 6
72335 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 5
72335 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 36.0 (TID 242) in 3466 ms on 192.168.1.4 (executor 0) (3/8)
72335 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72657 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 4
72657 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 36.0 (TID 237) in 3788 ms on 192.168.1.4 (executor 0) (4/8)
72658 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72718 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 3
72718 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 36.0 (TID 235) in 3850 ms on 192.168.1.4 (executor 0) (5/8)
72719 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72730 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 2
72730 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 36.0 (TID 239) in 3861 ms on 192.168.1.4 (executor 0) (6/8)
72730 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72763 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 1
72763 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 36.0 (TID 236) in 3894 ms on 192.168.1.4 (executor 0) (7/8)
72764 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72785 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 0
72785 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 36.0 (TID 238) in 3916 ms on 192.168.1.4 (executor 0) (8/8)
72785 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 36.0, whose tasks have all completed, from pool 
72785 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72785 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 36 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.917 s
72785 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
72785 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
72785 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 37)
72785 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
72785 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 14
72785 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 37)
72785 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72785 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 37 (MapPartitionsRDD[76] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
72785 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 37)
72786 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50 stored as values in memory (estimated size 3.6 KB, free 366.0 MB)
72786 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_50 locally took  0 ms
72786 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_50 without replication took  0 ms
72794 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(34)
72794 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 34
72794 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 34
72794 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 34
72794 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 34
72794 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_34_piece0
72794 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34_piece0 of size 1570 dropped from memory (free 383778994)
72794 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
72794 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_34_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.2 MB)
72795 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_34_piece0
72795 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_34_piece0
72795 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_34
72795 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34 of size 2504 dropped from memory (free 383781498)
72795 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_50_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.2 MB)
72795 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 34, response is 0
72795 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_50_piece0
72795 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_50_piece0
72795 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_50_piece0 locally took  1 ms
72795 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_50_piece0 without replication took  1 ms
72795 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72795 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 50 from broadcast at DAGScheduler.scala:1006
72795 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[76] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
72795 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 37.0 with 2 tasks
72795 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_34_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.4 MB)
72795 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 37.0: 14
72796 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 37.0: NODE_LOCAL, ANY
72796 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_37.0, runningTasks: 0
72796 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 37.0 (TID 243, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
72796 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 37.0 (TID 244, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
72796 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
72796 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 243 on executor id: 0 hostname: 192.168.1.4.
72796 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 34
72796 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(41)
72796 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 41
72796 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 41
72796 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 244 on executor id: 0 hostname: 192.168.1.4.
72796 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 41
72797 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 41
72797 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_41
72797 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41 of size 27976 dropped from memory (free 383809474)
72797 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_41_piece0
72797 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41_piece0 of size 2531 dropped from memory (free 383812005)
72797 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_41_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.2 MB)
72797 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_41_piece0
72797 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_41_piece0
72797 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 41, response is 0
72797 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72798 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_41_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
72799 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 41
72799 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(9)
72799 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 9
72799 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 9
72799 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 9
72799 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 9, response is true
72799 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(42)
72799 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 42
72799 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
72799 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 42
72799 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_50_piece0 as bytes
72799 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_50_piece0 is StorageLevel(disk, memory, 1 replicas)
72799 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 42
72799 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 42
72799 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_42
72799 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42 of size 9088 dropped from memory (free 383821093)
72800 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_42_piece0
72800 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42_piece0 of size 4136 dropped from memory (free 383825229)
72800 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_42_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.2 MB)
72800 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_42_piece0
72800 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_42_piece0
72800 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 42, response is 0
72800 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72801 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_42_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
72801 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_50_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
72801 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 42
72801 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(8)
72801 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 8
72802 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 8
72802 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 8
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 8, response is true
72802 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(44)
72802 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 44
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
72802 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 44
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 44
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 44
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_44
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44 of size 1448 dropped from memory (free 383826677)
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_44_piece0
72802 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44_piece0 of size 1006 dropped from memory (free 383827683)
72802 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_44_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.2 MB)
72803 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_44_piece0
72803 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_44_piece0
72803 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 44, response is 0
72803 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72803 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_44_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
72803 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 12 to 192.168.1.4:59114
72803 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 12 to 192.168.1.4:59114
72803 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 12
72803 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 12
72804 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 12 is 159 bytes
72804 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 44
72804 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(37)
72804 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 37
72804 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 37
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 37
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 37
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_37_piece0
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37_piece0 of size 2197 dropped from memory (free 383829880)
72804 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_37_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.2 MB)
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_37_piece0
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_37_piece0
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_37
72804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37 of size 3600 dropped from memory (free 383833480)
72805 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 37, response is 0
72805 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72805 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_37_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
72806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 37
72806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(7)
72806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 7
72806 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 7
72806 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 7
72806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 7, response is true
72806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(29)
72806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 29
72806 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 29
72806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
72806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 29
72806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 29
72806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_29_piece0
72806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29_piece0 of size 1428 dropped from memory (free 383834908)
72806 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_29_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.2 MB)
72807 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_29_piece0
72807 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_29_piece0
72807 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_29
72807 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29 of size 8224 dropped from memory (free 383843132)
72807 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 29, response is 0
72807 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72807 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_29_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.4 MB)
72808 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 29
72808 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(31)
72808 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 31
72808 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 31
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 31
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 31
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_31_piece0
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31_piece0 of size 4134 dropped from memory (free 383847266)
72808 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_31_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.3 MB)
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_31_piece0
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_31_piece0
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_31
72808 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31 of size 9088 dropped from memory (free 383856354)
72808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 31, response is 0
72808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72809 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_31_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
72809 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 31
72809 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(6)
72809 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 6
72809 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 6
72810 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 6
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 6, response is true
72810 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(30)
72810 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 30
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
72810 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 30
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 30
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 30
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_30
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30 of size 27528 dropped from memory (free 383883882)
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_30_piece0
72810 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30_piece0 of size 2531 dropped from memory (free 383886413)
72810 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_30_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.3 MB)
72811 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_30_piece0
72811 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_30_piece0
72811 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 30, response is 0
72811 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72811 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_30_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
72812 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 30
72812 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(33)
72812 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 33
72812 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 33
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 33
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 33
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_33
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33 of size 1448 dropped from memory (free 383887861)
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_33_piece0
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33_piece0 of size 1006 dropped from memory (free 383888867)
72812 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_33_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.3 MB)
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_33_piece0
72812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_33_piece0
72812 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 33, response is 0
72813 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72813 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_33_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
72813 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 33
72813 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(26)
72813 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 26
72813 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 26
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 26
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 26
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_26_piece0
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26_piece0 of size 2197 dropped from memory (free 383891064)
72814 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_26_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_26_piece0
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_26_piece0
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_26
72814 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26 of size 3600 dropped from memory (free 383894664)
72814 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 26, response is 0
72814 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72814 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_26_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
72815 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 26
72815 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(40)
72815 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 40
72815 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 40
72815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 40
72815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 40
72815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_40
72815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40 of size 8224 dropped from memory (free 383902888)
72815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_40_piece0
72815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40_piece0 of size 1428 dropped from memory (free 383904316)
72816 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_40_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.3 MB)
72816 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_40_piece0
72816 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_40_piece0
72816 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 40, response is 0
72816 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72816 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_40_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.4 MB)
72817 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 40
72817 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(43)
72817 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 43
72817 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 43
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 43
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 43
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_43_piece0
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43_piece0 of size 2125 dropped from memory (free 383906441)
72817 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_43_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_43_piece0
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_43_piece0
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_43
72817 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43 of size 3656 dropped from memory (free 383910097)
72817 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 43, response is 0
72818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72818 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_43_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
72818 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 43
72818 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(11)
72818 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 11
72819 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 11
72819 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 11
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 11, response is true
72819 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(36)
72819 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 36
72819 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 36
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 36
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 36
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_36
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36 of size 31656 dropped from memory (free 383941753)
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_36_piece0
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36_piece0 of size 5327 dropped from memory (free 383947080)
72819 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_36_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.3 MB)
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_36_piece0
72819 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_36_piece0
72819 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 36, response is 0
72819 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72820 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_36_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
72820 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 36
72820 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(32)
72820 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 32
72820 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 32
72820 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 32
72820 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 32
72820 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_32
72820 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32 of size 3656 dropped from memory (free 383950736)
72820 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_32_piece0
72821 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32_piece0 of size 2124 dropped from memory (free 383952860)
72821 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_32_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
72821 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_32_piece0
72821 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_32_piece0
72821 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 32, response is 0
72821 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72821 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_32_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
72822 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 32
72822 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(10)
72822 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 10
72822 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 10
72822 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 10
72822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 10, response is true
72822 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(38)
72822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
72822 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 38
72822 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 38
72822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 38
72822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 38
72822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_38_piece0
72822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38_piece0 of size 3630 dropped from memory (free 383956490)
72822 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_38_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
72823 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_38_piece0
72823 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_38_piece0
72823 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_38
72823 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38 of size 6712 dropped from memory (free 383963202)
72823 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 38, response is 0
72823 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72823 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_38_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.4 MB)
72824 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 38
72824 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(46)
72824 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 46
72824 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 46
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 46
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 46
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_46_piece0
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46_piece0 of size 1460 dropped from memory (free 383964662)
72824 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_46_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_46_piece0
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_46_piece0
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_46
72824 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46 of size 2216 dropped from memory (free 383966878)
72824 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 46, response is 0
72824 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72825 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_46_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
72825 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 46
72825 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(28)
72825 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 28
72825 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 28
72825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 28
72825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 28
72825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_28_piece0
72826 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28_piece0 of size 2135 dropped from memory (free 383969013)
72826 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_28_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
72826 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_28_piece0
72826 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_28_piece0
72826 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_28
72826 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28 of size 3672 dropped from memory (free 383972685)
72826 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 28, response is 0
72826 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72826 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_28_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
72827 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 28
72827 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(45)
72827 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 45
72827 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 45
72827 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 45
72827 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 45
72827 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_45
72827 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45 of size 2504 dropped from memory (free 383975189)
72827 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_45_piece0
72827 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45_piece0 of size 1570 dropped from memory (free 383976759)
72827 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_45_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.3 MB)
72828 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_45_piece0
72828 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_45_piece0
72828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 45, response is 0
72828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72828 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_45_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.4 MB)
72829 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 45
72829 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(27)
72829 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 27
72829 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 27
72829 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 27
72829 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 27
72829 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_27_piece0
72829 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27_piece0 of size 3630 dropped from memory (free 383980389)
72829 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_27_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
72830 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_27_piece0
72830 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_27_piece0
72830 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_27
72830 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27 of size 6712 dropped from memory (free 383987101)
72830 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 27, response is 0
72830 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72830 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_27_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.4 MB)
72831 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 27
72831 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(35)
72831 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 35
72831 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 35
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 35
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 35
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_35_piece0
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35_piece0 of size 1460 dropped from memory (free 383988561)
72831 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_35_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_35_piece0
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_35_piece0
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_35
72831 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35 of size 2216 dropped from memory (free 383990777)
72831 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 35, response is 0
72832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72832 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_35_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
72832 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 35
72832 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(48)
72832 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 48
72832 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 48
72832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 48
72833 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 48
72833 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_48_piece0
72833 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48_piece0 of size 2197 dropped from memory (free 383992974)
72833 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_48_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
72833 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_48_piece0
72833 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_48_piece0
72833 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_48
72833 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48 of size 3600 dropped from memory (free 383996574)
72833 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 48, response is 0
72833 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72833 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_48_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
72834 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 48
72834 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(25)
72834 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 25
72834 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 25
72834 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 25
72834 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 25
72834 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_25_piece0
72834 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25_piece0 of size 5323 dropped from memory (free 384001897)
72835 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_25_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.3 MB)
72835 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_25_piece0
72835 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_25_piece0
72835 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_25
72835 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25 of size 32104 dropped from memory (free 384034001)
72835 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 25, response is 0
72835 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72835 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_25_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
72836 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 25
72836 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(39)
72836 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 39
72836 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 39
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 39
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 39
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_39
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39 of size 3672 dropped from memory (free 384037673)
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_39_piece0
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39_piece0 of size 2135 dropped from memory (free 384039808)
72836 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_39_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_39_piece0
72836 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_39_piece0
72836 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 39, response is 0
72836 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
72837 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_39_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
72837 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 39
72857 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_37.0, runningTasks: 1
72857 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_37.0, runningTasks: 0
72857 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 37.0 (TID 243) in 61 ms on 192.168.1.4 (executor 0) (1/2)
72857 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 37.0 (TID 244) in 61 ms on 192.168.1.4 (executor 0) (2/2)
72857 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 37.0, whose tasks have all completed, from pool 
72857 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 37 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.061 s
72857 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 35, remaining stages = 2
72857 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 37, remaining stages = 1
72857 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 36, remaining stages = 0
72858 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 23 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.040172 s
72858 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
72860 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
72860 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_51 locally took  1 ms
72860 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_51 without replication took  1 ms
72860 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
72861 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_51_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
72861 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_51_piece0
72861 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_51_piece0
72861 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_51_piece0 locally took  1 ms
72861 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_51_piece0 without replication took  1 ms
72861 [main] INFO org.apache.spark.SparkContext  - Created broadcast 51 from broadcast at SparkDl4jMultiLayer.java:595
72861 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
72862 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_52 locally took  0 ms
72862 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_52 without replication took  1 ms
72862 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
72862 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_52_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
72862 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_52_piece0
72863 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_52_piece0
72863 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_52_piece0 locally took  1 ms
72863 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_52_piece0 without replication took  1 ms
72863 [main] INFO org.apache.spark.SparkContext  - Created broadcast 52 from broadcast at SparkDl4jMultiLayer.java:596
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72863 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72864 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72864 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72864 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72864 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
72864 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72865 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72866 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72867 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72867 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72867 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
72867 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
72868 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72869 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72870 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
72871 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
72872 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72873 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
72873 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
72873 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 14 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
72873 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 79 (treeAggregate at SparkDl4jMultiLayer.java:598)
72873 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 24 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
72873 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 39 (treeAggregate at SparkDl4jMultiLayer.java:598)
72873 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 38)
72873 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 38)
72874 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 39)
72874 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 38)
72874 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 38)
72874 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72874 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 38 (MapPartitionsRDD[79] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
72874 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 38)
72875 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53 stored as values in memory (estimated size 8.9 KB, free 366.2 MB)
72875 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_53 locally took  1 ms
72875 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_53 without replication took  1 ms
72876 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.2 MB)
72876 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_53_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
72876 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_53_piece0
72876 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_53_piece0
72876 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_53_piece0 locally took  0 ms
72876 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_53_piece0 without replication took  0 ms
72876 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 53 from broadcast at DAGScheduler.scala:1006
72876 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[79] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
72876 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 38.0 with 8 tasks
72877 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 38.0: 14
72877 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 38.0: NO_PREF, ANY
72877 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 0
72877 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 38.0 (TID 245, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
72877 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 38.0 (TID 246, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
72878 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 38.0 (TID 247, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
72878 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 38.0 (TID 248, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
72878 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 38.0 (TID 249, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
72879 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 38.0 (TID 250, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
72879 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 38.0 (TID 251, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
72879 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 38.0 (TID 252, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
72880 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 245 on executor id: 0 hostname: 192.168.1.4.
72880 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 246 on executor id: 0 hostname: 192.168.1.4.
72880 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 247 on executor id: 0 hostname: 192.168.1.4.
72880 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 248 on executor id: 0 hostname: 192.168.1.4.
72880 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 249 on executor id: 0 hostname: 192.168.1.4.
72880 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 250 on executor id: 0 hostname: 192.168.1.4.
72881 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 251 on executor id: 0 hostname: 192.168.1.4.
72881 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 252 on executor id: 0 hostname: 192.168.1.4.
72885 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_53_piece0 as bytes
72885 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_53_piece0 is StorageLevel(disk, memory, 1 replicas)
72886 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_53_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
72890 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_52_piece0 as bytes
72890 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_52_piece0 is StorageLevel(disk, memory, 1 replicas)
72891 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_52_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
72917 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_51_piece0 as bytes
72917 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_51_piece0 is StorageLevel(disk, memory, 1 replicas)
72918 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_51_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
73040 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 7
73041 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
73041 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 38.0 (TID 252) in 162 ms on 192.168.1.4 (executor 0) (1/8)
73041 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73114 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 6
73114 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 5
73114 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 38.0 (TID 250) in 236 ms on 192.168.1.4 (executor 0) (2/8)
73115 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 38.0 (TID 251) in 235 ms on 192.168.1.4 (executor 0) (3/8)
73115 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73115 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73144 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 4
73144 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 38.0 (TID 249) in 266 ms on 192.168.1.4 (executor 0) (4/8)
73145 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73193 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 3
73194 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 38.0 (TID 248) in 316 ms on 192.168.1.4 (executor 0) (5/8)
73194 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73244 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 2
73244 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 38.0 (TID 246) in 367 ms on 192.168.1.4 (executor 0) (6/8)
73244 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73263 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 1
73263 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 38.0 (TID 247) in 385 ms on 192.168.1.4 (executor 0) (7/8)
73264 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73285 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 0
73285 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 38.0 (TID 245) in 408 ms on 192.168.1.4 (executor 0) (8/8)
73285 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 38.0, whose tasks have all completed, from pool 
73286 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73286 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 38 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.409 s
73286 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
73286 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
73286 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 39)
73286 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
73286 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 15
73286 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 39)
73286 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
73286 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 39 (MapPartitionsRDD[81] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
73286 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 39)
73287 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
73287 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_54 locally took  1 ms
73287 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_54 without replication took  1 ms
73287 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
73287 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_54_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
73288 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_54_piece0
73288 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_54_piece0
73288 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_54_piece0 locally took  1 ms
73288 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_54_piece0 without replication took  1 ms
73288 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 54 from broadcast at DAGScheduler.scala:1006
73289 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[81] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
73289 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 39.0 with 2 tasks
73289 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 39.0: 15
73289 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 39.0: NODE_LOCAL, ANY
73289 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_39.0, runningTasks: 0
73289 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 39.0 (TID 253, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
73289 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 39.0 (TID 254, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
73289 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
73289 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 253 on executor id: 0 hostname: 192.168.1.4.
73289 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 254 on executor id: 0 hostname: 192.168.1.4.
73292 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_54_piece0 as bytes
73292 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_54_piece0 is StorageLevel(disk, memory, 1 replicas)
73293 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_54_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
73295 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 14 to 192.168.1.4:59114
73295 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 14 to 192.168.1.4:59114
73295 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 14
73295 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 14
73295 [map-output-dispatcher-6] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 14 is 159 bytes
73299 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_39.0, runningTasks: 1
73299 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_39.0, runningTasks: 0
73299 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 39.0 (TID 254) in 10 ms on 192.168.1.4 (executor 0) (1/2)
73299 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 39.0 (TID 253) in 10 ms on 192.168.1.4 (executor 0) (2/2)
73300 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 39.0, whose tasks have all completed, from pool 
73300 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 39 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.011 s
73300 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 38, remaining stages = 1
73300 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 39, remaining stages = 0
73300 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 24 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.427213 s
73301 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 4: Accuracy = 0.00, F1 = NaN
73301 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 4
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73301 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73302 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
73302 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
73302 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 25 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
73303 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 40 (count at ParameterAveragingTrainingMaster.java:325)
73303 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
73303 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
73303 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 40)
73303 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
73303 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 40 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
73303 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 40)
73303 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
73303 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_55 locally took  0 ms
73303 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_55 without replication took  0 ms
73304 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
73304 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_55_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
73304 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_55_piece0
73304 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_55_piece0
73304 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_55_piece0 locally took  0 ms
73304 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_55_piece0 without replication took  0 ms
73304 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 55 from broadcast at DAGScheduler.scala:1006
73305 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 40 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
73305 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 40.0 with 8 tasks
73305 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 40.0: 15
73305 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 40.0: PROCESS_LOCAL, NODE_LOCAL, ANY
73305 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 0
73306 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 40 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
73306 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 40.0 (TID 255, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
73307 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 40.0 (TID 256, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
73307 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 40.0 (TID 257, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
73308 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 40.0 (TID 258, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
73309 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 40.0 (TID 259, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
73310 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 40.0 (TID 260, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
73311 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 40.0 (TID 261, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
73311 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 40.0 (TID 262, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
73312 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 255 on executor id: 0 hostname: 192.168.1.4.
73312 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 256 on executor id: 0 hostname: 192.168.1.4.
73312 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 257 on executor id: 0 hostname: 192.168.1.4.
73313 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 258 on executor id: 0 hostname: 192.168.1.4.
73313 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 259 on executor id: 0 hostname: 192.168.1.4.
73313 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 260 on executor id: 0 hostname: 192.168.1.4.
73313 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 261 on executor id: 0 hostname: 192.168.1.4.
73313 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 262 on executor id: 0 hostname: 192.168.1.4.
73320 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_55_piece0 as bytes
73320 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_55_piece0 is StorageLevel(disk, memory, 1 replicas)
73321 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_55_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
73324 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 8
73325 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 7
73325 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
73325 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
73325 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 6
73325 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 5
73326 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 40.0 (TID 255) in 21 ms on 192.168.1.4 (executor 0) (1/8)
73326 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 40.0 (TID 262) in 15 ms on 192.168.1.4 (executor 0) (2/8)
73326 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 4
73326 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 3
73326 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 2
73326 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 40.0 (TID 260) in 17 ms on 192.168.1.4 (executor 0) (3/8)
73326 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 40.0 (TID 261) in 16 ms on 192.168.1.4 (executor 0) (4/8)
73326 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 40.0 (TID 257) in 19 ms on 192.168.1.4 (executor 0) (5/8)
73326 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 1
73326 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 40.0 (TID 259) in 18 ms on 192.168.1.4 (executor 0) (6/8)
73326 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 40.0 (TID 256) in 20 ms on 192.168.1.4 (executor 0) (7/8)
73329 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 0
73330 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 40.0 (TID 258) in 23 ms on 192.168.1.4 (executor 0) (8/8)
73330 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 40.0, whose tasks have all completed, from pool 
73330 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 40 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.025 s
73330 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 40, remaining stages = 0
73330 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 25 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.027569 s
73330 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
73330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
73330 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
73331 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
73331 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
73332 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353)
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
73333 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353)
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
73334 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73335 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
73335 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
73335 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 26 (collect at SparkUtils.java:353) with 8 output partitions
73335 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 41 (collect at SparkUtils.java:353)
73335 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
73336 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
73336 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 41)
73336 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
73336 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 41 (MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
73336 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 41)
73336 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
73336 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_56 locally took  0 ms
73336 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_56 without replication took  0 ms
73337 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
73337 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_56_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
73337 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_56_piece0
73337 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_56_piece0
73337 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_56_piece0 locally took  0 ms
73337 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_56_piece0 without replication took  0 ms
73337 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 56 from broadcast at DAGScheduler.scala:1006
73338 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 41 (MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
73338 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 41.0 with 8 tasks
73338 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 41.0: 15
73338 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 41.0: PROCESS_LOCAL, NODE_LOCAL, ANY
73338 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 0
73339 [dispatcher-event-loop-1] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 41 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
73339 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 41.0 (TID 263, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
73339 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 41.0 (TID 264, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
73340 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 41.0 (TID 265, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
73341 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 41.0 (TID 266, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
73342 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 41.0 (TID 267, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
73342 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 41.0 (TID 268, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
73343 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 41.0 (TID 269, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
73344 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 41.0 (TID 270, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
73344 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 263 on executor id: 0 hostname: 192.168.1.4.
73344 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 264 on executor id: 0 hostname: 192.168.1.4.
73344 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 265 on executor id: 0 hostname: 192.168.1.4.
73345 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 266 on executor id: 0 hostname: 192.168.1.4.
73345 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 267 on executor id: 0 hostname: 192.168.1.4.
73345 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 268 on executor id: 0 hostname: 192.168.1.4.
73345 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 269 on executor id: 0 hostname: 192.168.1.4.
73345 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 270 on executor id: 0 hostname: 192.168.1.4.
73349 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_56_piece0 as bytes
73349 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_56_piece0 is StorageLevel(disk, memory, 1 replicas)
73350 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_56_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
73354 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 7
73354 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
73354 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
73354 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 41.0 (TID 269) in 12 ms on 192.168.1.4 (executor 0) (1/8)
73354 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 6
73354 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 41.0 (TID 268) in 12 ms on 192.168.1.4 (executor 0) (2/8)
73355 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 5
73355 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 41.0 (TID 266) in 15 ms on 192.168.1.4 (executor 0) (3/8)
73355 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 4
73355 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 41.0 (TID 267) in 14 ms on 192.168.1.4 (executor 0) (4/8)
73356 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 3
73356 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 2
73356 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 41.0 (TID 265) in 17 ms on 192.168.1.4 (executor 0) (5/8)
73356 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 41.0 (TID 263) in 18 ms on 192.168.1.4 (executor 0) (6/8)
73357 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 1
73357 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 41.0 (TID 270) in 14 ms on 192.168.1.4 (executor 0) (7/8)
73358 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 0
73358 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 41.0 (TID 264) in 19 ms on 192.168.1.4 (executor 0) (8/8)
73358 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 41.0, whose tasks have all completed, from pool 
73358 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 41 (collect at SparkUtils.java:353) finished in 0.020 s
73358 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 41, remaining stages = 0
73358 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 26 finished: collect at SparkUtils.java:353, took 0.022907 s
73358 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
73359 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73360 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
73360 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
73360 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 27 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
73360 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 42 (zipWithIndex at SparkUtils.java:391)
73360 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
73361 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
73361 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 42)
73361 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
73361 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 42 (MapPartitionsRDD[82] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
73361 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 42)
73361 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
73361 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_57 locally took  0 ms
73361 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_57 without replication took  0 ms
73362 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
73362 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_57_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
73362 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_57_piece0
73362 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_57_piece0
73362 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_57_piece0 locally took  0 ms
73362 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_57_piece0 without replication took  0 ms
73362 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 57 from broadcast at DAGScheduler.scala:1006
73363 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 42 (MapPartitionsRDD[82] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
73363 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 42.0 with 7 tasks
73363 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 42.0: 15
73363 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 42.0: PROCESS_LOCAL, NODE_LOCAL, ANY
73363 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 0
73364 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 42 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
73364 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 42.0 (TID 271, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
73365 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 42.0 (TID 272, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
73365 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 42.0 (TID 273, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
73366 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 42.0 (TID 274, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
73367 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 42.0 (TID 275, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
73368 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 42.0 (TID 276, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
73368 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 42.0 (TID 277, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
73368 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
73368 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
73369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 271 on executor id: 0 hostname: 192.168.1.4.
73369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 272 on executor id: 0 hostname: 192.168.1.4.
73369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 273 on executor id: 0 hostname: 192.168.1.4.
73369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 274 on executor id: 0 hostname: 192.168.1.4.
73369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 275 on executor id: 0 hostname: 192.168.1.4.
73369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 276 on executor id: 0 hostname: 192.168.1.4.
73369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 277 on executor id: 0 hostname: 192.168.1.4.
73374 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_57_piece0 as bytes
73374 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_57_piece0 is StorageLevel(disk, memory, 1 replicas)
73375 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_57_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
73379 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 6
73379 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 5
73379 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 42.0 (TID 276) in 12 ms on 192.168.1.4 (executor 0) (1/7)
73379 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 42.0 (TID 274) in 14 ms on 192.168.1.4 (executor 0) (2/7)
73380 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 4
73380 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 3
73380 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 42.0 (TID 275) in 14 ms on 192.168.1.4 (executor 0) (3/7)
73380 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 42.0 (TID 277) in 12 ms on 192.168.1.4 (executor 0) (4/7)
73384 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 2
73384 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 42.0 (TID 271) in 21 ms on 192.168.1.4 (executor 0) (5/7)
73384 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 1
73384 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 42.0 (TID 273) in 19 ms on 192.168.1.4 (executor 0) (6/7)
73384 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 0
73384 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 42.0 (TID 272) in 20 ms on 192.168.1.4 (executor 0) (7/7)
73384 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 42.0, whose tasks have all completed, from pool 
73384 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 42 (zipWithIndex at SparkUtils.java:391) finished in 0.021 s
73384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 42, remaining stages = 0
73385 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 27 finished: zipWithIndex at SparkUtils.java:391, took 0.024433 s
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73385 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73386 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73386 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73386 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73386 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
73386 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73387 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
73388 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58 stored as values in memory (estimated size 30.9 KB, free 366.2 MB)
73388 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_58 locally took  1 ms
73388 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_58 without replication took  1 ms
73389 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
73389 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_58_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.3 MB)
73389 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_58_piece0
73389 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_58_piece0
73389 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_58_piece0 locally took  0 ms
73389 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_58_piece0 without replication took  0 ms
73389 [main] INFO org.apache.spark.SparkContext  - Created broadcast 58 from broadcast at ParameterAveragingTrainingMaster.java:259
73389 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73390 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73391 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73392 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73393 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73394 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73395 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
73396 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
73397 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73398 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
73399 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
73400 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
73400 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
73400 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
73400 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
73400 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 15 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
73400 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 85 (mapToPair at SparkUtils.java:391)
73400 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 90 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
73400 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 28 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
73400 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 45 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
73400 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 44)
73400 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 44)
73400 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 45)
73400 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 44)
73400 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 44)
73400 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 43)
73400 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 43)
73401 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
73401 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 43 (MapPartitionsRDD[85] at mapToPair at SparkUtils.java:391), which has no missing parents
73401 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 43)
73401 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
73402 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_59 locally took  1 ms
73402 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_59 without replication took  1 ms
73402 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
73402 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_59_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
73402 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_59_piece0
73403 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_59_piece0
73403 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_59_piece0 locally took  1 ms
73403 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_59_piece0 without replication took  1 ms
73403 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 59 from broadcast at DAGScheduler.scala:1006
73403 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[85] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
73403 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 43.0 with 8 tasks
73403 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 43.0: 15
73403 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 43.0: PROCESS_LOCAL, NODE_LOCAL, ANY
73403 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 0
73404 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 43 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
73404 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 43.0 (TID 278, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
73405 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 43.0 (TID 279, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
73405 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 43.0 (TID 280, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
73406 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 43.0 (TID 281, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
73407 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 43.0 (TID 282, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
73408 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 43.0 (TID 283, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
73409 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 43.0 (TID 284, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
73409 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 43.0 (TID 285, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 278 on executor id: 0 hostname: 192.168.1.4.
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 279 on executor id: 0 hostname: 192.168.1.4.
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 280 on executor id: 0 hostname: 192.168.1.4.
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 281 on executor id: 0 hostname: 192.168.1.4.
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 282 on executor id: 0 hostname: 192.168.1.4.
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 283 on executor id: 0 hostname: 192.168.1.4.
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 284 on executor id: 0 hostname: 192.168.1.4.
73410 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 285 on executor id: 0 hostname: 192.168.1.4.
73415 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_59_piece0 as bytes
73415 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_59_piece0 is StorageLevel(disk, memory, 1 replicas)
73416 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_59_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
73426 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 7
73426 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
73426 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
73427 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 43.0 (TID 281) in 22 ms on 192.168.1.4 (executor 0) (1/8)
73427 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73428 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 6
73428 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 5
73428 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 43.0 (TID 285) in 19 ms on 192.168.1.4 (executor 0) (2/8)
73428 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 43.0 (TID 283) in 21 ms on 192.168.1.4 (executor 0) (3/8)
73428 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73429 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73429 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 4
73429 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 3
73429 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 43.0 (TID 282) in 23 ms on 192.168.1.4 (executor 0) (4/8)
73429 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 43.0 (TID 284) in 21 ms on 192.168.1.4 (executor 0) (5/8)
73430 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73430 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73435 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 2
73435 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 43.0 (TID 278) in 32 ms on 192.168.1.4 (executor 0) (6/8)
73436 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 1
73436 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73436 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 43.0 (TID 280) in 31 ms on 192.168.1.4 (executor 0) (7/8)
73436 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73437 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 0
73437 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 43.0 (TID 279) in 33 ms on 192.168.1.4 (executor 0) (8/8)
73437 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 43.0, whose tasks have all completed, from pool 
73438 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
73438 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 43 (mapToPair at SparkUtils.java:391) finished in 0.035 s
73438 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
73438 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
73438 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 45, ShuffleMapStage 44)
73438 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
73438 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 16
73438 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 44)
73438 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
73438 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 44 (MapPartitionsRDD[90] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
73438 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 44)
73439 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
73439 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_60 locally took  0 ms
73439 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_60 without replication took  0 ms
73440 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
73440 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_60_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.3 MB)
73440 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_60_piece0
73440 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_60_piece0
73440 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_60_piece0 locally took  0 ms
73440 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_60_piece0 without replication took  0 ms
73440 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 60 from broadcast at DAGScheduler.scala:1006
73440 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[90] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
73440 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 44.0 with 8 tasks
73440 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 44.0: 16
73440 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 44.0: NODE_LOCAL, ANY
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 0
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 44.0 (TID 286, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 44.0 (TID 287, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 44.0 (TID 288, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 44.0 (TID 289, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 44.0 (TID 290, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 44.0 (TID 291, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 44.0 (TID 292, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 44.0 (TID 293, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 286 on executor id: 0 hostname: 192.168.1.4.
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 287 on executor id: 0 hostname: 192.168.1.4.
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 288 on executor id: 0 hostname: 192.168.1.4.
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 289 on executor id: 0 hostname: 192.168.1.4.
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 290 on executor id: 0 hostname: 192.168.1.4.
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 291 on executor id: 0 hostname: 192.168.1.4.
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 292 on executor id: 0 hostname: 192.168.1.4.
73441 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 293 on executor id: 0 hostname: 192.168.1.4.
73444 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_60_piece0 as bytes
73445 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_60_piece0 is StorageLevel(disk, memory, 1 replicas)
73446 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_60_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
73448 [dispatcher-event-loop-4] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 16 to 192.168.1.4:59114
73448 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 16 to 192.168.1.4:59114
73448 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 16
73448 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 16
73449 [map-output-dispatcher-7] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 16 is 186 bytes
73452 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_58_piece0 as bytes
73452 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_58_piece0 is StorageLevel(disk, memory, 1 replicas)
73453 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_58_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
74320 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 8
75308 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 7
75308 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
75308 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 44.0 (TID 293) in 1867 ms on 192.168.1.4 (executor 0) (1/8)
75308 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
75320 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 7
76324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 7
76918 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 6
76919 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 44.0 (TID 291) in 3477 ms on 192.168.1.4 (executor 0) (2/8)
76919 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76928 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 5
76928 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 44.0 (TID 292) in 3487 ms on 192.168.1.4 (executor 0) (3/8)
76928 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77307 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 4
77307 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 44.0 (TID 290) in 3866 ms on 192.168.1.4 (executor 0) (4/8)
77308 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77322 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 4
77324 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 3
77324 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 44.0 (TID 288) in 3883 ms on 192.168.1.4 (executor 0) (5/8)
77324 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77374 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 2
77374 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 44.0 (TID 289) in 3933 ms on 192.168.1.4 (executor 0) (6/8)
77374 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77377 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 1
77377 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 44.0 (TID 286) in 3936 ms on 192.168.1.4 (executor 0) (7/8)
77377 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77384 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 0
77384 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 44.0 (TID 287) in 3943 ms on 192.168.1.4 (executor 0) (8/8)
77384 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 44.0, whose tasks have all completed, from pool 
77384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77384 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 44 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.944 s
77384 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
77384 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
77384 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 45)
77384 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
77384 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 17
77384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 45)
77384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77384 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 45 (MapPartitionsRDD[92] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
77384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 45)
77385 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
77385 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_61 locally took  0 ms
77385 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_61 without replication took  0 ms
77386 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
77386 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_61_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
77386 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_61_piece0
77386 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_61_piece0
77386 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_61_piece0 locally took  0 ms
77386 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_61_piece0 without replication took  0 ms
77386 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 61 from broadcast at DAGScheduler.scala:1006
77386 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[92] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
77386 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 45.0 with 2 tasks
77387 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 45.0: 17
77387 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 45.0: NODE_LOCAL, ANY
77387 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_45.0, runningTasks: 0
77387 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 45.0 (TID 294, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
77387 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 45.0 (TID 295, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
77387 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77387 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 294 on executor id: 0 hostname: 192.168.1.4.
77387 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 295 on executor id: 0 hostname: 192.168.1.4.
77390 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_61_piece0 as bytes
77390 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_61_piece0 is StorageLevel(disk, memory, 1 replicas)
77391 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_61_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
77393 [dispatcher-event-loop-1] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 15 to 192.168.1.4:59114
77393 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 15 to 192.168.1.4:59114
77393 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 15
77393 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 15
77393 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 15 is 159 bytes
77460 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_45.0, runningTasks: 1
77460 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_45.0, runningTasks: 0
77461 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 45.0 (TID 295) in 74 ms on 192.168.1.4 (executor 0) (1/2)
77461 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 45.0 (TID 294) in 74 ms on 192.168.1.4 (executor 0) (2/2)
77461 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 45.0, whose tasks have all completed, from pool 
77461 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 45 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.074 s
77461 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 44, remaining stages = 2
77461 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 43, remaining stages = 1
77461 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 45, remaining stages = 0
77461 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 28 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.061844 s
77462 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
77463 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
77463 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_62 locally took  0 ms
77463 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_62 without replication took  0 ms
77464 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
77464 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_62_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
77464 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_62_piece0
77464 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_62_piece0
77464 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_62_piece0 locally took  0 ms
77464 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_62_piece0 without replication took  0 ms
77464 [main] INFO org.apache.spark.SparkContext  - Created broadcast 62 from broadcast at SparkDl4jMultiLayer.java:595
77465 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
77465 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_63 locally took  1 ms
77465 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_63 without replication took  1 ms
77466 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
77466 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_63_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
77466 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_63_piece0
77466 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_63_piece0
77466 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_63_piece0 locally took  0 ms
77466 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_63_piece0 without replication took  0 ms
77466 [main] INFO org.apache.spark.SparkContext  - Created broadcast 63 from broadcast at SparkDl4jMultiLayer.java:596
77466 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
77467 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77468 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77469 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
77470 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77471 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77472 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77473 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77474 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77475 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77476 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
77476 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
77476 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 17 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
77476 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 95 (treeAggregate at SparkDl4jMultiLayer.java:598)
77477 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 29 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
77477 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 47 (treeAggregate at SparkDl4jMultiLayer.java:598)
77477 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 46)
77477 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 46)
77477 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 47)
77477 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 46)
77477 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 46)
77477 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77477 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 46 (MapPartitionsRDD[95] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
77477 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 46)
77478 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64 stored as values in memory (estimated size 8.9 KB, free 366.1 MB)
77478 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_64 locally took  0 ms
77478 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_64 without replication took  0 ms
77479 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.1 MB)
77479 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_64_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_64_piece0
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_64_piece0
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_64_piece0 locally took  1 ms
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_64_piece0 without replication took  1 ms
77479 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 64 from broadcast at DAGScheduler.scala:1006
77479 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[95] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77479 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 46.0 with 8 tasks
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 46.0: 17
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 46.0: NO_PREF, ANY
77480 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 0
77480 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 46.0 (TID 296, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
77480 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 46.0 (TID 297, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
77481 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 46.0 (TID 298, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
77481 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 46.0 (TID 299, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
77481 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 46.0 (TID 300, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
77481 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 46.0 (TID 301, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
77482 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 46.0 (TID 302, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
77482 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 46.0 (TID 303, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
77482 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 296 on executor id: 0 hostname: 192.168.1.4.
77483 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 297 on executor id: 0 hostname: 192.168.1.4.
77483 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 298 on executor id: 0 hostname: 192.168.1.4.
77483 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 299 on executor id: 0 hostname: 192.168.1.4.
77483 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 300 on executor id: 0 hostname: 192.168.1.4.
77483 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 301 on executor id: 0 hostname: 192.168.1.4.
77483 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 302 on executor id: 0 hostname: 192.168.1.4.
77483 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 303 on executor id: 0 hostname: 192.168.1.4.
77486 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_64_piece0 as bytes
77486 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_64_piece0 is StorageLevel(disk, memory, 1 replicas)
77487 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_64_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
77490 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_63_piece0 as bytes
77490 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_63_piece0 is StorageLevel(disk, memory, 1 replicas)
77491 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_63_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
77533 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_62_piece0 as bytes
77533 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_62_piece0 is StorageLevel(disk, memory, 1 replicas)
77534 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_62_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
77674 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 7
77674 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
77674 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 46.0 (TID 303) in 192 ms on 192.168.1.4 (executor 0) (1/8)
77674 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77753 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 6
77754 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 46.0 (TID 302) in 272 ms on 192.168.1.4 (executor 0) (2/8)
77754 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77816 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 5
77816 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 46.0 (TID 300) in 335 ms on 192.168.1.4 (executor 0) (3/8)
77816 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77831 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 4
77831 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 46.0 (TID 301) in 350 ms on 192.168.1.4 (executor 0) (4/8)
77832 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77854 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 3
77854 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 2
77854 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 46.0 (TID 298) in 374 ms on 192.168.1.4 (executor 0) (5/8)
77854 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 46.0 (TID 297) in 374 ms on 192.168.1.4 (executor 0) (6/8)
77854 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77855 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77855 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 1
77855 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 46.0 (TID 299) in 374 ms on 192.168.1.4 (executor 0) (7/8)
77855 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77860 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 0
77860 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 46.0 (TID 296) in 380 ms on 192.168.1.4 (executor 0) (8/8)
77860 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 46.0, whose tasks have all completed, from pool 
77860 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 46 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.380 s
77861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
77861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
77861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 47)
77861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
77861 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 18
77861 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 47)
77861 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 47 (MapPartitionsRDD[97] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
77861 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 47)
77862 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
77862 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_65 locally took  1 ms
77862 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_65 without replication took  1 ms
77862 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
77862 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_65_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
77862 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_65_piece0
77862 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_65_piece0
77862 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_65_piece0 locally took  0 ms
77863 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_65_piece0 without replication took  1 ms
77863 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 65 from broadcast at DAGScheduler.scala:1006
77863 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[97] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
77863 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 47.0 with 2 tasks
77863 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 47.0: 18
77863 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 47.0: NODE_LOCAL, ANY
77863 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_47.0, runningTasks: 0
77863 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 47.0 (TID 304, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
77863 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 47.0 (TID 305, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
77863 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77864 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 304 on executor id: 0 hostname: 192.168.1.4.
77864 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 305 on executor id: 0 hostname: 192.168.1.4.
77866 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_65_piece0 as bytes
77866 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_65_piece0 is StorageLevel(disk, memory, 1 replicas)
77867 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_65_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
77869 [dispatcher-event-loop-3] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 17 to 192.168.1.4:59114
77869 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 17 to 192.168.1.4:59114
77869 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 17
77869 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 17
77869 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 17 is 159 bytes
77873 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_47.0, runningTasks: 1
77873 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_47.0, runningTasks: 0
77874 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 47.0 (TID 305) in 11 ms on 192.168.1.4 (executor 0) (1/2)
77874 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 47.0 (TID 304) in 11 ms on 192.168.1.4 (executor 0) (2/2)
77874 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 47.0, whose tasks have all completed, from pool 
77874 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 47 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.011 s
77874 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 47, remaining stages = 1
77874 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 46, remaining stages = 0
77874 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 29 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.398258 s
77875 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 5: Accuracy = 0.00, F1 = NaN
77875 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 5
77875 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
77875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
77876 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
77877 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
77877 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 30 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
77877 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 48 (count at ParameterAveragingTrainingMaster.java:325)
77877 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
77878 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
77878 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 48)
77878 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77878 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 48 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
77878 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 48)
77878 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
77878 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_66 locally took  0 ms
77878 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_66 without replication took  0 ms
77879 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
77879 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_66_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
77879 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_66_piece0
77879 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_66_piece0
77879 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_66_piece0 locally took  0 ms
77879 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_66_piece0 without replication took  0 ms
77879 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 66 from broadcast at DAGScheduler.scala:1006
77879 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 48 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77879 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 48.0 with 8 tasks
77879 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 48.0: 18
77880 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 48.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77880 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 0
77880 [dispatcher-event-loop-1] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 48 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77880 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 48.0 (TID 306, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
77881 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 48.0 (TID 307, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
77882 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 48.0 (TID 308, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
77883 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 48.0 (TID 309, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
77884 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 48.0 (TID 310, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
77884 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 48.0 (TID 311, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
77885 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 48.0 (TID 312, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
77886 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 48.0 (TID 313, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
77886 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 306 on executor id: 0 hostname: 192.168.1.4.
77886 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 307 on executor id: 0 hostname: 192.168.1.4.
77886 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 308 on executor id: 0 hostname: 192.168.1.4.
77887 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 309 on executor id: 0 hostname: 192.168.1.4.
77887 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 310 on executor id: 0 hostname: 192.168.1.4.
77887 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 311 on executor id: 0 hostname: 192.168.1.4.
77887 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 312 on executor id: 0 hostname: 192.168.1.4.
77887 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 313 on executor id: 0 hostname: 192.168.1.4.
77891 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_66_piece0 as bytes
77891 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_66_piece0 is StorageLevel(disk, memory, 1 replicas)
77892 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_66_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
77895 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 7
77895 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77895 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77895 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 48.0 (TID 308) in 14 ms on 192.168.1.4 (executor 0) (1/8)
77896 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 6
77896 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 48.0 (TID 313) in 11 ms on 192.168.1.4 (executor 0) (2/8)
77896 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 5
77896 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 48.0 (TID 307) in 15 ms on 192.168.1.4 (executor 0) (3/8)
77896 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 4
77896 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 48.0 (TID 311) in 12 ms on 192.168.1.4 (executor 0) (4/8)
77897 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 3
77897 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 48.0 (TID 310) in 14 ms on 192.168.1.4 (executor 0) (5/8)
77897 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 2
77897 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 48.0 (TID 312) in 13 ms on 192.168.1.4 (executor 0) (6/8)
77897 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 1
77897 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 48.0 (TID 306) in 17 ms on 192.168.1.4 (executor 0) (7/8)
77898 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 0
77898 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 48.0 (TID 309) in 16 ms on 192.168.1.4 (executor 0) (8/8)
77898 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 48.0, whose tasks have all completed, from pool 
77898 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 48 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.018 s
77898 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 48, remaining stages = 0
77898 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 30 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.021414 s
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77899 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
77900 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353
77901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353)
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
77902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353)
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77903 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
77904 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
77904 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 31 (collect at SparkUtils.java:353) with 8 output partitions
77904 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 49 (collect at SparkUtils.java:353)
77904 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
77904 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
77904 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 49)
77904 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77904 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 49 (MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
77904 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 49)
77905 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
77905 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_67 locally took  0 ms
77905 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_67 without replication took  0 ms
77906 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.1 MB)
77906 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_67_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
77906 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_67_piece0
77906 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_67_piece0
77906 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_67_piece0 locally took  1 ms
77906 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_67_piece0 without replication took  1 ms
77906 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 67 from broadcast at DAGScheduler.scala:1006
77906 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 49 (MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77906 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 49.0 with 8 tasks
77906 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 49.0: 18
77906 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 49.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77906 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 0
77907 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 49 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77907 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 49.0 (TID 314, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
77908 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 49.0 (TID 315, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
77909 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 49.0 (TID 316, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
77909 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 49.0 (TID 317, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
77910 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 49.0 (TID 318, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
77911 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 49.0 (TID 319, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
77912 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 49.0 (TID 320, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
77912 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 49.0 (TID 321, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
77913 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 314 on executor id: 0 hostname: 192.168.1.4.
77913 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 315 on executor id: 0 hostname: 192.168.1.4.
77913 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 316 on executor id: 0 hostname: 192.168.1.4.
77913 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 317 on executor id: 0 hostname: 192.168.1.4.
77913 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 318 on executor id: 0 hostname: 192.168.1.4.
77913 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 319 on executor id: 0 hostname: 192.168.1.4.
77913 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 320 on executor id: 0 hostname: 192.168.1.4.
77914 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 321 on executor id: 0 hostname: 192.168.1.4.
77918 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_67_piece0 as bytes
77918 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_67_piece0 is StorageLevel(disk, memory, 1 replicas)
77918 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_67_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
77923 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 7
77923 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77923 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77923 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 49.0 (TID 319) in 13 ms on 192.168.1.4 (executor 0) (1/8)
77923 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 6
77923 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 5
77923 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 49.0 (TID 321) in 11 ms on 192.168.1.4 (executor 0) (2/8)
77923 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 49.0 (TID 315) in 16 ms on 192.168.1.4 (executor 0) (3/8)
77924 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 4
77924 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 49.0 (TID 320) in 13 ms on 192.168.1.4 (executor 0) (4/8)
77925 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 3
77925 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 49.0 (TID 318) in 16 ms on 192.168.1.4 (executor 0) (5/8)
77926 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 2
77927 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 49.0 (TID 317) in 17 ms on 192.168.1.4 (executor 0) (6/8)
77927 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 1
77927 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 49.0 (TID 314) in 21 ms on 192.168.1.4 (executor 0) (7/8)
77927 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 0
77928 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 49.0 (TID 316) in 19 ms on 192.168.1.4 (executor 0) (8/8)
77928 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 49.0, whose tasks have all completed, from pool 
77928 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 49 (collect at SparkUtils.java:353) finished in 0.022 s
77928 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 49, remaining stages = 0
77928 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 31 finished: collect at SparkUtils.java:353, took 0.024239 s
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
77930 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
77931 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 32 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
77931 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 50 (zipWithIndex at SparkUtils.java:391)
77931 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
77931 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
77931 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 50)
77931 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77931 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 50 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
77931 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 50)
77931 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68 stored as values in memory (estimated size 2.2 KB, free 366.1 MB)
77932 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_68 locally took  1 ms
77932 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_68 without replication took  1 ms
77932 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.1 MB)
77932 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_68_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.2 MB)
77933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_68_piece0
77933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_68_piece0
77933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_68_piece0 locally took  1 ms
77933 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_68_piece0 without replication took  1 ms
77933 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 68 from broadcast at DAGScheduler.scala:1006
77933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 50 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
77933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 50.0 with 7 tasks
77933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 50.0: 18
77933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 50.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77933 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 0
77934 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 50 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77934 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 50.0 (TID 322, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
77935 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 50.0 (TID 323, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
77935 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 50.0 (TID 324, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
77936 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 50.0 (TID 325, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
77937 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 50.0 (TID 326, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
77938 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 50.0 (TID 327, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
77938 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 50.0 (TID 328, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
77938 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77938 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77939 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 322 on executor id: 0 hostname: 192.168.1.4.
77939 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 323 on executor id: 0 hostname: 192.168.1.4.
77939 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 324 on executor id: 0 hostname: 192.168.1.4.
77939 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 325 on executor id: 0 hostname: 192.168.1.4.
77939 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 326 on executor id: 0 hostname: 192.168.1.4.
77939 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 327 on executor id: 0 hostname: 192.168.1.4.
77939 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 328 on executor id: 0 hostname: 192.168.1.4.
77943 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_68_piece0 as bytes
77944 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_68_piece0 is StorageLevel(disk, memory, 1 replicas)
77945 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_68_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
77948 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 6
77948 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 5
77948 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 50.0 (TID 328) in 10 ms on 192.168.1.4 (executor 0) (1/7)
77948 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 50.0 (TID 327) in 11 ms on 192.168.1.4 (executor 0) (2/7)
77949 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 4
77949 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 3
77949 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 50.0 (TID 324) in 14 ms on 192.168.1.4 (executor 0) (3/7)
77949 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 50.0 (TID 323) in 15 ms on 192.168.1.4 (executor 0) (4/7)
77950 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 2
77950 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 50.0 (TID 326) in 14 ms on 192.168.1.4 (executor 0) (5/7)
77951 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 1
77951 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 50.0 (TID 325) in 16 ms on 192.168.1.4 (executor 0) (6/7)
77951 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 0
77951 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 50.0 (TID 322) in 18 ms on 192.168.1.4 (executor 0) (7/7)
77951 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 50.0, whose tasks have all completed, from pool 
77951 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 50 (zipWithIndex at SparkUtils.java:391) finished in 0.018 s
77951 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 50, remaining stages = 0
77951 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 32 finished: zipWithIndex at SparkUtils.java:391, took 0.020861 s
77951 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77952 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77953 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
77954 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69 stored as values in memory (estimated size 31.4 KB, free 366.0 MB)
77954 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_69 locally took  1 ms
77954 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_69 without replication took  1 ms
77955 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.0 MB)
77955 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_69_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.2 MB)
77955 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_69_piece0
77955 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_69_piece0
77955 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_69_piece0 locally took  0 ms
77955 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_69_piece0 without replication took  0 ms
77955 [main] INFO org.apache.spark.SparkContext  - Created broadcast 69 from broadcast at ParameterAveragingTrainingMaster.java:259
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77956 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77957 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77958 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77959 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77960 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77961 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77962 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
77963 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77964 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77965 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77965 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77965 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77965 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
77965 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
77965 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 18 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
77965 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 101 (mapToPair at SparkUtils.java:391)
77965 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 106 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
77965 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 33 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
77965 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 53 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
77965 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 52)
77965 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 52)
77966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 53)
77966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 52)
77966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 52)
77966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 51)
77966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 51)
77966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77966 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 51 (MapPartitionsRDD[101] at mapToPair at SparkUtils.java:391), which has no missing parents
77966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 51)
77967 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
77967 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_70 locally took  0 ms
77967 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_70 without replication took  0 ms
77968 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
77968 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_70_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.2 MB)
77968 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_70_piece0
77968 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_70_piece0
77968 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_70_piece0 locally took  0 ms
77968 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_70_piece0 without replication took  0 ms
77968 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 70 from broadcast at DAGScheduler.scala:1006
77968 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[101] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77968 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 51.0 with 8 tasks
77968 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 51.0: 18
77969 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 51.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77969 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 0
77969 [dispatcher-event-loop-6] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 51 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77969 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 51.0 (TID 329, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
77970 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 51.0 (TID 330, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
77971 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 51.0 (TID 331, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
77972 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 51.0 (TID 332, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
77973 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 51.0 (TID 333, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
77973 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 51.0 (TID 334, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
77974 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 51.0 (TID 335, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
77975 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 51.0 (TID 336, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
77975 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 329 on executor id: 0 hostname: 192.168.1.4.
77975 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 330 on executor id: 0 hostname: 192.168.1.4.
77976 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 331 on executor id: 0 hostname: 192.168.1.4.
77976 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 332 on executor id: 0 hostname: 192.168.1.4.
77976 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 333 on executor id: 0 hostname: 192.168.1.4.
77976 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 334 on executor id: 0 hostname: 192.168.1.4.
77976 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 335 on executor id: 0 hostname: 192.168.1.4.
77976 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 336 on executor id: 0 hostname: 192.168.1.4.
77981 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_70_piece0 as bytes
77981 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_70_piece0 is StorageLevel(disk, memory, 1 replicas)
77982 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_70_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
77990 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 7
77990 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77990 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77991 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 6
77991 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 51.0 (TID 334) in 18 ms on 192.168.1.4 (executor 0) (1/8)
77991 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 51.0 (TID 331) in 21 ms on 192.168.1.4 (executor 0) (2/8)
77991 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77991 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77994 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 5
77994 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 4
77994 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 51.0 (TID 330) in 25 ms on 192.168.1.4 (executor 0) (3/8)
77994 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 51.0 (TID 333) in 22 ms on 192.168.1.4 (executor 0) (4/8)
77994 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77994 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77995 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 3
77995 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 51.0 (TID 335) in 22 ms on 192.168.1.4 (executor 0) (5/8)
77996 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77998 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 2
77998 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 51.0 (TID 336) in 24 ms on 192.168.1.4 (executor 0) (6/8)
77998 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 1
77998 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77999 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 51.0 (TID 329) in 30 ms on 192.168.1.4 (executor 0) (7/8)
77999 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
78000 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 0
78000 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 51.0 (TID 332) in 29 ms on 192.168.1.4 (executor 0) (8/8)
78000 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 51.0, whose tasks have all completed, from pool 
78000 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
78000 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 51 (mapToPair at SparkUtils.java:391) finished in 0.031 s
78000 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
78001 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
78001 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 52, ResultStage 53)
78001 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
78001 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 19
78001 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 52)
78001 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
78001 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 52 (MapPartitionsRDD[106] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
78001 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 52)
78002 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71 stored as values in memory (estimated size 6.6 KB, free 366.0 MB)
78002 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_71 locally took  0 ms
78002 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_71 without replication took  0 ms
78003 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.0 MB)
78003 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_71_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.2 MB)
78003 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_71_piece0
78003 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_71_piece0
78003 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_71_piece0 locally took  0 ms
78003 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_71_piece0 without replication took  0 ms
78003 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 71 from broadcast at DAGScheduler.scala:1006
78003 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[106] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
78003 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 52.0 with 8 tasks
78003 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 52.0: 19
78003 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 52.0: NODE_LOCAL, ANY
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 0
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 52.0 (TID 337, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 52.0 (TID 338, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 52.0 (TID 339, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 52.0 (TID 340, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 52.0 (TID 341, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 52.0 (TID 342, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 52.0 (TID 343, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 52.0 (TID 344, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 337 on executor id: 0 hostname: 192.168.1.4.
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 338 on executor id: 0 hostname: 192.168.1.4.
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 339 on executor id: 0 hostname: 192.168.1.4.
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 340 on executor id: 0 hostname: 192.168.1.4.
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 341 on executor id: 0 hostname: 192.168.1.4.
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 342 on executor id: 0 hostname: 192.168.1.4.
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 343 on executor id: 0 hostname: 192.168.1.4.
78004 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 344 on executor id: 0 hostname: 192.168.1.4.
78007 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_71_piece0 as bytes
78007 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_71_piece0 is StorageLevel(disk, memory, 1 replicas)
78008 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_71_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
78010 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 19 to 192.168.1.4:59114
78010 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 19 to 192.168.1.4:59114
78010 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 19
78010 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 19
78011 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 19 is 186 bytes
78013 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_69_piece0 as bytes
78014 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_69_piece0 is StorageLevel(disk, memory, 1 replicas)
78015 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_69_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
78320 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 8
79320 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 8
79998 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 7
79998 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
79998 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 52.0 (TID 344) in 1994 ms on 192.168.1.4 (executor 0) (1/8)
79998 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
80323 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 7
81321 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 7
81397 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 6
81397 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 52.0 (TID 342) in 3393 ms on 192.168.1.4 (executor 0) (2/8)
81397 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81503 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 5
81504 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 52.0 (TID 343) in 3500 ms on 192.168.1.4 (executor 0) (3/8)
81504 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81900 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 4
81900 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 3
81900 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 52.0 (TID 341) in 3896 ms on 192.168.1.4 (executor 0) (4/8)
81900 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 52.0 (TID 337) in 3896 ms on 192.168.1.4 (executor 0) (5/8)
81901 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81901 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81936 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 2
81936 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 52.0 (TID 338) in 3932 ms on 192.168.1.4 (executor 0) (6/8)
81937 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81959 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 1
81959 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 52.0 (TID 340) in 3955 ms on 192.168.1.4 (executor 0) (7/8)
81959 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81993 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 0
81994 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 52.0 (TID 339) in 3989 ms on 192.168.1.4 (executor 0) (8/8)
81994 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 52.0, whose tasks have all completed, from pool 
81994 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81994 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 52 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.991 s
81994 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
81994 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
81994 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 53)
81994 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
81994 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 20
81994 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 53)
81994 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
81994 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 53 (MapPartitionsRDD[108] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
81994 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 53)
81995 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72 stored as values in memory (estimated size 3.6 KB, free 366.0 MB)
81995 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_72 locally took  1 ms
81995 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_72 without replication took  1 ms
81995 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
81996 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_72_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.2 MB)
81996 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_72_piece0
81996 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_72_piece0
81996 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_72_piece0 locally took  1 ms
81996 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_72_piece0 without replication took  1 ms
81996 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 72 from broadcast at DAGScheduler.scala:1006
81996 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[108] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
81996 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 53.0 with 2 tasks
81996 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 53.0: 20
81996 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 53.0: NODE_LOCAL, ANY
81997 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_53.0, runningTasks: 0
81997 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 53.0 (TID 345, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
81997 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 53.0 (TID 346, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
81997 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
81997 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 345 on executor id: 0 hostname: 192.168.1.4.
81997 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 346 on executor id: 0 hostname: 192.168.1.4.
81999 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_72_piece0 as bytes
81999 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_72_piece0 is StorageLevel(disk, memory, 1 replicas)
82000 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_72_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
82002 [dispatcher-event-loop-2] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 18 to 192.168.1.4:59114
82002 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 18 to 192.168.1.4:59114
82002 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 18
82002 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 18
82002 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 18 is 159 bytes
82083 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_53.0, runningTasks: 1
82083 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_53.0, runningTasks: 0
82083 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 53.0 (TID 346) in 86 ms on 192.168.1.4 (executor 0) (1/2)
82084 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 53.0 (TID 345) in 87 ms on 192.168.1.4 (executor 0) (2/2)
82084 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 53.0, whose tasks have all completed, from pool 
82084 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 53 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.088 s
82084 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 53, remaining stages = 2
82084 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 52, remaining stages = 1
82084 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 51, remaining stages = 0
82084 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 33 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.119571 s
82085 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
82086 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73 stored as values in memory (estimated size 8.0 KB, free 366.0 MB)
82086 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_73 locally took  0 ms
82086 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_73 without replication took  0 ms
82087 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.0 MB)
82087 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_73_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.2 MB)
82087 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_73_piece0
82087 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_73_piece0
82087 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_73_piece0 locally took  0 ms
82087 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_73_piece0 without replication took  0 ms
82087 [main] INFO org.apache.spark.SparkContext  - Created broadcast 73 from broadcast at SparkDl4jMultiLayer.java:595
82088 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74 stored as values in memory (estimated size 27.8 KB, free 366.0 MB)
82088 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_74 locally took  1 ms
82088 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_74 without replication took  1 ms
82088 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
82088 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_74_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.2 MB)
82089 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_74_piece0
82089 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_74_piece0
82089 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_74_piece0 locally took  1 ms
82089 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_74_piece0 without replication took  1 ms
82089 [main] INFO org.apache.spark.SparkContext  - Created broadcast 74 from broadcast at SparkDl4jMultiLayer.java:596
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82090 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82091 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82092 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
82094 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82095 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82096 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82097 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82098 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
82098 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
82098 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 20 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
82098 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 111 (treeAggregate at SparkDl4jMultiLayer.java:598)
82098 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 34 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
82098 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 55 (treeAggregate at SparkDl4jMultiLayer.java:598)
82098 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 54)
82098 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 54)
82098 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 55)
82098 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 54)
82099 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 54)
82099 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82099 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 54 (MapPartitionsRDD[111] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
82099 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 54)
82099 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75 stored as values in memory (estimated size 8.9 KB, free 366.0 MB)
82099 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_75 locally took  0 ms
82099 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_75 without replication took  0 ms
82107 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(58)
82107 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 58
82107 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 58
82107 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 58
82107 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 58
82107 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_58
82107 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58 of size 31656 dropped from memory (free 383761044)
82107 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_58_piece0
82107 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.0 MB)
82107 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58_piece0 of size 5327 dropped from memory (free 383766371)
82108 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_58_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.2 MB)
82108 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_58_piece0
82108 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_58_piece0
82108 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 58, response is 0
82108 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_75_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.2 MB)
82108 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82108 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_75_piece0
82108 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_75_piece0
82108 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_75_piece0 locally took  1 ms
82108 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_75_piece0 without replication took  1 ms
82108 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 75 from broadcast at DAGScheduler.scala:1006
82108 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[111] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82108 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 54.0 with 8 tasks
82108 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 54.0: 20
82108 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 54.0: NO_PREF, ANY
82108 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_58_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
82109 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 0
82109 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 54.0 (TID 347, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
82109 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 54.0 (TID 348, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
82109 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 58
82109 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(62)
82109 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 62
82109 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 62
82109 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 62
82109 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 62
82110 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 54.0 (TID 349, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
82110 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_62
82110 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62 of size 8224 dropped from memory (free 383774595)
82110 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_62_piece0
82110 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62_piece0 of size 1428 dropped from memory (free 383776023)
82110 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 54.0 (TID 350, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
82110 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_62_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.2 MB)
82110 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_62_piece0
82110 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_62_piece0
82110 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 62, response is 0
82110 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82110 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_62_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.4 MB)
82110 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 54.0 (TID 351, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
82111 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 54.0 (TID 352, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
82111 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 62
82111 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(15)
82111 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 15
82111 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 15
82111 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 54.0 (TID 353, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
82111 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 15, response is true
82111 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 15
82111 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82111 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(57)
82111 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 57
82111 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 57
82111 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 57
82111 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 57
82112 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_57
82112 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57 of size 2216 dropped from memory (free 383778239)
82112 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 54.0 (TID 354, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
82112 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_57_piece0
82112 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57_piece0 of size 1460 dropped from memory (free 383779699)
82112 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 347 on executor id: 0 hostname: 192.168.1.4.
82112 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 348 on executor id: 0 hostname: 192.168.1.4.
82112 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_57_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.2 MB)
82112 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 349 on executor id: 0 hostname: 192.168.1.4.
82112 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_57_piece0
82112 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 350 on executor id: 0 hostname: 192.168.1.4.
82112 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_57_piece0
82112 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 57, response is 0
82112 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 351 on executor id: 0 hostname: 192.168.1.4.
82112 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82112 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 352 on executor id: 0 hostname: 192.168.1.4.
82113 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 353 on executor id: 0 hostname: 192.168.1.4.
82113 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_57_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
82113 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 354 on executor id: 0 hostname: 192.168.1.4.
82115 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 57
82115 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(63)
82115 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 63
82115 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 63
82115 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 63
82115 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 63
82115 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_63
82115 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63 of size 27976 dropped from memory (free 383807675)
82115 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_63_piece0
82115 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63_piece0 of size 2531 dropped from memory (free 383810206)
82116 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_63_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.2 MB)
82116 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_63_piece0
82116 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_63_piece0
82116 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 63, response is 0
82116 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82116 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_63_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
82117 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_75_piece0 as bytes
82117 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_75_piece0 is StorageLevel(disk, memory, 1 replicas)
82117 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 63
82117 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(67)
82117 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 67
82117 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 67
82117 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 67
82117 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 67
82117 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_67_piece0
82117 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67_piece0 of size 1570 dropped from memory (free 383811776)
82118 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_67_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.2 MB)
82118 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_67_piece0
82118 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_67_piece0
82118 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_67
82118 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67 of size 2504 dropped from memory (free 383814280)
82118 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 67, response is 0
82118 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82118 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_67_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.4 MB)
82118 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_75_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
82119 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 67
82119 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(19)
82119 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 19
82119 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 19
82119 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(53)
82119 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 53
82119 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 53
82119 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 19
82119 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 19, response is true
82119 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 53
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 53
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_53
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53 of size 9088 dropped from memory (free 383823368)
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_53_piece0
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53_piece0 of size 4135 dropped from memory (free 383827503)
82120 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_53_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.2 MB)
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_53_piece0
82120 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_53_piece0
82121 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 53, response is 0
82121 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82122 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_53_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
82123 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 53
82123 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(55)
82123 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 55
82123 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 55
82123 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 55
82123 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 55
82123 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_55_piece0
82123 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55_piece0 of size 1006 dropped from memory (free 383828509)
82124 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_55_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.2 MB)
82124 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_55_piece0
82124 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_55_piece0
82124 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_55
82124 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55 of size 1448 dropped from memory (free 383829957)
82124 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 55, response is 0
82124 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82124 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_55_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
82125 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 55
82125 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(13)
82125 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 13
82126 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 13
82126 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(47)
82126 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 47
82126 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 47
82126 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 13
82126 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 13, response is true
82126 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82126 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 47
82126 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 47
82126 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_47_piece0
82126 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47_piece0 of size 5327 dropped from memory (free 383835284)
82127 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_47_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.3 MB)
82127 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_47_piece0
82127 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_47_piece0
82127 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_47
82127 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47 of size 32104 dropped from memory (free 383867388)
82127 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 47, response is 0
82127 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82127 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_47_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
82128 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 47
82128 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(49)
82128 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 49
82128 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 49
82128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 49
82128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 49
82128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_49_piece0
82128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49_piece0 of size 3630 dropped from memory (free 383871018)
82129 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_49_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
82129 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_49_piece0
82129 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_49_piece0
82129 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_49
82129 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49 of size 6712 dropped from memory (free 383877730)
82129 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 49, response is 0
82129 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82129 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_49_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.4 MB)
82130 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 49
82130 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(14)
82130 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 14
82130 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 14
82130 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 14
82130 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 14, response is true
82130 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(70)
82130 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 70
82130 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82130 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 70
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 70
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 70
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_70
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70 of size 3600 dropped from memory (free 383881330)
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_70_piece0
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70_piece0 of size 2197 dropped from memory (free 383883527)
82131 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_74_piece0 as bytes
82131 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_74_piece0 is StorageLevel(disk, memory, 1 replicas)
82131 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_70_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_70_piece0
82131 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_70_piece0
82131 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_70_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
82131 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 70, response is 0
82132 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82132 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 70
82132 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(54)
82132 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 54
82132 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 54
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 54
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 54
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_54
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54 of size 3656 dropped from memory (free 383887183)
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_54_piece0
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54_piece0 of size 2126 dropped from memory (free 383889309)
82133 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_54_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_54_piece0
82133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_54_piece0
82133 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 54, response is 0
82133 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_74_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
82133 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82133 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_54_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
82134 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 54
82134 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(56)
82134 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 56
82134 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 56
82134 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 56
82134 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 56
82134 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_56_piece0
82134 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56_piece0 of size 1570 dropped from memory (free 383890879)
82135 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_56_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.3 MB)
82135 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_56_piece0
82135 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_56_piece0
82135 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_56
82135 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56 of size 2504 dropped from memory (free 383893383)
82135 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 56, response is 0
82135 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_56_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.4 MB)
82135 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82136 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 56
82136 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(60)
82136 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 60
82136 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 60
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 60
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 60
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_60
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60 of size 6712 dropped from memory (free 383900095)
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_60_piece0
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60_piece0 of size 3629 dropped from memory (free 383903724)
82136 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_60_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_60_piece0
82136 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_60_piece0
82136 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 60, response is 0
82136 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82137 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_60_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.4 MB)
82137 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 60
82137 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(65)
82137 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 65
82137 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 65
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 65
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 65
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_65
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65 of size 3656 dropped from memory (free 383907380)
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_65_piece0
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65_piece0 of size 2125 dropped from memory (free 383909505)
82138 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_65_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_65_piece0
82138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_65_piece0
82138 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 65, response is 0
82138 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82138 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_65_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
82139 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 65
82139 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(66)
82139 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 66
82139 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 66
82139 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 66
82139 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 66
82139 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_66_piece0
82139 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66_piece0 of size 1006 dropped from memory (free 383910511)
82139 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_66_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.3 MB)
82140 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_66_piece0
82140 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_66_piece0
82140 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_66
82140 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66 of size 1448 dropped from memory (free 383911959)
82140 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 66, response is 0
82140 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82140 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_66_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
82141 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 66
82141 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(71)
82141 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 71
82141 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 71
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 71
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 71
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_71
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71 of size 6712 dropped from memory (free 383918671)
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_71_piece0
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71_piece0 of size 3634 dropped from memory (free 383922305)
82141 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_71_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_71_piece0
82141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_71_piece0
82141 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 71, response is 0
82141 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82141 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_71_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.4 MB)
82142 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 71
82142 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(69)
82142 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 69
82142 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 69
82142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 69
82142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 69
82142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_69
82142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69 of size 32104 dropped from memory (free 383954409)
82142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_69_piece0
82142 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69_piece0 of size 5323 dropped from memory (free 383959732)
82143 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_69_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.3 MB)
82143 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_69_piece0
82143 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_69_piece0
82143 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 69, response is 0
82143 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82143 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_69_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
82144 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 69
82144 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(59)
82144 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 59
82144 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 59
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 59
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 59
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_59
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59 of size 3600 dropped from memory (free 383963332)
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_59_piece0
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59_piece0 of size 2197 dropped from memory (free 383965529)
82144 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_59_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_59_piece0
82144 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_59_piece0
82144 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 59, response is 0
82144 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82144 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_59_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
82145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 59
82145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(52)
82145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 52
82145 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 52
82145 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 52
82145 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 52
82145 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_52_piece0
82145 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52_piece0 of size 2531 dropped from memory (free 383968060)
82145 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_52_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.3 MB)
82146 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_52_piece0
82146 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_52_piece0
82146 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_52
82146 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52 of size 27528 dropped from memory (free 383995588)
82146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 52, response is 0
82146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82146 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_52_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
82146 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 52
82146 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(61)
82146 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 61
82146 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 61
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 61
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 61
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_61
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61 of size 3672 dropped from memory (free 383999260)
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_61_piece0
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61_piece0 of size 2133 dropped from memory (free 384001393)
82147 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_61_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_61_piece0
82147 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_61_piece0
82147 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 61, response is 0
82147 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82147 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_61_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
82148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 61
82148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(64)
82148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 64
82148 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 64
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 64
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 64
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_64_piece0
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64_piece0 of size 4135 dropped from memory (free 384005528)
82148 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_64_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.3 MB)
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_64_piece0
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_64_piece0
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_64
82148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64 of size 9088 dropped from memory (free 384014616)
82149 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 64, response is 0
82149 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82149 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_64_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
82149 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 64
82149 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(68)
82149 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 68
82149 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 68
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 68
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 68
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_68_piece0
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68_piece0 of size 1460 dropped from memory (free 384016076)
82150 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_68_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_68_piece0
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_68_piece0
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_68
82150 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68 of size 2216 dropped from memory (free 384018292)
82150 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 68, response is 0
82150 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82150 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_68_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
82151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 68
82151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(17)
82151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 17
82151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 17
82151 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 17
82151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(16)
82151 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 17, response is true
82151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 16
82151 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82151 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 16
82151 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 16
82151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 16, response is true
82151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(18)
82151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 18
82151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 18
82152 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 18
82152 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 18, response is true
82152 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(12)
82152 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 12
82152 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82152 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 12
82152 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 12
82152 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(50)
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 12, response is true
82152 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 50
82152 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 50
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 50
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 50
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_50
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50 of size 3672 dropped from memory (free 384021964)
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_50_piece0
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50_piece0 of size 2135 dropped from memory (free 384024099)
82152 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_50_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_50_piece0
82152 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_50_piece0
82153 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 50, response is 0
82153 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82153 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_50_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
82154 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 50
82154 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(72)
82154 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 72
82154 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 72
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 72
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 72
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_72_piece0
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72_piece0 of size 2135 dropped from memory (free 384026234)
82154 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_72_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_72_piece0
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_72_piece0
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_72
82154 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72 of size 3672 dropped from memory (free 384029906)
82154 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 72, response is 0
82154 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82155 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_72_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.5 MB)
82155 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 72
82155 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(51)
82155 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 51
82155 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 51
82155 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 51
82155 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 51
82155 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_51
82155 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51 of size 8224 dropped from memory (free 384038130)
82156 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_51_piece0
82156 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51_piece0 of size 1428 dropped from memory (free 384039558)
82156 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_51_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.3 MB)
82156 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_51_piece0
82156 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_51_piece0
82156 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 51, response is 0
82156 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
82156 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_51_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.5 MB)
82157 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 51
82188 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_73_piece0 as bytes
82188 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_73_piece0 is StorageLevel(disk, memory, 1 replicas)
82189 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_73_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.5 MB)
82320 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 7
82320 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
82320 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 54.0 (TID 354) in 209 ms on 192.168.1.4 (executor 0) (1/8)
82320 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 7
82320 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82475 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 6
82475 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 54.0 (TID 352) in 365 ms on 192.168.1.4 (executor 0) (2/8)
82475 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 5
82475 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82475 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 54.0 (TID 353) in 364 ms on 192.168.1.4 (executor 0) (3/8)
82475 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82502 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 4
82502 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 54.0 (TID 350) in 392 ms on 192.168.1.4 (executor 0) (4/8)
82502 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82519 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 3
82519 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 54.0 (TID 349) in 410 ms on 192.168.1.4 (executor 0) (5/8)
82519 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82520 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 2
82520 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 54.0 (TID 347) in 411 ms on 192.168.1.4 (executor 0) (6/8)
82520 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82523 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 1
82523 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 0
82523 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 54.0 (TID 351) in 413 ms on 192.168.1.4 (executor 0) (7/8)
82523 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 54.0 (TID 348) in 414 ms on 192.168.1.4 (executor 0) (8/8)
82523 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 54.0, whose tasks have all completed, from pool 
82523 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82523 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82524 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 54 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.415 s
82524 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
82524 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
82524 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 55)
82524 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
82524 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 21
82524 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 55)
82524 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82524 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 55 (MapPartitionsRDD[113] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
82524 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 55)
82525 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
82525 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_76 locally took  1 ms
82525 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_76 without replication took  1 ms
82525 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
82526 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_76_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
82526 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_76_piece0
82526 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_76_piece0
82526 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_76_piece0 locally took  1 ms
82526 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_76_piece0 without replication took  1 ms
82526 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 76 from broadcast at DAGScheduler.scala:1006
82526 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[113] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
82526 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 55.0 with 2 tasks
82526 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 55.0: 21
82526 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 55.0: NODE_LOCAL, ANY
82526 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_55.0, runningTasks: 0
82526 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 55.0 (TID 355, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
82526 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 55.0 (TID 356, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
82526 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82527 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 355 on executor id: 0 hostname: 192.168.1.4.
82527 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 356 on executor id: 0 hostname: 192.168.1.4.
82529 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_76_piece0 as bytes
82529 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_76_piece0 is StorageLevel(disk, memory, 1 replicas)
82530 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_76_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
82532 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 20 to 192.168.1.4:59114
82532 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 20 to 192.168.1.4:59114
82532 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 20
82532 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 20
82532 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 20 is 159 bytes
82535 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_55.0, runningTasks: 1
82536 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_55.0, runningTasks: 0
82536 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 55.0 (TID 356) in 10 ms on 192.168.1.4 (executor 0) (1/2)
82536 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 55.0 (TID 355) in 10 ms on 192.168.1.4 (executor 0) (2/2)
82536 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 55.0, whose tasks have all completed, from pool 
82536 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 55 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.010 s
82536 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 55, remaining stages = 1
82536 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 54, remaining stages = 0
82536 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 34 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.438382 s
82537 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 6: Accuracy = 0.00, F1 = NaN
82537 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 6
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82538 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
82538 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
82539 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 35 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
82539 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 56 (count at ParameterAveragingTrainingMaster.java:325)
82539 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
82539 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
82539 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 56)
82539 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82539 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 56 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
82539 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 56)
82540 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
82540 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_77 locally took  1 ms
82540 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_77 without replication took  1 ms
82540 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
82540 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_77_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
82540 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_77_piece0
82540 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_77_piece0
82541 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_77_piece0 locally took  0 ms
82541 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_77_piece0 without replication took  1 ms
82541 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 77 from broadcast at DAGScheduler.scala:1006
82541 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 56 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82541 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 56.0 with 8 tasks
82541 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 56.0: 21
82541 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 56.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82541 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 0
82542 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 56 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82542 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 56.0 (TID 357, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
82543 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 56.0 (TID 358, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
82543 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 56.0 (TID 359, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
82544 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 56.0 (TID 360, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
82545 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 56.0 (TID 361, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
82546 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 56.0 (TID 362, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
82547 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 56.0 (TID 363, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
82547 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 56.0 (TID 364, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
82548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 357 on executor id: 0 hostname: 192.168.1.4.
82548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 358 on executor id: 0 hostname: 192.168.1.4.
82548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 359 on executor id: 0 hostname: 192.168.1.4.
82548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 360 on executor id: 0 hostname: 192.168.1.4.
82548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 361 on executor id: 0 hostname: 192.168.1.4.
82548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 362 on executor id: 0 hostname: 192.168.1.4.
82549 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 363 on executor id: 0 hostname: 192.168.1.4.
82549 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 364 on executor id: 0 hostname: 192.168.1.4.
82554 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_77_piece0 as bytes
82554 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_77_piece0 is StorageLevel(disk, memory, 1 replicas)
82555 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_77_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
82558 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 7
82558 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82558 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82558 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 6
82558 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 56.0 (TID 360) in 15 ms on 192.168.1.4 (executor 0) (1/8)
82559 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 56.0 (TID 361) in 15 ms on 192.168.1.4 (executor 0) (2/8)
82559 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 5
82559 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 4
82559 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 56.0 (TID 357) in 18 ms on 192.168.1.4 (executor 0) (3/8)
82559 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 56.0 (TID 363) in 13 ms on 192.168.1.4 (executor 0) (4/8)
82559 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 3
82559 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 2
82559 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 1
82559 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 56.0 (TID 358) in 17 ms on 192.168.1.4 (executor 0) (5/8)
82559 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 56.0 (TID 364) in 12 ms on 192.168.1.4 (executor 0) (6/8)
82559 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 56.0 (TID 362) in 14 ms on 192.168.1.4 (executor 0) (7/8)
82560 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 0
82560 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 56.0 (TID 359) in 17 ms on 192.168.1.4 (executor 0) (8/8)
82560 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 56.0, whose tasks have all completed, from pool 
82560 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 56 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.019 s
82560 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 56, remaining stages = 0
82561 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 35 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.022028 s
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
82562 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
82563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353)
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
82564 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353)
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
82565 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
82566 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
82566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 36 (collect at SparkUtils.java:353) with 8 output partitions
82566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 57 (collect at SparkUtils.java:353)
82566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
82567 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
82567 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 57)
82567 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82567 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 57 (MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
82567 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 57)
82567 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
82567 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_78 locally took  0 ms
82567 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_78 without replication took  0 ms
82568 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
82568 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_78_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
82568 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_78_piece0
82568 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_78_piece0
82568 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_78_piece0 locally took  0 ms
82568 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_78_piece0 without replication took  0 ms
82569 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 78 from broadcast at DAGScheduler.scala:1006
82569 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 57 (MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82569 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 57.0 with 8 tasks
82569 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 57.0: 21
82569 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 57.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82569 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 0
82570 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 57 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82570 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 57.0 (TID 365, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
82571 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 57.0 (TID 366, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
82571 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 57.0 (TID 367, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
82572 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 57.0 (TID 368, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
82573 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 57.0 (TID 369, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
82574 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 57.0 (TID 370, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
82574 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 57.0 (TID 371, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
82575 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 57.0 (TID 372, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
82576 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 365 on executor id: 0 hostname: 192.168.1.4.
82576 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 366 on executor id: 0 hostname: 192.168.1.4.
82576 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 367 on executor id: 0 hostname: 192.168.1.4.
82576 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 368 on executor id: 0 hostname: 192.168.1.4.
82576 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 369 on executor id: 0 hostname: 192.168.1.4.
82577 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 370 on executor id: 0 hostname: 192.168.1.4.
82577 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 371 on executor id: 0 hostname: 192.168.1.4.
82577 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 372 on executor id: 0 hostname: 192.168.1.4.
82581 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_78_piece0 as bytes
82581 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_78_piece0 is StorageLevel(disk, memory, 1 replicas)
82583 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_78_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
82586 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 7
82587 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82587 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82587 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 6
82587 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 57.0 (TID 368) in 16 ms on 192.168.1.4 (executor 0) (1/8)
82587 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 5
82587 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 57.0 (TID 367) in 16 ms on 192.168.1.4 (executor 0) (2/8)
82587 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 57.0 (TID 366) in 17 ms on 192.168.1.4 (executor 0) (3/8)
82588 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 4
82588 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 3
82588 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 57.0 (TID 369) in 16 ms on 192.168.1.4 (executor 0) (4/8)
82588 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 57.0 (TID 372) in 14 ms on 192.168.1.4 (executor 0) (5/8)
82588 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 2
82588 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 57.0 (TID 370) in 15 ms on 192.168.1.4 (executor 0) (6/8)
82589 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 1
82589 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 57.0 (TID 371) in 15 ms on 192.168.1.4 (executor 0) (7/8)
82589 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 0
82589 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 57.0 (TID 365) in 20 ms on 192.168.1.4 (executor 0) (8/8)
82589 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 57.0, whose tasks have all completed, from pool 
82589 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 57 (collect at SparkUtils.java:353) finished in 0.020 s
82589 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 57, remaining stages = 0
82590 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 36 finished: collect at SparkUtils.java:353, took 0.023513 s
82590 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
82592 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
82592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 37 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
82592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 58 (zipWithIndex at SparkUtils.java:391)
82592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
82592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
82592 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 58)
82592 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 58 (MapPartitionsRDD[114] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
82592 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 58)
82593 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
82593 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_79 locally took  0 ms
82593 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_79 without replication took  0 ms
82594 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
82594 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_79_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
82594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_79_piece0
82594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_79_piece0
82594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_79_piece0 locally took  0 ms
82594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_79_piece0 without replication took  0 ms
82594 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 79 from broadcast at DAGScheduler.scala:1006
82594 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 58 (MapPartitionsRDD[114] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
82594 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 58.0 with 7 tasks
82594 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 58.0: 21
82594 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 58.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82595 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 0
82595 [dispatcher-event-loop-1] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 58 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82595 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 58.0 (TID 373, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
82596 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 58.0 (TID 374, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
82597 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 58.0 (TID 375, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
82598 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 58.0 (TID 376, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
82599 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 58.0 (TID 377, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
82600 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 58.0 (TID 378, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
82600 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 58.0 (TID 379, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
82600 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82600 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82601 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 373 on executor id: 0 hostname: 192.168.1.4.
82601 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 374 on executor id: 0 hostname: 192.168.1.4.
82601 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 375 on executor id: 0 hostname: 192.168.1.4.
82601 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 376 on executor id: 0 hostname: 192.168.1.4.
82601 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 377 on executor id: 0 hostname: 192.168.1.4.
82601 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 378 on executor id: 0 hostname: 192.168.1.4.
82602 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 379 on executor id: 0 hostname: 192.168.1.4.
82606 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_79_piece0 as bytes
82606 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_79_piece0 is StorageLevel(disk, memory, 1 replicas)
82607 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_79_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
82611 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 6
82612 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 5
82612 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 4
82612 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 58.0 (TID 375) in 16 ms on 192.168.1.4 (executor 0) (1/7)
82612 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 58.0 (TID 379) in 12 ms on 192.168.1.4 (executor 0) (2/7)
82612 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 58.0 (TID 376) in 15 ms on 192.168.1.4 (executor 0) (3/7)
82612 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 3
82612 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 58.0 (TID 377) in 14 ms on 192.168.1.4 (executor 0) (4/7)
82613 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 2
82613 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 58.0 (TID 374) in 18 ms on 192.168.1.4 (executor 0) (5/7)
82613 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 1
82613 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 58.0 (TID 373) in 18 ms on 192.168.1.4 (executor 0) (6/7)
82613 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 0
82614 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 58.0 (TID 378) in 15 ms on 192.168.1.4 (executor 0) (7/7)
82614 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 58.0, whose tasks have all completed, from pool 
82614 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 58 (zipWithIndex at SparkUtils.java:391) finished in 0.019 s
82614 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 58, remaining stages = 0
82614 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 37 finished: zipWithIndex at SparkUtils.java:391, took 0.022029 s
82614 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
82615 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
82617 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80 stored as values in memory (estimated size 30.5 KB, free 366.2 MB)
82617 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_80 locally took  1 ms
82617 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_80 without replication took  1 ms
82618 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.2 MB)
82618 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_80_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.3 MB)
82618 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_80_piece0
82618 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_80_piece0
82618 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_80_piece0 locally took  0 ms
82618 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_80_piece0 without replication took  0 ms
82618 [main] INFO org.apache.spark.SparkContext  - Created broadcast 80 from broadcast at ParameterAveragingTrainingMaster.java:259
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82620 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
82623 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
82628 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
82628 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 21 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
82628 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 117 (mapToPair at SparkUtils.java:391)
82629 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 122 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
82629 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 38 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
82629 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 61 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
82629 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 60)
82629 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 60)
82629 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 61)
82629 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 60)
82629 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 60)
82629 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 59)
82629 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 59)
82629 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82629 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 59 (MapPartitionsRDD[117] at mapToPair at SparkUtils.java:391), which has no missing parents
82629 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 59)
82630 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81 stored as values in memory (estimated size 3.5 KB, free 366.2 MB)
82630 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_81 locally took  0 ms
82630 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_81 without replication took  0 ms
82631 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
82631 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_81_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
82631 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_81_piece0
82631 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_81_piece0
82631 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_81_piece0 locally took  0 ms
82631 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_81_piece0 without replication took  0 ms
82631 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 81 from broadcast at DAGScheduler.scala:1006
82631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[117] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 59.0 with 8 tasks
82631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 59.0: 21
82631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 59.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82632 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 0
82632 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 59 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82632 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 59.0 (TID 380, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
82633 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 59.0 (TID 381, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
82634 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 59.0 (TID 382, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
82635 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 59.0 (TID 383, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
82635 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 59.0 (TID 384, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
82636 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 59.0 (TID 385, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
82637 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 59.0 (TID 386, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
82638 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 59.0 (TID 387, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
82638 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 380 on executor id: 0 hostname: 192.168.1.4.
82638 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 381 on executor id: 0 hostname: 192.168.1.4.
82638 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 382 on executor id: 0 hostname: 192.168.1.4.
82638 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 383 on executor id: 0 hostname: 192.168.1.4.
82638 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 384 on executor id: 0 hostname: 192.168.1.4.
82638 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 385 on executor id: 0 hostname: 192.168.1.4.
82638 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 386 on executor id: 0 hostname: 192.168.1.4.
82639 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 387 on executor id: 0 hostname: 192.168.1.4.
82643 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_81_piece0 as bytes
82643 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_81_piece0 is StorageLevel(disk, memory, 1 replicas)
82644 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_81_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
82652 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 7
82652 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82652 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82652 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 6
82652 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 59.0 (TID 380) in 20 ms on 192.168.1.4 (executor 0) (1/8)
82652 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 59.0 (TID 382) in 19 ms on 192.168.1.4 (executor 0) (2/8)
82652 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82652 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82653 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 5
82653 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 59.0 (TID 385) in 18 ms on 192.168.1.4 (executor 0) (3/8)
82653 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82656 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 4
82656 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 59.0 (TID 383) in 22 ms on 192.168.1.4 (executor 0) (4/8)
82656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82657 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 3
82657 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 59.0 (TID 381) in 25 ms on 192.168.1.4 (executor 0) (5/8)
82657 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 2
82657 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82657 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 59.0 (TID 384) in 22 ms on 192.168.1.4 (executor 0) (6/8)
82657 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82659 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 1
82659 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 0
82659 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 59.0 (TID 386) in 23 ms on 192.168.1.4 (executor 0) (7/8)
82660 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 59.0 (TID 387) in 23 ms on 192.168.1.4 (executor 0) (8/8)
82660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82660 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 59.0, whose tasks have all completed, from pool 
82660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 59 (mapToPair at SparkUtils.java:391) finished in 0.029 s
82660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
82660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
82660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 60, ResultStage 61)
82660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
82660 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 22
82660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 60)
82660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 60 (MapPartitionsRDD[122] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
82660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 60)
82661 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82 stored as values in memory (estimated size 6.6 KB, free 366.2 MB)
82661 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_82 locally took  0 ms
82661 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_82 without replication took  0 ms
82662 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
82662 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_82_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.3 MB)
82662 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_82_piece0
82662 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_82_piece0
82662 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_82_piece0 locally took  0 ms
82662 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_82_piece0 without replication took  0 ms
82662 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 82 from broadcast at DAGScheduler.scala:1006
82662 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[122] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82662 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 60.0 with 8 tasks
82662 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 60.0: 22
82662 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 60.0: NODE_LOCAL, ANY
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 0
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 60.0 (TID 388, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 60.0 (TID 389, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 60.0 (TID 390, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 60.0 (TID 391, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 60.0 (TID 392, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 60.0 (TID 393, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 60.0 (TID 394, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 60.0 (TID 395, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 388 on executor id: 0 hostname: 192.168.1.4.
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 389 on executor id: 0 hostname: 192.168.1.4.
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 390 on executor id: 0 hostname: 192.168.1.4.
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 391 on executor id: 0 hostname: 192.168.1.4.
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 392 on executor id: 0 hostname: 192.168.1.4.
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 393 on executor id: 0 hostname: 192.168.1.4.
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 394 on executor id: 0 hostname: 192.168.1.4.
82663 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 395 on executor id: 0 hostname: 192.168.1.4.
82666 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_82_piece0 as bytes
82666 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_82_piece0 is StorageLevel(disk, memory, 1 replicas)
82667 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_82_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
82669 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 22 to 192.168.1.4:59114
82669 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 22 to 192.168.1.4:59114
82669 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 22
82669 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 22
82669 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 22 is 186 bytes
82672 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_80_piece0 as bytes
82672 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_80_piece0 is StorageLevel(disk, memory, 1 replicas)
82673 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_80_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
83320 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 8
84321 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 8
84479 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 7
84480 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
84480 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 60.0 (TID 393) in 1817 ms on 192.168.1.4 (executor 0) (1/8)
84480 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
85320 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 7
86128 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 6
86128 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 60.0 (TID 394) in 3465 ms on 192.168.1.4 (executor 0) (2/8)
86128 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86155 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 5
86155 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 60.0 (TID 395) in 3492 ms on 192.168.1.4 (executor 0) (3/8)
86155 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 5
86506 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 4
86506 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 60.0 (TID 390) in 3843 ms on 192.168.1.4 (executor 0) (4/8)
86507 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86516 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 3
86517 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 60.0 (TID 389) in 3854 ms on 192.168.1.4 (executor 0) (5/8)
86517 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86530 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 2
86530 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 60.0 (TID 388) in 3867 ms on 192.168.1.4 (executor 0) (6/8)
86530 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86532 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 1
86532 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 60.0 (TID 391) in 3869 ms on 192.168.1.4 (executor 0) (7/8)
86532 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86545 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 0
86545 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 60.0 (TID 392) in 3882 ms on 192.168.1.4 (executor 0) (8/8)
86545 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 60.0, whose tasks have all completed, from pool 
86546 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86546 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 60 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.883 s
86546 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
86546 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
86546 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 61)
86546 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
86546 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 23
86546 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 61)
86546 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
86546 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 61 (MapPartitionsRDD[124] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
86546 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 61)
86547 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
86547 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_83 locally took  1 ms
86547 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_83 without replication took  1 ms
86547 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
86547 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_83_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
86548 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_83_piece0
86548 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_83_piece0
86548 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_83_piece0 locally took  1 ms
86548 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_83_piece0 without replication took  1 ms
86548 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 83 from broadcast at DAGScheduler.scala:1006
86548 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[124] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
86548 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 61.0 with 2 tasks
86548 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 61.0: 23
86548 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 61.0: NODE_LOCAL, ANY
86548 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_61.0, runningTasks: 0
86548 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 61.0 (TID 396, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
86548 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 61.0 (TID 397, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
86548 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
86548 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 396 on executor id: 0 hostname: 192.168.1.4.
86549 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 397 on executor id: 0 hostname: 192.168.1.4.
86551 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_83_piece0 as bytes
86551 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_83_piece0 is StorageLevel(disk, memory, 1 replicas)
86552 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_83_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
86553 [dispatcher-event-loop-0] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 21 to 192.168.1.4:59114
86553 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 21 to 192.168.1.4:59114
86553 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 21
86553 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 21
86553 [map-output-dispatcher-6] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 21 is 159 bytes
86646 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_61.0, runningTasks: 1
86646 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_61.0, runningTasks: 0
86646 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 61.0 (TID 396) in 98 ms on 192.168.1.4 (executor 0) (1/2)
86647 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 61.0 (TID 397) in 99 ms on 192.168.1.4 (executor 0) (2/2)
86647 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 61.0, whose tasks have all completed, from pool 
86647 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 61 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.099 s
86647 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 59, remaining stages = 2
86647 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 61, remaining stages = 1
86647 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 60, remaining stages = 0
86647 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 38 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.019489 s
86648 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
86654 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
86654 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_84 locally took  0 ms
86654 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_84 without replication took  0 ms
86655 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
86655 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_84_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
86655 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_84_piece0
86655 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_84_piece0
86656 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_84_piece0 locally took  0 ms
86656 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_84_piece0 without replication took  1 ms
86656 [main] INFO org.apache.spark.SparkContext  - Created broadcast 84 from broadcast at SparkDl4jMultiLayer.java:595
86656 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85 stored as values in memory (estimated size 26.9 KB, free 366.1 MB)
86656 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_85 locally took  0 ms
86656 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_85 without replication took  0 ms
86657 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
86657 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_85_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
86657 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_85_piece0
86657 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_85_piece0
86657 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_85_piece0 locally took  0 ms
86657 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_85_piece0 without replication took  0 ms
86657 [main] INFO org.apache.spark.SparkContext  - Created broadcast 85 from broadcast at SparkDl4jMultiLayer.java:596
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86660 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86661 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86661 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86661 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86661 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
86661 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86662 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
86663 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86664 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86665 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
86666 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
86667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
86667 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
86667 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 23 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
86667 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 127 (treeAggregate at SparkDl4jMultiLayer.java:598)
86667 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 39 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
86667 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 63 (treeAggregate at SparkDl4jMultiLayer.java:598)
86667 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 62)
86668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 62)
86668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 63)
86668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 62)
86668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 62)
86668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
86668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 62 (MapPartitionsRDD[127] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
86668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 62)
86669 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86 stored as values in memory (estimated size 8.9 KB, free 366.1 MB)
86669 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_86 locally took  1 ms
86669 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_86 without replication took  1 ms
86669 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.1 MB)
86669 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_86_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
86670 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_86_piece0
86670 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_86_piece0
86670 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_86_piece0 locally took  1 ms
86670 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_86_piece0 without replication took  1 ms
86670 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 86 from broadcast at DAGScheduler.scala:1006
86670 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[127] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
86670 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 62.0 with 8 tasks
86670 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 62.0: 23
86670 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 62.0: NO_PREF, ANY
86670 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 0
86670 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 62.0 (TID 398, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
86671 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 62.0 (TID 399, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
86671 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 62.0 (TID 400, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
86671 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 62.0 (TID 401, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
86672 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 62.0 (TID 402, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
86672 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 62.0 (TID 403, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
86672 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 62.0 (TID 404, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
86673 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 62.0 (TID 405, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 398 on executor id: 0 hostname: 192.168.1.4.
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 399 on executor id: 0 hostname: 192.168.1.4.
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 400 on executor id: 0 hostname: 192.168.1.4.
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 401 on executor id: 0 hostname: 192.168.1.4.
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 402 on executor id: 0 hostname: 192.168.1.4.
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 403 on executor id: 0 hostname: 192.168.1.4.
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 404 on executor id: 0 hostname: 192.168.1.4.
86673 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 405 on executor id: 0 hostname: 192.168.1.4.
86678 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_86_piece0 as bytes
86678 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_86_piece0 is StorageLevel(disk, memory, 1 replicas)
86679 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_86_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
86682 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_85_piece0 as bytes
86682 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_85_piece0 is StorageLevel(disk, memory, 1 replicas)
86682 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_85_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
86733 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_84_piece0 as bytes
86733 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_84_piece0 is StorageLevel(disk, memory, 1 replicas)
86734 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_84_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
86892 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 7
86892 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
86892 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 62.0 (TID 405) in 220 ms on 192.168.1.4 (executor 0) (1/8)
86892 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86995 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 6
86996 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 62.0 (TID 399) in 326 ms on 192.168.1.4 (executor 0) (2/8)
86996 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87003 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 5
87003 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 62.0 (TID 400) in 332 ms on 192.168.1.4 (executor 0) (3/8)
87003 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87007 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 4
87007 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 62.0 (TID 403) in 335 ms on 192.168.1.4 (executor 0) (4/8)
87007 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87025 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 3
87025 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 62.0 (TID 402) in 354 ms on 192.168.1.4 (executor 0) (5/8)
87025 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87057 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 2
87057 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 62.0 (TID 404) in 385 ms on 192.168.1.4 (executor 0) (6/8)
87057 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87066 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 1
87066 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 62.0 (TID 401) in 395 ms on 192.168.1.4 (executor 0) (7/8)
87066 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87071 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 0
87071 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 62.0 (TID 398) in 401 ms on 192.168.1.4 (executor 0) (8/8)
87071 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 62.0, whose tasks have all completed, from pool 
87071 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87071 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 62 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.401 s
87071 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
87071 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
87071 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 63)
87071 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
87071 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 24
87071 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 63)
87071 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87071 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 63 (MapPartitionsRDD[129] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
87071 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 63)
87072 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
87072 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_87 locally took  0 ms
87072 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_87 without replication took  0 ms
87073 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
87073 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_87_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
87073 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_87_piece0
87073 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_87_piece0
87073 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_87_piece0 locally took  0 ms
87073 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_87_piece0 without replication took  0 ms
87073 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 87 from broadcast at DAGScheduler.scala:1006
87073 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 63 (MapPartitionsRDD[129] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
87074 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 63.0 with 2 tasks
87074 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 63.0: 24
87074 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 63.0: NODE_LOCAL, ANY
87074 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_63.0, runningTasks: 0
87074 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 63.0 (TID 406, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
87074 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 63.0 (TID 407, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
87074 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87074 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 406 on executor id: 0 hostname: 192.168.1.4.
87074 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 407 on executor id: 0 hostname: 192.168.1.4.
87076 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_87_piece0 as bytes
87076 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_87_piece0 is StorageLevel(disk, memory, 1 replicas)
87077 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_87_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
87078 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 23 to 192.168.1.4:59114
87079 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 23 to 192.168.1.4:59114
87079 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 23
87079 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 23
87079 [map-output-dispatcher-7] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 23 is 159 bytes
87082 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_63.0, runningTasks: 1
87082 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_63.0, runningTasks: 0
87082 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 63.0 (TID 406) in 8 ms on 192.168.1.4 (executor 0) (1/2)
87082 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 63.0 (TID 407) in 8 ms on 192.168.1.4 (executor 0) (2/2)
87082 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 63.0, whose tasks have all completed, from pool 
87082 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 63 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.008 s
87082 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 62, remaining stages = 1
87082 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 63, remaining stages = 0
87083 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 39 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.415703 s
87083 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 7: Accuracy = 0.00, F1 = NaN
87083 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 7
87083 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
87085 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
87085 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 40 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
87085 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 64 (count at ParameterAveragingTrainingMaster.java:325)
87085 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
87085 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
87085 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 64)
87085 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87085 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 64 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
87085 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 64)
87086 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
87086 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_88 locally took  1 ms
87086 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_88 without replication took  1 ms
87086 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
87086 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_88_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.3 MB)
87086 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_88_piece0
87086 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_88_piece0
87086 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_88_piece0 locally took  0 ms
87086 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_88_piece0 without replication took  0 ms
87087 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 88 from broadcast at DAGScheduler.scala:1006
87087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 64 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87087 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 64.0 with 8 tasks
87087 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 64.0: 24
87087 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 64.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87087 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 0
87088 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 64 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87088 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 64.0 (TID 408, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
87088 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 64.0 (TID 409, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
87089 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 64.0 (TID 410, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
87090 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 64.0 (TID 411, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
87091 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 64.0 (TID 412, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
87091 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 64.0 (TID 413, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
87092 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 64.0 (TID 414, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
87093 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 64.0 (TID 415, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
87093 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 408 on executor id: 0 hostname: 192.168.1.4.
87093 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 409 on executor id: 0 hostname: 192.168.1.4.
87093 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 410 on executor id: 0 hostname: 192.168.1.4.
87093 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 411 on executor id: 0 hostname: 192.168.1.4.
87094 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 412 on executor id: 0 hostname: 192.168.1.4.
87094 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 413 on executor id: 0 hostname: 192.168.1.4.
87094 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 414 on executor id: 0 hostname: 192.168.1.4.
87094 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 415 on executor id: 0 hostname: 192.168.1.4.
87098 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_88_piece0 as bytes
87098 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_88_piece0 is StorageLevel(disk, memory, 1 replicas)
87099 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_88_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
87102 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 7
87102 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87102 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87102 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 64.0 (TID 408) in 15 ms on 192.168.1.4 (executor 0) (1/8)
87102 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 6
87103 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 5
87103 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 64.0 (TID 413) in 12 ms on 192.168.1.4 (executor 0) (2/8)
87103 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 64.0 (TID 415) in 11 ms on 192.168.1.4 (executor 0) (3/8)
87103 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 4
87103 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 64.0 (TID 412) in 13 ms on 192.168.1.4 (executor 0) (4/8)
87103 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 3
87103 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 64.0 (TID 410) in 15 ms on 192.168.1.4 (executor 0) (5/8)
87103 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 2
87103 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 64.0 (TID 414) in 12 ms on 192.168.1.4 (executor 0) (6/8)
87104 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 1
87104 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 64.0 (TID 411) in 15 ms on 192.168.1.4 (executor 0) (7/8)
87104 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 0
87104 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 64.0 (TID 409) in 16 ms on 192.168.1.4 (executor 0) (8/8)
87104 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 64.0, whose tasks have all completed, from pool 
87104 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 64 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.017 s
87104 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 64, remaining stages = 0
87104 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 40 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.019671 s
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87105 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
87106 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87106 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87107 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
87108 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
87108 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
87108 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353)
87108 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
87109 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
87109 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353)
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87110 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87111 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87111 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87111 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87111 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
87111 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
87111 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 41 (collect at SparkUtils.java:353) with 8 output partitions
87111 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 65 (collect at SparkUtils.java:353)
87111 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
87111 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
87111 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 65)
87112 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87112 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 65 (MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
87112 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 65)
87112 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
87112 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_89 locally took  0 ms
87112 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_89 without replication took  0 ms
87113 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.1 MB)
87113 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_89_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
87113 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_89_piece0
87113 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_89_piece0
87113 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_89_piece0 locally took  0 ms
87113 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_89_piece0 without replication took  0 ms
87113 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 89 from broadcast at DAGScheduler.scala:1006
87114 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 65 (MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87114 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 65.0 with 8 tasks
87114 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 65.0: 24
87114 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 65.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87114 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 0
87115 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 65 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87115 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 65.0 (TID 416, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
87116 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 65.0 (TID 417, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
87116 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 65.0 (TID 418, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
87117 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 65.0 (TID 419, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
87118 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 65.0 (TID 420, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
87118 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 65.0 (TID 421, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
87119 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 65.0 (TID 422, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
87120 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 65.0 (TID 423, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
87120 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 416 on executor id: 0 hostname: 192.168.1.4.
87120 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 417 on executor id: 0 hostname: 192.168.1.4.
87120 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 418 on executor id: 0 hostname: 192.168.1.4.
87120 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 419 on executor id: 0 hostname: 192.168.1.4.
87121 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 420 on executor id: 0 hostname: 192.168.1.4.
87121 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 421 on executor id: 0 hostname: 192.168.1.4.
87121 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 422 on executor id: 0 hostname: 192.168.1.4.
87121 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 423 on executor id: 0 hostname: 192.168.1.4.
87126 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_89_piece0 as bytes
87126 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_89_piece0 is StorageLevel(disk, memory, 1 replicas)
87127 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_89_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
87131 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 7
87131 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87131 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87131 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 65.0 (TID 421) in 13 ms on 192.168.1.4 (executor 0) (1/8)
87131 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 6
87131 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 5
87131 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 65.0 (TID 416) in 17 ms on 192.168.1.4 (executor 0) (2/8)
87131 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 65.0 (TID 418) in 15 ms on 192.168.1.4 (executor 0) (3/8)
87131 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 4
87131 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 3
87131 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 2
87131 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 65.0 (TID 423) in 12 ms on 192.168.1.4 (executor 0) (4/8)
87132 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 1
87132 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 65.0 (TID 422) in 14 ms on 192.168.1.4 (executor 0) (5/8)
87132 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 65.0 (TID 419) in 16 ms on 192.168.1.4 (executor 0) (6/8)
87132 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 65.0 (TID 420) in 15 ms on 192.168.1.4 (executor 0) (7/8)
87132 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 0
87132 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 65.0 (TID 417) in 17 ms on 192.168.1.4 (executor 0) (8/8)
87132 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 65.0, whose tasks have all completed, from pool 
87132 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 65 (collect at SparkUtils.java:353) finished in 0.018 s
87132 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 65, remaining stages = 0
87132 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 41 finished: collect at SparkUtils.java:353, took 0.021303 s
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
87134 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
87134 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 42 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
87134 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 66 (zipWithIndex at SparkUtils.java:391)
87134 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
87135 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
87135 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 66)
87135 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87135 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 66 (MapPartitionsRDD[130] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
87135 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 66)
87135 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90 stored as values in memory (estimated size 2.2 KB, free 366.1 MB)
87135 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_90 locally took  0 ms
87135 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_90 without replication took  0 ms
87136 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.1 MB)
87137 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_90_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
87137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_90_piece0
87137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_90_piece0
87137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_90_piece0 locally took  1 ms
87137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_90_piece0 without replication took  1 ms
87137 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 90 from broadcast at DAGScheduler.scala:1006
87137 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 66 (MapPartitionsRDD[130] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
87137 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 66.0 with 7 tasks
87137 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 66.0: 24
87137 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 66.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87137 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 0
87138 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 66 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87138 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 66.0 (TID 424, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
87139 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 66.0 (TID 425, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
87139 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 66.0 (TID 426, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
87140 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 66.0 (TID 427, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
87141 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 66.0 (TID 428, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
87142 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 66.0 (TID 429, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
87142 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 66.0 (TID 430, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
87142 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87142 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87143 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 424 on executor id: 0 hostname: 192.168.1.4.
87143 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 425 on executor id: 0 hostname: 192.168.1.4.
87143 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 426 on executor id: 0 hostname: 192.168.1.4.
87143 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 427 on executor id: 0 hostname: 192.168.1.4.
87143 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 428 on executor id: 0 hostname: 192.168.1.4.
87143 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 429 on executor id: 0 hostname: 192.168.1.4.
87143 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 430 on executor id: 0 hostname: 192.168.1.4.
87147 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_90_piece0 as bytes
87147 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_90_piece0 is StorageLevel(disk, memory, 1 replicas)
87148 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_90_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.4 MB)
87151 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 6
87151 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 66.0 (TID 426) in 12 ms on 192.168.1.4 (executor 0) (1/7)
87151 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 5
87152 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 66.0 (TID 428) in 12 ms on 192.168.1.4 (executor 0) (2/7)
87152 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 4
87152 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 66.0 (TID 429) in 11 ms on 192.168.1.4 (executor 0) (3/7)
87152 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 3
87152 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 2
87152 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 66.0 (TID 424) in 15 ms on 192.168.1.4 (executor 0) (4/7)
87152 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 66.0 (TID 430) in 10 ms on 192.168.1.4 (executor 0) (5/7)
87153 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 1
87153 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 66.0 (TID 425) in 15 ms on 192.168.1.4 (executor 0) (6/7)
87153 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 0
87153 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 66.0 (TID 427) in 13 ms on 192.168.1.4 (executor 0) (7/7)
87153 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 66.0, whose tasks have all completed, from pool 
87153 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 66 (zipWithIndex at SparkUtils.java:391) finished in 0.016 s
87153 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 66, remaining stages = 0
87154 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 42 finished: zipWithIndex at SparkUtils.java:391, took 0.019321 s
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87154 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87155 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87155 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87155 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
87155 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87156 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
87157 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_91 stored as values in memory (estimated size 30.9 KB, free 366.1 MB)
87157 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_91 locally took  1 ms
87157 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_91 without replication took  1 ms
87158 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_91_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
87158 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_91_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.3 MB)
87158 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_91_piece0
87158 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_91_piece0
87158 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_91_piece0 locally took  0 ms
87158 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_91_piece0 without replication took  0 ms
87158 [main] INFO org.apache.spark.SparkContext  - Created broadcast 91 from broadcast at ParameterAveragingTrainingMaster.java:259
87158 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
87159 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87160 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87161 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87162 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87163 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87164 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87165 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87166 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87167 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
87167 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
87167 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 24 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
87168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 133 (mapToPair at SparkUtils.java:391)
87168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 138 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
87168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 43 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
87168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 69 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
87168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 68)
87168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 68)
87168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 69)
87168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 68)
87168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 68)
87168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 67)
87168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 67)
87168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87168 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 67 (MapPartitionsRDD[133] at mapToPair at SparkUtils.java:391), which has no missing parents
87168 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 67)
87169 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_92 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
87169 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_92 locally took  0 ms
87169 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_92 without replication took  0 ms
87170 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_92_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
87170 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_92_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
87170 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_92_piece0
87170 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_92_piece0
87170 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_92_piece0 locally took  0 ms
87170 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_92_piece0 without replication took  0 ms
87170 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 92 from broadcast at DAGScheduler.scala:1006
87171 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[133] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87171 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 67.0 with 8 tasks
87171 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 67.0: 24
87171 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 67.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87171 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 0
87172 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 67 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87172 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 67.0 (TID 431, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
87173 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 67.0 (TID 432, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
87173 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 67.0 (TID 433, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
87174 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 67.0 (TID 434, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
87175 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 67.0 (TID 435, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
87175 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 67.0 (TID 436, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
87176 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 67.0 (TID 437, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
87177 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 67.0 (TID 438, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
87177 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 431 on executor id: 0 hostname: 192.168.1.4.
87177 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 432 on executor id: 0 hostname: 192.168.1.4.
87177 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 433 on executor id: 0 hostname: 192.168.1.4.
87177 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 434 on executor id: 0 hostname: 192.168.1.4.
87178 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 435 on executor id: 0 hostname: 192.168.1.4.
87178 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 436 on executor id: 0 hostname: 192.168.1.4.
87178 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 437 on executor id: 0 hostname: 192.168.1.4.
87178 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 438 on executor id: 0 hostname: 192.168.1.4.
87182 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_92_piece0 as bytes
87182 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_92_piece0 is StorageLevel(disk, memory, 1 replicas)
87183 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_92_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
87191 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 7
87191 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87191 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87191 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 6
87191 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 67.0 (TID 437) in 16 ms on 192.168.1.4 (executor 0) (1/8)
87192 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 67.0 (TID 431) in 21 ms on 192.168.1.4 (executor 0) (2/8)
87192 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87192 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87192 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 5
87192 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 67.0 (TID 432) in 20 ms on 192.168.1.4 (executor 0) (3/8)
87192 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 4
87192 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87192 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 67.0 (TID 436) in 17 ms on 192.168.1.4 (executor 0) (4/8)
87192 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87193 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 3
87193 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 67.0 (TID 433) in 20 ms on 192.168.1.4 (executor 0) (5/8)
87193 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87194 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 2
87194 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 67.0 (TID 435) in 20 ms on 192.168.1.4 (executor 0) (6/8)
87195 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87195 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 1
87195 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 67.0 (TID 438) in 19 ms on 192.168.1.4 (executor 0) (7/8)
87195 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 0
87195 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87195 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 67.0 (TID 434) in 22 ms on 192.168.1.4 (executor 0) (8/8)
87195 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 67.0, whose tasks have all completed, from pool 
87195 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87195 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 67 (mapToPair at SparkUtils.java:391) finished in 0.024 s
87195 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
87195 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
87195 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 68, ResultStage 69)
87195 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
87196 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 25
87196 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 68)
87196 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87196 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 68 (MapPartitionsRDD[138] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
87196 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 68)
87197 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_93 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
87197 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_93 locally took  0 ms
87197 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_93 without replication took  0 ms
87197 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_93_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
87198 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_93_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.2 MB)
87198 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_93_piece0
87198 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_93_piece0
87198 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_93_piece0 locally took  1 ms
87198 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_93_piece0 without replication took  1 ms
87198 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 93 from broadcast at DAGScheduler.scala:1006
87198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[138] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 68.0 with 8 tasks
87198 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 68.0: 25
87198 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 68.0: NODE_LOCAL, ANY
87198 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 0
87198 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 68.0 (TID 439, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
87198 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 68.0 (TID 440, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
87199 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 68.0 (TID 441, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
87199 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 68.0 (TID 442, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
87199 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 68.0 (TID 443, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
87199 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 68.0 (TID 444, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
87199 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 68.0 (TID 445, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
87199 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 68.0 (TID 446, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 439 on executor id: 0 hostname: 192.168.1.4.
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 440 on executor id: 0 hostname: 192.168.1.4.
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 441 on executor id: 0 hostname: 192.168.1.4.
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 442 on executor id: 0 hostname: 192.168.1.4.
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 443 on executor id: 0 hostname: 192.168.1.4.
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 444 on executor id: 0 hostname: 192.168.1.4.
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 445 on executor id: 0 hostname: 192.168.1.4.
87199 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 446 on executor id: 0 hostname: 192.168.1.4.
87202 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_93_piece0 as bytes
87202 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_93_piece0 is StorageLevel(disk, memory, 1 replicas)
87203 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_93_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.4 MB)
87204 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 25 to 192.168.1.4:59114
87204 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 25 to 192.168.1.4:59114
87204 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 25
87204 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 25
87205 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 25 is 186 bytes
87207 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_91_piece0 as bytes
87208 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_91_piece0 is StorageLevel(disk, memory, 1 replicas)
87208 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_91_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
87320 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 8
88322 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 8
89007 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 7
89007 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
89007 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 68.0 (TID 445) in 1808 ms on 192.168.1.4 (executor 0) (1/8)
89008 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
89320 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 7
90323 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 7
90626 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 6
90626 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 5
90626 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 68.0 (TID 446) in 3427 ms on 192.168.1.4 (executor 0) (2/8)
90627 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 68.0 (TID 444) in 3428 ms on 192.168.1.4 (executor 0) (3/8)
90627 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
90627 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91005 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 4
91005 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 68.0 (TID 443) in 3806 ms on 192.168.1.4 (executor 0) (4/8)
91005 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91013 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 3
91013 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 68.0 (TID 441) in 3814 ms on 192.168.1.4 (executor 0) (5/8)
91013 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91021 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 2
91021 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 68.0 (TID 439) in 3823 ms on 192.168.1.4 (executor 0) (6/8)
91021 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91025 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 1
91025 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 68.0 (TID 442) in 3826 ms on 192.168.1.4 (executor 0) (7/8)
91025 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91035 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 0
91035 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 68.0 (TID 440) in 3837 ms on 192.168.1.4 (executor 0) (8/8)
91035 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 68.0, whose tasks have all completed, from pool 
91035 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91035 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 68 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.837 s
91035 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
91035 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
91035 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 69)
91035 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
91035 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 26
91036 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 69)
91036 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91036 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 69 (MapPartitionsRDD[140] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
91036 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 69)
91036 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_94 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
91036 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_94 locally took  0 ms
91036 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_94 without replication took  0 ms
91037 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_94_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
91037 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_94_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.2 MB)
91037 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_94_piece0
91037 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_94_piece0
91037 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_94_piece0 locally took  0 ms
91037 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_94_piece0 without replication took  0 ms
91038 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 94 from broadcast at DAGScheduler.scala:1006
91038 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 69 (MapPartitionsRDD[140] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
91038 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 69.0 with 2 tasks
91038 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 69.0: 26
91038 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 69.0: NODE_LOCAL, ANY
91038 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_69.0, runningTasks: 0
91038 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 69.0 (TID 447, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
91038 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 69.0 (TID 448, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
91038 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
91038 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 447 on executor id: 0 hostname: 192.168.1.4.
91038 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 448 on executor id: 0 hostname: 192.168.1.4.
91040 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_94_piece0 as bytes
91040 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_94_piece0 is StorageLevel(disk, memory, 1 replicas)
91041 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_94_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
91043 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 24 to 192.168.1.4:59114
91043 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 24 to 192.168.1.4:59114
91043 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 24
91043 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 24
91043 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 24 is 159 bytes
91124 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_69.0, runningTasks: 1
91124 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_69.0, runningTasks: 0
91124 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 69.0 (TID 447) in 86 ms on 192.168.1.4 (executor 0) (1/2)
91124 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 69.0 (TID 448) in 86 ms on 192.168.1.4 (executor 0) (2/2)
91124 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 69.0, whose tasks have all completed, from pool 
91125 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 69 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.086 s
91125 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 68, remaining stages = 2
91125 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 67, remaining stages = 1
91125 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 69, remaining stages = 0
91125 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 43 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 3.957780 s
91126 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
91127 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_95 stored as values in memory (estimated size 8.0 KB, free 366.0 MB)
91127 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_95 locally took  1 ms
91127 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_95 without replication took  1 ms
91127 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_95_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.0 MB)
91128 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_95_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.2 MB)
91128 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_95_piece0
91128 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_95_piece0
91128 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_95_piece0 locally took  1 ms
91128 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_95_piece0 without replication took  1 ms
91128 [main] INFO org.apache.spark.SparkContext  - Created broadcast 95 from broadcast at SparkDl4jMultiLayer.java:595
91128 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_96 stored as values in memory (estimated size 27.3 KB, free 366.0 MB)
91128 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_96 locally took  0 ms
91128 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_96 without replication took  0 ms
91129 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_96_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
91129 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_96_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.2 MB)
91129 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_96_piece0
91129 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_96_piece0
91129 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_96_piece0 locally took  0 ms
91129 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_96_piece0 without replication took  0 ms
91129 [main] INFO org.apache.spark.SparkContext  - Created broadcast 96 from broadcast at SparkDl4jMultiLayer.java:596
91129 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
91133 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
91133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
91133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
91133 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
91134 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91135 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91136 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91137 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91138 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91139 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91139 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91139 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
91139 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
91139 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 26 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
91139 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 143 (treeAggregate at SparkDl4jMultiLayer.java:598)
91139 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 44 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
91139 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 71 (treeAggregate at SparkDl4jMultiLayer.java:598)
91139 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 70)
91139 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 70)
91139 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 71)
91139 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 70)
91139 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 70)
91139 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91139 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 70 (MapPartitionsRDD[143] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
91139 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 70)
91140 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_97 stored as values in memory (estimated size 8.9 KB, free 366.0 MB)
91140 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_97 locally took  0 ms
91140 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_97 without replication took  0 ms
91141 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_97_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.0 MB)
91141 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_97_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.2 MB)
91141 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_97_piece0
91141 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_97_piece0
91141 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_97_piece0 locally took  0 ms
91141 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_97_piece0 without replication took  0 ms
91141 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 97 from broadcast at DAGScheduler.scala:1006
91142 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[143] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
91142 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 70.0 with 8 tasks
91142 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 70.0: 26
91142 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 70.0: NO_PREF, ANY
91142 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 0
91142 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 70.0 (TID 449, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
91142 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 70.0 (TID 450, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
91143 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 70.0 (TID 451, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
91143 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 70.0 (TID 452, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
91143 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 70.0 (TID 453, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
91144 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 70.0 (TID 454, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
91144 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 70.0 (TID 455, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
91144 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 70.0 (TID 456, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
91144 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 449 on executor id: 0 hostname: 192.168.1.4.
91145 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 450 on executor id: 0 hostname: 192.168.1.4.
91145 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 451 on executor id: 0 hostname: 192.168.1.4.
91145 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 452 on executor id: 0 hostname: 192.168.1.4.
91145 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 453 on executor id: 0 hostname: 192.168.1.4.
91145 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 454 on executor id: 0 hostname: 192.168.1.4.
91145 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 455 on executor id: 0 hostname: 192.168.1.4.
91145 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 456 on executor id: 0 hostname: 192.168.1.4.
91148 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_97_piece0 as bytes
91148 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_97_piece0 is StorageLevel(disk, memory, 1 replicas)
91149 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_97_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
91152 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_96_piece0 as bytes
91152 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_96_piece0 is StorageLevel(disk, memory, 1 replicas)
91152 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_96_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
91165 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_95_piece0 as bytes
91165 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_95_piece0 is StorageLevel(disk, memory, 1 replicas)
91166 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_95_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
91295 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 7
91295 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
91295 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 70.0 (TID 456) in 151 ms on 192.168.1.4 (executor 0) (1/8)
91295 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91321 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 7
91353 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 6
91354 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 70.0 (TID 455) in 209 ms on 192.168.1.4 (executor 0) (2/8)
91354 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91372 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 5
91372 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 70.0 (TID 454) in 229 ms on 192.168.1.4 (executor 0) (3/8)
91372 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91412 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 4
91412 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 70.0 (TID 453) in 269 ms on 192.168.1.4 (executor 0) (4/8)
91412 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91422 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 3
91422 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 70.0 (TID 451) in 279 ms on 192.168.1.4 (executor 0) (5/8)
91422 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 2
91423 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91423 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 70.0 (TID 452) in 280 ms on 192.168.1.4 (executor 0) (6/8)
91423 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91500 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 1
91500 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 70.0 (TID 449) in 358 ms on 192.168.1.4 (executor 0) (7/8)
91500 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91501 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 0
91501 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 70.0 (TID 450) in 359 ms on 192.168.1.4 (executor 0) (8/8)
91501 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 70.0, whose tasks have all completed, from pool 
91501 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 70 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.359 s
91501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
91501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
91501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 71)
91501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
91501 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 27
91501 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 71)
91501 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91501 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 71 (MapPartitionsRDD[145] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
91501 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 71)
91502 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_98 stored as values in memory (estimated size 3.6 KB, free 366.0 MB)
91502 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_98 locally took  0 ms
91502 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_98 without replication took  0 ms
91503 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_98_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
91503 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_98_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.2 MB)
91503 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_98_piece0
91503 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_98_piece0
91503 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_98_piece0 locally took  0 ms
91503 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_98_piece0 without replication took  0 ms
91503 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 98 from broadcast at DAGScheduler.scala:1006
91503 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 71 (MapPartitionsRDD[145] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
91503 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 71.0 with 2 tasks
91503 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 71.0: 27
91503 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 71.0: NODE_LOCAL, ANY
91504 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_71.0, runningTasks: 0
91504 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 71.0 (TID 457, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
91504 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 71.0 (TID 458, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
91504 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
91504 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 457 on executor id: 0 hostname: 192.168.1.4.
91504 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 458 on executor id: 0 hostname: 192.168.1.4.
91506 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_98_piece0 as bytes
91506 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_98_piece0 is StorageLevel(disk, memory, 1 replicas)
91507 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_98_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
91509 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 26 to 192.168.1.4:59114
91509 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 26 to 192.168.1.4:59114
91509 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 26
91509 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 26
91509 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 26 is 159 bytes
91512 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_71.0, runningTasks: 1
91512 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_71.0, runningTasks: 0
91513 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 71.0 (TID 457) in 8 ms on 192.168.1.4 (executor 0) (1/2)
91513 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 71.0 (TID 458) in 9 ms on 192.168.1.4 (executor 0) (2/2)
91513 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 71.0, whose tasks have all completed, from pool 
91513 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 71 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.010 s
91513 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 71, remaining stages = 1
91513 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 70, remaining stages = 0
91513 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 44 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.374295 s
91513 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 8: Accuracy = 0.00, F1 = NaN
91513 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 8
91513 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
91514 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91515 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91515 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91515 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91515 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91515 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91515 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
91515 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
91515 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 45 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
91515 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 72 (count at ParameterAveragingTrainingMaster.java:325)
91515 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
91515 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
91515 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 72)
91515 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91515 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 72 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
91515 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 72)
91516 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_99 stored as values in memory (estimated size 1448.0 B, free 366.0 MB)
91516 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_99 locally took  0 ms
91516 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_99 without replication took  0 ms
91517 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_99_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.0 MB)
91517 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_99_piece0 in memory on 192.168.1.4:59108 (size: 1006.0 B, free: 366.2 MB)
91517 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_99_piece0
91517 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_99_piece0
91517 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_99_piece0 locally took  1 ms
91517 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_99_piece0 without replication took  1 ms
91517 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 99 from broadcast at DAGScheduler.scala:1006
91517 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 72 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
91517 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 72.0 with 8 tasks
91517 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 72.0: 27
91517 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 72.0: PROCESS_LOCAL, NODE_LOCAL, ANY
91517 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 0
91518 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 72 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
91518 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 72.0 (TID 459, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
91519 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 72.0 (TID 460, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
91520 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 72.0 (TID 461, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
91520 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 72.0 (TID 462, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
91521 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 72.0 (TID 463, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
91522 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 72.0 (TID 464, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
91523 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 72.0 (TID 465, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
91523 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 72.0 (TID 466, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
91524 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 459 on executor id: 0 hostname: 192.168.1.4.
91524 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 460 on executor id: 0 hostname: 192.168.1.4.
91524 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 461 on executor id: 0 hostname: 192.168.1.4.
91524 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 462 on executor id: 0 hostname: 192.168.1.4.
91533 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 463 on executor id: 0 hostname: 192.168.1.4.
91533 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(78)
91533 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 464 on executor id: 0 hostname: 192.168.1.4.
91533 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 78
91534 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 78
91534 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 465 on executor id: 0 hostname: 192.168.1.4.
91534 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 466 on executor id: 0 hostname: 192.168.1.4.
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 78
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 78
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_78
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78 of size 2504 dropped from memory (free 383778132)
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_78_piece0
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78_piece0 of size 1570 dropped from memory (free 383779702)
91534 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_78_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.2 MB)
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_78_piece0
91534 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_78_piece0
91534 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 78, response is 0
91534 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91536 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_99_piece0 as bytes
91536 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_99_piece0 is StorageLevel(disk, memory, 1 replicas)
91537 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_78_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.4 MB)
91537 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_99_piece0 in memory on 192.168.1.4:59116 (size: 1006.0 B, free: 365.4 MB)
91537 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 78
91538 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(92)
91538 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 92
91538 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 92
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 92
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 92
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_92
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_92 of size 3600 dropped from memory (free 383783302)
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_92_piece0
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_92_piece0 of size 2197 dropped from memory (free 383785499)
91538 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_92_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.2 MB)
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_92_piece0
91538 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_92_piece0
91538 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 92, response is 0
91538 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91538 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_92_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
91539 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 92
91539 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(25)
91539 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 25
91539 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 25
91539 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 25, response is true
91539 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 25
91539 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
91539 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(74)
91539 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 74
91539 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 74
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 74
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 74
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_74
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74 of size 28424 dropped from memory (free 383813923)
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_74_piece0
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74_piece0 of size 2531 dropped from memory (free 383816454)
91540 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_74_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.2 MB)
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_74_piece0
91540 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_74_piece0
91540 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 74, response is 0
91540 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91541 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_74_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
91541 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 7
91541 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
91541 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
91541 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 72.0 (TID 459) in 24 ms on 192.168.1.4 (executor 0) (1/8)
91541 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 6
91541 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 72.0 (TID 466) in 18 ms on 192.168.1.4 (executor 0) (2/8)
91541 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 74
91541 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(22)
91541 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 22
91542 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 22
91542 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 22
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 22, response is true
91542 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(87)
91542 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 87
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
91542 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 87
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 87
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 87
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_87_piece0
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87_piece0 of size 2125 dropped from memory (free 383818579)
91542 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_87_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.2 MB)
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_87_piece0
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_87_piece0
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_87
91542 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87 of size 3656 dropped from memory (free 383822235)
91542 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 87, response is 0
91542 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91543 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_87_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
91543 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 87
91543 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(91)
91543 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 91
91543 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 91
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 91
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 91
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_91
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_91 of size 31656 dropped from memory (free 383853891)
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_91_piece0
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_91_piece0 of size 5327 dropped from memory (free 383859218)
91544 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_91_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.2 MB)
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_91_piece0
91544 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_91_piece0
91544 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 91, response is 0
91544 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 5
91544 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91544 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 72.0 (TID 465) in 22 ms on 192.168.1.4 (executor 0) (3/8)
91544 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_91_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
91545 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 91
91545 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(79)
91545 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 79
91545 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 79
91545 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 79
91545 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 79
91545 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_79
91545 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79 of size 2216 dropped from memory (free 383861434)
91545 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_79_piece0
91545 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79_piece0 of size 1460 dropped from memory (free 383862894)
91546 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_79_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
91546 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_79_piece0
91546 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_79_piece0
91546 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 79, response is 0
91546 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91546 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_79_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
91546 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 4
91546 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 72.0 (TID 464) in 25 ms on 192.168.1.4 (executor 0) (4/8)
91547 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 3
91547 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 72.0 (TID 463) in 27 ms on 192.168.1.4 (executor 0) (5/8)
91547 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 79
91547 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(77)
91547 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 77
91547 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 77
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 77
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 77
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_77_piece0
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77_piece0 of size 1006 dropped from memory (free 383863900)
91547 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_77_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.3 MB)
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_77_piece0
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_77_piece0
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_77
91547 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77 of size 1448 dropped from memory (free 383865348)
91547 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 77, response is 0
91548 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91548 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 2
91548 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 72.0 (TID 460) in 30 ms on 192.168.1.4 (executor 0) (6/8)
91548 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_77_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
91549 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 1
91549 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 72.0 (TID 461) in 30 ms on 192.168.1.4 (executor 0) (7/8)
91549 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 77
91549 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(98)
91549 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 98
91549 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 98
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 98
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 98
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_98
91549 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 0
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_98 of size 3656 dropped from memory (free 383869004)
91549 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 72.0 (TID 462) in 29 ms on 192.168.1.4 (executor 0) (8/8)
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_98_piece0
91549 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 72.0, whose tasks have all completed, from pool 
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_98_piece0 of size 2125 dropped from memory (free 383871129)
91549 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_98_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
91549 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 72 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.032 s
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_98_piece0
91549 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_98_piece0
91549 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 72, remaining stages = 0
91549 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 98, response is 0
91549 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 45 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.034543 s
91549 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91550 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_98_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91550 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 98
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91550 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(23)
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91550 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 23
91550 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 23
91550 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 23
91550 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(84)
91550 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 23, response is true
91550 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 84
91550 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 84
91550 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
91550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 84
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 84
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_84_piece0
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84_piece0 of size 1428 dropped from memory (free 383872557)
91551 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91551 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_84_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.3 MB)
91551 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91551 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_84_piece0
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_84_piece0
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_84
91551 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84 of size 8224 dropped from memory (free 383880781)
91551 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 84, response is 0
91551 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91551 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
91551 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_84_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.4 MB)
91551 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91552 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 84
91552 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(21)
91552 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 21
91552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91552 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 21
91552 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 21
91552 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(75)
91552 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 75
91552 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 21, response is true
91552 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 75
91552 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 75
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 75
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_75
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75 of size 9088 dropped from memory (free 383889869)
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_75_piece0
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75_piece0 of size 4135 dropped from memory (free 383894004)
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
91553 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_75_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.3 MB)
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_75_piece0
91553 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_75_piece0
91553 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 75, response is 0
91553 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91553 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_75_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
91553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353
91554 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91554 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 75
91554 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(24)
91554 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 24
91554 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 24
91554 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 24
91554 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(76)
91554 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 76
91554 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 24, response is true
91554 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 76
91554 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 76
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 76
91555 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
91555 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_76_piece0
91555 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76_piece0 of size 2127 dropped from memory (free 383896131)
91555 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353)
91555 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
91555 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_76_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_76_piece0
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_76_piece0
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_76
91555 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76 of size 3656 dropped from memory (free 383899787)
91555 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 76, response is 0
91555 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
91555 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
91555 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91555 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_76_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353
91556 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 76
91556 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(88)
91556 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 88
91556 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 88
91556 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 88
91556 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 88
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
91556 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_88_piece0
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
91556 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88_piece0 of size 1006 dropped from memory (free 383900793)
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353)
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
91556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
91556 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_88_piece0 on 192.168.1.4:59108 in memory (size: 1006.0 B, free: 366.3 MB)
91557 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_88_piece0
91557 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_88_piece0
91557 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_88
91557 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88 of size 1448 dropped from memory (free 383902241)
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
91557 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 88, response is 0
91557 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91557 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_88_piece0 on 192.168.1.4:59116 in memory (size: 1006.0 B, free: 365.4 MB)
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
91558 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
91558 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 88
91558 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(85)
91558 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 85
91558 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 85
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 85
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 85
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_85_piece0
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85_piece0 of size 2531 dropped from memory (free 383904772)
91558 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 46 (collect at SparkUtils.java:353) with 8 output partitions
91558 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 73 (collect at SparkUtils.java:353)
91558 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
91558 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_85_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.3 MB)
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_85_piece0
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_85_piece0
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_85
91558 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85 of size 27528 dropped from memory (free 383932300)
91558 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
91558 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 85, response is 0
91558 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91558 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 73)
91558 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91558 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 73 (MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
91558 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 73)
91558 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_85_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
91559 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_100 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
91559 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 85
91559 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_100 locally took  0 ms
91559 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(93)
91559 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 93
91559 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 93
91559 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_100 without replication took  0 ms
91559 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 93
91559 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 93
91559 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_93_piece0
91559 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_93_piece0 of size 3630 dropped from memory (free 383933426)
91559 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_93_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
91560 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_93_piece0
91560 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_93_piece0
91560 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_93
91560 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_93 of size 6712 dropped from memory (free 383940138)
91560 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 93, response is 0
91560 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91560 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_100_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
91560 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_93_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.4 MB)
91560 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_100_piece0 in memory on 192.168.1.4:59108 (size: 1570.0 B, free: 366.3 MB)
91560 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_100_piece0
91560 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_100_piece0
91560 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_100_piece0 locally took  0 ms
91560 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_100_piece0 without replication took  0 ms
91560 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 100 from broadcast at DAGScheduler.scala:1006
91560 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 73 (MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
91561 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 73.0 with 8 tasks
91561 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 93
91561 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(80)
91561 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 80
91561 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 80
91561 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 73.0: 27
91561 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 73.0: PROCESS_LOCAL, NODE_LOCAL, ANY
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 80
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 80
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_80
91561 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 0
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80 of size 31208 dropped from memory (free 383969776)
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_80_piece0
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80_piece0 of size 5325 dropped from memory (free 383975101)
91561 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_80_piece0 on 192.168.1.4:59108 in memory (size: 5.2 KB, free: 366.3 MB)
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_80_piece0
91561 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_80_piece0
91561 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 80, response is 0
91561 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91561 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_80_piece0 on 192.168.1.4:59116 in memory (size: 5.2 KB, free: 365.4 MB)
91562 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 73 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
91562 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 73.0 (TID 467, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
91562 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 80
91562 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(81)
91562 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 81
91562 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 81
91562 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 81
91562 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 81
91562 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_81
91562 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81 of size 3600 dropped from memory (free 383978701)
91562 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_81_piece0
91562 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81_piece0 of size 2197 dropped from memory (free 383980898)
91563 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_81_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
91563 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_81_piece0
91563 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_81_piece0
91563 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 81, response is 0
91563 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91563 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 73.0 (TID 468, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
91563 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_81_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
91563 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 81
91564 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(20)
91564 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 20
91564 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 20
91564 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 73.0 (TID 469, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
91564 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 20
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 20, response is true
91564 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(96)
91564 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 96
91564 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 96
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 96
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 96
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_96
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_96 of size 27976 dropped from memory (free 384008874)
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_96_piece0
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_96_piece0 of size 2531 dropped from memory (free 384011405)
91564 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_96_piece0 on 192.168.1.4:59108 in memory (size: 2.5 KB, free: 366.3 MB)
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_96_piece0
91564 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_96_piece0
91564 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 96, response is 0
91565 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91565 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_96_piece0 on 192.168.1.4:59116 in memory (size: 2.5 KB, free: 365.4 MB)
91565 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 73.0 (TID 470, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
91565 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 96
91565 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(83)
91565 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 83
91565 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 83
91565 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 83
91565 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 83
91565 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_83
91565 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83 of size 3672 dropped from memory (free 384015077)
91566 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_83_piece0
91566 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83_piece0 of size 2135 dropped from memory (free 384017212)
91566 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_83_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
91566 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_83_piece0
91566 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_83_piece0
91566 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 83, response is 0
91566 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 73.0 (TID 471, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
91566 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91566 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_83_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.4 MB)
91566 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 83
91566 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(90)
91567 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 90
91567 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 90
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 90
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 90
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_90_piece0
91567 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 73.0 (TID 472, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90_piece0 of size 1460 dropped from memory (free 384018672)
91567 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_90_piece0 on 192.168.1.4:59108 in memory (size: 1460.0 B, free: 366.3 MB)
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_90_piece0
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_90_piece0
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_90
91567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90 of size 2216 dropped from memory (free 384020888)
91567 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 90, response is 0
91567 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91567 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_90_piece0 on 192.168.1.4:59116 in memory (size: 1460.0 B, free: 365.4 MB)
91568 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 90
91568 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(95)
91568 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 95
91568 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 95
91568 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 73.0 (TID 473, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 95
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 95
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_95
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_95 of size 8224 dropped from memory (free 384029112)
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_95_piece0
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_95_piece0 of size 1428 dropped from memory (free 384030540)
91568 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_95_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.3 MB)
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_95_piece0
91568 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_95_piece0
91569 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 95, response is 0
91569 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91569 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_95_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.4 MB)
91569 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 73.0 (TID 474, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
91569 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 467 on executor id: 0 hostname: 192.168.1.4.
91569 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 95
91569 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 468 on executor id: 0 hostname: 192.168.1.4.
91569 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(97)
91569 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 97
91569 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 97
91569 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 469 on executor id: 0 hostname: 192.168.1.4.
91570 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 470 on executor id: 0 hostname: 192.168.1.4.
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 97
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 97
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_97_piece0
91570 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 471 on executor id: 0 hostname: 192.168.1.4.
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_97_piece0 of size 4136 dropped from memory (free 384034676)
91570 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 472 on executor id: 0 hostname: 192.168.1.4.
91570 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_97_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.3 MB)
91570 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 473 on executor id: 0 hostname: 192.168.1.4.
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_97_piece0
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_97_piece0
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_97
91570 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 474 on executor id: 0 hostname: 192.168.1.4.
91570 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_97 of size 9088 dropped from memory (free 384043764)
91570 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 97, response is 0
91570 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91573 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_97_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.4 MB)
91574 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 97
91574 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(86)
91574 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 86
91574 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 86
91574 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 86
91574 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 86
91574 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_86
91574 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86 of size 9088 dropped from memory (free 384052852)
91574 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_86_piece0
91575 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86_piece0 of size 4136 dropped from memory (free 384056988)
91575 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_86_piece0 on 192.168.1.4:59108 in memory (size: 4.0 KB, free: 366.3 MB)
91575 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_86_piece0
91575 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_86_piece0
91575 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 86, response is 0
91575 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91575 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_100_piece0 as bytes
91575 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_100_piece0 is StorageLevel(disk, memory, 1 replicas)
91575 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_86_piece0 on 192.168.1.4:59116 in memory (size: 4.0 KB, free: 365.5 MB)
91576 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 86
91576 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(73)
91576 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 73
91576 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 73
91576 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_100_piece0 in memory on 192.168.1.4:59116 (size: 1570.0 B, free: 365.4 MB)
91576 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 73
91576 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 73
91576 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_73_piece0
91577 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73_piece0 of size 1428 dropped from memory (free 384058416)
91577 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_73_piece0 on 192.168.1.4:59108 in memory (size: 1428.0 B, free: 366.3 MB)
91577 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_73_piece0
91577 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_73_piece0
91577 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_73
91577 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73 of size 8224 dropped from memory (free 384066640)
91577 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 73, response is 0
91577 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91577 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_73_piece0 on 192.168.1.4:59116 in memory (size: 1428.0 B, free: 365.5 MB)
91578 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 73
91578 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(89)
91578 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 89
91578 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 89
91578 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 89
91578 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 89
91578 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_89
91579 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89 of size 2504 dropped from memory (free 384069144)
91579 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_89_piece0
91579 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89_piece0 of size 1570 dropped from memory (free 384070714)
91579 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_89_piece0 on 192.168.1.4:59108 in memory (size: 1570.0 B, free: 366.3 MB)
91579 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_89_piece0
91579 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_89_piece0
91579 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 89, response is 0
91579 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91579 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_89_piece0 on 192.168.1.4:59116 in memory (size: 1570.0 B, free: 365.5 MB)
91580 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 7
91580 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
91580 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
91580 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 6
91580 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 73.0 (TID 469) in 17 ms on 192.168.1.4 (executor 0) (1/8)
91580 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 89
91580 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(82)
91580 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 82
91580 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 82
91580 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 73.0 (TID 473) in 13 ms on 192.168.1.4 (executor 0) (2/8)
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 82
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 82
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_82
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82 of size 6712 dropped from memory (free 384077426)
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_82_piece0
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82_piece0 of size 3628 dropped from memory (free 384081054)
91581 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_82_piece0 on 192.168.1.4:59108 in memory (size: 3.5 KB, free: 366.3 MB)
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_82_piece0
91581 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_82_piece0
91581 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 82, response is 0
91581 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91581 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_82_piece0 on 192.168.1.4:59116 in memory (size: 3.5 KB, free: 365.5 MB)
91582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 82
91582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(26)
91582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 26
91582 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 26
91582 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 26
91582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(94)
91582 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 26, response is true
91582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 94
91582 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:59102
91582 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 94
91582 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 5
91582 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 94
91582 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 94
91582 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_94_piece0
91583 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_94_piece0 of size 2134 dropped from memory (free 384083188)
91583 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 73.0 (TID 472) in 17 ms on 192.168.1.4 (executor 0) (3/8)
91583 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_94_piece0 on 192.168.1.4:59108 in memory (size: 2.1 KB, free: 366.3 MB)
91583 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_94_piece0
91583 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_94_piece0
91583 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_94
91583 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_94 of size 3672 dropped from memory (free 384086860)
91583 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 94, response is 0
91583 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
91583 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_94_piece0 on 192.168.1.4:59116 in memory (size: 2.1 KB, free: 365.5 MB)
91584 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 94
91587 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 4
91587 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 73.0 (TID 467) in 26 ms on 192.168.1.4 (executor 0) (4/8)
91588 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 3
91588 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 73.0 (TID 468) in 26 ms on 192.168.1.4 (executor 0) (5/8)
91588 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 2
91588 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 73.0 (TID 470) in 24 ms on 192.168.1.4 (executor 0) (6/8)
91589 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 1
91589 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 73.0 (TID 471) in 24 ms on 192.168.1.4 (executor 0) (7/8)
91590 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 0
91590 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 73.0 (TID 474) in 22 ms on 192.168.1.4 (executor 0) (8/8)
91590 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 73.0, whose tasks have all completed, from pool 
91590 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 73 (collect at SparkUtils.java:353) finished in 0.029 s
91590 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 73, remaining stages = 0
91590 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 46 finished: collect at SparkUtils.java:353, took 0.032292 s
91590 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91591 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91592 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
91592 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
91592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 47 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
91592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 74 (zipWithIndex at SparkUtils.java:391)
91592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
91592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
91592 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 74)
91592 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91592 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 74 (MapPartitionsRDD[146] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
91592 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 74)
91593 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_101 stored as values in memory (estimated size 2.2 KB, free 366.3 MB)
91593 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_101 locally took  0 ms
91593 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_101 without replication took  0 ms
91594 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_101_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.3 MB)
91594 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_101_piece0 in memory on 192.168.1.4:59108 (size: 1460.0 B, free: 366.3 MB)
91594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_101_piece0
91594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_101_piece0
91594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_101_piece0 locally took  1 ms
91594 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_101_piece0 without replication took  1 ms
91594 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 101 from broadcast at DAGScheduler.scala:1006
91594 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 74 (MapPartitionsRDD[146] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
91594 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 74.0 with 7 tasks
91594 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 74.0: 27
91594 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 74.0: PROCESS_LOCAL, NODE_LOCAL, ANY
91594 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 0
91595 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 74 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
91595 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 74.0 (TID 475, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
91596 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 74.0 (TID 476, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
91597 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 74.0 (TID 477, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
91597 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 74.0 (TID 478, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
91598 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 74.0 (TID 479, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
91599 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 74.0 (TID 480, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
91600 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 74.0 (TID 481, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 475 on executor id: 0 hostname: 192.168.1.4.
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 476 on executor id: 0 hostname: 192.168.1.4.
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 477 on executor id: 0 hostname: 192.168.1.4.
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 478 on executor id: 0 hostname: 192.168.1.4.
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 479 on executor id: 0 hostname: 192.168.1.4.
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 480 on executor id: 0 hostname: 192.168.1.4.
91600 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 481 on executor id: 0 hostname: 192.168.1.4.
91604 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_101_piece0 as bytes
91604 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_101_piece0 is StorageLevel(disk, memory, 1 replicas)
91605 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_101_piece0 in memory on 192.168.1.4:59116 (size: 1460.0 B, free: 365.5 MB)
91608 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 6
91608 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 74.0 (TID 480) in 10 ms on 192.168.1.4 (executor 0) (1/7)
91608 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 5
91609 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 74.0 (TID 478) in 12 ms on 192.168.1.4 (executor 0) (2/7)
91609 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 4
91609 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 74.0 (TID 475) in 15 ms on 192.168.1.4 (executor 0) (3/7)
91609 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 3
91609 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 74.0 (TID 481) in 10 ms on 192.168.1.4 (executor 0) (4/7)
91609 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 2
91609 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 1
91609 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 74.0 (TID 477) in 13 ms on 192.168.1.4 (executor 0) (5/7)
91610 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 74.0 (TID 476) in 14 ms on 192.168.1.4 (executor 0) (6/7)
91610 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 0
91610 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 74.0 (TID 479) in 13 ms on 192.168.1.4 (executor 0) (7/7)
91610 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 74.0, whose tasks have all completed, from pool 
91610 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 74 (zipWithIndex at SparkUtils.java:391) finished in 0.016 s
91610 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 74, remaining stages = 0
91611 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 47 finished: zipWithIndex at SparkUtils.java:391, took 0.018678 s
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91611 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91612 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
91613 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_102 stored as values in memory (estimated size 30.5 KB, free 366.3 MB)
91613 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_102 locally took  0 ms
91613 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_102 without replication took  0 ms
91614 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_102_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.3 MB)
91614 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_102_piece0 in memory on 192.168.1.4:59108 (size: 5.2 KB, free: 366.3 MB)
91614 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_102_piece0
91614 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_102_piece0
91614 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_102_piece0 locally took  0 ms
91614 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_102_piece0 without replication took  0 ms
91615 [main] INFO org.apache.spark.SparkContext  - Created broadcast 102 from broadcast at ParameterAveragingTrainingMaster.java:259
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91615 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91616 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91617 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91618 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91619 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91620 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91621 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91622 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
91623 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
91624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
91624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
91624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
91624 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
91624 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 27 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
91624 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 149 (mapToPair at SparkUtils.java:391)
91624 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 154 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
91624 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 48 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
91624 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 77 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
91624 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 76)
91624 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 76)
91624 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 77)
91624 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 76)
91624 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 76)
91624 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 75)
91624 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 75)
91625 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91625 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 75 (MapPartitionsRDD[149] at mapToPair at SparkUtils.java:391), which has no missing parents
91625 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 75)
91625 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_103 stored as values in memory (estimated size 3.5 KB, free 366.3 MB)
91626 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_103 locally took  1 ms
91626 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_103 without replication took  1 ms
91626 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_103_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
91626 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_103_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
91626 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_103_piece0
91626 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_103_piece0
91627 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_103_piece0 locally took  1 ms
91627 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_103_piece0 without replication took  1 ms
91627 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 103 from broadcast at DAGScheduler.scala:1006
91627 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[149] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
91627 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 75.0 with 8 tasks
91627 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 75.0: 27
91627 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 75.0: PROCESS_LOCAL, NODE_LOCAL, ANY
91627 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 0
91628 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 75 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
91628 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 75.0 (TID 482, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
91629 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 75.0 (TID 483, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
91630 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 75.0 (TID 484, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
91630 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 75.0 (TID 485, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
91631 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 75.0 (TID 486, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
91632 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 75.0 (TID 487, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
91633 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 75.0 (TID 488, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
91634 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 75.0 (TID 489, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 482 on executor id: 0 hostname: 192.168.1.4.
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 483 on executor id: 0 hostname: 192.168.1.4.
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 484 on executor id: 0 hostname: 192.168.1.4.
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 485 on executor id: 0 hostname: 192.168.1.4.
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 486 on executor id: 0 hostname: 192.168.1.4.
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 487 on executor id: 0 hostname: 192.168.1.4.
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 488 on executor id: 0 hostname: 192.168.1.4.
91634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 489 on executor id: 0 hostname: 192.168.1.4.
91639 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_103_piece0 as bytes
91639 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_103_piece0 is StorageLevel(disk, memory, 1 replicas)
91640 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_103_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.5 MB)
91647 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 7
91647 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
91647 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
91647 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 75.0 (TID 487) in 16 ms on 192.168.1.4 (executor 0) (1/8)
91647 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91648 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 6
91648 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 5
91649 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 75.0 (TID 482) in 21 ms on 192.168.1.4 (executor 0) (2/8)
91649 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 75.0 (TID 485) in 19 ms on 192.168.1.4 (executor 0) (3/8)
91649 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91649 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91649 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 4
91649 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 75.0 (TID 484) in 20 ms on 192.168.1.4 (executor 0) (4/8)
91650 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91650 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 3
91650 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 75.0 (TID 488) in 18 ms on 192.168.1.4 (executor 0) (5/8)
91650 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 2
91650 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91650 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 75.0 (TID 483) in 22 ms on 192.168.1.4 (executor 0) (6/8)
91650 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91652 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 1
91652 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 75.0 (TID 489) in 19 ms on 192.168.1.4 (executor 0) (7/8)
91652 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91653 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 0
91653 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 75.0 (TID 486) in 22 ms on 192.168.1.4 (executor 0) (8/8)
91653 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 75.0, whose tasks have all completed, from pool 
91654 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91654 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 75 (mapToPair at SparkUtils.java:391) finished in 0.027 s
91654 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
91654 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
91654 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 76, ResultStage 77)
91654 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
91654 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 28
91654 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 76)
91654 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91654 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 76 (MapPartitionsRDD[154] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
91654 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 76)
91655 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_104 stored as values in memory (estimated size 6.6 KB, free 366.2 MB)
91655 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_104 locally took  0 ms
91655 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_104 without replication took  0 ms
91656 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_104_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
91656 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_104_piece0 in memory on 192.168.1.4:59108 (size: 3.5 KB, free: 366.3 MB)
91656 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_104_piece0
91656 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_104_piece0
91656 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_104_piece0 locally took  0 ms
91656 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_104_piece0 without replication took  0 ms
91656 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 104 from broadcast at DAGScheduler.scala:1006
91656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[154] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
91656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 76.0 with 8 tasks
91656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 76.0: 28
91656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 76.0: NODE_LOCAL, ANY
91656 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 0
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 76.0 (TID 490, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 76.0 (TID 491, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 76.0 (TID 492, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 76.0 (TID 493, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 76.0 (TID 494, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 76.0 (TID 495, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 76.0 (TID 496, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 76.0 (TID 497, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 490 on executor id: 0 hostname: 192.168.1.4.
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 491 on executor id: 0 hostname: 192.168.1.4.
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 492 on executor id: 0 hostname: 192.168.1.4.
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 493 on executor id: 0 hostname: 192.168.1.4.
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 494 on executor id: 0 hostname: 192.168.1.4.
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 495 on executor id: 0 hostname: 192.168.1.4.
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 496 on executor id: 0 hostname: 192.168.1.4.
91657 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 497 on executor id: 0 hostname: 192.168.1.4.
91660 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_104_piece0 as bytes
91660 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_104_piece0 is StorageLevel(disk, memory, 1 replicas)
91661 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_104_piece0 in memory on 192.168.1.4:59116 (size: 3.5 KB, free: 365.5 MB)
91662 [dispatcher-event-loop-1] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 28 to 192.168.1.4:59114
91662 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 28 to 192.168.1.4:59114
91662 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 28
91662 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 28
91662 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 28 is 186 bytes
91665 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_102_piece0 as bytes
91665 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_102_piece0 is StorageLevel(disk, memory, 1 replicas)
91666 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_102_piece0 in memory on 192.168.1.4:59116 (size: 5.2 KB, free: 365.4 MB)
92320 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 8
93321 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 7
93321 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
93321 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 76.0 (TID 495) in 1664 ms on 192.168.1.4 (executor 0) (1/8)
93321 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
93322 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 7
94320 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 7
94957 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 6
94958 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 76.0 (TID 496) in 3301 ms on 192.168.1.4 (executor 0) (2/8)
94958 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95002 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 5
95002 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 76.0 (TID 497) in 3345 ms on 192.168.1.4 (executor 0) (3/8)
95003 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95322 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 5
95515 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 4
95515 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 76.0 (TID 490) in 3859 ms on 192.168.1.4 (executor 0) (4/8)
95515 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 3
95515 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95515 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 2
95515 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 76.0 (TID 493) in 3858 ms on 192.168.1.4 (executor 0) (5/8)
95516 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95516 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 76.0 (TID 494) in 3859 ms on 192.168.1.4 (executor 0) (6/8)
95516 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95516 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 1
95516 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 76.0 (TID 492) in 3859 ms on 192.168.1.4 (executor 0) (7/8)
95516 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95558 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 0
95558 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 76.0 (TID 491) in 3901 ms on 192.168.1.4 (executor 0) (8/8)
95558 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 76.0, whose tasks have all completed, from pool 
95558 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95559 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 76 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.902 s
95559 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
95559 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
95559 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 77)
95559 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
95559 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 29
95559 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 77)
95559 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
95559 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 77 (MapPartitionsRDD[156] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
95559 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 77)
95560 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_105 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
95560 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_105 locally took  1 ms
95560 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_105 without replication took  1 ms
95561 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_105_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
95561 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_105_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
95561 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_105_piece0
95561 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_105_piece0
95561 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_105_piece0 locally took  0 ms
95561 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_105_piece0 without replication took  0 ms
95561 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 105 from broadcast at DAGScheduler.scala:1006
95561 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 77 (MapPartitionsRDD[156] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
95561 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 77.0 with 2 tasks
95562 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 77.0: 29
95562 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 77.0: NODE_LOCAL, ANY
95562 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_77.0, runningTasks: 0
95562 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 77.0 (TID 498, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
95562 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 77.0 (TID 499, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
95562 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
95562 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 498 on executor id: 0 hostname: 192.168.1.4.
95562 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 499 on executor id: 0 hostname: 192.168.1.4.
95565 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_105_piece0 as bytes
95565 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_105_piece0 is StorageLevel(disk, memory, 1 replicas)
95566 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_105_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
95567 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 27 to 192.168.1.4:59114
95567 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 27 to 192.168.1.4:59114
95567 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 27
95567 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 27
95568 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 27 is 159 bytes
95645 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_77.0, runningTasks: 1
95645 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_77.0, runningTasks: 0
95645 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 77.0 (TID 498) in 83 ms on 192.168.1.4 (executor 0) (1/2)
95645 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 77.0 (TID 499) in 83 ms on 192.168.1.4 (executor 0) (2/2)
95645 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 77.0, whose tasks have all completed, from pool 
95645 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 77 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.083 s
95645 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 77, remaining stages = 2
95646 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 76, remaining stages = 1
95646 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 75, remaining stages = 0
95646 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 48 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.022312 s
95646 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
95647 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_106 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
95647 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_106 locally took  0 ms
95647 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_106 without replication took  0 ms
95648 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_106_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
95648 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_106_piece0 in memory on 192.168.1.4:59108 (size: 1428.0 B, free: 366.3 MB)
95648 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_106_piece0
95648 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_106_piece0
95648 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_106_piece0 locally took  0 ms
95648 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_106_piece0 without replication took  0 ms
95648 [main] INFO org.apache.spark.SparkContext  - Created broadcast 106 from broadcast at SparkDl4jMultiLayer.java:595
95649 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_107 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
95649 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_107 locally took  0 ms
95649 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_107 without replication took  0 ms
95650 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_107_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
95650 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_107_piece0 in memory on 192.168.1.4:59108 (size: 2.5 KB, free: 366.3 MB)
95650 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_107_piece0
95650 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_107_piece0
95650 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_107_piece0 locally took  0 ms
95650 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_107_piece0 without replication took  0 ms
95650 [main] INFO org.apache.spark.SparkContext  - Created broadcast 107 from broadcast at SparkDl4jMultiLayer.java:596
95650 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
95652 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
95654 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
95655 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
95656 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
95657 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95658 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
95659 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
95659 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
95659 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 29 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
95660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 159 (treeAggregate at SparkDl4jMultiLayer.java:598)
95660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 49 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
95660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 79 (treeAggregate at SparkDl4jMultiLayer.java:598)
95660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 78)
95660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 78)
95660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 79)
95660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 78)
95660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 78)
95660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
95660 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 78 (MapPartitionsRDD[159] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
95660 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 78)
95661 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_108 stored as values in memory (estimated size 8.9 KB, free 366.2 MB)
95661 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_108 locally took  1 ms
95661 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_108 without replication took  1 ms
95661 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_108_piece0 stored as bytes in memory (estimated size 4.0 KB, free 366.2 MB)
95661 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_108_piece0 in memory on 192.168.1.4:59108 (size: 4.0 KB, free: 366.3 MB)
95661 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_108_piece0
95662 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_108_piece0
95662 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_108_piece0 locally took  1 ms
95662 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_108_piece0 without replication took  1 ms
95662 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 108 from broadcast at DAGScheduler.scala:1006
95662 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[159] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
95662 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 78.0 with 8 tasks
95662 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 78.0: 29
95662 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 78.0: NO_PREF, ANY
95662 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 0
95662 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 78.0 (TID 500, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
95663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 78.0 (TID 501, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
95663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 78.0 (TID 502, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
95663 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 78.0 (TID 503, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
95664 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 78.0 (TID 504, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
95664 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 78.0 (TID 505, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
95664 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 78.0 (TID 506, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
95665 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 78.0 (TID 507, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 500 on executor id: 0 hostname: 192.168.1.4.
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 501 on executor id: 0 hostname: 192.168.1.4.
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 502 on executor id: 0 hostname: 192.168.1.4.
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 503 on executor id: 0 hostname: 192.168.1.4.
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 504 on executor id: 0 hostname: 192.168.1.4.
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 505 on executor id: 0 hostname: 192.168.1.4.
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 506 on executor id: 0 hostname: 192.168.1.4.
95665 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 507 on executor id: 0 hostname: 192.168.1.4.
95668 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_108_piece0 as bytes
95668 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_108_piece0 is StorageLevel(disk, memory, 1 replicas)
95669 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_108_piece0 in memory on 192.168.1.4:59116 (size: 4.0 KB, free: 365.4 MB)
95672 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_107_piece0 as bytes
95672 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_107_piece0 is StorageLevel(disk, memory, 1 replicas)
95673 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_107_piece0 in memory on 192.168.1.4:59116 (size: 2.5 KB, free: 365.4 MB)
95701 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_106_piece0 as bytes
95701 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_106_piece0 is StorageLevel(disk, memory, 1 replicas)
95702 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_106_piece0 in memory on 192.168.1.4:59116 (size: 1428.0 B, free: 365.4 MB)
95864 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 7
95864 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
95864 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 78.0 (TID 507) in 200 ms on 192.168.1.4 (executor 0) (1/8)
95864 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95955 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 6
95955 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 78.0 (TID 506) in 291 ms on 192.168.1.4 (executor 0) (2/8)
95955 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95959 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 5
95959 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 78.0 (TID 504) in 296 ms on 192.168.1.4 (executor 0) (3/8)
95959 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95965 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 4
95966 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 78.0 (TID 503) in 303 ms on 192.168.1.4 (executor 0) (4/8)
95966 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95993 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 3
95993 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 2
95993 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 78.0 (TID 505) in 329 ms on 192.168.1.4 (executor 0) (5/8)
95993 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 78.0 (TID 501) in 331 ms on 192.168.1.4 (executor 0) (6/8)
95993 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95993 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96023 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 1
96023 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 78.0 (TID 502) in 360 ms on 192.168.1.4 (executor 0) (7/8)
96024 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96034 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 0
96034 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 78.0 (TID 500) in 372 ms on 192.168.1.4 (executor 0) (8/8)
96034 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 78.0, whose tasks have all completed, from pool 
96034 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96034 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 78 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.372 s
96034 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
96034 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
96034 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 79)
96034 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
96034 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 30
96034 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 79)
96034 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
96034 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 79 (MapPartitionsRDD[161] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
96034 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 79)
96035 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_109 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
96035 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_109 locally took  0 ms
96035 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_109 without replication took  0 ms
96036 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_109_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
96036 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_109_piece0 in memory on 192.168.1.4:59108 (size: 2.1 KB, free: 366.3 MB)
96036 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_109_piece0
96036 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_109_piece0
96036 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_109_piece0 locally took  0 ms
96036 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_109_piece0 without replication took  0 ms
96036 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 109 from broadcast at DAGScheduler.scala:1006
96036 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 79 (MapPartitionsRDD[161] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
96036 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 79.0 with 2 tasks
96036 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 79.0: 30
96036 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 79.0: NODE_LOCAL, ANY
96037 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_79.0, runningTasks: 0
96037 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 79.0 (TID 508, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
96037 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 79.0 (TID 509, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
96037 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
96037 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 508 on executor id: 0 hostname: 192.168.1.4.
96037 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 509 on executor id: 0 hostname: 192.168.1.4.
96039 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_109_piece0 as bytes
96039 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_109_piece0 is StorageLevel(disk, memory, 1 replicas)
96040 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_109_piece0 in memory on 192.168.1.4:59116 (size: 2.1 KB, free: 365.4 MB)
96041 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 29 to 192.168.1.4:59114
96041 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 29 to 192.168.1.4:59114
96041 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 29
96041 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 29
96041 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 29 is 159 bytes
96044 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_79.0, runningTasks: 1
96044 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_79.0, runningTasks: 0
96045 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 79.0 (TID 509) in 8 ms on 192.168.1.4 (executor 0) (1/2)
96045 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 79.0 (TID 508) in 8 ms on 192.168.1.4 (executor 0) (2/2)
96045 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 79.0, whose tasks have all completed, from pool 
96045 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 79 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.009 s
96045 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 79, remaining stages = 1
96045 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 78, remaining stages = 0
96045 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 49 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.385992 s
96046 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 9: Accuracy = 0.00, F1 = NaN
96046 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 9
96046 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - ##############EVALUTAION##########
##############DONE############
96046 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - ----- Example Complete -----
96048 [Thread-1] INFO org.apache.spark.SparkContext  - Invoking stop() from shutdown hook
96049 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.Server@37fbe4a8
96049 [Thread-1] DEBUG org.spark_project.jetty.server.Server  - doStop org.spark_project.jetty.server.Server@37fbe4a8
96049 [SparkUI-49] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran SparkUI-49-acceptor-0@7db0565c-ServerConnector@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
96051 [Thread-1] DEBUG org.spark_project.jetty.server.Server  - Graceful shutdown org.spark_project.jetty.server.Server@37fbe4a8 by 
96051 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping Spark@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
96051 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17
96051 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
96051 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
96052 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@611dc87e on org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
96052 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96052 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@611dc87e
96052 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
96052 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
96052 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
96052 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@53347bc3 on org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=0 selected=0
96052 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96052 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@53347bc3
96053 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 produced null
96053 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 produce exit
96053 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=-1 selected=-1
96053 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=-1 selected=-1
96053 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@20312893 id=3 keys=-1 selected=-1
96053 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
96053 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
96053 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@5ce517e3 on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
96053 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96053 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@5ce517e3
96053 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
96053 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
96053 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@63c20050 on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=0 selected=0
96054 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96054 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@63c20050
96054 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@172d01cb produced null
96054 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@172d01cb produce exit
96054 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=2 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4ef4f9b7 on org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
96054 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96054 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4ef4f9b7
96054 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
96054 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
96054 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3eee69c9 on org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=0 selected=0
96054 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96054 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3eee69c9
96054 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@67a32ded produced null
96054 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@67a32ded produce exit
96054 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@4e9658b5 id=1 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4a403bf8 on org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
96054 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96054 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4a403bf8
96054 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
96054 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
96054 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@39f36260 on org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=0 selected=0
96054 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
96054 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@39f36260
96054 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@14e30b89 produced null
96054 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@14e30b89 produce exit
96054 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@213e3629 id=0 keys=-1 selected=-1
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@345e5a17
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping HttpConnectionFactory@57f791c6[HTTP/1.1]
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED HttpConnectionFactory@57f791c6[HTTP/1.1]
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@24f43aa3
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@24f43aa3
96054 [Thread-1] INFO org.spark_project.jetty.server.AbstractConnector  - Stopped Spark@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED Spark@2ef8a8c3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
96054 [Thread-1] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - stopping org.spark_project.jetty.server.Server@37fbe4a8
96054 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1, org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667, o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,SHUTDOWN,@Spark}]
96055 [Thread-1] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1, org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667, o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,SHUTDOWN,@Spark}]
96144 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@263f04ca[org.spark_project.jetty.server.handler.gzip.GzipHandler@37d3d232, org.spark_project.jetty.server.handler.gzip.GzipHandler@58dea0a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@320e400, org.spark_project.jetty.server.handler.gzip.GzipHandler@436390f4, org.spark_project.jetty.server.handler.gzip.GzipHandler@50b8ae8d, org.spark_project.jetty.server.handler.gzip.GzipHandler@58783f6c, org.spark_project.jetty.server.handler.gzip.GzipHandler@88d6f9b, org.spark_project.jetty.server.handler.gzip.GzipHandler@7577b641, org.spark_project.jetty.server.handler.gzip.GzipHandler@10b3df93, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c321bdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fabf088, org.spark_project.jetty.server.handler.gzip.GzipHandler@74d7184a, org.spark_project.jetty.server.handler.gzip.GzipHandler@5cbf9e9f, org.spark_project.jetty.server.handler.gzip.GzipHandler@42deb43a, org.spark_project.jetty.server.handler.gzip.GzipHandler@1bdaa23d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a7704c, org.spark_project.jetty.server.handler.gzip.GzipHandler@7561db12, org.spark_project.jetty.server.handler.gzip.GzipHandler@5af5def9, org.spark_project.jetty.server.handler.gzip.GzipHandler@7692cd34, org.spark_project.jetty.server.handler.gzip.GzipHandler@10ad20cb, org.spark_project.jetty.server.handler.gzip.GzipHandler@53bc1328, org.spark_project.jetty.server.handler.gzip.GzipHandler@4102b1b1, org.spark_project.jetty.server.handler.gzip.GzipHandler@77b325b3, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d4d48a6, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e287667, o.s.j.s.ServletContextHandler@4e904fd5{/metrics/json,null,SHUTDOWN,@Spark}]
96145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanRDD(0)
96158 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.handler.ErrorHandler@6d6bc158
96159 [Thread-1] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - stopping org.spark_project.jetty.server.handler.ErrorHandler@6d6bc158
96159 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.handler.ErrorHandler@6d6bc158
96159 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
96159 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning RDD 0
96160 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
96160 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.Server@37fbe4a8
96160 [Thread-1] INFO org.apache.spark.ui.SparkUI  - Stopped Spark web UI at http://192.168.1.4:4040
96163 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing RDD 0
96164 [block-manager-slave-async-thread-pool-0] INFO org.apache.spark.storage.BlockManager  - Removing RDD 0
96165 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing RDD 0, response is 0
96165 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:59102
96174 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned RDD 0
96176 [Thread-1] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - Shutting down all executors
96177 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Asking each executor to shut down
96184 [dispatcher-event-loop-2] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - MapOutputTrackerMasterEndpoint stopped!
96195 [Thread-1] INFO org.apache.spark.storage.memory.MemoryStore  - MemoryStore cleared
96196 [Thread-1] INFO org.apache.spark.storage.BlockManager  - BlockManager stopped
96196 [Thread-1] INFO org.apache.spark.storage.BlockManagerMaster  - BlockManagerMaster stopped
96198 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint  - OutputCommitCoordinator stopped!
96200 [rpc-server-3-2] DEBUG io.netty.buffer.PoolThreadCache  - Freed 3 thread-local buffer(s) from thread: rpc-server-3-2
96203 [Thread-1] INFO org.apache.spark.SparkContext  - Successfully stopped SparkContext
96203 [Thread-1] INFO org.apache.spark.util.ShutdownHookManager  - Shutdown hook called
96204 [Thread-1] INFO org.apache.spark.util.ShutdownHookManager  - Deleting directory /private/var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T/spark-d18d2520-aa87-48bd-ab4e-784a2007b0a4
