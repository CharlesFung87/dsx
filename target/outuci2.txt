0 [main] INFO org.apache.spark.SparkContext  - Running Spark version 2.2.0
60 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory  - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
68 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory  - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
68 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory  - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
69 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl  - UgiMetrics, User and group related metrics
254 [main] DEBUG org.apache.hadoop.util.Shell  - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:326)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:351)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:273)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:261)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:791)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:761)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:634)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2430)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2430)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:58)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
304 [main] DEBUG org.apache.hadoop.util.Shell  - setsid is not available on this machine. So not using it.
304 [main] DEBUG org.apache.hadoop.util.Shell  - setsid exited with exit code 0
311 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName  - Kerberos krb5 configuration not found, setting default realm to empty
313 [main] DEBUG org.apache.hadoop.security.Groups  -  Creating new Groups object
314 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader  - Trying to load the custom-built native-hadoop library...
315 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader  - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
315 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader  - java.library.path=/Users/tomhanlon/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
315 [main] WARN org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
315 [main] DEBUG org.apache.hadoop.util.PerformanceAdvisory  - Falling back to shell based
315 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback  - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
383 [main] DEBUG org.apache.hadoop.security.Groups  - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
386 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - hadoop login
387 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - hadoop login commit
391 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - using local user:UnixPrincipal: tomhanlon
392 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - Using user: "UnixPrincipal: tomhanlon" with name tomhanlon
392 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - User entry: "tomhanlon"
392 [main] DEBUG org.apache.hadoop.security.UserGroupInformation  - UGI loginUser:tomhanlon (auth:SIMPLE)
434 [main] INFO org.apache.spark.SparkContext  - Submitted application: DL4J Spark RNN Example
451 [main] INFO org.apache.spark.SecurityManager  - Changing view acls to: tomhanlon
451 [main] INFO org.apache.spark.SecurityManager  - Changing modify acls to: tomhanlon
452 [main] INFO org.apache.spark.SecurityManager  - Changing view acls groups to: 
452 [main] INFO org.apache.spark.SecurityManager  - Changing modify acls groups to: 
452 [main] INFO org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomhanlon); groups with view permissions: Set(); users  with modify permissions: Set(tomhanlon); groups with modify permissions: Set()
462 [main] DEBUG org.apache.spark.SecurityManager  - Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
519 [main] DEBUG io.netty.util.internal.logging.InternalLoggerFactory  - Using SLF4J as the default logging framework
521 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.noUnsafe: false
523 [main] DEBUG io.netty.util.internal.PlatformDependent0  - java.nio.Buffer.address: available
523 [main] DEBUG io.netty.util.internal.PlatformDependent0  - sun.misc.Unsafe.theUnsafe: available
524 [main] DEBUG io.netty.util.internal.PlatformDependent0  - sun.misc.Unsafe.copyMemory: available
524 [main] DEBUG io.netty.util.internal.PlatformDependent0  - direct buffer constructor: available
525 [main] DEBUG io.netty.util.internal.PlatformDependent0  - java.nio.Bits.unaligned: available, true
525 [main] DEBUG io.netty.util.internal.PlatformDependent0  - java.nio.DirectByteBuffer.<init>(long, int): available
525 [main] DEBUG io.netty.util.internal.Cleaner0  - java.nio.ByteBuffer.cleaner(): available
526 [main] DEBUG io.netty.util.internal.PlatformDependent  - Java version: 8
526 [main] DEBUG io.netty.util.internal.PlatformDependent  - sun.misc.Unsafe: available
526 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.noJavassist: false
577 [main] DEBUG io.netty.util.internal.PlatformDependent  - Javassist: available
577 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.tmpdir: /var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T (java.io.tmpdir)
577 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.bitMode: 64 (sun.arch.data.model)
577 [main] DEBUG io.netty.util.internal.PlatformDependent  - -Dio.netty.noPreferDirect: false
577 [main] DEBUG io.netty.util.internal.PlatformDependent  - io.netty.maxDirectMemory: 954728448 bytes
579 [main] DEBUG io.netty.util.internal.JavassistTypeParameterMatcherGenerator  - Generated: io.netty.util.internal.__matchers__.org.apache.spark.network.protocol.MessageMatcher
582 [main] DEBUG io.netty.util.internal.JavassistTypeParameterMatcherGenerator  - Generated: io.netty.util.internal.__matchers__.io.netty.buffer.ByteBufMatcher
591 [main] DEBUG io.netty.channel.MultithreadEventLoopGroup  - -Dio.netty.eventLoopThreads: 16
608 [main] DEBUG io.netty.channel.nio.NioEventLoop  - -Dio.netty.noKeySetOptimization: false
608 [main] DEBUG io.netty.channel.nio.NioEventLoop  - -Dio.netty.selectorAutoRebuildThreshold: 512
611 [main] DEBUG io.netty.util.internal.PlatformDependent  - org.jctools-core.MpscChunkedArrayQueue: available
631 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.numHeapArenas: 9
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.numDirectArenas: 9
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.pageSize: 8192
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.maxOrder: 11
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.chunkSize: 16777216
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.tinyCacheSize: 512
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.smallCacheSize: 256
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.normalCacheSize: 64
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.cacheTrimInterval: 8192
632 [main] DEBUG io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.useCacheForAllThreads
669 [main] DEBUG io.netty.util.internal.ThreadLocalRandom  - -Dio.netty.initialSeedUniquifier: 0x202bc3ffee5c9d32 (took 0 ms)
688 [main] DEBUG io.netty.buffer.ByteBufUtil  - -Dio.netty.allocator.type: unpooled
688 [main] DEBUG io.netty.buffer.ByteBufUtil  - -Dio.netty.threadLocalDirectBufferSize: 65536
690 [main] DEBUG io.netty.buffer.ByteBufUtil  - -Dio.netty.maxThreadLocalCharBufferSize: 16384
715 [main] DEBUG io.netty.util.NetUtil  - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
715 [main] DEBUG io.netty.util.NetUtil  - /proc/sys/net/core/somaxconn: 128 (non-existent)
725 [main] DEBUG org.apache.spark.network.server.TransportServer  - Shuffle server started on port: 49902
728 [main] INFO org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 49902.
728 [main] DEBUG org.apache.spark.SparkEnv  - Using serializer: class org.apache.spark.serializer.JavaSerializer
744 [main] INFO org.apache.spark.SparkEnv  - Registering MapOutputTracker
745 [main] DEBUG org.apache.spark.MapOutputTrackerMasterEndpoint  - init
761 [main] INFO org.apache.spark.SparkEnv  - Registering BlockManagerMaster
764 [main] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
764 [main] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
777 [main] INFO org.apache.spark.storage.DiskBlockManager  - Created local directory at /private/var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T/blockmgr-e501ba74-d887-48be-b5e5-7b810328235b
778 [main] DEBUG org.apache.spark.storage.DiskBlockManager  - Adding shutdown hook
779 [main] DEBUG org.apache.spark.util.ShutdownHookManager  - Adding shutdown hook
796 [main] INFO org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 366.3 MB
834 [main] INFO org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
835 [main] DEBUG org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint  - init
847 [main] DEBUG org.apache.spark.SecurityManager  - Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
897 [main] DEBUG org.spark_project.jetty.util.log  - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
900 [main] INFO org.spark_project.jetty.util.log  - Logging initialized @1888ms
908 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70fab835
914 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@1b11ef33{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@476aac9,MANAGED}
917 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@476aac9 added {org.apache.spark.ui.JettyUtils$$anon$3-19b30c92@d46bde31==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
918 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@476aac9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-19b30c92,POJO}
918 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@307765b4
919 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@4a9e6faf{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2c95ac9e,MANAGED}
919 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2c95ac9e added {org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b@d7fbc9dc==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
919 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2c95ac9e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b,POJO}
919 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2a76b80a
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@7eb01b12{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2f4854d6,MANAGED}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2f4854d6 added {org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0@38764b08==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2f4854d6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0,POJO}
920 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e70bd39
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@e6516e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6de54b40,MANAGED}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@6de54b40 added {org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3@d67b1b8d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
920 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@6de54b40 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3,POJO}
929 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5c1bd44c
929 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@9f46d94{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18cc679e,MANAGED}
929 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@18cc679e added {org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf@acd53f8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
929 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@18cc679e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf,POJO}
929 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c4ca0f9
929 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@67ef029{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7df587ef,MANAGED}
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7df587ef added {org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e@a6e9b181==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7df587ef added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e,POJO}
930 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@56db847e
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@740abb5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@560cbf1a,MANAGED}
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@560cbf1a added {org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721@c5e41004==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@560cbf1a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721,POJO}
930 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@551a20d6
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@578524c3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@64c2b546,MANAGED}
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@64c2b546 added {org.apache.spark.ui.JettyUtils$$anon$3-7e094740@6488442==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
930 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@64c2b546 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7e094740,POJO}
930 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4cc547a
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@7555b920{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4152d38d,MANAGED}
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@4152d38d added {org.apache.spark.ui.JettyUtils$$anon$3-3591009c@8a81ab30==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@4152d38d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3591009c,POJO}
931 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5398edd0
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@b5cc23a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5cc5b667,MANAGED}
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5cc5b667 added {org.apache.spark.ui.JettyUtils$$anon$3-61edc883@3c877b76==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
931 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5cc5b667 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-61edc883,POJO}
934 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@9cd25ff
934 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@27e0f2f5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3574e198,MANAGED}
934 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@3574e198 added {org.apache.spark.ui.JettyUtils$$anon$3-6db66836@beaa1113==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
934 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@3574e198 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6db66836,POJO}
934 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@db44aa2
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@2de366bb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3f093abe,MANAGED}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@3f093abe added {org.apache.spark.ui.JettyUtils$$anon$3-61a002b1@32c01267==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@3f093abe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-61a002b1,POJO}
935 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@780ec4a5
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@e24ddd0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6f70f32f,MANAGED}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@6f70f32f added {org.apache.spark.ui.JettyUtils$$anon$3-548e76f1@268901a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@6f70f32f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-548e76f1,POJO}
935 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5aabbb29
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@72c927f1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1ac85b0c,MANAGED}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1ac85b0c added {org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a@8a7245e8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
935 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1ac85b0c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a,POJO}
936 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5003041b
936 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@724bade8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@16fb356,MANAGED}
936 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@16fb356 added {org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed@565932aa==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
937 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@16fb356 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed,POJO}
937 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@23a9ba52
937 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@ca27722{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@70ab80e3,MANAGED}
937 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@70ab80e3 added {org.apache.spark.ui.JettyUtils$$anon$3-9573b3b@ffb2210d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
937 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@70ab80e3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-9573b3b,POJO}
938 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58c540cf
938 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@3d6300e8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1b822fcc,MANAGED}
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1b822fcc added {org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f@32134e5b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1b822fcc added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f,POJO}
939 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@56102e1c
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@73511076{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7927bd9f,MANAGED}
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7927bd9f added {org.apache.spark.ui.JettyUtils$$anon$3-532721fd@e4db210c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@7927bd9f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-532721fd,POJO}
939 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7fb9f71f
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@3b366632{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@51f49060,MANAGED}
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@51f49060 added {org.apache.spark.ui.JettyUtils$$anon$3-514eedd8@811882ec==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
939 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@51f49060 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-514eedd8,POJO}
939 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@617fe9e1
940 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@6970140a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1cf2fed4,MANAGED}
940 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1cf2fed4 added {org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf@ef205177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
940 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1cf2fed4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf,POJO}
940 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4d63b624
940 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@466cf502{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5b800468,MANAGED}
944 [main] DEBUG org.spark_project.jetty.http.PreEncodedHttpField  - HttpField encoders loaded: [org.spark_project.jetty.http.Http1FieldPreEncoder@42257bdd]
950 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5b800468 added {org.spark_project.jetty.servlet.DefaultServlet-2af616d3@229e5d02==org.spark_project.jetty.servlet.DefaultServlet,-1,true,AUTO}
950 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@5b800468 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-2af616d3,POJO}
951 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@62d363ab
951 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@7889a1ac{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3aee3976,MANAGED}
951 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@3aee3976 added {org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e@86fdb7c3==org.apache.spark.ui.JettyUtils$$anon$4,-1,true,AUTO}
951 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@3aee3976 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e,POJO}
951 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5910de75
952 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@4108fa66{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1f130eaf,MANAGED}
954 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1f130eaf added {org.glassfish.jersey.servlet.ServletContainer-7d61eccf@3351f097==org.glassfish.jersey.servlet.ServletContainer,-1,false,AUTO}
954 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1f130eaf added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-7d61eccf,POJO}
955 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2427e004
955 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@5ebd56e9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@63f34b70,MANAGED}
955 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@63f34b70 added {org.apache.spark.ui.JettyUtils$$anon$4-641856@73337c91==org.apache.spark.ui.JettyUtils$$anon$4,-1,true,AUTO}
955 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@63f34b70 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-641856,POJO}
955 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@56b78e55
956 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@76318a7d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2a492f2a,MANAGED}
956 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2a492f2a added {org.apache.spark.ui.JettyUtils$$anon$4-3277e499@dd1b6cd9==org.apache.spark.ui.JettyUtils$$anon$4,-1,true,AUTO}
956 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@2a492f2a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-3277e499,POJO}
962 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@7d373bcf added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
963 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@7d373bcf added {org.spark_project.jetty.server.handler.ErrorHandler@10027fc9,AUTO}
965 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@7d373bcf added {org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[],MANAGED}
966 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.Server@7d373bcf
967 [main] INFO org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT
980 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.Server@7d373bcf
980 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
981 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1970ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
982 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.ErrorHandler@10027fc9
982 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.ErrorHandler@10027fc9
982 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1970ms org.spark_project.jetty.server.handler.ErrorHandler@10027fc9
982 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[]
982 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[]
982 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1970ms org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[]
982 [main] INFO org.spark_project.jetty.server.Server  - Started @1970ms
982 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1970ms org.spark_project.jetty.server.Server@7d373bcf
987 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - HttpConnectionFactory@6c4f9535[HTTP/1.1] added {HttpConfiguration@5bd1ceca{32768/8192,8192/8192,https://:0,[]},POJO}
992 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@7d373bcf,UNMANAGED}
993 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
993 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@1e11bc55,AUTO}
993 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@7544a1e4,POJO}
993 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@6c4f9535[HTTP/1.1],AUTO}
993 [main] DEBUG org.spark_project.jetty.server.AbstractConnector  - ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@6c4f9535[HTTP/1.1]
996 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42,MANAGED}
996 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
998 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
998 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@1e11bc55
998 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1986ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@1e11bc55
998 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting HttpConnectionFactory@6c4f9535[HTTP/1.1]
998 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1986ms HttpConnectionFactory@6c4f9535[HTTP/1.1]
998 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42
1001 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42 added {org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=-1 selected=-1,AUTO}
1001 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42 added {org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=-1 selected=-1,AUTO}
1001 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42 added {org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=-1 selected=-1,AUTO}
1002 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42 added {org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=-1 selected=-1,AUTO}
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=-1 selected=-1
1002 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1990ms org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=-1 selected=-1
1002 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
1002 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
1002 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 execute
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1990ms org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
1002 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 produce enter
1002 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=-1 selected=-1
1002 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 producing
1002 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
1002 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6ab3e57 execute
1002 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
1002 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1991ms org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
1002 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6ab3e57 produce enter
1002 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6ab3e57 producing
1002 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
1003 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=-1 selected=-1
1003 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@223853fc execute
1003 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
1003 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@223853fc produce enter
1003 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@223853fc producing
1003 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
1003 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
1003 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1991ms org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
1003 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
1003 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1991ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42
1003 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@19e9d793 execute
1003 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@19e9d793 produce enter
1003 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@19e9d793 producing
1003 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
1004 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@52eacb4b,POJO}
1004 [main] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - queue acceptor-0@52eacb4b
1004 [main] INFO org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
1004 [SparkUI-49] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - run acceptor-0@52eacb4b
1004 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @1992ms ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
1004 [main] INFO org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
1004 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.Server@7d373bcf added {Spark@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
1019 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c mime types IncludeExclude@22db8f4{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2b46a8c1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1d572e62}
1020 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c added {o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,null,@Spark},MANAGED}
1020 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,UNMANAGED}
1020 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,null,@Spark}]}]
1020 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c
1021 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c
1021 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,null,@Spark}
1022 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,STARTING,@Spark}
1022 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@476aac9
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-19b30c92 from default=false
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-19b30c92@d46bde31==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1024 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-19b30c92=org.apache.spark.ui.JettyUtils$$anon$3-19b30c92@d46bde31==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1025 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@476aac9
1025 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2013ms org.spark_project.jetty.servlet.ServletHandler@476aac9
1025 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-19b30c92@d46bde31==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1027 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2015ms org.apache.spark.ui.JettyUtils$$anon$3-19b30c92@d46bde31==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1028 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2a2bb0eb for org.apache.spark.ui.JettyUtils$$anon$3-19b30c92
1028 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2016ms o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}
1028 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2016ms org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c
1029 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad mime types IncludeExclude@2d0566ba{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@733037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7728643a}
1029 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad added {o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,null,@Spark},MANAGED}
1029 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,UNMANAGED}
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,null,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1029 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad
1029 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad
1029 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,null,@Spark}
1029 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,STARTING,@Spark}
1029 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@2c95ac9e
1029 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b from default=false
1029 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1029 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1029 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b@d7fbc9dc==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b=org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b@d7fbc9dc==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1030 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@2c95ac9e
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2018ms org.spark_project.jetty.servlet.ServletHandler@2c95ac9e
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b@d7fbc9dc==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2018ms org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b@d7fbc9dc==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1030 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5167268 for org.apache.spark.ui.JettyUtils$$anon$3-4e4efc1b
1030 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2018ms o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}
1030 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2018ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad
1031 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875 mime types IncludeExclude@28c0b664{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2c444798,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1af7f54a}
1031 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875 added {o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,null,@Spark},MANAGED}
1031 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,UNMANAGED}
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,null,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875
1031 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,null,@Spark}
1031 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,STARTING,@Spark}
1031 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@2f4854d6
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0 from default=false
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1031 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1032 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0@38764b08==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1032 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0=org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0@38764b08==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1032 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@2f4854d6
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2020ms org.spark_project.jetty.servlet.ServletHandler@2f4854d6
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0@38764b08==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2020ms org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0@38764b08==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1032 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@436390f4 for org.apache.spark.ui.JettyUtils$$anon$3-61d9efe0
1032 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2020ms o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}
1032 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2020ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875
1032 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca mime types IncludeExclude@6d1310f6{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3228d990,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@54e7391d}
1033 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca added {o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,null,@Spark},MANAGED}
1033 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,UNMANAGED}
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,null,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca
1033 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,null,@Spark}
1033 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,STARTING,@Spark}
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@6de54b40
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3 from default=false
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3@d67b1b8d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1033 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3=org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3@d67b1b8d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1033 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@6de54b40
1033 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2022ms org.spark_project.jetty.servlet.ServletHandler@6de54b40
1034 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3@d67b1b8d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1034 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2022ms org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3@d67b1b8d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1034 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@255990cc for org.apache.spark.ui.JettyUtils$$anon$3-43ed0ff3
1034 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}
1034 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2022ms o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}
1034 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2022ms org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca
1034 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae mime types IncludeExclude@3c8bdd5b{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@29d2d081,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@40e4ea87}
1034 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae added {o.s.j.s.ServletContextHandler@9f46d94{/stages,null,null,@Spark},MANAGED}
1034 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,UNMANAGED}
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,null,@Spark}]}]
1034 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae
1034 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@9f46d94{/stages,null,null,@Spark}
1035 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@9f46d94{/stages,null,STARTING,@Spark}
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@18cc679e
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf from default=false
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf@acd53f8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf=org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf@acd53f8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1035 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@18cc679e
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2023ms org.spark_project.jetty.servlet.ServletHandler@18cc679e
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf@acd53f8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2023ms org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf@acd53f8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1035 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3a7b503d for org.apache.spark.ui.JettyUtils$$anon$3-2e77b8cf
1035 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2023ms o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}
1035 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2023ms org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae
1035 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b mime types IncludeExclude@62c5bbdc{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7bdf6bb7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1bc53649}
1035 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b added {o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,null,@Spark},MANAGED}
1036 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,UNMANAGED}
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,null,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1036 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b
1036 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b
1036 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,null,@Spark}
1036 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,STARTING,@Spark}
1036 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@7df587ef
1036 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e from default=false
1036 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1036 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1036 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1036 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e@a6e9b181==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1036 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e=org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e@a6e9b181==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1036 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@7df587ef
1036 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2025ms org.spark_project.jetty.servlet.ServletHandler@7df587ef
1036 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e@a6e9b181==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1036 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2025ms org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e@a6e9b181==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1036 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47d93e0d for org.apache.spark.ui.JettyUtils$$anon$3-6e57e95e
1037 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2025ms o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}
1037 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2025ms org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b
1037 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792 mime types IncludeExclude@751e664e{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@160c3ec1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@182b435b}
1037 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792 added {o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,null,@Spark},MANAGED}
1037 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,UNMANAGED}
1037 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1037 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1037 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,null,@Spark}]}]
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792
1038 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,null,@Spark}
1038 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,STARTING,@Spark}
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@560cbf1a
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721 from default=false
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721@c5e41004==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1038 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721=org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721@c5e41004==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1038 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@560cbf1a
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2027ms org.spark_project.jetty.servlet.ServletHandler@560cbf1a
1038 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721@c5e41004==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2027ms org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721@c5e41004==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1039 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2fa7ae9 for org.apache.spark.ui.JettyUtils$$anon$3-5fe8b721
1039 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2027ms o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}
1039 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2027ms org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792
1039 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc mime types IncludeExclude@60afd40d{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@28a2a3e7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3f2049b6}
1039 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc added {o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,null,@Spark},MANAGED}
1040 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,UNMANAGED}
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,null,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1040 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc
1040 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc
1040 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,null,@Spark}
1040 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,STARTING,@Spark}
1040 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@64c2b546
1040 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7e094740 from default=false
1040 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1040 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1040 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1040 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-7e094740@6488442==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1040 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7e094740=org.apache.spark.ui.JettyUtils$$anon$3-7e094740@6488442==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1040 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@64c2b546
1040 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2029ms org.spark_project.jetty.servlet.ServletHandler@64c2b546
1040 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-7e094740@6488442==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2029ms org.apache.spark.ui.JettyUtils$$anon$3-7e094740@6488442==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1041 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ea27e34 for org.apache.spark.ui.JettyUtils$$anon$3-7e094740
1041 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2029ms o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}
1041 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2029ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc
1041 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c mime types IncludeExclude@e72dba7{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@33c2bd,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1dfd5f51}
1041 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c added {o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,null,@Spark},MANAGED}
1041 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,UNMANAGED}
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1041 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,null,@Spark}]}]
1042 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c
1042 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c
1042 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,null,@Spark}
1042 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,STARTING,@Spark}
1042 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@4152d38d
1042 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3591009c from default=false
1042 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1042 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1042 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1042 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3591009c@8a81ab30==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1042 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3591009c=org.apache.spark.ui.JettyUtils$$anon$3-3591009c@8a81ab30==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1042 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@4152d38d
1043 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2031ms org.spark_project.jetty.servlet.ServletHandler@4152d38d
1043 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-3591009c@8a81ab30==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1043 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2031ms org.apache.spark.ui.JettyUtils$$anon$3-3591009c@8a81ab30==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1043 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@24855019 for org.apache.spark.ui.JettyUtils$$anon$3-3591009c
1043 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}
1043 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2031ms o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}
1043 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2031ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c
1043 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e mime types IncludeExclude@4d4d8fcf{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@610db97e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6f0628de}
1043 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e added {o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,null,@Spark},MANAGED}
1043 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,UNMANAGED}
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,null,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1044 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e
1044 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e
1044 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,null,@Spark}
1045 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,STARTING,@Spark}
1045 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@5cc5b667
1045 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-61edc883 from default=false
1045 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1045 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1045 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1045 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-61edc883@3c877b76==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1045 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-61edc883=org.apache.spark.ui.JettyUtils$$anon$3-61edc883@3c877b76==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1045 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@5cc5b667
1045 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2033ms org.spark_project.jetty.servlet.ServletHandler@5cc5b667
1045 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-61edc883@3c877b76==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1045 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2033ms org.apache.spark.ui.JettyUtils$$anon$3-61edc883@3c877b76==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1045 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1e392345 for org.apache.spark.ui.JettyUtils$$anon$3-61edc883
1045 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}
1045 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2033ms o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}
1045 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2033ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e
1045 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5 mime types IncludeExclude@4ced35ed{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2c22a348,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7bd69e82}
1045 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5 added {o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,null,@Spark},MANAGED}
1045 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,UNMANAGED}
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,null,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1046 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5
1046 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5
1046 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,null,@Spark}
1046 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,STARTING,@Spark}
1046 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@3574e198
1046 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6db66836 from default=false
1046 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1046 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1046 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1046 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6db66836@beaa1113==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1046 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6db66836=org.apache.spark.ui.JettyUtils$$anon$3-6db66836@beaa1113==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1046 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@3574e198
1046 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2035ms org.spark_project.jetty.servlet.ServletHandler@3574e198
1046 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-6db66836@beaa1113==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1046 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2035ms org.apache.spark.ui.JettyUtils$$anon$3-6db66836@beaa1113==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1047 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b01960 for org.apache.spark.ui.JettyUtils$$anon$3-6db66836
1047 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}
1047 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2035ms o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}
1047 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2035ms org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5
1047 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd mime types IncludeExclude@27dc79f7{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6b85300e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3aaf4f07}
1047 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd added {o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,null,@Spark},MANAGED}
1047 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,UNMANAGED}
1047 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1048 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,null,@Spark}]}]
1049 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1049 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1049 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd
1049 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,null,@Spark}
1049 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,STARTING,@Spark}
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@3f093abe
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-61a002b1 from default=false
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-61a002b1@32c01267==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-61a002b1=org.apache.spark.ui.JettyUtils$$anon$3-61a002b1@32c01267==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1049 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@3f093abe
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2037ms org.spark_project.jetty.servlet.ServletHandler@3f093abe
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-61a002b1@32c01267==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1049 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2038ms org.apache.spark.ui.JettyUtils$$anon$3-61a002b1@32c01267==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1049 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@18e8473e for org.apache.spark.ui.JettyUtils$$anon$3-61a002b1
1050 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}
1050 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2038ms o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}
1050 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2038ms org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd
1050 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d mime types IncludeExclude@1a38ba58{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3ad394e6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6058e535}
1050 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d added {o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,null,@Spark},MANAGED}
1050 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,UNMANAGED}
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1050 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,null,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d
1051 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,null,@Spark}
1051 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,STARTING,@Spark}
1051 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@6f70f32f
1051 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-548e76f1 from default=false
1052 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1052 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1052 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1052 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-548e76f1@268901a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1052 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-548e76f1=org.apache.spark.ui.JettyUtils$$anon$3-548e76f1@268901a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1052 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@6f70f32f
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2040ms org.spark_project.jetty.servlet.ServletHandler@6f70f32f
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-548e76f1@268901a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2040ms org.apache.spark.ui.JettyUtils$$anon$3-548e76f1@268901a2==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1052 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1deb2c43 for org.apache.spark.ui.JettyUtils$$anon$3-548e76f1
1052 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2040ms o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}
1052 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2040ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d
1052 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc mime types IncludeExclude@1cefc4b3{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@2b27cc70,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6f6a7463}
1052 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc added {o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,null,@Spark},MANAGED}
1053 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,UNMANAGED}
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,null,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1053 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc
1054 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,null,@Spark}
1054 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,STARTING,@Spark}
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@1ac85b0c
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a from default=false
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a@8a7245e8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a=org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a@8a7245e8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1054 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@1ac85b0c
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2042ms org.spark_project.jetty.servlet.ServletHandler@1ac85b0c
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a@8a7245e8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2042ms org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a@8a7245e8==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1054 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@79f227a9 for org.apache.spark.ui.JettyUtils$$anon$3-3dd69f5a
1054 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2042ms o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}
1054 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2042ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc
1054 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab mime types IncludeExclude@50d68830{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1e53135d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7674a051}
1055 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab added {o.s.j.s.ServletContextHandler@724bade8{/environment,null,null,@Spark},MANAGED}
1055 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,UNMANAGED}
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,null,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1055 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab
1055 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab
1055 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@724bade8{/environment,null,null,@Spark}
1055 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@724bade8{/environment,null,STARTING,@Spark}
1055 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@16fb356
1055 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed from default=false
1055 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1055 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1055 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1055 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed@565932aa==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1056 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed=org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed@565932aa==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1056 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@16fb356
1056 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2044ms org.spark_project.jetty.servlet.ServletHandler@16fb356
1056 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed@565932aa==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1056 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2044ms org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed@565932aa==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1056 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6754ef00 for org.apache.spark.ui.JettyUtils$$anon$3-6bc248ed
1056 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}
1056 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2044ms o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}
1056 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2044ms org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab
1056 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c mime types IncludeExclude@323e8306{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@a23a01d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@4acf72b6}
1056 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c added {o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,null,@Spark},MANAGED}
1056 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,UNMANAGED}
1056 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1056 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1056 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1056 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,null,@Spark}]}]
1056 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1056 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1056 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1057 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c
1057 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c
1057 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,null,@Spark}
1057 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,STARTING,@Spark}
1057 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@70ab80e3
1057 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-9573b3b from default=false
1057 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1057 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1057 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1057 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-9573b3b@ffb2210d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1057 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-9573b3b=org.apache.spark.ui.JettyUtils$$anon$3-9573b3b@ffb2210d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1057 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@70ab80e3
1057 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2046ms org.spark_project.jetty.servlet.ServletHandler@70ab80e3
1057 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-9573b3b@ffb2210d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1058 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2046ms org.apache.spark.ui.JettyUtils$$anon$3-9573b3b@ffb2210d==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1058 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3301500b for org.apache.spark.ui.JettyUtils$$anon$3-9573b3b
1058 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}
1058 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2046ms o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}
1058 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2046ms org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c
1058 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e mime types IncludeExclude@15deb1dc{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6e9c413e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@57a4d5ee}
1058 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e added {o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,null,@Spark},MANAGED}
1058 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,UNMANAGED}
1058 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1058 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,null,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1059 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e
1059 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e
1059 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,null,@Spark}
1059 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,STARTING,@Spark}
1059 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@1b822fcc
1059 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f from default=false
1059 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1059 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1059 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1059 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f@32134e5b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1059 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f=org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f@32134e5b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1059 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@1b822fcc
1059 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2048ms org.spark_project.jetty.servlet.ServletHandler@1b822fcc
1059 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f@32134e5b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1059 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2048ms org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f@32134e5b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1059 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3a45c42a for org.apache.spark.ui.JettyUtils$$anon$3-24a1c17f
1059 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}
1060 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2048ms o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}
1060 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2048ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e
1060 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed mime types IncludeExclude@47a64f7d{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@33d05366,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@27a0a5a2}
1060 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed added {o.s.j.s.ServletContextHandler@73511076{/executors/json,null,null,@Spark},MANAGED}
1060 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,UNMANAGED}
1060 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1060 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,null,@Spark}]}]
1060 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1060 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1061 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed
1061 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed
1061 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@73511076{/executors/json,null,null,@Spark}
1061 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@73511076{/executors/json,null,STARTING,@Spark}
1061 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@7927bd9f
1061 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-532721fd from default=false
1061 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1061 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1061 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1062 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-532721fd@e4db210c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1062 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-532721fd=org.apache.spark.ui.JettyUtils$$anon$3-532721fd@e4db210c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1062 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@7927bd9f
1062 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2050ms org.spark_project.jetty.servlet.ServletHandler@7927bd9f
1062 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-532721fd@e4db210c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1062 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2050ms org.apache.spark.ui.JettyUtils$$anon$3-532721fd@e4db210c==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1062 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@33aa93c for org.apache.spark.ui.JettyUtils$$anon$3-532721fd
1062 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}
1062 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2050ms o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}
1062 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2050ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed
1062 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e mime types IncludeExclude@106faf11{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@70f43b45,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@26d10f2e}
1062 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e added {o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,null,@Spark},MANAGED}
1062 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,UNMANAGED}
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,null,@Spark}]}]
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e
1063 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,null,@Spark}
1063 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,STARTING,@Spark}
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@51f49060
1063 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-514eedd8 from default=false
1063 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1063 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1063 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1063 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-514eedd8@811882ec==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1063 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-514eedd8=org.apache.spark.ui.JettyUtils$$anon$3-514eedd8@811882ec==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1063 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@51f49060
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2051ms org.spark_project.jetty.servlet.ServletHandler@51f49060
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-514eedd8@811882ec==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2052ms org.apache.spark.ui.JettyUtils$$anon$3-514eedd8@811882ec==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1063 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7dd712e8 for org.apache.spark.ui.JettyUtils$$anon$3-514eedd8
1063 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2052ms o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}
1063 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2052ms org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e
1064 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004 mime types IncludeExclude@22ee2d0{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7bfc3126,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@3e792ce3}
1064 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004 added {o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,null,@Spark},MANAGED}
1064 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,UNMANAGED}
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,[o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,null,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1064 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004
1065 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,null,@Spark}
1065 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,STARTING,@Spark}
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@1cf2fed4
1065 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf from default=false
1065 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1065 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1065 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1065 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf@ef205177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1065 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf=org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf@ef205177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1065 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@1cf2fed4
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2053ms org.spark_project.jetty.servlet.ServletHandler@1cf2fed4
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf@ef205177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2053ms org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf@ef205177==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1065 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@26f143ed for org.apache.spark.ui.JettyUtils$$anon$3-3af4e0bf
1065 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2053ms o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}
1065 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2053ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004
1065 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314 mime types IncludeExclude@4b770e40{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@78e16155,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@54a3ab8f}
1065 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314 added {o.s.j.s.ServletContextHandler@466cf502{/static,null,null,@Spark},MANAGED}
1066 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314,UNMANAGED}
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314,[o.s.j.s.ServletContextHandler@466cf502{/static,null,null,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,[o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1066 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314
1066 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314
1066 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@466cf502{/static,null,null,@Spark}
1066 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@466cf502{/static,null,STARTING,@Spark}
1066 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@5b800468
1066 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-2af616d3 from default=false
1067 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1067 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1067 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1067 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-2af616d3@229e5d02==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
1067 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-2af616d3=org.spark_project.jetty.servlet.DefaultServlet-2af616d3@229e5d02==org.spark_project.jetty.servlet.DefaultServlet,-1,true}
1067 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@5b800468
1067 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2055ms org.spark_project.jetty.servlet.ServletHandler@5b800468
1067 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.DefaultServlet-2af616d3@229e5d02==org.spark_project.jetty.servlet.DefaultServlet,-1,true
1067 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2055ms org.spark_project.jetty.servlet.DefaultServlet-2af616d3@229e5d02==org.spark_project.jetty.servlet.DefaultServlet,-1,true
1067 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.spark_project.jetty.servlet.DefaultServlet@6a1ebcff for org.spark_project.jetty.servlet.DefaultServlet-2af616d3
1073 [main] DEBUG org.spark_project.jetty.servlet.DefaultServlet  - resource base = jar:file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-core_2.11-2.2.0.jar!/org/apache/spark/ui/static
1073 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@466cf502{/static,null,AVAILABLE,@Spark}
1073 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2061ms o.s.j.s.ServletContextHandler@466cf502{/static,null,AVAILABLE,@Spark}
1073 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2061ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314
1073 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100 mime types IncludeExclude@5b69fd74{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@f325091,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@437e951d}
1073 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100 added {o.s.j.s.ServletContextHandler@7889a1ac{/,null,null,@Spark},MANAGED}
1073 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100,UNMANAGED}
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100,[o.s.j.s.ServletContextHandler@7889a1ac{/,null,null,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314,[o.s.j.s.ServletContextHandler@466cf502{/static,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,[o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1074 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1075 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1075 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1075 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1075 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100
1075 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@7889a1ac{/,null,null,@Spark}
1075 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@7889a1ac{/,null,STARTING,@Spark}
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@3aee3976
1075 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e from default=false
1075 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1075 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1075 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1075 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e@86fdb7c3==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1075 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e=org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e@86fdb7c3==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1075 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@3aee3976
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2063ms org.spark_project.jetty.servlet.ServletHandler@3aee3976
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e@86fdb7c3==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2063ms org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e@86fdb7c3==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1075 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@63a5e46c for org.apache.spark.ui.JettyUtils$$anon$4-5ef8df1e
1075 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7889a1ac{/,null,AVAILABLE,@Spark}
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2064ms o.s.j.s.ServletContextHandler@7889a1ac{/,null,AVAILABLE,@Spark}
1075 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2064ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100
1076 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651 mime types IncludeExclude@49ef32e0{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@271f18d3,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@6bd51ed8}
1076 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651 added {o.s.j.s.ServletContextHandler@4108fa66{/api,null,null,@Spark},MANAGED}
1076 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100, org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651,UNMANAGED}
1076 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100,[o.s.j.s.ServletContextHandler@7889a1ac{/,null,AVAILABLE,@Spark}]}]
1076 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1076 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314,[o.s.j.s.ServletContextHandler@466cf502{/static,null,AVAILABLE,@Spark}]}]
1076 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1076 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1076 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,[o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651,[o.s.j.s.ServletContextHandler@4108fa66{/api,null,null,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1077 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651
1077 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651
1077 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@4108fa66{/api,null,null,@Spark}
1077 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@4108fa66{/api,null,STARTING,@Spark}
1077 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@1f130eaf
1077 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-7d61eccf from default=false
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-7d61eccf@3351f097==org.glassfish.jersey.servlet.ServletContainer,-1,false}
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-7d61eccf=org.glassfish.jersey.servlet.ServletContainer-7d61eccf@3351f097==org.glassfish.jersey.servlet.ServletContainer,-1,false}
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@1f130eaf
1078 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1f130eaf added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6@b57ed55d==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false,AUTO}
1078 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@1f130eaf added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6,POJO}
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-7d61eccf from default=false
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6 from default=false
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-7d61eccf@3351f097==org.glassfish.jersey.servlet.ServletContainer,-1,false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6@b57ed55d==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false}
1078 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6@b57ed55d==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false, org.glassfish.jersey.servlet.ServletContainer-7d61eccf=org.glassfish.jersey.servlet.ServletContainer-7d61eccf@3351f097==org.glassfish.jersey.servlet.ServletContainer,-1,false}
1078 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@1f130eaf
1078 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2067ms org.spark_project.jetty.servlet.ServletHandler@1f130eaf
1078 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.glassfish.jersey.servlet.ServletContainer-7d61eccf@3351f097==org.glassfish.jersey.servlet.ServletContainer,-1,false
1078 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2067ms org.glassfish.jersey.servlet.ServletContainer-7d61eccf@3351f097==org.glassfish.jersey.servlet.ServletContainer,-1,false
1078 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6@b57ed55d==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
1079 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2067ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4d4d48a6@b57ed55d==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
1079 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4108fa66{/api,null,AVAILABLE,@Spark}
1079 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2067ms o.s.j.s.ServletContextHandler@4108fa66{/api,null,AVAILABLE,@Spark}
1079 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2067ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651
1079 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec mime types IncludeExclude@5cad8b7d{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@7b02e036,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@25243bc1}
1079 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec added {o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,null,@Spark},MANAGED}
1079 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100, org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec,UNMANAGED}
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100,[o.s.j.s.ServletContextHandler@7889a1ac{/,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314,[o.s.j.s.ServletContextHandler@466cf502{/static,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,[o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1079 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651,[o.s.j.s.ServletContextHandler@4108fa66{/api,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec,[o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,null,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec
1080 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,null,@Spark}
1080 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,STARTING,@Spark}
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@63f34b70
1080 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-641856 from default=false
1080 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1080 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1080 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1080 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-641856@73337c91==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1080 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-641856=org.apache.spark.ui.JettyUtils$$anon$4-641856@73337c91==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1080 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@63f34b70
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2068ms org.spark_project.jetty.servlet.ServletHandler@63f34b70
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$4-641856@73337c91==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2068ms org.apache.spark.ui.JettyUtils$$anon$4-641856@73337c91==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1080 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@2e6ee0bc for org.apache.spark.ui.JettyUtils$$anon$4-641856
1080 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,AVAILABLE,@Spark}
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2068ms o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,AVAILABLE,@Spark}
1080 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2068ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec
1080 [main] DEBUG org.spark_project.jetty.server.handler.gzip.GzipHandler  - org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617 mime types IncludeExclude@467f77a5{i=[],ip=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@1bb9aa43,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExclude$SetContainsPredicate@420bc288}
1080 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617 added {o.s.j.s.ServletContextHandler@76318a7d{/stages/stage/kill,null,null,@Spark},MANAGED}
1080 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100, org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec, org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617,UNMANAGED}
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100,[o.s.j.s.ServletContextHandler@7889a1ac{/,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651,[o.s.j.s.ServletContextHandler@4108fa66{/api,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314,[o.s.j.s.ServletContextHandler@466cf502{/static,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,[o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617,[o.s.j.s.ServletContextHandler@76318a7d{/stages/stage/kill,null,null,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec,[o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1081 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617
1081 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617
1082 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@76318a7d{/stages/stage/kill,null,null,@Spark}
1082 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@76318a7d{/stages/stage/kill,null,STARTING,@Spark}
1082 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@2a492f2a
1082 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-3277e499 from default=false
1082 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1082 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1082 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1082 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-3277e499@dd1b6cd9==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1082 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-3277e499=org.apache.spark.ui.JettyUtils$$anon$4-3277e499@dd1b6cd9==org.apache.spark.ui.JettyUtils$$anon$4,-1,true}
1082 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@2a492f2a
1082 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2070ms org.spark_project.jetty.servlet.ServletHandler@2a492f2a
1082 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$4-3277e499@dd1b6cd9==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1082 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2070ms org.apache.spark.ui.JettyUtils$$anon$4-3277e499@dd1b6cd9==org.apache.spark.ui.JettyUtils$$anon$4,-1,true
1082 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@308a6984 for org.apache.spark.ui.JettyUtils$$anon$4-3277e499
1082 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@76318a7d{/stages/stage/kill,null,AVAILABLE,@Spark}
1082 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2070ms o.s.j.s.ServletContextHandler@76318a7d{/stages/stage/kill,null,AVAILABLE,@Spark}
1082 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2070ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617
1084 [main] INFO org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040
1102 [main] INFO org.apache.spark.SparkContext  - Added JAR file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.1.4:49902/jars/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1512520190447
1280 [main] INFO org.apache.spark.SparkContext  - Added file file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/uci.zip at spark://192.168.1.4:49902/files/uci.zip with timestamp 1512520190624
1281 [main] INFO org.apache.spark.util.Utils  - Copying /Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/uci.zip to /private/var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T/spark-3119c848-bdd7-430c-b867-32e535f8e122/userFiles-918bdac9-000e-4652-b4d0-564fd5f4e7d5/uci.zip
1406 [appclient-register-master-threadpool-0] INFO org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint  - Connecting to master spark://Toms-MacBook-Pro.local:7077...
1422 [netty-rpc-connection-0] DEBUG org.apache.spark.network.client.TransportClientFactory  - Creating new connection to Toms-MacBook-Pro.local/192.168.1.4:7077
1442 [rpc-client-1-1] DEBUG io.netty.buffer.AbstractByteBuf  - -Dio.netty.buffer.bytebuf.checkAccessible: true
1445 [rpc-client-1-1] DEBUG io.netty.util.ResourceLeakDetector  - -Dio.netty.leakDetection.level: simple
1445 [rpc-client-1-1] DEBUG io.netty.util.ResourceLeakDetector  - -Dio.netty.leakDetection.maxRecords: 4
1445 [rpc-client-1-1] DEBUG io.netty.util.ResourceLeakDetectorFactory  - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@6210256d
1450 [netty-rpc-connection-0] DEBUG org.apache.spark.network.client.TransportClientFactory  - Connection to Toms-MacBook-Pro.local/192.168.1.4:7077 successful, running bootstraps...
1450 [netty-rpc-connection-0] INFO org.apache.spark.network.client.TransportClientFactory  - Successfully created connection to Toms-MacBook-Pro.local/192.168.1.4:7077 after 27 ms (0 ms spent in bootstraps)
1455 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.maxCapacity.default: 32768
1455 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.maxSharedCapacityFactor: 2
1455 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.linkCapacity: 16
1455 [netty-rpc-connection-0] DEBUG io.netty.util.Recycler  - -Dio.netty.recycler.ratio: 8
1524 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - Connected to Spark cluster with app ID app-20171205192950-0019
1527 [dispatcher-event-loop-1] INFO org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint  - Executor added: app-20171205192950-0019/0 on worker-20171205023234-192.168.1.4-63497 (192.168.1.4:63497) with 8 cores
1528 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - Granted executor ID app-20171205192950-0019/0 on hostPort 192.168.1.4:63497 with 8 cores, 1024.0 MB RAM
1530 [main] DEBUG org.apache.spark.network.server.TransportServer  - Shuffle server started on port: 49908
1530 [main] INFO org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49908.
1531 [main] INFO org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.1.4:49908
1532 [main] INFO org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
1534 [main] INFO org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.1.4, 49908, None)
1537 [dispatcher-event-loop-0] DEBUG org.apache.spark.storage.DefaultTopologyMapper  - Got a request for 192.168.1.4
1537 [dispatcher-event-loop-5] INFO org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint  - Executor updated: app-20171205192950-0019/0 is now RUNNING
1538 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.1.4:49908 with 366.3 MB RAM, BlockManagerId(driver, 192.168.1.4, 49908, None)
1541 [main] INFO org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.1.4, 49908, None)
1541 [main] INFO org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.1.4, 49908, None)
1662 [main] DEBUG org.spark_project.jetty.util.DecoratedObjectFactory  - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@b18c4
1662 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - o.s.j.s.ServletContextHandler@4cbf4f53{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@597f48df,MANAGED}
1662 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@597f48df added {org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2@6f1658b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true,AUTO}
1662 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.servlet.ServletHandler@597f48df added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2,POJO}
1664 [main] DEBUG org.spark_project.jetty.util.component.ContainerLifeCycle  - org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100, org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec, org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617, o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,null,@Spark},UNMANAGED}
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - ->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100,[o.s.j.s.ServletContextHandler@7889a1ac{/,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d,[o.s.j.s.ServletContextHandler@e24ddd0{/storage/rdd,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5,[o.s.j.s.ServletContextHandler@27e0f2f5{/storage,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc,[o.s.j.s.ServletContextHandler@72c927f1{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651,[o.s.j.s.ServletContextHandler@4108fa66{/api,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e,[o.s.j.s.ServletContextHandler@b5cc23a{/stages/pool/json,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c,[o.s.j.s.ServletContextHandler@7555b920{/stages/pool,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad,[o.s.j.s.ServletContextHandler@4a9e6faf{/jobs/json,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314,[o.s.j.s.ServletContextHandler@466cf502{/static,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed,[o.s.j.s.ServletContextHandler@73511076{/executors/json,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc,[o.s.j.s.ServletContextHandler@578524c3{/stages/stage/json,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004,[o.s.j.s.ServletContextHandler@6970140a{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
1664 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c,[o.s.j.s.ServletContextHandler@ca27722{/environment/json,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca,[o.s.j.s.ServletContextHandler@e6516e{/jobs/job/json,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c,[o.s.j.s.ServletContextHandler@1b11ef33{/jobs,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b,[o.s.j.s.ServletContextHandler@67ef029{/stages/json,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792,[o.s.j.s.ServletContextHandler@740abb5{/stages/stage,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd,[o.s.j.s.ServletContextHandler@2de366bb{/storage/json,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617,[o.s.j.s.ServletContextHandler@76318a7d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875,[o.s.j.s.ServletContextHandler@7eb01b12{/jobs/job,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab,[o.s.j.s.ServletContextHandler@724bade8{/environment,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae,[o.s.j.s.ServletContextHandler@9f46d94{/stages,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e,[o.s.j.s.ServletContextHandler@3d6300e8{/executors,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec,[o.s.j.s.ServletContextHandler@5ebd56e9{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - metrics/json->[{o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,null,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.server.handler.ContextHandlerCollection  - executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e,[o.s.j.s.ServletContextHandler@3b366632{/executors/threadDump,null,AVAILABLE,@Spark}]}]
1665 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,null,@Spark}
1665 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,STARTING,@Spark}
1665 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.spark_project.jetty.servlet.ServletHandler@597f48df
1665 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2 from default=false
1665 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - filterNameMap={}
1665 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - pathFilters=null
1665 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletFilterMap=null
1665 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2@6f1658b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1665 [main] DEBUG org.spark_project.jetty.servlet.ServletHandler  - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2=org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2@6f1658b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true}
1665 [main] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - starting org.spark_project.jetty.servlet.ServletHandler@597f48df
1665 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2653ms org.spark_project.jetty.servlet.ServletHandler@597f48df
1665 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - starting org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2@6f1658b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1665 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2654ms org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2@6f1658b==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
1665 [main] DEBUG org.spark_project.jetty.servlet.ServletHolder  - Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@54aca26f for org.apache.spark.ui.JettyUtils$$anon$3-15dd5ac2
1665 [main] INFO org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,AVAILABLE,@Spark}
1665 [main] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STARTED @2654ms o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,AVAILABLE,@Spark}
1679 [main] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
1684 [main] DEBUG org.apache.spark.SparkContext  - Adding shutdown hook
name: uci/                 | size:      0 | compressed size:      0
name: uci/test/            | size:      0 | compressed size:      0
name: uci/test/features/   | size:      0 | compressed size:      0
name: uci/test/features/0.csv | size:    475 | compressed size:    239
name: uci/test/features/1.csv | size:    468 | compressed size:    224
name: uci/test/features/10.csv | size:    474 | compressed size:    225
name: uci/test/features/100.csv | size:    472 | compressed size:    230
name: uci/test/features/101.csv | size:    471 | compressed size:    226
name: uci/test/features/102.csv | size:    473 | compressed size:    231
name: uci/test/features/103.csv | size:    474 | compressed size:    224
name: uci/test/features/104.csv | size:    470 | compressed size:    225
name: uci/test/features/105.csv | size:    475 | compressed size:    229
name: uci/test/features/106.csv | size:    473 | compressed size:    236
name: uci/test/features/107.csv | size:    466 | compressed size:    222
name: uci/test/features/108.csv | size:    470 | compressed size:    234
name: uci/test/features/109.csv | size:    476 | compressed size:    234
name: uci/test/features/11.csv | size:    472 | compressed size:    222
name: uci/test/features/110.csv | size:    476 | compressed size:    229
name: uci/test/features/111.csv | size:    472 | compressed size:    227
name: uci/test/features/112.csv | size:    469 | compressed size:    233
name: uci/test/features/113.csv | size:    474 | compressed size:    228
name: uci/test/features/114.csv | size:    472 | compressed size:    224
name: uci/test/features/115.csv | size:    475 | compressed size:    230
name: uci/test/features/116.csv | size:    470 | compressed size:    237
name: uci/test/features/117.csv | size:    473 | compressed size:    227
name: uci/test/features/118.csv | size:    470 | compressed size:    223
name: uci/test/features/119.csv | size:    469 | compressed size:    236
name: uci/test/features/12.csv | size:    471 | compressed size:    228
name: uci/test/features/120.csv | size:    472 | compressed size:    236
name: uci/test/features/121.csv | size:    475 | compressed size:    224
name: uci/test/features/122.csv | size:    471 | compressed size:    237
name: uci/test/features/123.csv | size:    475 | compressed size:    233
name: uci/test/features/124.csv | size:    473 | compressed size:    242
name: uci/test/features/125.csv | size:    466 | compressed size:    216
name: uci/test/features/126.csv | size:    471 | compressed size:    220
name: uci/test/features/127.csv | size:    473 | compressed size:    227
name: uci/test/features/128.csv | size:    471 | compressed size:    225
name: uci/test/features/129.csv | size:    472 | compressed size:    240
name: uci/test/features/13.csv | size:    473 | compressed size:    231
name: uci/test/features/130.csv | size:    473 | compressed size:    228
name: uci/test/features/131.csv | size:    474 | compressed size:    224
name: uci/test/features/132.csv | size:    471 | compressed size:    236
name: uci/test/features/133.csv | size:    473 | compressed size:    232
name: uci/test/features/134.csv | size:    469 | compressed size:    227
name: uci/test/features/135.csv | size:    472 | compressed size:    231
name: uci/test/features/136.csv | size:    470 | compressed size:    220
name: uci/test/features/137.csv | size:    482 | compressed size:    243
name: uci/test/features/138.csv | size:    471 | compressed size:    225
name: uci/test/features/139.csv | size:    475 | compressed size:    227
name: uci/test/features/14.csv | size:    475 | compressed size:    227
name: uci/test/features/140.csv | size:    475 | compressed size:    243
name: uci/test/features/141.csv | size:    472 | compressed size:    224
name: uci/test/features/142.csv | size:    468 | compressed size:    226
name: uci/test/features/143.csv | size:    471 | compressed size:    227
name: uci/test/features/144.csv | size:    471 | compressed size:    229
name: uci/test/features/145.csv | size:    473 | compressed size:    232
name: uci/test/features/146.csv | size:    470 | compressed size:    237
name: uci/test/features/147.csv | size:    470 | compressed size:    220
name: uci/test/features/148.csv | size:    472 | compressed size:    234
name: uci/test/features/149.csv | size:    475 | compressed size:    231
name: uci/test/features/15.csv | size:    473 | compressed size:    224
name: uci/test/features/16.csv | size:    474 | compressed size:    237
name: uci/test/features/17.csv | size:    472 | compressed size:    230
name: uci/test/features/18.csv | size:    475 | compressed size:    233
name: uci/test/features/19.csv | size:    472 | compressed size:    231
name: uci/test/features/2.csv | size:    473 | compressed size:    233
name: uci/test/features/20.csv | size:    472 | compressed size:    229
name: uci/test/features/21.csv | size:    474 | compressed size:    228
name: uci/test/features/22.csv | size:    469 | compressed size:    231
name: uci/test/features/23.csv | size:    472 | compressed size:    234
name: uci/test/features/24.csv | size:    469 | compressed size:    229
name: uci/test/features/25.csv | size:    474 | compressed size:    240
name: uci/test/features/26.csv | size:    469 | compressed size:    232
name: uci/test/features/27.csv | size:    474 | compressed size:    238
name: uci/test/features/28.csv | size:    475 | compressed size:    228
name: uci/test/features/29.csv | size:    478 | compressed size:    238
name: uci/test/features/3.csv | size:    476 | compressed size:    227
name: uci/test/features/30.csv | size:    468 | compressed size:    233
name: uci/test/features/31.csv | size:    471 | compressed size:    239
name: uci/test/features/32.csv | size:    470 | compressed size:    229
name: uci/test/features/33.csv | size:    473 | compressed size:    237
name: uci/test/features/34.csv | size:    468 | compressed size:    221
name: uci/test/features/35.csv | size:    473 | compressed size:    224
name: uci/test/features/36.csv | size:    476 | compressed size:    234
name: uci/test/features/37.csv | size:    462 | compressed size:    226
name: uci/test/features/38.csv | size:    470 | compressed size:    233
name: uci/test/features/39.csv | size:    469 | compressed size:    219
name: uci/test/features/4.csv | size:    477 | compressed size:    234
name: uci/test/features/40.csv | size:    473 | compressed size:    236
name: uci/test/features/41.csv | size:    474 | compressed size:    239
name: uci/test/features/42.csv | size:    470 | compressed size:    233
name: uci/test/features/43.csv | size:    471 | compressed size:    234
name: uci/test/features/44.csv | size:    476 | compressed size:    233
name: uci/test/features/45.csv | size:    471 | compressed size:    226
name: uci/test/features/46.csv | size:    472 | compressed size:    231
name: uci/test/features/47.csv | size:    468 | compressed size:    228
name: uci/test/features/48.csv | size:    474 | compressed size:    228
name: uci/test/features/49.csv | size:    478 | compressed size:    238
name: uci/test/features/5.csv | size:    475 | compressed size:    232
name: uci/test/features/50.csv | size:    469 | compressed size:    232
name: uci/test/features/51.csv | size:    472 | compressed size:    226
name: uci/test/features/52.csv | size:    475 | compressed size:    229
name: uci/test/features/53.csv | size:    474 | compressed size:    232
name: uci/test/features/54.csv | size:    471 | compressed size:    236
name: uci/test/features/55.csv | size:    471 | compressed size:    242
name: uci/test/features/56.csv | size:    475 | compressed size:    231
name: uci/test/features/57.csv | size:    468 | compressed size:    225
name: uci/test/features/58.csv | size:    471 | compressed size:    235
name: uci/test/features/59.csv | size:    474 | compressed size:    233
name: uci/test/features/6.csv | size:    473 | compressed size:    232
name: uci/test/features/60.csv | size:    473 | compressed size:    223
name: uci/test/features/61.csv | size:    471 | compressed size:    230
name: uci/test/features/62.csv | size:    473 | compressed size:    220
name: uci/test/features/63.csv | size:    476 | compressed size:    224
name: uci/test/features/64.csv | size:    470 | compressed size:    230
name: uci/test/features/65.csv | size:    473 | compressed size:    231
name: uci/test/features/66.csv | size:    471 | compressed size:    228
name: uci/test/features/67.csv | size:    477 | compressed size:    234
name: uci/test/features/68.csv | size:    469 | compressed size:    230
name: uci/test/features/69.csv | size:    468 | compressed size:    219
name: uci/test/features/7.csv | size:    468 | compressed size:    237
name: uci/test/features/70.csv | size:    470 | compressed size:    221
name: uci/test/features/71.csv | size:    471 | compressed size:    224
name: uci/test/features/72.csv | size:    471 | compressed size:    228
name: uci/test/features/73.csv | size:    465 | compressed size:    231
name: uci/test/features/74.csv | size:    471 | compressed size:    221
name: uci/test/features/75.csv | size:    469 | compressed size:    234
name: uci/test/features/76.csv | size:    473 | compressed size:    234
name: uci/test/features/77.csv | size:    472 | compressed size:    232
name: uci/test/features/78.csv | size:    472 | compressed size:    226
name: uci/test/features/79.csv | size:    470 | compressed size:    227
name: uci/test/features/8.csv | size:    470 | compressed size:    226
name: uci/test/features/80.csv | size:    471 | compressed size:    228
name: uci/test/features/81.csv | size:    476 | compressed size:    238
name: uci/test/features/82.csv | size:    475 | compressed size:    234
name: uci/test/features/83.csv | size:    470 | compressed size:    222
name: uci/test/features/84.csv | size:    474 | compressed size:    230
name: uci/test/features/85.csv | size:    477 | compressed size:    241
name: uci/test/features/86.csv | size:    476 | compressed size:    232
name: uci/test/features/87.csv | size:    467 | compressed size:    228
name: uci/test/features/88.csv | size:    473 | compressed size:    230
name: uci/test/features/89.csv | size:    465 | compressed size:    227
name: uci/test/features/9.csv | size:    474 | compressed size:    224
name: uci/test/features/90.csv | size:    472 | compressed size:    230
name: uci/test/features/91.csv | size:    472 | compressed size:    235
name: uci/test/features/92.csv | size:    474 | compressed size:    241
name: uci/test/features/93.csv | size:    474 | compressed size:    233
name: uci/test/features/94.csv | size:    473 | compressed size:    232
name: uci/test/features/95.csv | size:    474 | compressed size:    231
name: uci/test/features/96.csv | size:    472 | compressed size:    231
name: uci/test/features/97.csv | size:    475 | compressed size:    229
name: uci/test/features/98.csv | size:    468 | compressed size:    236
name: uci/test/features/99.csv | size:    471 | compressed size:    231
name: uci/test/labels/     | size:      0 | compressed size:      0
name: uci/test/labels/0.csv | size:      1 | compressed size:      1
name: uci/test/labels/1.csv | size:      1 | compressed size:      1
name: uci/test/labels/10.csv | size:      1 | compressed size:      1
name: uci/test/labels/100.csv | size:      1 | compressed size:      1
name: uci/test/labels/101.csv | size:      1 | compressed size:      1
name: uci/test/labels/102.csv | size:      1 | compressed size:      1
name: uci/test/labels/103.csv | size:      1 | compressed size:      1
name: uci/test/labels/104.csv | size:      1 | compressed size:      1
name: uci/test/labels/105.csv | size:      1 | compressed size:      1
name: uci/test/labels/106.csv | size:      1 | compressed size:      1
name: uci/test/labels/107.csv | size:      1 | compressed size:      1
name: uci/test/labels/108.csv | size:      1 | compressed size:      1
name: uci/test/labels/109.csv | size:      1 | compressed size:      1
name: uci/test/labels/11.csv | size:      1 | compressed size:      1
name: uci/test/labels/110.csv | size:      1 | compressed size:      1
name: uci/test/labels/111.csv | size:      1 | compressed size:      1
name: uci/test/labels/112.csv | size:      1 | compressed size:      1
name: uci/test/labels/113.csv | size:      1 | compressed size:      1
name: uci/test/labels/114.csv | size:      1 | compressed size:      1
name: uci/test/labels/115.csv | size:      1 | compressed size:      1
name: uci/test/labels/116.csv | size:      1 | compressed size:      1
name: uci/test/labels/117.csv | size:      1 | compressed size:      1
name: uci/test/labels/118.csv | size:      1 | compressed size:      1
name: uci/test/labels/119.csv | size:      1 | compressed size:      1
name: uci/test/labels/12.csv | size:      1 | compressed size:      1
name: uci/test/labels/120.csv | size:      1 | compressed size:      1
name: uci/test/labels/121.csv | size:      1 | compressed size:      1
name: uci/test/labels/122.csv | size:      1 | compressed size:      1
name: uci/test/labels/123.csv | size:      1 | compressed size:      1
name: uci/test/labels/124.csv | size:      1 | compressed size:      1
name: uci/test/labels/125.csv | size:      1 | compressed size:      1
name: uci/test/labels/126.csv | size:      1 | compressed size:      1
name: uci/test/labels/127.csv | size:      1 | compressed size:      1
name: uci/test/labels/128.csv | size:      1 | compressed size:      1
name: uci/test/labels/129.csv | size:      1 | compressed size:      1
name: uci/test/labels/13.csv | size:      1 | compressed size:      1
name: uci/test/labels/130.csv | size:      1 | compressed size:      1
name: uci/test/labels/131.csv | size:      1 | compressed size:      1
name: uci/test/labels/132.csv | size:      1 | compressed size:      1
name: uci/test/labels/133.csv | size:      1 | compressed size:      1
name: uci/test/labels/134.csv | size:      1 | compressed size:      1
name: uci/test/labels/135.csv | size:      1 | compressed size:      1
name: uci/test/labels/136.csv | size:      1 | compressed size:      1
name: uci/test/labels/137.csv | size:      1 | compressed size:      1
name: uci/test/labels/138.csv | size:      1 | compressed size:      1
name: uci/test/labels/139.csv | size:      1 | compressed size:      1
name: uci/test/labels/14.csv | size:      1 | compressed size:      1
name: uci/test/labels/140.csv | size:      1 | compressed size:      1
name: uci/test/labels/141.csv | size:      1 | compressed size:      1
name: uci/test/labels/142.csv | size:      1 | compressed size:      1
name: uci/test/labels/143.csv | size:      1 | compressed size:      1
name: uci/test/labels/144.csv | size:      1 | compressed size:      1
name: uci/test/labels/145.csv | size:      1 | compressed size:      1
name: uci/test/labels/146.csv | size:      1 | compressed size:      1
name: uci/test/labels/147.csv | size:      1 | compressed size:      1
name: uci/test/labels/148.csv | size:      1 | compressed size:      1
name: uci/test/labels/149.csv | size:      1 | compressed size:      1
name: uci/test/labels/15.csv | size:      1 | compressed size:      1
name: uci/test/labels/16.csv | size:      1 | compressed size:      1
name: uci/test/labels/17.csv | size:      1 | compressed size:      1
name: uci/test/labels/18.csv | size:      1 | compressed size:      1
name: uci/test/labels/19.csv | size:      1 | compressed size:      1
name: uci/test/labels/2.csv | size:      1 | compressed size:      1
name: uci/test/labels/20.csv | size:      1 | compressed size:      1
name: uci/test/labels/21.csv | size:      1 | compressed size:      1
name: uci/test/labels/22.csv | size:      1 | compressed size:      1
name: uci/test/labels/23.csv | size:      1 | compressed size:      1
name: uci/test/labels/24.csv | size:      1 | compressed size:      1
name: uci/test/labels/25.csv | size:      1 | compressed size:      1
name: uci/test/labels/26.csv | size:      1 | compressed size:      1
name: uci/test/labels/27.csv | size:      1 | compressed size:      1
name: uci/test/labels/28.csv | size:      1 | compressed size:      1
name: uci/test/labels/29.csv | size:      1 | compressed size:      1
name: uci/test/labels/3.csv | size:      1 | compressed size:      1
name: uci/test/labels/30.csv | size:      1 | compressed size:      1
name: uci/test/labels/31.csv | size:      1 | compressed size:      1
name: uci/test/labels/32.csv | size:      1 | compressed size:      1
name: uci/test/labels/33.csv | size:      1 | compressed size:      1
name: uci/test/labels/34.csv | size:      1 | compressed size:      1
name: uci/test/labels/35.csv | size:      1 | compressed size:      1
name: uci/test/labels/36.csv | size:      1 | compressed size:      1
name: uci/test/labels/37.csv | size:      1 | compressed size:      1
name: uci/test/labels/38.csv | size:      1 | compressed size:      1
name: uci/test/labels/39.csv | size:      1 | compressed size:      1
name: uci/test/labels/4.csv | size:      1 | compressed size:      1
name: uci/test/labels/40.csv | size:      1 | compressed size:      1
name: uci/test/labels/41.csv | size:      1 | compressed size:      1
name: uci/test/labels/42.csv | size:      1 | compressed size:      1
name: uci/test/labels/43.csv | size:      1 | compressed size:      1
name: uci/test/labels/44.csv | size:      1 | compressed size:      1
name: uci/test/labels/45.csv | size:      1 | compressed size:      1
name: uci/test/labels/46.csv | size:      1 | compressed size:      1
name: uci/test/labels/47.csv | size:      1 | compressed size:      1
name: uci/test/labels/48.csv | size:      1 | compressed size:      1
name: uci/test/labels/49.csv | size:      1 | compressed size:      1
name: uci/test/labels/5.csv | size:      1 | compressed size:      1
name: uci/test/labels/50.csv | size:      1 | compressed size:      1
name: uci/test/labels/51.csv | size:      1 | compressed size:      1
name: uci/test/labels/52.csv | size:      1 | compressed size:      1
name: uci/test/labels/53.csv | size:      1 | compressed size:      1
name: uci/test/labels/54.csv | size:      1 | compressed size:      1
name: uci/test/labels/55.csv | size:      1 | compressed size:      1
name: uci/test/labels/56.csv | size:      1 | compressed size:      1
name: uci/test/labels/57.csv | size:      1 | compressed size:      1
name: uci/test/labels/58.csv | size:      1 | compressed size:      1
name: uci/test/labels/59.csv | size:      1 | compressed size:      1
name: uci/test/labels/6.csv | size:      1 | compressed size:      1
name: uci/test/labels/60.csv | size:      1 | compressed size:      1
name: uci/test/labels/61.csv | size:      1 | compressed size:      1
name: uci/test/labels/62.csv | size:      1 | compressed size:      1
name: uci/test/labels/63.csv | size:      1 | compressed size:      1
name: uci/test/labels/64.csv | size:      1 | compressed size:      1
name: uci/test/labels/65.csv | size:      1 | compressed size:      1
name: uci/test/labels/66.csv | size:      1 | compressed size:      1
name: uci/test/labels/67.csv | size:      1 | compressed size:      1
name: uci/test/labels/68.csv | size:      1 | compressed size:      1
name: uci/test/labels/69.csv | size:      1 | compressed size:      1
name: uci/test/labels/7.csv | size:      1 | compressed size:      1
name: uci/test/labels/70.csv | size:      1 | compressed size:      1
name: uci/test/labels/71.csv | size:      1 | compressed size:      1
name: uci/test/labels/72.csv | size:      1 | compressed size:      1
name: uci/test/labels/73.csv | size:      1 | compressed size:      1
name: uci/test/labels/74.csv | size:      1 | compressed size:      1
name: uci/test/labels/75.csv | size:      1 | compressed size:      1
name: uci/test/labels/76.csv | size:      1 | compressed size:      1
name: uci/test/labels/77.csv | size:      1 | compressed size:      1
name: uci/test/labels/78.csv | size:      1 | compressed size:      1
name: uci/test/labels/79.csv | size:      1 | compressed size:      1
name: uci/test/labels/8.csv | size:      1 | compressed size:      1
name: uci/test/labels/80.csv | size:      1 | compressed size:      1
name: uci/test/labels/81.csv | size:      1 | compressed size:      1
name: uci/test/labels/82.csv | size:      1 | compressed size:      1
name: uci/test/labels/83.csv | size:      1 | compressed size:      1
name: uci/test/labels/84.csv | size:      1 | compressed size:      1
name: uci/test/labels/85.csv | size:      1 | compressed size:      1
name: uci/test/labels/86.csv | size:      1 | compressed size:      1
name: uci/test/labels/87.csv | size:      1 | compressed size:      1
name: uci/test/labels/88.csv | size:      1 | compressed size:      1
name: uci/test/labels/89.csv | size:      1 | compressed size:      1
name: uci/test/labels/9.csv | size:      1 | compressed size:      1
name: uci/test/labels/90.csv | size:      1 | compressed size:      1
name: uci/test/labels/91.csv | size:      1 | compressed size:      1
name: uci/test/labels/92.csv | size:      1 | compressed size:      1
name: uci/test/labels/93.csv | size:      1 | compressed size:      1
name: uci/test/labels/94.csv | size:      1 | compressed size:      1
name: uci/test/labels/95.csv | size:      1 | compressed size:      1
name: uci/test/labels/96.csv | size:      1 | compressed size:      1
name: uci/test/labels/97.csv | size:      1 | compressed size:      1
name: uci/test/labels/98.csv | size:      1 | compressed size:      1
name: uci/test/labels/99.csv | size:      1 | compressed size:      1
name: uci/train/           | size:      0 | compressed size:      0
name: uci/train/features/  | size:      0 | compressed size:      0
name: uci/train/features/0.csv | size:    473 | compressed size:    227
name: uci/train/features/1.csv | size:    468 | compressed size:    224
name: uci/train/features/10.csv | size:    472 | compressed size:    226
name: uci/train/features/100.csv | size:    468 | compressed size:    228
name: uci/train/features/101.csv | size:    474 | compressed size:    227
name: uci/train/features/102.csv | size:    471 | compressed size:    231
name: uci/train/features/103.csv | size:    474 | compressed size:    229
name: uci/train/features/104.csv | size:    470 | compressed size:    229
name: uci/train/features/105.csv | size:    473 | compressed size:    234
name: uci/train/features/106.csv | size:    476 | compressed size:    226
name: uci/train/features/107.csv | size:    474 | compressed size:    242
name: uci/train/features/108.csv | size:    477 | compressed size:    236
name: uci/train/features/109.csv | size:    471 | compressed size:    236
name: uci/train/features/11.csv | size:    466 | compressed size:    220
name: uci/train/features/110.csv | size:    477 | compressed size:    233
name: uci/train/features/111.csv | size:    472 | compressed size:    227
name: uci/train/features/112.csv | size:    473 | compressed size:    228
name: uci/train/features/113.csv | size:    466 | compressed size:    217
name: uci/train/features/114.csv | size:    474 | compressed size:    230
name: uci/train/features/115.csv | size:    469 | compressed size:    226
name: uci/train/features/116.csv | size:    474 | compressed size:    234
name: uci/train/features/117.csv | size:    468 | compressed size:    229
name: uci/train/features/118.csv | size:    474 | compressed size:    225
name: uci/train/features/119.csv | size:    469 | compressed size:    226
name: uci/train/features/12.csv | size:    472 | compressed size:    230
name: uci/train/features/120.csv | size:    474 | compressed size:    235
name: uci/train/features/121.csv | size:    472 | compressed size:    228
name: uci/train/features/122.csv | size:    470 | compressed size:    219
name: uci/train/features/123.csv | size:    469 | compressed size:    226
name: uci/train/features/124.csv | size:    476 | compressed size:    227
name: uci/train/features/125.csv | size:    476 | compressed size:    233
name: uci/train/features/126.csv | size:    472 | compressed size:    233
name: uci/train/features/127.csv | size:    474 | compressed size:    229
name: uci/train/features/128.csv | size:    471 | compressed size:    226
name: uci/train/features/129.csv | size:    477 | compressed size:    222
name: uci/train/features/13.csv | size:    473 | compressed size:    222
name: uci/train/features/130.csv | size:    470 | compressed size:    225
name: uci/train/features/131.csv | size:    470 | compressed size:    227
name: uci/train/features/132.csv | size:    472 | compressed size:    229
name: uci/train/features/133.csv | size:    477 | compressed size:    229
name: uci/train/features/134.csv | size:    474 | compressed size:    237
name: uci/train/features/135.csv | size:    474 | compressed size:    229
name: uci/train/features/136.csv | size:    476 | compressed size:    226
name: uci/train/features/137.csv | size:    474 | compressed size:    232
name: uci/train/features/138.csv | size:    472 | compressed size:    222
name: uci/train/features/139.csv | size:    475 | compressed size:    230
name: uci/train/features/14.csv | size:    468 | compressed size:    231
name: uci/train/features/140.csv | size:    469 | compressed size:    232
name: uci/train/features/141.csv | size:    476 | compressed size:    233
name: uci/train/features/142.csv | size:    469 | compressed size:    232
name: uci/train/features/143.csv | size:    477 | compressed size:    234
name: uci/train/features/144.csv | size:    474 | compressed size:    233
name: uci/train/features/145.csv | size:    475 | compressed size:    239
name: uci/train/features/146.csv | size:    470 | compressed size:    230
name: uci/train/features/147.csv | size:    475 | compressed size:    235
name: uci/train/features/148.csv | size:    473 | compressed size:    233
name: uci/train/features/149.csv | size:    475 | compressed size:    233
name: uci/train/features/15.csv | size:    469 | compressed size:    225
name: uci/train/features/150.csv | size:    474 | compressed size:    229
name: uci/train/features/151.csv | size:    473 | compressed size:    229
name: uci/train/features/152.csv | size:    468 | compressed size:    238
name: uci/train/features/153.csv | size:    467 | compressed size:    236
name: uci/train/features/154.csv | size:    472 | compressed size:    227
name: uci/train/features/155.csv | size:    473 | compressed size:    227
name: uci/train/features/156.csv | size:    477 | compressed size:    243
name: uci/train/features/157.csv | size:    473 | compressed size:    224
name: uci/train/features/158.csv | size:    477 | compressed size:    240
name: uci/train/features/159.csv | size:    475 | compressed size:    235
name: uci/train/features/16.csv | size:    481 | compressed size:    242
name: uci/train/features/160.csv | size:    473 | compressed size:    241
name: uci/train/features/161.csv | size:    472 | compressed size:    228
name: uci/train/features/162.csv | size:    474 | compressed size:    224
name: uci/train/features/163.csv | size:    474 | compressed size:    228
name: uci/train/features/164.csv | size:    477 | compressed size:    236
name: uci/train/features/165.csv | size:    473 | compressed size:    230
name: uci/train/features/166.csv | size:    471 | compressed size:    231
name: uci/train/features/167.csv | size:    470 | compressed size:    226
name: uci/train/features/168.csv | size:    474 | compressed size:    232
name: uci/train/features/169.csv | size:    472 | compressed size:    235
name: uci/train/features/17.csv | size:    480 | compressed size:    241
name: uci/train/features/170.csv | size:    473 | compressed size:    228
name: uci/train/features/171.csv | size:    465 | compressed size:    222
name: uci/train/features/172.csv | size:    471 | compressed size:    225
name: uci/train/features/173.csv | size:    469 | compressed size:    228
name: uci/train/features/174.csv | size:    473 | compressed size:    224
name: uci/train/features/175.csv | size:    472 | compressed size:    225
name: uci/train/features/176.csv | size:    473 | compressed size:    234
name: uci/train/features/177.csv | size:    470 | compressed size:    229
name: uci/train/features/178.csv | size:    471 | compressed size:    222
name: uci/train/features/179.csv | size:    469 | compressed size:    226
name: uci/train/features/18.csv | size:    473 | compressed size:    223
name: uci/train/features/180.csv | size:    470 | compressed size:    226
name: uci/train/features/181.csv | size:    474 | compressed size:    233
name: uci/train/features/182.csv | size:    473 | compressed size:    230
name: uci/train/features/183.csv | size:    470 | compressed size:    233
name: uci/train/features/184.csv | size:    471 | compressed size:    227
name: uci/train/features/185.csv | size:    475 | compressed size:    231
name: uci/train/features/186.csv | size:    472 | compressed size:    237
name: uci/train/features/187.csv | size:    470 | compressed size:    231
name: uci/train/features/188.csv | size:    473 | compressed size:    221
name: uci/train/features/189.csv | size:    471 | compressed size:    230
name: uci/train/features/19.csv | size:    476 | compressed size:    243
name: uci/train/features/190.csv | size:    468 | compressed size:    222
name: uci/train/features/191.csv | size:    473 | compressed size:    222
name: uci/train/features/192.csv | size:    476 | compressed size:    232
name: uci/train/features/193.csv | size:    471 | compressed size:    229
name: uci/train/features/194.csv | size:    475 | compressed size:    237
name: uci/train/features/195.csv | size:    471 | compressed size:    230
name: uci/train/features/196.csv | size:    471 | compressed size:    237
name: uci/train/features/197.csv | size:    469 | compressed size:    222
name: uci/train/features/198.csv | size:    471 | compressed size:    233
name: uci/train/features/199.csv | size:    470 | compressed size:    227
name: uci/train/features/2.csv | size:    471 | compressed size:    241
name: uci/train/features/20.csv | size:    476 | compressed size:    227
name: uci/train/features/200.csv | size:    472 | compressed size:    229
name: uci/train/features/201.csv | size:    474 | compressed size:    223
name: uci/train/features/202.csv | size:    478 | compressed size:    233
name: uci/train/features/203.csv | size:    472 | compressed size:    227
name: uci/train/features/204.csv | size:    473 | compressed size:    235
name: uci/train/features/205.csv | size:    472 | compressed size:    238
name: uci/train/features/206.csv | size:    470 | compressed size:    218
name: uci/train/features/207.csv | size:    472 | compressed size:    222
name: uci/train/features/208.csv | size:    467 | compressed size:    232
name: uci/train/features/209.csv | size:    471 | compressed size:    226
name: uci/train/features/21.csv | size:    470 | compressed size:    233
name: uci/train/features/210.csv | size:    472 | compressed size:    237
name: uci/train/features/211.csv | size:    474 | compressed size:    233
name: uci/train/features/212.csv | size:    472 | compressed size:    230
name: uci/train/features/213.csv | size:    473 | compressed size:    230
name: uci/train/features/214.csv | size:    474 | compressed size:    233
name: uci/train/features/215.csv | size:    471 | compressed size:    237
name: uci/train/features/216.csv | size:    471 | compressed size:    230
name: uci/train/features/217.csv | size:    471 | compressed size:    230
name: uci/train/features/218.csv | size:    470 | compressed size:    230
name: uci/train/features/219.csv | size:    476 | compressed size:    224
name: uci/train/features/22.csv | size:    473 | compressed size:    233
name: uci/train/features/220.csv | size:    472 | compressed size:    226
name: uci/train/features/221.csv | size:    474 | compressed size:    234
name: uci/train/features/222.csv | size:    472 | compressed size:    217
name: uci/train/features/223.csv | size:    473 | compressed size:    225
name: uci/train/features/224.csv | size:    474 | compressed size:    242
name: uci/train/features/225.csv | size:    474 | compressed size:    229
name: uci/train/features/226.csv | size:    472 | compressed size:    226
name: uci/train/features/227.csv | size:    473 | compressed size:    236
name: uci/train/features/228.csv | size:    471 | compressed size:    238
name: uci/train/features/229.csv | size:    482 | compressed size:    241
name: uci/train/features/23.csv | size:    474 | compressed size:    224
name: uci/train/features/230.csv | size:    476 | compressed size:    234
name: uci/train/features/231.csv | size:    476 | compressed size:    232
name: uci/train/features/232.csv | size:    473 | compressed size:    218
name: uci/train/features/233.csv | size:    474 | compressed size:    221
name: uci/train/features/234.csv | size:    473 | compressed size:    240
name: uci/train/features/235.csv | size:    478 | compressed size:    225
name: uci/train/features/236.csv | size:    477 | compressed size:    235
name: uci/train/features/237.csv | size:    471 | compressed size:    230
name: uci/train/features/238.csv | size:    466 | compressed size:    229
name: uci/train/features/239.csv | size:    474 | compressed size:    234
name: uci/train/features/24.csv | size:    477 | compressed size:    241
name: uci/train/features/240.csv | size:    473 | compressed size:    226
name: uci/train/features/241.csv | size:    471 | compressed size:    224
name: uci/train/features/242.csv | size:    473 | compressed size:    224
name: uci/train/features/243.csv | size:    471 | compressed size:    225
name: uci/train/features/244.csv | size:    475 | compressed size:    226
name: uci/train/features/245.csv | size:    471 | compressed size:    226
name: uci/train/features/246.csv | size:    475 | compressed size:    233
name: uci/train/features/247.csv | size:    472 | compressed size:    238
name: uci/train/features/248.csv | size:    470 | compressed size:    219
name: uci/train/features/249.csv | size:    474 | compressed size:    235
name: uci/train/features/25.csv | size:    471 | compressed size:    233
name: uci/train/features/250.csv | size:    473 | compressed size:    231
name: uci/train/features/251.csv | size:    472 | compressed size:    229
name: uci/train/features/252.csv | size:    470 | compressed size:    228
name: uci/train/features/253.csv | size:    476 | compressed size:    237
name: uci/train/features/254.csv | size:    472 | compressed size:    229
name: uci/train/features/255.csv | size:    473 | compressed size:    235
name: uci/train/features/256.csv | size:    477 | compressed size:    241
name: uci/train/features/257.csv | size:    467 | compressed size:    224
name: uci/train/features/258.csv | size:    466 | compressed size:    224
name: uci/train/features/259.csv | size:    474 | compressed size:    226
name: uci/train/features/26.csv | size:    473 | compressed size:    239
name: uci/train/features/260.csv | size:    477 | compressed size:    231
name: uci/train/features/261.csv | size:    480 | compressed size:    240
name: uci/train/features/262.csv | size:    475 | compressed size:    235
name: uci/train/features/263.csv | size:    475 | compressed size:    235
name: uci/train/features/264.csv | size:    471 | compressed size:    236
name: uci/train/features/265.csv | size:    467 | compressed size:    225
name: uci/train/features/266.csv | size:    472 | compressed size:    231
name: uci/train/features/267.csv | size:    470 | compressed size:    227
name: uci/train/features/268.csv | size:    463 | compressed size:    220
name: uci/train/features/269.csv | size:    473 | compressed size:    223
name: uci/train/features/27.csv | size:    470 | compressed size:    225
name: uci/train/features/270.csv | size:    475 | compressed size:    224
name: uci/train/features/271.csv | size:    477 | compressed size:    243
name: uci/train/features/272.csv | size:    473 | compressed size:    229
name: uci/train/features/273.csv | size:    475 | compressed size:    239
name: uci/train/features/274.csv | size:    471 | compressed size:    229
name: uci/train/features/275.csv | size:    478 | compressed size:    237
name: uci/train/features/276.csv | size:    469 | compressed size:    229
name: uci/train/features/277.csv | size:    470 | compressed size:    227
name: uci/train/features/278.csv | size:    474 | compressed size:    231
name: uci/train/features/279.csv | size:    476 | compressed size:    232
name: uci/train/features/28.csv | size:    476 | compressed size:    229
name: uci/train/features/280.csv | size:    473 | compressed size:    230
name: uci/train/features/281.csv | size:    476 | compressed size:    230
name: uci/train/features/282.csv | size:    472 | compressed size:    218
name: uci/train/features/283.csv | size:    467 | compressed size:    226
name: uci/train/features/284.csv | size:    471 | compressed size:    230
name: uci/train/features/285.csv | size:    469 | compressed size:    227
name: uci/train/features/286.csv | size:    471 | compressed size:    225
name: uci/train/features/287.csv | size:    471 | compressed size:    227
name: uci/train/features/288.csv | size:    477 | compressed size:    226
name: uci/train/features/289.csv | size:    477 | compressed size:    232
name: uci/train/features/29.csv | size:    475 | compressed size:    227
name: uci/train/features/290.csv | size:    469 | compressed size:    223
name: uci/train/features/291.csv | size:    473 | compressed size:    235
name: uci/train/features/292.csv | size:    473 | compressed size:    231
name: uci/train/features/293.csv | size:    469 | compressed size:    231
name: uci/train/features/294.csv | size:    470 | compressed size:    232
name: uci/train/features/295.csv | size:    471 | compressed size:    227
name: uci/train/features/296.csv | size:    473 | compressed size:    234
name: uci/train/features/297.csv | size:    472 | compressed size:    234
name: uci/train/features/298.csv | size:    475 | compressed size:    239
name: uci/train/features/299.csv | size:    473 | compressed size:    228
name: uci/train/features/3.csv | size:    467 | compressed size:    224
name: uci/train/features/30.csv | size:    475 | compressed size:    234
name: uci/train/features/300.csv | size:    472 | compressed size:    237
name: uci/train/features/301.csv | size:    472 | compressed size:    237
name: uci/train/features/302.csv | size:    472 | compressed size:    228
name: uci/train/features/303.csv | size:    470 | compressed size:    237
name: uci/train/features/304.csv | size:    476 | compressed size:    230
name: uci/train/features/305.csv | size:    476 | compressed size:    227
name: uci/train/features/306.csv | size:    476 | compressed size:    233
name: uci/train/features/307.csv | size:    473 | compressed size:    233
name: uci/train/features/308.csv | size:    470 | compressed size:    217
name: uci/train/features/309.csv | size:    468 | compressed size:    228
name: uci/train/features/31.csv | size:    468 | compressed size:    228
name: uci/train/features/310.csv | size:    477 | compressed size:    236
name: uci/train/features/311.csv | size:    469 | compressed size:    228
name: uci/train/features/312.csv | size:    470 | compressed size:    239
name: uci/train/features/313.csv | size:    471 | compressed size:    230
name: uci/train/features/314.csv | size:    472 | compressed size:    228
name: uci/train/features/315.csv | size:    470 | compressed size:    235
name: uci/train/features/316.csv | size:    477 | compressed size:    233
name: uci/train/features/317.csv | size:    473 | compressed size:    231
name: uci/train/features/318.csv | size:    477 | compressed size:    232
name: uci/train/features/319.csv | size:    474 | compressed size:    224
name: uci/train/features/32.csv | size:    474 | compressed size:    238
name: uci/train/features/320.csv | size:    472 | compressed size:    231
name: uci/train/features/321.csv | size:    466 | compressed size:    230
name: uci/train/features/322.csv | size:    475 | compressed size:    240
name: uci/train/features/323.csv | size:    473 | compressed size:    232
name: uci/train/features/324.csv | size:    471 | compressed size:    225
name: uci/train/features/325.csv | size:    472 | compressed size:    228
name: uci/train/features/326.csv | size:    472 | compressed size:    242
name: uci/train/features/327.csv | size:    472 | compressed size:    231
name: uci/train/features/328.csv | size:    474 | compressed size:    229
name: uci/train/features/329.csv | size:    473 | compressed size:    237
name: uci/train/features/33.csv | size:    473 | compressed size:    230
name: uci/train/features/330.csv | size:    476 | compressed size:    230
name: uci/train/features/331.csv | size:    472 | compressed size:    238
name: uci/train/features/332.csv | size:    471 | compressed size:    235
name: uci/train/features/333.csv | size:    475 | compressed size:    226
name: uci/train/features/334.csv | size:    476 | compressed size:    226
name: uci/train/features/335.csv | size:    467 | compressed size:    235
name: uci/train/features/336.csv | size:    473 | compressed size:    235
name: uci/train/features/337.csv | size:    472 | compressed size:    225
name: uci/train/features/338.csv | size:    476 | compressed size:    236
name: uci/train/features/339.csv | size:    476 | compressed size:    235
name: uci/train/features/34.csv | size:    472 | compressed size:    237
name: uci/train/features/340.csv | size:    472 | compressed size:    224
name: uci/train/features/341.csv | size:    475 | compressed size:    228
name: uci/train/features/342.csv | size:    477 | compressed size:    231
name: uci/train/features/343.csv | size:    472 | compressed size:    236
name: uci/train/features/344.csv | size:    468 | compressed size:    224
name: uci/train/features/345.csv | size:    466 | compressed size:    236
name: uci/train/features/346.csv | size:    471 | compressed size:    236
name: uci/train/features/347.csv | size:    471 | compressed size:    229
name: uci/train/features/348.csv | size:    472 | compressed size:    227
name: uci/train/features/349.csv | size:    471 | compressed size:    231
name: uci/train/features/35.csv | size:    469 | compressed size:    220
name: uci/train/features/350.csv | size:    475 | compressed size:    225
name: uci/train/features/351.csv | size:    469 | compressed size:    224
name: uci/train/features/352.csv | size:    473 | compressed size:    239
name: uci/train/features/353.csv | size:    475 | compressed size:    225
name: uci/train/features/354.csv | size:    473 | compressed size:    222
name: uci/train/features/355.csv | size:    467 | compressed size:    223
name: uci/train/features/356.csv | size:    472 | compressed size:    232
name: uci/train/features/357.csv | size:    474 | compressed size:    224
name: uci/train/features/358.csv | size:    475 | compressed size:    233
name: uci/train/features/359.csv | size:    472 | compressed size:    238
name: uci/train/features/36.csv | size:    476 | compressed size:    230
name: uci/train/features/360.csv | size:    469 | compressed size:    231
name: uci/train/features/361.csv | size:    468 | compressed size:    224
name: uci/train/features/362.csv | size:    470 | compressed size:    224
name: uci/train/features/363.csv | size:    477 | compressed size:    237
name: uci/train/features/364.csv | size:    472 | compressed size:    225
name: uci/train/features/365.csv | size:    467 | compressed size:    226
name: uci/train/features/366.csv | size:    472 | compressed size:    234
name: uci/train/features/367.csv | size:    473 | compressed size:    242
name: uci/train/features/368.csv | size:    469 | compressed size:    225
name: uci/train/features/369.csv | size:    471 | compressed size:    224
name: uci/train/features/37.csv | size:    474 | compressed size:    220
name: uci/train/features/370.csv | size:    473 | compressed size:    231
name: uci/train/features/371.csv | size:    469 | compressed size:    220
name: uci/train/features/372.csv | size:    469 | compressed size:    229
name: uci/train/features/373.csv | size:    476 | compressed size:    240
name: uci/train/features/374.csv | size:    472 | compressed size:    227
name: uci/train/features/375.csv | size:    470 | compressed size:    232
name: uci/train/features/376.csv | size:    471 | compressed size:    235
name: uci/train/features/377.csv | size:    476 | compressed size:    227
name: uci/train/features/378.csv | size:    472 | compressed size:    228
name: uci/train/features/379.csv | size:    467 | compressed size:    233
name: uci/train/features/38.csv | size:    473 | compressed size:    222
name: uci/train/features/380.csv | size:    473 | compressed size:    237
name: uci/train/features/381.csv | size:    471 | compressed size:    229
name: uci/train/features/382.csv | size:    470 | compressed size:    231
name: uci/train/features/383.csv | size:    471 | compressed size:    231
name: uci/train/features/384.csv | size:    473 | compressed size:    232
name: uci/train/features/385.csv | size:    470 | compressed size:    226
name: uci/train/features/386.csv | size:    473 | compressed size:    234
name: uci/train/features/387.csv | size:    471 | compressed size:    232
name: uci/train/features/388.csv | size:    476 | compressed size:    230
name: uci/train/features/389.csv | size:    474 | compressed size:    227
name: uci/train/features/39.csv | size:    473 | compressed size:    230
name: uci/train/features/390.csv | size:    474 | compressed size:    232
name: uci/train/features/391.csv | size:    472 | compressed size:    233
name: uci/train/features/392.csv | size:    473 | compressed size:    230
name: uci/train/features/393.csv | size:    472 | compressed size:    228
name: uci/train/features/394.csv | size:    477 | compressed size:    238
name: uci/train/features/395.csv | size:    470 | compressed size:    236
name: uci/train/features/396.csv | size:    468 | compressed size:    224
name: uci/train/features/397.csv | size:    475 | compressed size:    227
name: uci/train/features/398.csv | size:    474 | compressed size:    233
name: uci/train/features/399.csv | size:    472 | compressed size:    231
name: uci/train/features/4.csv | size:    466 | compressed size:    226
name: uci/train/features/40.csv | size:    473 | compressed size:    231
name: uci/train/features/400.csv | size:    476 | compressed size:    225
name: uci/train/features/401.csv | size:    474 | compressed size:    229
name: uci/train/features/402.csv | size:    476 | compressed size:    222
name: uci/train/features/403.csv | size:    475 | compressed size:    239
name: uci/train/features/404.csv | size:    469 | compressed size:    229
name: uci/train/features/405.csv | size:    465 | compressed size:    227
name: uci/train/features/406.csv | size:    473 | compressed size:    232
name: uci/train/features/407.csv | size:    472 | compressed size:    223
name: uci/train/features/408.csv | size:    470 | compressed size:    229
name: uci/train/features/409.csv | size:    475 | compressed size:    234
name: uci/train/features/41.csv | size:    471 | compressed size:    239
name: uci/train/features/410.csv | size:    473 | compressed size:    232
name: uci/train/features/411.csv | size:    472 | compressed size:    235
name: uci/train/features/412.csv | size:    476 | compressed size:    231
name: uci/train/features/413.csv | size:    470 | compressed size:    224
name: uci/train/features/414.csv | size:    471 | compressed size:    225
name: uci/train/features/415.csv | size:    470 | compressed size:    236
name: uci/train/features/416.csv | size:    472 | compressed size:    231
name: uci/train/features/417.csv | size:    480 | compressed size:    241
name: uci/train/features/418.csv | size:    471 | compressed size:    231
name: uci/train/features/419.csv | size:    475 | compressed size:    227
name: uci/train/features/42.csv | size:    475 | compressed size:    238
name: uci/train/features/420.csv | size:    472 | compressed size:    230
name: uci/train/features/421.csv | size:    471 | compressed size:    229
name: uci/train/features/422.csv | size:    472 | compressed size:    225
name: uci/train/features/423.csv | size:    474 | compressed size:    231
name: uci/train/features/424.csv | size:    473 | compressed size:    237
name: uci/train/features/425.csv | size:    470 | compressed size:    222
name: uci/train/features/426.csv | size:    482 | compressed size:    237
name: uci/train/features/427.csv | size:    474 | compressed size:    237
name: uci/train/features/428.csv | size:    469 | compressed size:    224
name: uci/train/features/429.csv | size:    470 | compressed size:    231
name: uci/train/features/43.csv | size:    471 | compressed size:    226
name: uci/train/features/430.csv | size:    471 | compressed size:    227
name: uci/train/features/431.csv | size:    470 | compressed size:    229
name: uci/train/features/432.csv | size:    474 | compressed size:    241
name: uci/train/features/433.csv | size:    476 | compressed size:    231
name: uci/train/features/434.csv | size:    475 | compressed size:    228
name: uci/train/features/435.csv | size:    474 | compressed size:    230
name: uci/train/features/436.csv | size:    473 | compressed size:    218
name: uci/train/features/437.csv | size:    467 | compressed size:    241
name: uci/train/features/438.csv | size:    474 | compressed size:    238
name: uci/train/features/439.csv | size:    475 | compressed size:    226
name: uci/train/features/44.csv | size:    477 | compressed size:    231
name: uci/train/features/440.csv | size:    472 | compressed size:    236
name: uci/train/features/441.csv | size:    468 | compressed size:    232
name: uci/train/features/442.csv | size:    477 | compressed size:    235
name: uci/train/features/443.csv | size:    470 | compressed size:    227
name: uci/train/features/444.csv | size:    470 | compressed size:    221
name: uci/train/features/445.csv | size:    473 | compressed size:    222
name: uci/train/features/446.csv | size:    471 | compressed size:    234
name: uci/train/features/447.csv | size:    472 | compressed size:    234
name: uci/train/features/448.csv | size:    472 | compressed size:    221
name: uci/train/features/449.csv | size:    476 | compressed size:    228
name: uci/train/features/45.csv | size:    477 | compressed size:    231
name: uci/train/features/46.csv | size:    470 | compressed size:    234
name: uci/train/features/47.csv | size:    468 | compressed size:    215
name: uci/train/features/48.csv | size:    474 | compressed size:    240
name: uci/train/features/49.csv | size:    476 | compressed size:    231
name: uci/train/features/5.csv | size:    475 | compressed size:    219
name: uci/train/features/50.csv | size:    469 | compressed size:    228
name: uci/train/features/51.csv | size:    471 | compressed size:    220
name: uci/train/features/52.csv | size:    471 | compressed size:    228
name: uci/train/features/53.csv | size:    476 | compressed size:    226
name: uci/train/features/54.csv | size:    475 | compressed size:    230
name: uci/train/features/55.csv | size:    477 | compressed size:    231
name: uci/train/features/56.csv | size:    474 | compressed size:    239
name: uci/train/features/57.csv | size:    464 | compressed size:    223
name: uci/train/features/58.csv | size:    474 | compressed size:    226
name: uci/train/features/59.csv | size:    471 | compressed size:    222
name: uci/train/features/6.csv | size:    474 | compressed size:    222
name: uci/train/features/60.csv | size:    474 | compressed size:    231
name: uci/train/features/61.csv | size:    475 | compressed size:    222
name: uci/train/features/62.csv | size:    471 | compressed size:    231
name: uci/train/features/63.csv | size:    472 | compressed size:    232
name: uci/train/features/64.csv | size:    475 | compressed size:    231
name: uci/train/features/65.csv | size:    474 | compressed size:    230
name: uci/train/features/66.csv | size:    470 | compressed size:    239
name: uci/train/features/67.csv | size:    473 | compressed size:    229
name: uci/train/features/68.csv | size:    476 | compressed size:    234
name: uci/train/features/69.csv | size:    473 | compressed size:    228
name: uci/train/features/7.csv | size:    470 | compressed size:    224
name: uci/train/features/70.csv | size:    473 | compressed size:    238
name: uci/train/features/71.csv | size:    478 | compressed size:    230
name: uci/train/features/72.csv | size:    475 | compressed size:    241
name: uci/train/features/73.csv | size:    472 | compressed size:    231
name: uci/train/features/74.csv | size:    471 | compressed size:    237
name: uci/train/features/75.csv | size:    475 | compressed size:    221
name: uci/train/features/76.csv | size:    469 | compressed size:    226
name: uci/train/features/77.csv | size:    475 | compressed size:    239
name: uci/train/features/78.csv | size:    464 | compressed size:    230
name: uci/train/features/79.csv | size:    476 | compressed size:    234
name: uci/train/features/8.csv | size:    471 | compressed size:    235
name: uci/train/features/80.csv | size:    473 | compressed size:    223
name: uci/train/features/81.csv | size:    473 | compressed size:    229
name: uci/train/features/82.csv | size:    472 | compressed size:    222
name: uci/train/features/83.csv | size:    474 | compressed size:    235
name: uci/train/features/84.csv | size:    472 | compressed size:    220
name: uci/train/features/85.csv | size:    474 | compressed size:    233
name: uci/train/features/86.csv | size:    475 | compressed size:    229
name: uci/train/features/87.csv | size:    475 | compressed size:    233
name: uci/train/features/88.csv | size:    475 | compressed size:    228
name: uci/train/features/89.csv | size:    472 | compressed size:    219
name: uci/train/features/9.csv | size:    474 | compressed size:    230
name: uci/train/features/90.csv | size:    469 | compressed size:    236
name: uci/train/features/91.csv | size:    473 | compressed size:    221
name: uci/train/features/92.csv | size:    475 | compressed size:    231
name: uci/train/features/93.csv | size:    472 | compressed size:    232
name: uci/train/features/94.csv | size:    476 | compressed size:    237
name: uci/train/features/95.csv | size:    475 | compressed size:    226
name: uci/train/features/96.csv | size:    477 | compressed size:    238
name: uci/train/features/97.csv | size:    474 | compressed size:    230
name: uci/train/features/98.csv | size:    464 | compressed size:    221
name: uci/train/features/99.csv | size:    475 | compressed size:    233
name: uci/train/labels/    | size:      0 | compressed size:      0
name: uci/train/labels/0.csv | size:      1 | compressed size:      1
name: uci/train/labels/1.csv | size:      1 | compressed size:      1
name: uci/train/labels/10.csv | size:      1 | compressed size:      1
name: uci/train/labels/100.csv | size:      1 | compressed size:      1
name: uci/train/labels/101.csv | size:      1 | compressed size:      1
name: uci/train/labels/102.csv | size:      1 | compressed size:      1
name: uci/train/labels/103.csv | size:      1 | compressed size:      1
name: uci/train/labels/104.csv | size:      1 | compressed size:      1
name: uci/train/labels/105.csv | size:      1 | compressed size:      1
name: uci/train/labels/106.csv | size:      1 | compressed size:      1
name: uci/train/labels/107.csv | size:      1 | compressed size:      1
name: uci/train/labels/108.csv | size:      1 | compressed size:      1
name: uci/train/labels/109.csv | size:      1 | compressed size:      1
name: uci/train/labels/11.csv | size:      1 | compressed size:      1
name: uci/train/labels/110.csv | size:      1 | compressed size:      1
name: uci/train/labels/111.csv | size:      1 | compressed size:      1
name: uci/train/labels/112.csv | size:      1 | compressed size:      1
name: uci/train/labels/113.csv | size:      1 | compressed size:      1
name: uci/train/labels/114.csv | size:      1 | compressed size:      1
name: uci/train/labels/115.csv | size:      1 | compressed size:      1
name: uci/train/labels/116.csv | size:      1 | compressed size:      1
name: uci/train/labels/117.csv | size:      1 | compressed size:      1
name: uci/train/labels/118.csv | size:      1 | compressed size:      1
name: uci/train/labels/119.csv | size:      1 | compressed size:      1
name: uci/train/labels/12.csv | size:      1 | compressed size:      1
name: uci/train/labels/120.csv | size:      1 | compressed size:      1
name: uci/train/labels/121.csv | size:      1 | compressed size:      1
name: uci/train/labels/122.csv | size:      1 | compressed size:      1
name: uci/train/labels/123.csv | size:      1 | compressed size:      1
name: uci/train/labels/124.csv | size:      1 | compressed size:      1
name: uci/train/labels/125.csv | size:      1 | compressed size:      1
name: uci/train/labels/126.csv | size:      1 | compressed size:      1
name: uci/train/labels/127.csv | size:      1 | compressed size:      1
name: uci/train/labels/128.csv | size:      1 | compressed size:      1
name: uci/train/labels/129.csv | size:      1 | compressed size:      1
name: uci/train/labels/13.csv | size:      1 | compressed size:      1
name: uci/train/labels/130.csv | size:      1 | compressed size:      1
name: uci/train/labels/131.csv | size:      1 | compressed size:      1
name: uci/train/labels/132.csv | size:      1 | compressed size:      1
name: uci/train/labels/133.csv | size:      1 | compressed size:      1
name: uci/train/labels/134.csv | size:      1 | compressed size:      1
name: uci/train/labels/135.csv | size:      1 | compressed size:      1
name: uci/train/labels/136.csv | size:      1 | compressed size:      1
name: uci/train/labels/137.csv | size:      1 | compressed size:      1
name: uci/train/labels/138.csv | size:      1 | compressed size:      1
name: uci/train/labels/139.csv | size:      1 | compressed size:      1
name: uci/train/labels/14.csv | size:      1 | compressed size:      1
name: uci/train/labels/140.csv | size:      1 | compressed size:      1
name: uci/train/labels/141.csv | size:      1 | compressed size:      1
name: uci/train/labels/142.csv | size:      1 | compressed size:      1
name: uci/train/labels/143.csv | size:      1 | compressed size:      1
name: uci/train/labels/144.csv | size:      1 | compressed size:      1
name: uci/train/labels/145.csv | size:      1 | compressed size:      1
name: uci/train/labels/146.csv | size:      1 | compressed size:      1
name: uci/train/labels/147.csv | size:      1 | compressed size:      1
name: uci/train/labels/148.csv | size:      1 | compressed size:      1
name: uci/train/labels/149.csv | size:      1 | compressed size:      1
name: uci/train/labels/15.csv | size:      1 | compressed size:      1
name: uci/train/labels/150.csv | size:      1 | compressed size:      1
name: uci/train/labels/151.csv | size:      1 | compressed size:      1
name: uci/train/labels/152.csv | size:      1 | compressed size:      1
name: uci/train/labels/153.csv | size:      1 | compressed size:      1
name: uci/train/labels/154.csv | size:      1 | compressed size:      1
name: uci/train/labels/155.csv | size:      1 | compressed size:      1
name: uci/train/labels/156.csv | size:      1 | compressed size:      1
name: uci/train/labels/157.csv | size:      1 | compressed size:      1
name: uci/train/labels/158.csv | size:      1 | compressed size:      1
name: uci/train/labels/159.csv | size:      1 | compressed size:      1
name: uci/train/labels/16.csv | size:      1 | compressed size:      1
name: uci/train/labels/160.csv | size:      1 | compressed size:      1
name: uci/train/labels/161.csv | size:      1 | compressed size:      1
name: uci/train/labels/162.csv | size:      1 | compressed size:      1
name: uci/train/labels/163.csv | size:      1 | compressed size:      1
name: uci/train/labels/164.csv | size:      1 | compressed size:      1
name: uci/train/labels/165.csv | size:      1 | compressed size:      1
name: uci/train/labels/166.csv | size:      1 | compressed size:      1
name: uci/train/labels/167.csv | size:      1 | compressed size:      1
name: uci/train/labels/168.csv | size:      1 | compressed size:      1
name: uci/train/labels/169.csv | size:      1 | compressed size:      1
name: uci/train/labels/17.csv | size:      1 | compressed size:      1
name: uci/train/labels/170.csv | size:      1 | compressed size:      1
name: uci/train/labels/171.csv | size:      1 | compressed size:      1
name: uci/train/labels/172.csv | size:      1 | compressed size:      1
name: uci/train/labels/173.csv | size:      1 | compressed size:      1
name: uci/train/labels/174.csv | size:      1 | compressed size:      1
name: uci/train/labels/175.csv | size:      1 | compressed size:      1
name: uci/train/labels/176.csv | size:      1 | compressed size:      1
name: uci/train/labels/177.csv | size:      1 | compressed size:      1
name: uci/train/labels/178.csv | size:      1 | compressed size:      1
name: uci/train/labels/179.csv | size:      1 | compressed size:      1
name: uci/train/labels/18.csv | size:      1 | compressed size:      1
name: uci/train/labels/180.csv | size:      1 | compressed size:      1
name: uci/train/labels/181.csv | size:      1 | compressed size:      1
name: uci/train/labels/182.csv | size:      1 | compressed size:      1
name: uci/train/labels/183.csv | size:      1 | compressed size:      1
name: uci/train/labels/184.csv | size:      1 | compressed size:      1
name: uci/train/labels/185.csv | size:      1 | compressed size:      1
name: uci/train/labels/186.csv | size:      1 | compressed size:      1
name: uci/train/labels/187.csv | size:      1 | compressed size:      1
name: uci/train/labels/188.csv | size:      1 | compressed size:      1
name: uci/train/labels/189.csv | size:      1 | compressed size:      1
name: uci/train/labels/19.csv | size:      1 | compressed size:      1
name: uci/train/labels/190.csv | size:      1 | compressed size:      1
name: uci/train/labels/191.csv | size:      1 | compressed size:      1
name: uci/train/labels/192.csv | size:      1 | compressed size:      1
name: uci/train/labels/193.csv | size:      1 | compressed size:      1
name: uci/train/labels/194.csv | size:      1 | compressed size:      1
name: uci/train/labels/195.csv | size:      1 | compressed size:      1
name: uci/train/labels/196.csv | size:      1 | compressed size:      1
name: uci/train/labels/197.csv | size:      1 | compressed size:      1
name: uci/train/labels/198.csv | size:      1 | compressed size:      1
name: uci/train/labels/199.csv | size:      1 | compressed size:      1
name: uci/train/labels/2.csv | size:      1 | compressed size:      1
name: uci/train/labels/20.csv | size:      1 | compressed size:      1
name: uci/train/labels/200.csv | size:      1 | compressed size:      1
name: uci/train/labels/201.csv | size:      1 | compressed size:      1
name: uci/train/labels/202.csv | size:      1 | compressed size:      1
name: uci/train/labels/203.csv | size:      1 | compressed size:      1
name: uci/train/labels/204.csv | size:      1 | compressed size:      1
name: uci/train/labels/205.csv | size:      1 | compressed size:      1
name: uci/train/labels/206.csv | size:      1 | compressed size:      1
name: uci/train/labels/207.csv | size:      1 | compressed size:      1
name: uci/train/labels/208.csv | size:      1 | compressed size:      1
name: uci/train/labels/209.csv | size:      1 | compressed size:      1
name: uci/train/labels/21.csv | size:      1 | compressed size:      1
name: uci/train/labels/210.csv | size:      1 | compressed size:      1
name: uci/train/labels/211.csv | size:      1 | compressed size:      1
name: uci/train/labels/212.csv | size:      1 | compressed size:      1
name: uci/train/labels/213.csv | size:      1 | compressed size:      1
name: uci/train/labels/214.csv | size:      1 | compressed size:      1
name: uci/train/labels/215.csv | size:      1 | compressed size:      1
name: uci/train/labels/216.csv | size:      1 | compressed size:      1
name: uci/train/labels/217.csv | size:      1 | compressed size:      1
name: uci/train/labels/218.csv | size:      1 | compressed size:      1
name: uci/train/labels/219.csv | size:      1 | compressed size:      1
name: uci/train/labels/22.csv | size:      1 | compressed size:      1
name: uci/train/labels/220.csv | size:      1 | compressed size:      1
name: uci/train/labels/221.csv | size:      1 | compressed size:      1
name: uci/train/labels/222.csv | size:      1 | compressed size:      1
name: uci/train/labels/223.csv | size:      1 | compressed size:      1
name: uci/train/labels/224.csv | size:      1 | compressed size:      1
name: uci/train/labels/225.csv | size:      1 | compressed size:      1
name: uci/train/labels/226.csv | size:      1 | compressed size:      1
name: uci/train/labels/227.csv | size:      1 | compressed size:      1
name: uci/train/labels/228.csv | size:      1 | compressed size:      1
name: uci/train/labels/229.csv | size:      1 | compressed size:      1
name: uci/train/labels/23.csv | size:      1 | compressed size:      1
name: uci/train/labels/230.csv | size:      1 | compressed size:      1
name: uci/train/labels/231.csv | size:      1 | compressed size:      1
name: uci/train/labels/232.csv | size:      1 | compressed size:      1
name: uci/train/labels/233.csv | size:      1 | compressed size:      1
name: uci/train/labels/234.csv | size:      1 | compressed size:      1
name: uci/train/labels/235.csv | size:      1 | compressed size:      1
name: uci/train/labels/236.csv | size:      1 | compressed size:      1
name: uci/train/labels/237.csv | size:      1 | compressed size:      1
name: uci/train/labels/238.csv | size:      1 | compressed size:      1
name: uci/train/labels/239.csv | size:      1 | compressed size:      1
name: uci/train/labels/24.csv | size:      1 | compressed size:      1
name: uci/train/labels/240.csv | size:      1 | compressed size:      1
name: uci/train/labels/241.csv | size:      1 | compressed size:      1
name: uci/train/labels/242.csv | size:      1 | compressed size:      1
name: uci/train/labels/243.csv | size:      1 | compressed size:      1
name: uci/train/labels/244.csv | size:      1 | compressed size:      1
name: uci/train/labels/245.csv | size:      1 | compressed size:      1
name: uci/train/labels/246.csv | size:      1 | compressed size:      1
name: uci/train/labels/247.csv | size:      1 | compressed size:      1
name: uci/train/labels/248.csv | size:      1 | compressed size:      1
name: uci/train/labels/249.csv | size:      1 | compressed size:      1
name: uci/train/labels/25.csv | size:      1 | compressed size:      1
name: uci/train/labels/250.csv | size:      1 | compressed size:      1
name: uci/train/labels/251.csv | size:      1 | compressed size:      1
name: uci/train/labels/252.csv | size:      1 | compressed size:      1
name: uci/train/labels/253.csv | size:      1 | compressed size:      1
name: uci/train/labels/254.csv | size:      1 | compressed size:      1
name: uci/train/labels/255.csv | size:      1 | compressed size:      1
name: uci/train/labels/256.csv | size:      1 | compressed size:      1
name: uci/train/labels/257.csv | size:      1 | compressed size:      1
name: uci/train/labels/258.csv | size:      1 | compressed size:      1
name: uci/train/labels/259.csv | size:      1 | compressed size:      1
name: uci/train/labels/26.csv | size:      1 | compressed size:      1
name: uci/train/labels/260.csv | size:      1 | compressed size:      1
name: uci/train/labels/261.csv | size:      1 | compressed size:      1
name: uci/train/labels/262.csv | size:      1 | compressed size:      1
name: uci/train/labels/263.csv | size:      1 | compressed size:      1
name: uci/train/labels/264.csv | size:      1 | compressed size:      1
name: uci/train/labels/265.csv | size:      1 | compressed size:      1
name: uci/train/labels/266.csv | size:      1 | compressed size:      1
name: uci/train/labels/267.csv | size:      1 | compressed size:      1
name: uci/train/labels/268.csv | size:      1 | compressed size:      1
name: uci/train/labels/269.csv | size:      1 | compressed size:      1
name: uci/train/labels/27.csv | size:      1 | compressed size:      1
name: uci/train/labels/270.csv | size:      1 | compressed size:      1
name: uci/train/labels/271.csv | size:      1 | compressed size:      1
name: uci/train/labels/272.csv | size:      1 | compressed size:      1
name: uci/train/labels/273.csv | size:      1 | compressed size:      1
name: uci/train/labels/274.csv | size:      1 | compressed size:      1
name: uci/train/labels/275.csv | size:      1 | compressed size:      1
name: uci/train/labels/276.csv | size:      1 | compressed size:      1
name: uci/train/labels/277.csv | size:      1 | compressed size:      1
name: uci/train/labels/278.csv | size:      1 | compressed size:      1
name: uci/train/labels/279.csv | size:      1 | compressed size:      1
name: uci/train/labels/28.csv | size:      1 | compressed size:      1
name: uci/train/labels/280.csv | size:      1 | compressed size:      1
name: uci/train/labels/281.csv | size:      1 | compressed size:      1
name: uci/train/labels/282.csv | size:      1 | compressed size:      1
name: uci/train/labels/283.csv | size:      1 | compressed size:      1
name: uci/train/labels/284.csv | size:      1 | compressed size:      1
name: uci/train/labels/285.csv | size:      1 | compressed size:      1
name: uci/train/labels/286.csv | size:      1 | compressed size:      1
name: uci/train/labels/287.csv | size:      1 | compressed size:      1
name: uci/train/labels/288.csv | size:      1 | compressed size:      1
name: uci/train/labels/289.csv | size:      1 | compressed size:      1
name: uci/train/labels/29.csv | size:      1 | compressed size:      1
name: uci/train/labels/290.csv | size:      1 | compressed size:      1
name: uci/train/labels/291.csv | size:      1 | compressed size:      1
name: uci/train/labels/292.csv | size:      1 | compressed size:      1
name: uci/train/labels/293.csv | size:      1 | compressed size:      1
name: uci/train/labels/294.csv | size:      1 | compressed size:      1
name: uci/train/labels/295.csv | size:      1 | compressed size:      1
name: uci/train/labels/296.csv | size:      1 | compressed size:      1
name: uci/train/labels/297.csv | size:      1 | compressed size:      1
name: uci/train/labels/298.csv | size:      1 | compressed size:      1
name: uci/train/labels/299.csv | size:      1 | compressed size:      1
name: uci/train/labels/3.csv | size:      1 | compressed size:      1
name: uci/train/labels/30.csv | size:      1 | compressed size:      1
name: uci/train/labels/300.csv | size:      1 | compressed size:      1
name: uci/train/labels/301.csv | size:      1 | compressed size:      1
name: uci/train/labels/302.csv | size:      1 | compressed size:      1
name: uci/train/labels/303.csv | size:      1 | compressed size:      1
name: uci/train/labels/304.csv | size:      1 | compressed size:      1
name: uci/train/labels/305.csv | size:      1 | compressed size:      1
name: uci/train/labels/306.csv | size:      1 | compressed size:      1
name: uci/train/labels/307.csv | size:      1 | compressed size:      1
name: uci/train/labels/308.csv | size:      1 | compressed size:      1
name: uci/train/labels/309.csv | size:      1 | compressed size:      1
name: uci/train/labels/31.csv | size:      1 | compressed size:      1
name: uci/train/labels/310.csv | size:      1 | compressed size:      1
name: uci/train/labels/311.csv | size:      1 | compressed size:      1
name: uci/train/labels/312.csv | size:      1 | compressed size:      1
name: uci/train/labels/313.csv | size:      1 | compressed size:      1
name: uci/train/labels/314.csv | size:      1 | compressed size:      1
name: uci/train/labels/315.csv | size:      1 | compressed size:      1
name: uci/train/labels/316.csv | size:      1 | compressed size:      1
name: uci/train/labels/317.csv | size:      1 | compressed size:      1
name: uci/train/labels/318.csv | size:      1 | compressed size:      1
name: uci/train/labels/319.csv | size:      1 | compressed size:      1
name: uci/train/labels/32.csv | size:      1 | compressed size:      1
name: uci/train/labels/320.csv | size:      1 | compressed size:      1
name: uci/train/labels/321.csv | size:      1 | compressed size:      1
name: uci/train/labels/322.csv | size:      1 | compressed size:      1
name: uci/train/labels/323.csv | size:      1 | compressed size:      1
name: uci/train/labels/324.csv | size:      1 | compressed size:      1
name: uci/train/labels/325.csv | size:      1 | compressed size:      1
name: uci/train/labels/326.csv | size:      1 | compressed size:      1
name: uci/train/labels/327.csv | size:      1 | compressed size:      1
name: uci/train/labels/328.csv | size:      1 | compressed size:      1
name: uci/train/labels/329.csv | size:      1 | compressed size:      1
name: uci/train/labels/33.csv | size:      1 | compressed size:      1
name: uci/train/labels/330.csv | size:      1 | compressed size:      1
name: uci/train/labels/331.csv | size:      1 | compressed size:      1
name: uci/train/labels/332.csv | size:      1 | compressed size:      1
name: uci/train/labels/333.csv | size:      1 | compressed size:      1
name: uci/train/labels/334.csv | size:      1 | compressed size:      1
name: uci/train/labels/335.csv | size:      1 | compressed size:      1
name: uci/train/labels/336.csv | size:      1 | compressed size:      1
name: uci/train/labels/337.csv | size:      1 | compressed size:      1
name: uci/train/labels/338.csv | size:      1 | compressed size:      1
name: uci/train/labels/339.csv | size:      1 | compressed size:      1
name: uci/train/labels/34.csv | size:      1 | compressed size:      1
name: uci/train/labels/340.csv | size:      1 | compressed size:      1
name: uci/train/labels/341.csv | size:      1 | compressed size:      1
name: uci/train/labels/342.csv | size:      1 | compressed size:      1
name: uci/train/labels/343.csv | size:      1 | compressed size:      1
name: uci/train/labels/344.csv | size:      1 | compressed size:      1
name: uci/train/labels/345.csv | size:      1 | compressed size:      1
name: uci/train/labels/346.csv | size:      1 | compressed size:      1
name: uci/train/labels/347.csv | size:      1 | compressed size:      1
name: uci/train/labels/348.csv | size:      1 | compressed size:      1
name: uci/train/labels/349.csv | size:      1 | compressed size:      1
name: uci/train/labels/35.csv | size:      1 | compressed size:      1
name: uci/train/labels/350.csv | size:      1 | compressed size:      1
name: uci/train/labels/351.csv | size:      1 | compressed size:      1
name: uci/train/labels/352.csv | size:      1 | compressed size:      1
name: uci/train/labels/353.csv | size:      1 | compressed size:      1
name: uci/train/labels/354.csv | size:      1 | compressed size:      1
name: uci/train/labels/355.csv | size:      1 | compressed size:      1
name: uci/train/labels/356.csv | size:      1 | compressed size:      1
name: uci/train/labels/357.csv | size:      1 | compressed size:      1
name: uci/train/labels/358.csv | size:      1 | compressed size:      1
name: uci/train/labels/359.csv | size:      1 | compressed size:      1
name: uci/train/labels/36.csv | size:      1 | compressed size:      1
name: uci/train/labels/360.csv | size:      1 | compressed size:      1
name: uci/train/labels/361.csv | size:      1 | compressed size:      1
name: uci/train/labels/362.csv | size:      1 | compressed size:      1
name: uci/train/labels/363.csv | size:      1 | compressed size:      1
name: uci/train/labels/364.csv | size:      1 | compressed size:      1
name: uci/train/labels/365.csv | size:      1 | compressed size:      1
name: uci/train/labels/366.csv | size:      1 | compressed size:      1
name: uci/train/labels/367.csv | size:      1 | compressed size:      1
name: uci/train/labels/368.csv | size:      1 | compressed size:      1
name: uci/train/labels/369.csv | size:      1 | compressed size:      1
name: uci/train/labels/37.csv | size:      1 | compressed size:      1
name: uci/train/labels/370.csv | size:      1 | compressed size:      1
name: uci/train/labels/371.csv | size:      1 | compressed size:      1
name: uci/train/labels/372.csv | size:      1 | compressed size:      1
name: uci/train/labels/373.csv | size:      1 | compressed size:      1
name: uci/train/labels/374.csv | size:      1 | compressed size:      1
name: uci/train/labels/375.csv | size:      1 | compressed size:      1
name: uci/train/labels/376.csv | size:      1 | compressed size:      1
name: uci/train/labels/377.csv | size:      1 | compressed size:      1
name: uci/train/labels/378.csv | size:      1 | compressed size:      1
name: uci/train/labels/379.csv | size:      1 | compressed size:      1
name: uci/train/labels/38.csv | size:      1 | compressed size:      1
name: uci/train/labels/380.csv | size:      1 | compressed size:      1
name: uci/train/labels/381.csv | size:      1 | compressed size:      1
name: uci/train/labels/382.csv | size:      1 | compressed size:      1
name: uci/train/labels/383.csv | size:      1 | compressed size:      1
name: uci/train/labels/384.csv | size:      1 | compressed size:      1
name: uci/train/labels/385.csv | size:      1 | compressed size:      1
name: uci/train/labels/386.csv | size:      1 | compressed size:      1
name: uci/train/labels/387.csv | size:      1 | compressed size:      1
name: uci/train/labels/388.csv | size:      1 | compressed size:      1
name: uci/train/labels/389.csv | size:      1 | compressed size:      1
name: uci/train/labels/39.csv | size:      1 | compressed size:      1
name: uci/train/labels/390.csv | size:      1 | compressed size:      1
name: uci/train/labels/391.csv | size:      1 | compressed size:      1
name: uci/train/labels/392.csv | size:      1 | compressed size:      1
name: uci/train/labels/393.csv | size:      1 | compressed size:      1
name: uci/train/labels/394.csv | size:      1 | compressed size:      1
name: uci/train/labels/395.csv | size:      1 | compressed size:      1
name: uci/train/labels/396.csv | size:      1 | compressed size:      1
name: uci/train/labels/397.csv | size:      1 | compressed size:      1
name: uci/train/labels/398.csv | size:      1 | compressed size:      1
name: uci/train/labels/399.csv | size:      1 | compressed size:      1
name: uci/train/labels/4.csv | size:      1 | compressed size:      1
name: uci/train/labels/40.csv | size:      1 | compressed size:      1
name: uci/train/labels/400.csv | size:      1 | compressed size:      1
name: uci/train/labels/401.csv | size:      1 | compressed size:      1
name: uci/train/labels/402.csv | size:      1 | compressed size:      1
name: uci/train/labels/403.csv | size:      1 | compressed size:      1
name: uci/train/labels/404.csv | size:      1 | compressed size:      1
name: uci/train/labels/405.csv | size:      1 | compressed size:      1
name: uci/train/labels/406.csv | size:      1 | compressed size:      1
name: uci/train/labels/407.csv | size:      1 | compressed size:      1
name: uci/train/labels/408.csv | size:      1 | compressed size:      1
name: uci/train/labels/409.csv | size:      1 | compressed size:      1
name: uci/train/labels/41.csv | size:      1 | compressed size:      1
name: uci/train/labels/410.csv | size:      1 | compressed size:      1
name: uci/train/labels/411.csv | size:      1 | compressed size:      1
name: uci/train/labels/412.csv | size:      1 | compressed size:      1
name: uci/train/labels/413.csv | size:      1 | compressed size:      1
name: uci/train/labels/414.csv | size:      1 | compressed size:      1
name: uci/train/labels/415.csv | size:      1 | compressed size:      1
name: uci/train/labels/416.csv | size:      1 | compressed size:      1
name: uci/train/labels/417.csv | size:      1 | compressed size:      1
name: uci/train/labels/418.csv | size:      1 | compressed size:      1
name: uci/train/labels/419.csv | size:      1 | compressed size:      1
name: uci/train/labels/42.csv | size:      1 | compressed size:      1
name: uci/train/labels/420.csv | size:      1 | compressed size:      1
name: uci/train/labels/421.csv | size:      1 | compressed size:      1
name: uci/train/labels/422.csv | size:      1 | compressed size:      1
name: uci/train/labels/423.csv | size:      1 | compressed size:      1
name: uci/train/labels/424.csv | size:      1 | compressed size:      1
name: uci/train/labels/425.csv | size:      1 | compressed size:      1
name: uci/train/labels/426.csv | size:      1 | compressed size:      1
name: uci/train/labels/427.csv | size:      1 | compressed size:      1
name: uci/train/labels/428.csv | size:      1 | compressed size:      1
name: uci/train/labels/429.csv | size:      1 | compressed size:      1
name: uci/train/labels/43.csv | size:      1 | compressed size:      1
name: uci/train/labels/430.csv | size:      1 | compressed size:      1
name: uci/train/labels/431.csv | size:      1 | compressed size:      1
name: uci/train/labels/432.csv | size:      1 | compressed size:      1
name: uci/train/labels/433.csv | size:      1 | compressed size:      1
name: uci/train/labels/434.csv | size:      1 | compressed size:      1
name: uci/train/labels/435.csv | size:      1 | compressed size:      1
name: uci/train/labels/436.csv | size:      1 | compressed size:      1
name: uci/train/labels/437.csv | size:      1 | compressed size:      1
name: uci/train/labels/438.csv | size:      1 | compressed size:      1
name: uci/train/labels/439.csv | size:      1 | compressed size:      1
name: uci/train/labels/44.csv | size:      1 | compressed size:      1
name: uci/train/labels/440.csv | size:      1 | compressed size:      1
name: uci/train/labels/441.csv | size:      1 | compressed size:      1
name: uci/train/labels/442.csv | size:      1 | compressed size:      1
name: uci/train/labels/443.csv | size:      1 | compressed size:      1
name: uci/train/labels/444.csv | size:      1 | compressed size:      1
name: uci/train/labels/445.csv | size:      1 | compressed size:      1
name: uci/train/labels/446.csv | size:      1 | compressed size:      1
name: uci/train/labels/447.csv | size:      1 | compressed size:      1
name: uci/train/labels/448.csv | size:      1 | compressed size:      1
name: uci/train/labels/449.csv | size:      1 | compressed size:      1
name: uci/train/labels/45.csv | size:      1 | compressed size:      1
name: uci/train/labels/46.csv | size:      1 | compressed size:      1
name: uci/train/labels/47.csv | size:      1 | compressed size:      1
name: uci/train/labels/48.csv | size:      1 | compressed size:      1
name: uci/train/labels/49.csv | size:      1 | compressed size:      1
name: uci/train/labels/5.csv | size:      1 | compressed size:      1
name: uci/train/labels/50.csv | size:      1 | compressed size:      1
name: uci/train/labels/51.csv | size:      1 | compressed size:      1
name: uci/train/labels/52.csv | size:      1 | compressed size:      1
name: uci/train/labels/53.csv | size:      1 | compressed size:      1
name: uci/train/labels/54.csv | size:      1 | compressed size:      1
name: uci/train/labels/55.csv | size:      1 | compressed size:      1
name: uci/train/labels/56.csv | size:      1 | compressed size:      1
name: uci/train/labels/57.csv | size:      1 | compressed size:      1
name: uci/train/labels/58.csv | size:      1 | compressed size:      1
name: uci/train/labels/59.csv | size:      1 | compressed size:      1
name: uci/train/labels/6.csv | size:      1 | compressed size:      1
name: uci/train/labels/60.csv | size:      1 | compressed size:      1
name: uci/train/labels/61.csv | size:      1 | compressed size:      1
name: uci/train/labels/62.csv | size:      1 | compressed size:      1
name: uci/train/labels/63.csv | size:      1 | compressed size:      1
name: uci/train/labels/64.csv | size:      1 | compressed size:      1
name: uci/train/labels/65.csv | size:      1 | compressed size:      1
name: uci/train/labels/66.csv | size:      1 | compressed size:      1
name: uci/train/labels/67.csv | size:      1 | compressed size:      1
name: uci/train/labels/68.csv | size:      1 | compressed size:      1
name: uci/train/labels/69.csv | size:      1 | compressed size:      1
name: uci/train/labels/7.csv | size:      1 | compressed size:      1
name: uci/train/labels/70.csv | size:      1 | compressed size:      1
name: uci/train/labels/71.csv | size:      1 | compressed size:      1
name: uci/train/labels/72.csv | size:      1 | compressed size:      1
name: uci/train/labels/73.csv | size:      1 | compressed size:      1
name: uci/train/labels/74.csv | size:      1 | compressed size:      1
name: uci/train/labels/75.csv | size:      1 | compressed size:      1
name: uci/train/labels/76.csv | size:      1 | compressed size:      1
name: uci/train/labels/77.csv | size:      1 | compressed size:      1
name: uci/train/labels/78.csv | size:      1 | compressed size:      1
name: uci/train/labels/79.csv | size:      1 | compressed size:      1
name: uci/train/labels/8.csv | size:      1 | compressed size:      1
name: uci/train/labels/80.csv | size:      1 | compressed size:      1
name: uci/train/labels/81.csv | size:      1 | compressed size:      1
name: uci/train/labels/82.csv | size:      1 | compressed size:      1
name: uci/train/labels/83.csv | size:      1 | compressed size:      1
name: uci/train/labels/84.csv | size:      1 | compressed size:      1
name: uci/train/labels/85.csv | size:      1 | compressed size:      1
name: uci/train/labels/86.csv | size:      1 | compressed size:      1
name: uci/train/labels/87.csv | size:      1 | compressed size:      1
name: uci/train/labels/88.csv | size:      1 | compressed size:      1
name: uci/train/labels/89.csv | size:      1 | compressed size:      1
name: uci/train/labels/9.csv | size:      1 | compressed size:      1
name: uci/train/labels/90.csv | size:      1 | compressed size:      1
name: uci/train/labels/91.csv | size:      1 | compressed size:      1
name: uci/train/labels/92.csv | size:      1 | compressed size:      1
name: uci/train/labels/93.csv | size:      1 | compressed size:      1
name: uci/train/labels/94.csv | size:      1 | compressed size:      1
name: uci/train/labels/95.csv | size:      1 | compressed size:      1
name: uci/train/labels/96.csv | size:      1 | compressed size:      1
name: uci/train/labels/97.csv | size:      1 | compressed size:      1
name: uci/train/labels/98.csv | size:      1 | compressed size:      1
name: uci/train/labels/99.csv | size:      1 | compressed size:      1
2103 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend
2127 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ST4-4.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sketch_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/objenesis-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jline-2.12.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-xml_2.11-1.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsr305-1.3.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-collections-3.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/machinist_2.11-0.6.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-codec-1.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-metastore-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-yarn_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.ws.rs-api-2.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-rdbms-3.2.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/eigenbase-properties-1.1.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pyrolite-4.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-jackson-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-util-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill-java-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mesos-1.0.0-shaded-protobuf.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jaxb-api-2.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-encoding-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-log4j12-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-schema-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-shuffle_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scalap-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-annotations-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stream-2.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-server-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-kerberos-codec-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-mapper-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-all-4.0.43.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/py4j-0.10.4.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/zipfs.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-hdfs-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/oro-2.0.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-api-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/JavaEWAH-0.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-core_2.11-3.2.11.jar
file:/System/Library/Java/Extensions/j3dcore.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/zookeeper-3.4.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-jdbc-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-locator-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire_2.11-0.13.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/cldrdata.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/kryo-shaded-3.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-api-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-repackaged-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/compress-lzf-1.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib-local_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-media-jaxb-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-core-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/activation-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-2.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mesos_2.11-2.2.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/localedata.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-catalyst_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpcore-4.4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-jaxrs-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-utils-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-json-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-tags_2.11-2.2.0.jar
file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar
file:/System/Library/Java/Extensions/libJ3DAudio.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javolution-5.5.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.servlet-api-3.1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-api-jdo-3.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-scala_2.11-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jta-1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-net-2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bcprov-jdk15on-1.51.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jdo-api-3.0.1.jar
file:/System/Library/Java/Extensions/j3dutils.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-api-2.4.0-b34.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/sunec.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guava-14.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-java-1.1.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive-thriftserver_2.11-2.2.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/jaccess.jar
file:/System/Library/Java/Extensions/libJ3D.jnilib
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/jfxrt.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr4-runtime-4.5.3.jar
file:/System/Library/Java/Extensions/dns_sd.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-databind-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-common_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang-2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/janino-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-client-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-recipes-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-configuration-1.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-repl_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/shapeless_2.11-2.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-ast_2.11-3.2.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-core-3.2.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-dbcp-1.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-math3-3.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-guava-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-client-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-jackson_2.11-3.2.11.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/nashorn.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xbean-asm5-shaded-4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/RoaringBitmap-0.5.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-annotations-2.6.5.jar
file:/System/Library/Java/Extensions/vecmath.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stringtemplate-3.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-app-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-model-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/protobuf-java-2.5.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-column-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-bundle-1.6.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-graphite-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill_2.11-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze-macros_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-3.9.9.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-core-1.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-auth-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-runtime-3.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-core_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-cli-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libfb303-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javassist-3.18.1-GA.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-jvm-3.1.2.jar
file:/System/Library/Java/Extensions/mlibwrapper_jai.jar
file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-linq4j-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/joda-time-2.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/minlog-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compress-1.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/derby-10.12.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-io-2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-launcher_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-crypto-1.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-streaming_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/core-1.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-unsafe_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-format-2.3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/opencsv-2.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sql_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-core-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-common-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-avatica-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-exec-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mail-1.4.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jpam-1.1.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mx4j-3.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-graphx_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.annotation-api-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jcl-over-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-logging-1.1.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire-macros_2.11-0.13.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/validation-api-1.1.0.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/lz4-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/java-xmlbuilder-1.0.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/jre/lib/ext/dnsns.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-pool-1.5.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsp-api-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xz-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-xc-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-compiler-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/htrace-core-3.1.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/univocity-parsers-2.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-framework-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-util-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpclient-4.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bonecp-0.8.0.RELEASE.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/conf/
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-i18n-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compiler-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-cli-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/paranamer-2.6.jar
file:/System/Library/Java/Extensions/jai_core.jar
file:/System/Library/Java/Extensions/libJ3DUtils.jnilib
file:/System/Library/Java/Extensions/AppleScriptEngine.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-core-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/macro-compat_2.11-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-1.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jul-to-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ivy-2.4.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-digester-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jodd-core-3.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libthrift-0.9.3.jar
file:/System/Library/Java/Extensions/libmlib_jai.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-mapred-1.7.7-hadoop2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/base64-2.3.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jets3t-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-library-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/leveldbjni-all-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-core-2.22.2.jar
file:/System/Library/Java/Extensions/jai_codec.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-reflect-2.11.8.jar
file:/usr/lib/java/libjdns_sd.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-beeline-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-paranamer-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/log4j-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/super-csv-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-common-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/osgi-resource-locator-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-servlet-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-ipc-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang3-3.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-httpclient-3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jtransforms-2.4.0.jar
file:/System/Library/Java/Extensions/j3daudio.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-parser-combinators_2.11-1.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/gson-2.2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-asn1-api-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xmlenc-0.52.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-web-proxy-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/arpack_combined_all-0.1.jar
file:/System/Library/Java/Extensions/MRJToolkit.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0-2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xercesImpl-2.9.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apache-log4j-extras-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-1.jar
2491 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DAudio.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2507 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3D.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
3014 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
3094 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DUtils.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
3100 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libmlib_jai.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
3120 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/lib/java/libjdns_sd.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.reflections.Reflections.<init>(Reflections.java:170)
	at org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)
	at org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)
	at org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)
	at org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritablesSequence(RecordReaderMultiDataSetIterator.java:486)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:276)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)
	at org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:330)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:309)
	at org.deeplearning4j.datasets.datavec.SequenceRecordReaderDataSetIterator.next(SequenceRecordReaderDataSetIterator.java:32)
	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.fit(AbstractDataSetNormalizer.java:92)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
3130 [main] INFO org.reflections.Reflections  - Reflections took 1003 ms to scan 231 urls, producing 168762 keys and 188037 values 
3430 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 4
3432 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
jar:file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/
3504 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.4:49914) with ID 0
3571 [dispatcher-event-loop-1] DEBUG org.apache.spark.storage.DefaultTopologyMapper  - Got a request for 192.168.1.4
3572 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.1.4:49916 with 366.3 MB RAM, BlockManagerId(0, 192.168.1.4, 49916, None)
3781 [main] INFO org.reflections.Reflections  - Reflections took 349 ms to scan 1 urls, producing 31 keys and 227 values 
3957 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 4
3958 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Mac OS X]
3958 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [8]; Memory: [0.9GB];
3958 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]
3984 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
jar:file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/
4290 [main] INFO org.reflections.Reflections  - Reflections took 306 ms to scan 1 urls, producing 421 keys and 1666 values 
5044 [main] DEBUG org.reflections.Reflections  - going to scan these urls:
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ST4-4.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sketch_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/objenesis-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jline-2.12.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-xml_2.11-1.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsr305-1.3.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-collections-3.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/machinist_2.11-0.6.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-codec-1.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-metastore-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-yarn_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.ws.rs-api-2.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-rdbms-3.2.9.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/eigenbase-properties-1.1.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pyrolite-4.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-jackson-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-util-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill-java-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mesos-1.0.0-shaded-protobuf.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jaxb-api-2.2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-encoding-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-log4j12-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-schema-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-shuffle_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scalap-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-annotations-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stream-2.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-server-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-kerberos-codec-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-mapper-asl-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-all-4.0.43.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/py4j-0.10.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-hdfs-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/oro-2.0.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/slf4j-api-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/JavaEWAH-0.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-core_2.11-3.2.11.jar
file:/System/Library/Java/Extensions/j3dcore.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/zookeeper-3.4.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-jdbc-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-locator-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire_2.11-0.13.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/kryo-shaded-3.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-api-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-repackaged-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/compress-lzf-1.0.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mllib-local_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-media-jaxb-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-core-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/activation-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-2.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-mesos_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-catalyst_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpcore-4.4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-jaxrs-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-utils-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/aopalliance-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-json-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-tags_2.11-2.2.0.jar
file:/Users/tomhanlon/SkyMind/java/th_minimal_app2/dl4j-minimal-example/target/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar
file:/System/Library/Java/Extensions/libJ3DAudio.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javolution-5.5.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.servlet-api-3.1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-api-jdo-3.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-scala_2.11-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jta-1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-net-2.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bcprov-jdk15on-1.51.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jdo-api-3.0.1.jar
file:/System/Library/Java/Extensions/j3dutils.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hk2-api-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guava-14.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-java-1.1.2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-hive-thriftserver_2.11-2.2.0.jar
file:/System/Library/Java/Extensions/libJ3D.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr4-runtime-4.5.3.jar
file:/System/Library/Java/Extensions/dns_sd.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-databind-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-network-common_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang-2.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/janino-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-client-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-recipes-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-configuration-1.6.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-repl_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/shapeless_2.11-2.3.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-ast_2.11-3.2.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/datanucleus-core-3.2.10.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-dbcp-1.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-math3-3.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-guava-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-client-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/json4s-jackson_2.11-3.2.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xbean-asm5-shaded-4.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/RoaringBitmap-0.5.11.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-annotations-2.6.5.jar
file:/System/Library/Java/Extensions/vecmath.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stringtemplate-3.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-app-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/pmml-model-1.2.15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/protobuf-java-2.5.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-column-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-hadoop-bundle-1.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-graphite-3.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/chill_2.11-0.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze-macros_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/netty-3.9.9.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-core-1.8.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-auth-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-core-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/antlr-runtime-3.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-core_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-cli-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libfb303-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javassist-3.18.1-GA.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/metrics-jvm-3.1.2.jar
file:/System/Library/Java/Extensions/mlibwrapper_jai.jar
file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-linq4j-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/joda-time-2.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/minlog-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compress-1.4.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/derby-10.12.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-io-2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-launcher_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-crypto-1.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-streaming_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/core-1.1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-unsafe_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-format-2.3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/opencsv-2.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-sql_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-core-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-common-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/calcite-avatica-1.2.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-exec-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mail-1.4.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/breeze_2.11-0.13.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jpam-1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/mx4j-3.0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spark-graphx_2.11-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.annotation-api-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jcl-over-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-logging-1.1.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/spire-macros_2.11-0.13.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/validation-api-1.1.0.Final.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/lz4-1.3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/java-xmlbuilder-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-pool-1.5.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jsp-api-2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xz-1.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-xc-1.9.13.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-compiler-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/htrace-core-3.1.0-incubating.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/univocity-parsers-2.2.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/curator-framework-2.6.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/snappy-0.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jetty-util-6.1.26.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/httpclient-4.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/bonecp-0.8.0.RELEASE.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/conf/
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apacheds-i18n-2.0.0-M15.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-compiler-3.0.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-cli-1.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/paranamer-2.6.jar
file:/System/Library/Java/Extensions/jai_core.jar
file:/System/Library/Java/Extensions/libJ3DUtils.jnilib
file:/System/Library/Java/Extensions/AppleScriptEngine.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-core-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/macro-compat_2.11-1.1.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-beanutils-1.7.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jul-to-slf4j-1.7.16.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/ivy-2.4.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-digester-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-2.22.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jodd-core-3.5.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-client-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/libthrift-0.9.3.jar
file:/System/Library/Java/Extensions/libmlib_jai.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-mapred-1.7.7-hadoop2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/base64-2.3.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jets3t-0.9.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-library-2.11.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/leveldbjni-all-1.8.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jersey-container-servlet-core-2.22.2.jar
file:/System/Library/Java/Extensions/jai_codec.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-reflect-2.11.8.jar
file:/usr/lib/java/libjdns_sd.jnilib
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hive-beeline-1.2.1.spark2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jackson-module-paranamer-2.6.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/log4j-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/super-csv-2.2.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/parquet-common-1.8.2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/osgi-resource-locator-1.0.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/guice-servlet-3.0.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/avro-ipc-1.7.7.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-lang3-3.5.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-2.4.0-b34.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/commons-httpclient-3.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/jtransforms-2.4.0.jar
file:/System/Library/Java/Extensions/j3daudio.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/scala-parser-combinators_2.11-1.0.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/gson-2.2.4.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-common-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/api-asn1-api-1.0.0-M20.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xmlenc-0.52.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/hadoop-yarn-server-web-proxy-2.7.3.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/arpack_combined_all-0.1.jar
file:/System/Library/Java/Extensions/MRJToolkit.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/stax-api-1.0-2.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/xercesImpl-2.9.1.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/apache-log4j-extras-1.2.17.jar
file:/usr/local/Cellar/apache-spark/2.2.0/libexec/jars/javax.inject-1.jar
10770 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DAudio.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
11098 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3D.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
11776 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libAppleScriptEngine.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
12934 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libJ3DUtils.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
12953 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/System/Library/Java/Extensions/libmlib_jai.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
13301 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/lib/java/libjdns_sd.jnilib]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:109)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:91)
	at org.reflections.Reflections.scan(Reflections.java:237)
	at org.reflections.Reflections.scan(Reflections.java:204)
	at org.reflections.Reflections.<init>(Reflections.java:129)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)
	at skymind.dsx.UCISequenceClassificationSpark2.main(UCISequenceClassificationSpark2.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
13381 [main] INFO org.reflections.Reflections  - Reflections took 8337 ms to scan 221 urls, producing 7650 keys and 52161 values 
13425 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor
13425 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
13425 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer
13425 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
13425 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
13430 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor
13430 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
13430 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer
13430 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
13430 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex
13459 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]
13534 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
13549 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
13550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
13550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
13550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
13550 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
13551 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
13551 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
13552 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
13553 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
13556 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
13557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
13558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
13560 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
13561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
13562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
13562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
13562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
13564 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
13574 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 0 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
13575 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 0 (count at ParameterAveragingTrainingMaster.java:325)
13575 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
13578 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
13584 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 0)
13585 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
13587 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
13587 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 0)
13673 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0 stored as values in memory (estimated size 1448.0 B, free 366.3 MB)
13675 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_0 locally took  61 ms
13676 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_0 without replication took  62 ms
13701 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.3 MB)
13702 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_0_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.3 MB)
13703 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_0_piece0
13703 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_0_piece0
13703 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_0_piece0 locally took  4 ms
13703 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_0_piece0 without replication took  4 ms
13704 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
13718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
13718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 0.0 with 8 tasks
13728 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 0.0: 0
13730 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
13733 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 0
13754 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
13755 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 0.0 (TID 0, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
13762 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 0.0 (TID 1, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
13765 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 0.0 (TID 2, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
13767 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 0.0 (TID 3, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
13769 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 0.0 (TID 4, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
13770 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 0.0 (TID 5, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
13772 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 0.0 (TID 6, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
13774 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 0.0 (TID 7, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
13777 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 0 on executor id: 0 hostname: 192.168.1.4.
13779 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 1 on executor id: 0 hostname: 192.168.1.4.
13779 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 2 on executor id: 0 hostname: 192.168.1.4.
13780 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 3 on executor id: 0 hostname: 192.168.1.4.
13780 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 4 on executor id: 0 hostname: 192.168.1.4.
13780 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 5 on executor id: 0 hostname: 192.168.1.4.
13781 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 6 on executor id: 0 hostname: 192.168.1.4.
13781 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 7 on executor id: 0 hostname: 192.168.1.4.
14379 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
15378 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
16381 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
17377 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
18379 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
19377 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
20381 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
21381 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
22382 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
23379 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
24377 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
25378 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
26379 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
27377 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
28379 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
29377 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
30381 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
31380 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
32380 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
33378 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
34380 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
35379 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
36380 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
37377 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
38379 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
39376 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
40381 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 8
40835 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_0_piece0 as bytes
40837 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_0_piece0 is StorageLevel(disk, memory, 1 replicas)
40857 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_0_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 366.3 MB)
40992 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_5 in memory on 192.168.1.4:49916 (size: 95.7 KB, free: 366.2 MB)
40995 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_3 in memory on 192.168.1.4:49916 (size: 114.7 KB, free: 366.1 MB)
40995 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_1 in memory on 192.168.1.4:49916 (size: 114.7 KB, free: 366.0 MB)
40996 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_0 in memory on 192.168.1.4:49916 (size: 95.7 KB, free: 365.9 MB)
40997 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_6 in memory on 192.168.1.4:49916 (size: 114.7 KB, free: 365.8 MB)
40998 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_4 in memory on 192.168.1.4:49916 (size: 114.7 KB, free: 365.7 MB)
40998 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_2 in memory on 192.168.1.4:49916 (size: 95.7 KB, free: 365.6 MB)
40999 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added rdd_0_7 in memory on 192.168.1.4:49916 (size: 114.7 KB, free: 365.5 MB)
41046 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 7
41048 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
41051 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 6
41051 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 5
41051 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 4
41052 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 3
41052 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 2
41053 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 1
41054 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_0.0, runningTasks: 0
41059 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 0.0 (TID 5) in 27289 ms on 192.168.1.4 (executor 0) (1/8)
41060 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 0.0 (TID 6) in 27290 ms on 192.168.1.4 (executor 0) (2/8)
41061 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 0.0 (TID 0) in 27326 ms on 192.168.1.4 (executor 0) (3/8)
41061 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 0.0 (TID 1) in 27304 ms on 192.168.1.4 (executor 0) (4/8)
41062 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 0.0 (TID 2) in 27300 ms on 192.168.1.4 (executor 0) (5/8)
41062 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 0.0 (TID 3) in 27297 ms on 192.168.1.4 (executor 0) (6/8)
41062 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 0.0 (TID 4) in 27295 ms on 192.168.1.4 (executor 0) (7/8)
41062 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 0.0 (TID 7) in 27290 ms on 192.168.1.4 (executor 0) (8/8)
41063 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 0.0, whose tasks have all completed, from pool 
41068 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 0 (count at ParameterAveragingTrainingMaster.java:325) finished in 27.335 s
41070 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 0, remaining stages = 0
41071 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 0 finished: count at ParameterAveragingTrainingMaster.java:325, took 27.508335 s
41074 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
41074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
41074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
41074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
41074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
41075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
41078 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41079 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41080 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
41082 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
41082 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
41083 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353
41084 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
41085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
41085 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
41086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353)
41086 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
41087 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
41087 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
41088 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353
41089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
41089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
41089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
41089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353)
41089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
41089 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
41092 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41093 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
41094 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
41095 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 1 (collect at SparkUtils.java:353) with 8 output partitions
41095 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 1 (collect at SparkUtils.java:353)
41095 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
41097 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
41097 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 1)
41097 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
41097 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 1 (MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
41097 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 1)
41100 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1 stored as values in memory (estimated size 2.4 KB, free 366.3 MB)
41100 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_1 locally took  1 ms
41100 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_1 without replication took  1 ms
41101 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1571.0 B, free 366.3 MB)
41102 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_1_piece0 in memory on 192.168.1.4:49908 (size: 1571.0 B, free: 366.3 MB)
41102 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_1_piece0
41102 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_1_piece0
41102 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_1_piece0 locally took  1 ms
41102 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_1_piece0 without replication took  1 ms
41102 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
41103 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
41103 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 1.0 with 8 tasks
41103 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 1.0: 0
41105 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 1.0: PROCESS_LOCAL, NODE_LOCAL, ANY
41106 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 0
41107 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
41107 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 1.0 (TID 8, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
41109 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 1.0 (TID 9, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
41110 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 1.0 (TID 10, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
41111 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 1.0 (TID 11, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
41112 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 1.0 (TID 12, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
41113 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 1.0 (TID 13, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
41114 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 1.0 (TID 14, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
41116 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 1.0 (TID 15, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
41116 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 8 on executor id: 0 hostname: 192.168.1.4.
41117 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 9 on executor id: 0 hostname: 192.168.1.4.
41117 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 10 on executor id: 0 hostname: 192.168.1.4.
41117 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 11 on executor id: 0 hostname: 192.168.1.4.
41117 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 12 on executor id: 0 hostname: 192.168.1.4.
41118 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 13 on executor id: 0 hostname: 192.168.1.4.
41118 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 14 on executor id: 0 hostname: 192.168.1.4.
41118 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 15 on executor id: 0 hostname: 192.168.1.4.
41141 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_1_piece0 as bytes
41141 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_1_piece0 is StorageLevel(disk, memory, 1 replicas)
41144 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_1_piece0 in memory on 192.168.1.4:49916 (size: 1571.0 B, free: 365.5 MB)
41181 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 7
41181 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
41181 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
41181 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 1.0 (TID 15) in 67 ms on 192.168.1.4 (executor 0) (1/8)
41181 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 6
41182 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 1.0 (TID 13) in 70 ms on 192.168.1.4 (executor 0) (2/8)
41182 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 5
41182 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 1.0 (TID 8) in 76 ms on 192.168.1.4 (executor 0) (3/8)
41183 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 4
41183 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 1.0 (TID 14) in 70 ms on 192.168.1.4 (executor 0) (4/8)
41184 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 3
41184 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 1.0 (TID 9) in 77 ms on 192.168.1.4 (executor 0) (5/8)
41184 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 2
41185 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 1.0 (TID 12) in 74 ms on 192.168.1.4 (executor 0) (6/8)
41185 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 1
41186 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_1.0, runningTasks: 0
41186 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 1.0 (TID 10) in 77 ms on 192.168.1.4 (executor 0) (7/8)
41186 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 1.0 (TID 11) in 76 ms on 192.168.1.4 (executor 0) (8/8)
41186 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 1.0, whose tasks have all completed, from pool 
41187 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 1 (collect at SparkUtils.java:353) finished in 0.082 s
41187 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 1, remaining stages = 0
41187 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 1 finished: collect at SparkUtils.java:353, took 0.093146 s
41193 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41194 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41195 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41195 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41195 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
41196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
41197 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
41198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 2 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
41198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 2 (zipWithIndex at SparkUtils.java:391)
41198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
41198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
41198 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 2)
41198 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
41198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 2 (MapPartitionsRDD[2] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
41198 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 2)
41200 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2 stored as values in memory (estimated size 2.2 KB, free 366.3 MB)
41201 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_2 locally took  2 ms
41201 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_2 without replication took  2 ms
41202 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.3 MB)
41202 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_2_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
41203 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_2_piece0
41203 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_2_piece0
41203 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_2_piece0 locally took  1 ms
41203 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_2_piece0 without replication took  1 ms
41203 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
41204 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 2 (MapPartitionsRDD[2] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
41204 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 2.0 with 7 tasks
41204 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 2.0: 0
41204 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 2.0: PROCESS_LOCAL, NODE_LOCAL, ANY
41204 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 0
41205 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 2 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
41205 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 2.0 (TID 16, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
41206 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 2.0 (TID 17, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
41207 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 2.0 (TID 18, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
41208 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 2.0 (TID 19, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
41209 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 2.0 (TID 20, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
41210 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 2.0 (TID 21, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
41211 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 2.0 (TID 22, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
41211 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
41211 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
41212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 16 on executor id: 0 hostname: 192.168.1.4.
41212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 17 on executor id: 0 hostname: 192.168.1.4.
41212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 18 on executor id: 0 hostname: 192.168.1.4.
41212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 19 on executor id: 0 hostname: 192.168.1.4.
41213 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 20 on executor id: 0 hostname: 192.168.1.4.
41213 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 21 on executor id: 0 hostname: 192.168.1.4.
41213 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 22 on executor id: 0 hostname: 192.168.1.4.
41227 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_2_piece0 as bytes
41227 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_2_piece0 is StorageLevel(disk, memory, 1 replicas)
41230 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_2_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.5 MB)
41242 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 6
41242 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 5
41242 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 2.0 (TID 18) in 35 ms on 192.168.1.4 (executor 0) (1/7)
41242 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 2.0 (TID 21) in 33 ms on 192.168.1.4 (executor 0) (2/7)
41243 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 4
41243 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 3
41243 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 2.0 (TID 16) in 39 ms on 192.168.1.4 (executor 0) (3/7)
41243 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 2.0 (TID 20) in 35 ms on 192.168.1.4 (executor 0) (4/7)
41244 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 2
41244 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 2.0 (TID 19) in 37 ms on 192.168.1.4 (executor 0) (5/7)
41244 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 1
41244 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 2.0 (TID 22) in 34 ms on 192.168.1.4 (executor 0) (6/7)
41245 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_2.0, runningTasks: 0
41245 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 2.0 (TID 17) in 40 ms on 192.168.1.4 (executor 0) (7/7)
41245 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 2.0, whose tasks have all completed, from pool 
41245 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 2 (zipWithIndex at SparkUtils.java:391) finished in 0.041 s
41245 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 2, remaining stages = 0
41246 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 2 finished: zipWithIndex at SparkUtils.java:391, took 0.048356 s
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41256 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41257 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
41279 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3 stored as values in memory (estimated size 33.0 KB, free 366.3 MB)
41279 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_3 locally took  14 ms
41279 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_3 without replication took  14 ms
41296 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(1)
41297 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 1
41297 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 1
41302 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 1
41303 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 1
41308 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_1
41309 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1 of size 2504 dropped from memory (free 384051943)
41309 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_1_piece0
41310 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_1_piece0 of size 1571 dropped from memory (free 384053514)
41311 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_1_piece0 on 192.168.1.4:49908 in memory (size: 1571.0 B, free: 366.3 MB)
41311 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_1_piece0
41311 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_1_piece0
41313 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.0 KB, free 366.3 MB)
41313 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_3_piece0 in memory on 192.168.1.4:49908 (size: 5.0 KB, free: 366.3 MB)
41313 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_3_piece0
41313 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_3_piece0
41313 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_3_piece0 locally took  1 ms
41314 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_3_piece0 without replication took  2 ms
41314 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 1, response is 0
41314 [main] INFO org.apache.spark.SparkContext  - Created broadcast 3 from broadcast at ParameterAveragingTrainingMaster.java:259
41315 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
41316 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_1_piece0 on 192.168.1.4:49916 in memory (size: 1571.0 B, free: 365.5 MB)
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41320 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 1
41320 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(2)
41320 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 2
41320 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 2
41320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41320 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 2
41320 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 2
41320 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_2_piece0
41320 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2_piece0 of size 1460 dropped from memory (free 384049825)
41320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41321 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41321 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
41321 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_2_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.3 MB)
41321 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_2_piece0
41321 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_2_piece0
41321 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_2
41321 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_2 of size 2216 dropped from memory (free 384052041)
41321 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 2, response is 0
41321 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
41322 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_2_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.5 MB)
41324 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 2
41324 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(0)
41324 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 0
41324 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 0
41325 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 0
41325 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 0
41325 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_0_piece0
41325 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0_piece0 of size 1006 dropped from memory (free 384053047)
41326 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_0_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
41326 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_0_piece0
41326 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_0_piece0
41326 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_0
41326 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_0 of size 1448 dropped from memory (free 384054495)
41326 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 0, response is 0
41326 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
41327 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_0_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.5 MB)
41329 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 0
41333 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
41333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41333 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41334 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
41335 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41336 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
41337 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41338 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
41344 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41345 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41346 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41349 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41350 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41351 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41352 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41352 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41352 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41353 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41354 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41354 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41354 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41355 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41356 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41356 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41356 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
41357 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
41358 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
41358 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
41358 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
41359 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
41361 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 0 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
41364 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 5 (mapToPair at SparkUtils.java:391)
41365 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 10 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
41365 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 3 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
41365 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 5 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
41365 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 4)
41365 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 4)
41365 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 5)
41365 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 4)
41366 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 4)
41366 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 3)
41366 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 3)
41366 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
41366 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 3 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:391), which has no missing parents
41366 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 3)
41373 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 366.3 MB)
41373 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_4 locally took  1 ms
41373 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_4 without replication took  1 ms
41374 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.3 MB)
41374 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_4_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
41375 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_4_piece0
41375 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_4_piece0
41375 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_4_piece0 locally took  1 ms
41375 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_4_piece0 without replication took  1 ms
41375 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
41377 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
41377 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 3.0 with 8 tasks
41377 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 3.0: 0
41377 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 3.0: PROCESS_LOCAL, NODE_LOCAL, ANY
41378 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 0
41380 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 3 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
41380 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 3.0 (TID 23, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
41381 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 3.0 (TID 24, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
41382 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 3.0 (TID 25, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
41383 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 3.0 (TID 26, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
41384 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 3.0 (TID 27, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
41384 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 3.0 (TID 28, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
41385 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 3.0 (TID 29, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
41386 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 3.0 (TID 30, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
41387 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 23 on executor id: 0 hostname: 192.168.1.4.
41387 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 24 on executor id: 0 hostname: 192.168.1.4.
41387 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 25 on executor id: 0 hostname: 192.168.1.4.
41387 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 26 on executor id: 0 hostname: 192.168.1.4.
41388 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 27 on executor id: 0 hostname: 192.168.1.4.
41388 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 28 on executor id: 0 hostname: 192.168.1.4.
41388 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 29 on executor id: 0 hostname: 192.168.1.4.
41388 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 30 on executor id: 0 hostname: 192.168.1.4.
41401 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_4_piece0 as bytes
41401 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_4_piece0 is StorageLevel(disk, memory, 1 replicas)
41406 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_4_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.5 MB)
41471 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 7
41471 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
41471 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
41471 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 6
41472 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 5
41472 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 4
41473 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 3
41473 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 3.0 (TID 24) in 93 ms on 192.168.1.4 (executor 0) (1/8)
41473 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 3.0 (TID 29) in 89 ms on 192.168.1.4 (executor 0) (2/8)
41473 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 3.0 (TID 25) in 92 ms on 192.168.1.4 (executor 0) (3/8)
41473 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 3.0 (TID 28) in 89 ms on 192.168.1.4 (executor 0) (4/8)
41474 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 2
41474 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 3.0 (TID 30) in 89 ms on 192.168.1.4 (executor 0) (5/8)
41474 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 3.0 (TID 27) in 91 ms on 192.168.1.4 (executor 0) (6/8)
41474 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 1
41474 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41474 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 3.0 (TID 26) in 92 ms on 192.168.1.4 (executor 0) (7/8)
41474 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41475 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41475 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41476 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41476 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41476 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41479 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_3.0, runningTasks: 0
41479 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 3.0 (TID 23) in 101 ms on 192.168.1.4 (executor 0) (8/8)
41479 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 3.0, whose tasks have all completed, from pool 
41480 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
41480 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 3 (mapToPair at SparkUtils.java:391) finished in 0.103 s
41480 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
41481 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
41481 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 5, ShuffleMapStage 4)
41482 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
41483 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 1
41486 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 4)
41486 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
41486 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
41486 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 4)
41495 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5 stored as values in memory (estimated size 6.6 KB, free 366.3 MB)
41495 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_5 locally took  0 ms
41495 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_5 without replication took  0 ms
41496 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
41497 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_5_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
41497 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_5_piece0
41497 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_5_piece0
41497 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_5_piece0 locally took  1 ms
41497 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_5_piece0 without replication took  1 ms
41497 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
41498 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
41498 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 4.0 with 8 tasks
41498 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 4.0: 1
41498 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 4.0: NODE_LOCAL, ANY
41499 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 0
41499 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 4.0 (TID 31, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
41500 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 4.0 (TID 32, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
41500 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 4.0 (TID 33, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
41500 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 4.0 (TID 34, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
41500 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 4.0 (TID 35, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
41500 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 4.0 (TID 36, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
41501 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 4.0 (TID 37, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
41501 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 4.0 (TID 38, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
41501 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 31 on executor id: 0 hostname: 192.168.1.4.
41501 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 32 on executor id: 0 hostname: 192.168.1.4.
41501 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 33 on executor id: 0 hostname: 192.168.1.4.
41502 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 34 on executor id: 0 hostname: 192.168.1.4.
41502 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 35 on executor id: 0 hostname: 192.168.1.4.
41502 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 36 on executor id: 0 hostname: 192.168.1.4.
41502 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 37 on executor id: 0 hostname: 192.168.1.4.
41502 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 38 on executor id: 0 hostname: 192.168.1.4.
41509 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_5_piece0 as bytes
41509 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_5_piece0 is StorageLevel(disk, memory, 1 replicas)
41512 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_5_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.5 MB)
41558 [dispatcher-event-loop-3] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 1 to 192.168.1.4:49914
41559 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 1 to 192.168.1.4:49914
41560 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 1
41560 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 1
41562 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 1 is 186 bytes
41588 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_3_piece0 as bytes
41588 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_3_piece0 is StorageLevel(disk, memory, 1 replicas)
41590 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_3_piece0 in memory on 192.168.1.4:49916 (size: 5.0 KB, free: 365.4 MB)
42378 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
43378 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
44380 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
45378 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
46379 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
47377 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
48376 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
49380 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
50376 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
51376 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
52376 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 8
53098 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 7
53098 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
53099 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 4.0 (TID 34) in 11599 ms on 192.168.1.4 (executor 0) (1/8)
53099 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
53376 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 7
53925 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 6
53925 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 4.0 (TID 37) in 12425 ms on 192.168.1.4 (executor 0) (2/8)
53926 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54121 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 5
54122 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 4.0 (TID 38) in 12621 ms on 192.168.1.4 (executor 0) (3/8)
54122 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54218 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 4
54219 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 4.0 (TID 36) in 12719 ms on 192.168.1.4 (executor 0) (4/8)
54219 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54315 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 3
54315 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 4.0 (TID 31) in 12816 ms on 192.168.1.4 (executor 0) (5/8)
54316 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54376 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 3
54382 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 2
54382 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 4.0 (TID 33) in 12882 ms on 192.168.1.4 (executor 0) (6/8)
54383 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54418 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 1
54418 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 4.0 (TID 35) in 12918 ms on 192.168.1.4 (executor 0) (7/8)
54419 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54462 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_4.0, runningTasks: 0
54462 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 4.0 (TID 32) in 12962 ms on 192.168.1.4 (executor 0) (8/8)
54462 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 4.0, whose tasks have all completed, from pool 
54462 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
54462 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 4 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 12.963 s
54462 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
54463 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
54463 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 5)
54463 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
54463 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 2
54463 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 5)
54463 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54463 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 5 (MapPartitionsRDD[12] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
54463 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 5)
54465 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
54466 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_6 locally took  1 ms
54466 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_6 without replication took  1 ms
54467 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
54467 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_6_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
54467 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_6_piece0
54467 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_6_piece0
54467 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_6_piece0 locally took  1 ms
54467 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_6_piece0 without replication took  1 ms
54467 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
54468 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
54468 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 5.0 with 2 tasks
54468 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 5.0: 2
54468 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 5.0: NODE_LOCAL, ANY
54468 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_5.0, runningTasks: 0
54469 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 5.0 (TID 39, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
54469 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 5.0 (TID 40, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
54469 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
54469 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 39 on executor id: 0 hostname: 192.168.1.4.
54469 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 40 on executor id: 0 hostname: 192.168.1.4.
54475 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_6_piece0 as bytes
54475 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_6_piece0 is StorageLevel(disk, memory, 1 replicas)
54477 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_6_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
54485 [dispatcher-event-loop-3] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 0 to 192.168.1.4:49914
54485 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 0 to 192.168.1.4:49914
54485 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 0
54485 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 0
54485 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 0 is 159 bytes
54570 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_5.0, runningTasks: 1
54571 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_5.0, runningTasks: 0
54574 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 5.0 (TID 39) in 105 ms on 192.168.1.4 (executor 0) (1/2)
54574 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 5.0 (TID 40) in 105 ms on 192.168.1.4 (executor 0) (2/2)
54574 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 5.0, whose tasks have all completed, from pool 
54575 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 5 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.107 s
54575 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 5, remaining stages = 2
54575 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 4, remaining stages = 1
54575 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 3, remaining stages = 0
54576 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 3 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 13.217791 s
54578 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
54681 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
54681 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_7 locally took  1 ms
54681 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_7 without replication took  1 ms
54682 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
54682 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_7_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
54683 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_7_piece0
54683 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_7_piece0
54683 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_7_piece0 locally took  1 ms
54683 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_7_piece0 without replication took  1 ms
54683 [main] INFO org.apache.spark.SparkContext  - Created broadcast 7 from broadcast at SparkDl4jMultiLayer.java:595
54685 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
54685 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_8 locally took  2 ms
54686 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_8 without replication took  2 ms
54687 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
54687 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_8_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
54687 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_8_piece0
54687 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_8_piece0
54687 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_8_piece0 locally took  1 ms
54687 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_8_piece0 without replication took  1 ms
54687 [main] INFO org.apache.spark.SparkContext  - Created broadcast 8 from broadcast at SparkDl4jMultiLayer.java:596
54688 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
54699 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54701 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54702 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54702 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54702 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54702 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54703 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
54705 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
54705 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54705 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
54705 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
54705 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54705 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
54706 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
54706 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
54706 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
54706 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54706 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54706 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54707 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54707 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54707 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54708 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54709 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54710 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54712 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
54714 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
54716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
54717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
54717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
54717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
54717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
54717 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
54718 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 2 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
54718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 15 (treeAggregate at SparkDl4jMultiLayer.java:598)
54718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 4 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
54718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 7 (treeAggregate at SparkDl4jMultiLayer.java:598)
54718 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 6)
54719 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 6)
54719 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 7)
54719 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 6)
54719 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 6)
54719 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
54719 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
54719 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 6)
54721 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9 stored as values in memory (estimated size 9.0 KB, free 366.2 MB)
54721 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_9 locally took  0 ms
54721 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_9 without replication took  0 ms
54722 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.2 MB)
54723 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_9_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
54723 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_9_piece0
54723 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_9_piece0
54723 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_9_piece0 locally took  1 ms
54723 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_9_piece0 without replication took  1 ms
54723 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
54724 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
54724 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 6.0 with 8 tasks
54724 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 6.0: 2
54724 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 6.0: NO_PREF, ANY
54724 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 0
54725 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 6.0 (TID 41, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
54725 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 6.0 (TID 42, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
54726 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 6.0 (TID 43, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
54726 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 6.0 (TID 44, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
54727 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 6.0 (TID 45, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
54727 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 6.0 (TID 46, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
54728 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 6.0 (TID 47, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
54728 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 6.0 (TID 48, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
54729 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 41 on executor id: 0 hostname: 192.168.1.4.
54729 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 42 on executor id: 0 hostname: 192.168.1.4.
54729 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 43 on executor id: 0 hostname: 192.168.1.4.
54729 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 44 on executor id: 0 hostname: 192.168.1.4.
54730 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 45 on executor id: 0 hostname: 192.168.1.4.
54730 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 46 on executor id: 0 hostname: 192.168.1.4.
54730 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 47 on executor id: 0 hostname: 192.168.1.4.
54730 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 48 on executor id: 0 hostname: 192.168.1.4.
54736 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_9_piece0 as bytes
54737 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_9_piece0 is StorageLevel(disk, memory, 1 replicas)
54770 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_9_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
54803 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_8_piece0 as bytes
54803 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_8_piece0 is StorageLevel(disk, memory, 1 replicas)
54806 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_8_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
54853 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_7_piece0 as bytes
54853 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_7_piece0 is StorageLevel(disk, memory, 1 replicas)
54855 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_7_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
55383 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 8
55850 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 7
55850 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
55850 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 6.0 (TID 41) in 1126 ms on 192.168.1.4 (executor 0) (1/8)
55851 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
55863 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 6
55864 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 6.0 (TID 48) in 1136 ms on 192.168.1.4 (executor 0) (2/8)
55864 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56082 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 5
56082 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 6.0 (TID 44) in 1356 ms on 192.168.1.4 (executor 0) (3/8)
56082 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 4
56082 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 6.0 (TID 45) in 1356 ms on 192.168.1.4 (executor 0) (4/8)
56082 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56083 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56101 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 3
56101 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 6.0 (TID 43) in 1376 ms on 192.168.1.4 (executor 0) (5/8)
56101 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56109 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 2
56110 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 6.0 (TID 47) in 1383 ms on 192.168.1.4 (executor 0) (6/8)
56110 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56115 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 1
56115 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 6.0 (TID 42) in 1390 ms on 192.168.1.4 (executor 0) (7/8)
56115 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56116 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_6.0, runningTasks: 0
56116 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 6.0 (TID 46) in 1389 ms on 192.168.1.4 (executor 0) (8/8)
56116 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 6.0, whose tasks have all completed, from pool 
56117 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56117 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 6 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 1.393 s
56117 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
56117 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
56117 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 7)
56117 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
56117 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 3
56117 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 7)
56117 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
56117 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 7 (MapPartitionsRDD[17] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
56117 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 7)
56119 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
56119 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_10 locally took  1 ms
56119 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_10 without replication took  1 ms
56120 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
56120 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_10_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
56120 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_10_piece0
56120 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_10_piece0
56120 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_10_piece0 locally took  0 ms
56120 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_10_piece0 without replication took  0 ms
56121 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
56121 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
56121 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 7.0 with 2 tasks
56121 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 7.0: 3
56121 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 7.0: NODE_LOCAL, ANY
56121 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_7.0, runningTasks: 0
56122 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 7.0 (TID 49, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
56122 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 7.0 (TID 50, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
56122 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
56122 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 49 on executor id: 0 hostname: 192.168.1.4.
56122 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 50 on executor id: 0 hostname: 192.168.1.4.
56127 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_10_piece0 as bytes
56127 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_10_piece0 is StorageLevel(disk, memory, 1 replicas)
56130 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_10_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
56134 [dispatcher-event-loop-4] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 2 to 192.168.1.4:49914
56134 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 2 to 192.168.1.4:49914
56134 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 2
56134 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 2
56134 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 2 is 159 bytes
56144 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_7.0, runningTasks: 1
56147 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_7.0, runningTasks: 0
56151 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 7.0 (TID 49) in 30 ms on 192.168.1.4 (executor 0) (1/2)
56151 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 7.0 (TID 50) in 29 ms on 192.168.1.4 (executor 0) (2/2)
56151 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 7.0, whose tasks have all completed, from pool 
56151 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 7 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.030 s
56151 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 7, remaining stages = 1
56151 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 6, remaining stages = 0
56155 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 4 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 1.437837 s
56157 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 0: Accuracy = 0.19, F1 = 0.32
56157 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 0
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56157 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56158 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56158 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56158 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56158 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
56158 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
56158 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56159 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
56159 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
56160 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 5 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
56160 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 8 (count at ParameterAveragingTrainingMaster.java:325)
56160 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
56160 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
56160 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 8)
56160 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
56160 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 8 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
56160 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 8)
56161 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
56162 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_11 locally took  0 ms
56162 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_11 without replication took  1 ms
56162 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
56163 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_11_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.3 MB)
56163 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_11_piece0
56163 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_11_piece0
56163 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_11_piece0 locally took  1 ms
56163 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_11_piece0 without replication took  1 ms
56163 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
56164 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 8 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
56164 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 8.0 with 8 tasks
56164 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 8.0: 3
56164 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 8.0: PROCESS_LOCAL, NODE_LOCAL, ANY
56164 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 0
56165 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 8 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
56165 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 8.0 (TID 51, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
56166 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 8.0 (TID 52, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
56167 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 8.0 (TID 53, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
56168 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 8.0 (TID 54, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
56169 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 8.0 (TID 55, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
56169 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 8.0 (TID 56, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
56170 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 8.0 (TID 57, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
56171 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 8.0 (TID 58, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
56171 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 51 on executor id: 0 hostname: 192.168.1.4.
56172 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 52 on executor id: 0 hostname: 192.168.1.4.
56172 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 53 on executor id: 0 hostname: 192.168.1.4.
56172 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 54 on executor id: 0 hostname: 192.168.1.4.
56172 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 55 on executor id: 0 hostname: 192.168.1.4.
56172 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 56 on executor id: 0 hostname: 192.168.1.4.
56173 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 57 on executor id: 0 hostname: 192.168.1.4.
56173 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 58 on executor id: 0 hostname: 192.168.1.4.
56181 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_11_piece0 as bytes
56181 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_11_piece0 is StorageLevel(disk, memory, 1 replicas)
56183 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_11_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
56189 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 7
56189 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
56189 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
56189 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 8.0 (TID 53) in 23 ms on 192.168.1.4 (executor 0) (1/8)
56189 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 6
56189 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 8.0 (TID 55) in 21 ms on 192.168.1.4 (executor 0) (2/8)
56190 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 5
56190 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 8.0 (TID 56) in 21 ms on 192.168.1.4 (executor 0) (3/8)
56191 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 4
56191 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 8.0 (TID 57) in 22 ms on 192.168.1.4 (executor 0) (4/8)
56191 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 3
56192 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 8.0 (TID 54) in 25 ms on 192.168.1.4 (executor 0) (5/8)
56193 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 2
56193 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 8.0 (TID 58) in 23 ms on 192.168.1.4 (executor 0) (6/8)
56194 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 1
56194 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 8.0 (TID 52) in 29 ms on 192.168.1.4 (executor 0) (7/8)
56195 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_8.0, runningTasks: 0
56195 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 8.0 (TID 51) in 31 ms on 192.168.1.4 (executor 0) (8/8)
56195 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 8.0, whose tasks have all completed, from pool 
56195 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 8 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.031 s
56195 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 8, remaining stages = 0
56196 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 5 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.036311 s
56196 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
56196 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56197 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
56198 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
56198 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56199 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
56200 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353
56201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
56202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
56202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
56202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353)
56202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
56202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
56202 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
56203 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353
56204 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
56204 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
56204 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
56204 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353)
56204 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
56204 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
56204 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56205 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
56206 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
56206 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 6 (collect at SparkUtils.java:353) with 8 output partitions
56206 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 9 (collect at SparkUtils.java:353)
56206 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
56206 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
56207 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 9)
56207 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
56207 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 9 (MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
56207 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 9)
56208 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
56208 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_12 locally took  0 ms
56208 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_12 without replication took  0 ms
56209 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
56210 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_12_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.3 MB)
56210 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_12_piece0
56210 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_12_piece0
56210 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_12_piece0 locally took  1 ms
56210 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_12_piece0 without replication took  1 ms
56210 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
56211 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 9 (MapPartitionsRDD[19] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
56211 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 9.0 with 8 tasks
56211 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 9.0: 3
56211 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 9.0: PROCESS_LOCAL, NODE_LOCAL, ANY
56211 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 0
56213 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 9 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
56213 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 9.0 (TID 59, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
56214 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 9.0 (TID 60, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
56215 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 9.0 (TID 61, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
56217 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 9.0 (TID 62, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
56218 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 9.0 (TID 63, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
56220 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 9.0 (TID 64, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
56221 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 9.0 (TID 65, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
56222 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 9.0 (TID 66, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
56222 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 59 on executor id: 0 hostname: 192.168.1.4.
56223 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 60 on executor id: 0 hostname: 192.168.1.4.
56223 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 61 on executor id: 0 hostname: 192.168.1.4.
56223 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 62 on executor id: 0 hostname: 192.168.1.4.
56223 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 63 on executor id: 0 hostname: 192.168.1.4.
56224 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 64 on executor id: 0 hostname: 192.168.1.4.
56224 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 65 on executor id: 0 hostname: 192.168.1.4.
56224 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 66 on executor id: 0 hostname: 192.168.1.4.
56230 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_12_piece0 as bytes
56230 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_12_piece0 is StorageLevel(disk, memory, 1 replicas)
56232 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_12_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
56239 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 7
56239 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
56239 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
56240 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 9.0 (TID 61) in 26 ms on 192.168.1.4 (executor 0) (1/8)
56241 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 6
56241 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 9.0 (TID 62) in 26 ms on 192.168.1.4 (executor 0) (2/8)
56241 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 5
56242 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 9.0 (TID 65) in 22 ms on 192.168.1.4 (executor 0) (3/8)
56242 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 4
56242 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 9.0 (TID 59) in 31 ms on 192.168.1.4 (executor 0) (4/8)
56242 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 3
56242 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 9.0 (TID 60) in 29 ms on 192.168.1.4 (executor 0) (5/8)
56244 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 2
56244 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 9.0 (TID 63) in 27 ms on 192.168.1.4 (executor 0) (6/8)
56244 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 1
56244 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 9.0 (TID 64) in 26 ms on 192.168.1.4 (executor 0) (7/8)
56249 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_9.0, runningTasks: 0
56249 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 9.0 (TID 66) in 28 ms on 192.168.1.4 (executor 0) (8/8)
56249 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 9.0, whose tasks have all completed, from pool 
56249 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 9 (collect at SparkUtils.java:353) finished in 0.038 s
56249 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 9, remaining stages = 0
56249 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 6 finished: collect at SparkUtils.java:353, took 0.043832 s
56250 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56251 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56252 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
56252 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56253 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
56253 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
56254 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 7 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
56254 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 10 (zipWithIndex at SparkUtils.java:391)
56254 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
56254 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
56254 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 10)
56254 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
56254 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 10 (MapPartitionsRDD[18] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
56254 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 10)
56256 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
56256 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_13 locally took  1 ms
56256 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_13 without replication took  1 ms
56257 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
56257 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_13_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
56257 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_13_piece0
56257 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_13_piece0
56258 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_13_piece0 locally took  1 ms
56258 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_13_piece0 without replication took  1 ms
56258 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
56258 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 10 (MapPartitionsRDD[18] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
56258 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 10.0 with 7 tasks
56258 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 10.0: 3
56259 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 10.0: PROCESS_LOCAL, NODE_LOCAL, ANY
56259 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 0
56260 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 10 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
56260 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 10.0 (TID 67, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
56261 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 10.0 (TID 68, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
56262 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 10.0 (TID 69, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
56263 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 10.0 (TID 70, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
56265 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 10.0 (TID 71, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
56266 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 10.0 (TID 72, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
56268 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 10.0 (TID 73, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
56268 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
56268 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
56268 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 67 on executor id: 0 hostname: 192.168.1.4.
56268 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 68 on executor id: 0 hostname: 192.168.1.4.
56268 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 69 on executor id: 0 hostname: 192.168.1.4.
56269 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 70 on executor id: 0 hostname: 192.168.1.4.
56269 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 71 on executor id: 0 hostname: 192.168.1.4.
56269 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 72 on executor id: 0 hostname: 192.168.1.4.
56269 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 73 on executor id: 0 hostname: 192.168.1.4.
56276 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_13_piece0 as bytes
56277 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_13_piece0 is StorageLevel(disk, memory, 1 replicas)
56280 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_13_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.4 MB)
56286 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 6
56286 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 5
56286 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 10.0 (TID 68) in 26 ms on 192.168.1.4 (executor 0) (1/7)
56286 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 10.0 (TID 69) in 24 ms on 192.168.1.4 (executor 0) (2/7)
56288 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 4
56288 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 10.0 (TID 72) in 23 ms on 192.168.1.4 (executor 0) (3/7)
56289 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 3
56289 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 10.0 (TID 73) in 23 ms on 192.168.1.4 (executor 0) (4/7)
56289 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 2
56289 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 10.0 (TID 71) in 26 ms on 192.168.1.4 (executor 0) (5/7)
56290 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 1
56290 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 10.0 (TID 70) in 28 ms on 192.168.1.4 (executor 0) (6/7)
56291 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_10.0, runningTasks: 0
56291 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 10.0 (TID 67) in 32 ms on 192.168.1.4 (executor 0) (7/7)
56291 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 10.0, whose tasks have all completed, from pool 
56291 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 10 (zipWithIndex at SparkUtils.java:391) finished in 0.032 s
56291 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 10, remaining stages = 0
56291 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 7 finished: zipWithIndex at SparkUtils.java:391, took 0.037941 s
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56292 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56293 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
56294 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56295 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
56299 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14 stored as values in memory (estimated size 30.9 KB, free 366.1 MB)
56300 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_14 locally took  4 ms
56300 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_14 without replication took  4 ms
56305 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
56305 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_14_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
56305 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_14_piece0
56305 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_14_piece0
56305 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_14_piece0 locally took  1 ms
56305 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_14_piece0 without replication took  1 ms
56305 [main] INFO org.apache.spark.SparkContext  - Created broadcast 14 from broadcast at ParameterAveragingTrainingMaster.java:259
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
56308 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
56308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
56308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
56308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
56309 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
56313 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
56317 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
56317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56317 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
56318 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56319 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56320 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56321 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56321 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56321 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56321 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56322 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56323 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56323 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56323 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56323 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
56323 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
56324 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
56325 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
56325 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
56325 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
56325 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
56325 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 3 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
56326 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 21 (mapToPair at SparkUtils.java:391)
56326 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 26 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
56326 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 8 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
56326 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 13 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
56326 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 12)
56326 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 12)
56326 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 13)
56326 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 12)
56326 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 12)
56326 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 11)
56326 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 11)
56327 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
56327 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 11 (MapPartitionsRDD[21] at mapToPair at SparkUtils.java:391), which has no missing parents
56327 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 11)
56329 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
56329 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_15 locally took  1 ms
56329 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_15 without replication took  1 ms
56330 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
56330 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_15_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
56331 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_15_piece0
56331 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_15_piece0
56331 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_15_piece0 locally took  1 ms
56331 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_15_piece0 without replication took  1 ms
56331 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
56331 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[21] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
56332 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 11.0 with 8 tasks
56332 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 11.0: 3
56332 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 11.0: PROCESS_LOCAL, NODE_LOCAL, ANY
56332 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 0
56333 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 11 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
56333 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 11.0 (TID 74, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
56335 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 11.0 (TID 75, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
56336 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 11.0 (TID 76, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
56338 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 11.0 (TID 77, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
56339 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 11.0 (TID 78, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
56341 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 11.0 (TID 79, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
56342 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 11.0 (TID 80, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
56344 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 11.0 (TID 81, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
56345 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 74 on executor id: 0 hostname: 192.168.1.4.
56345 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 75 on executor id: 0 hostname: 192.168.1.4.
56346 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 76 on executor id: 0 hostname: 192.168.1.4.
56347 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 77 on executor id: 0 hostname: 192.168.1.4.
56347 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 78 on executor id: 0 hostname: 192.168.1.4.
56348 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 79 on executor id: 0 hostname: 192.168.1.4.
56349 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 80 on executor id: 0 hostname: 192.168.1.4.
56349 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 81 on executor id: 0 hostname: 192.168.1.4.
56359 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_15_piece0 as bytes
56359 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_15_piece0 is StorageLevel(disk, memory, 1 replicas)
56362 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_15_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
56376 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 8
56378 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 7
56378 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
56378 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
56378 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 11.0 (TID 78) in 40 ms on 192.168.1.4 (executor 0) (1/8)
56378 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56379 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 6
56379 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 11.0 (TID 77) in 43 ms on 192.168.1.4 (executor 0) (2/8)
56379 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56379 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 5
56379 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 11.0 (TID 81) in 37 ms on 192.168.1.4 (executor 0) (3/8)
56380 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56384 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 4
56384 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 11.0 (TID 74) in 52 ms on 192.168.1.4 (executor 0) (4/8)
56384 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 3
56384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56384 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 11.0 (TID 80) in 43 ms on 192.168.1.4 (executor 0) (5/8)
56384 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56387 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 2
56387 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 11.0 (TID 79) in 48 ms on 192.168.1.4 (executor 0) (6/8)
56387 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56387 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 1
56387 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 11.0 (TID 76) in 52 ms on 192.168.1.4 (executor 0) (7/8)
56388 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56389 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_11.0, runningTasks: 0
56389 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 11.0 (TID 75) in 56 ms on 192.168.1.4 (executor 0) (8/8)
56389 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 11.0, whose tasks have all completed, from pool 
56389 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
56389 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 11 (mapToPair at SparkUtils.java:391) finished in 0.057 s
56389 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
56389 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
56389 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 12, ResultStage 13)
56389 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
56390 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 4
56390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 12)
56390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
56390 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 12 (MapPartitionsRDD[26] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
56390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 12)
56392 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
56393 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_16 locally took  1 ms
56393 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_16 without replication took  1 ms
56394 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
56394 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_16_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
56394 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_16_piece0
56395 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_16_piece0
56395 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_16_piece0 locally took  1 ms
56395 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_16_piece0 without replication took  1 ms
56395 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
56395 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[26] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
56396 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 12.0 with 8 tasks
56396 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 12.0: 4
56396 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 12.0: NODE_LOCAL, ANY
56396 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 0
56396 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 12.0 (TID 82, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 12.0 (TID 83, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 12.0 (TID 84, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 12.0 (TID 85, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 12.0 (TID 86, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 12.0 (TID 87, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 12.0 (TID 88, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 12.0 (TID 89, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
56397 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 82 on executor id: 0 hostname: 192.168.1.4.
56398 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 83 on executor id: 0 hostname: 192.168.1.4.
56398 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 84 on executor id: 0 hostname: 192.168.1.4.
56398 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 85 on executor id: 0 hostname: 192.168.1.4.
56398 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 86 on executor id: 0 hostname: 192.168.1.4.
56398 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 87 on executor id: 0 hostname: 192.168.1.4.
56398 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 88 on executor id: 0 hostname: 192.168.1.4.
56398 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 89 on executor id: 0 hostname: 192.168.1.4.
56405 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_16_piece0 as bytes
56405 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_16_piece0 is StorageLevel(disk, memory, 1 replicas)
56409 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_16_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.4 MB)
56413 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 4 to 192.168.1.4:49914
56413 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 4 to 192.168.1.4:49914
56413 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 4
56413 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 4
56413 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 4 is 186 bytes
56419 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_14_piece0 as bytes
56419 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_14_piece0 is StorageLevel(disk, memory, 1 replicas)
56421 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_14_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
57376 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 8
58376 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 8
58603 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 7
58603 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
58603 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 12.0 (TID 89) in 2206 ms on 192.168.1.4 (executor 0) (1/8)
58604 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
59378 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 7
59973 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 6
59973 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 12.0 (TID 87) in 3576 ms on 192.168.1.4 (executor 0) (2/8)
59973 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
60082 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 5
60082 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 12.0 (TID 88) in 3685 ms on 192.168.1.4 (executor 0) (3/8)
60082 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
60377 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 5
60543 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 4
60544 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 12.0 (TID 85) in 4147 ms on 192.168.1.4 (executor 0) (4/8)
60544 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
60554 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 3
60554 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 12.0 (TID 86) in 4157 ms on 192.168.1.4 (executor 0) (5/8)
60555 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
60610 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 2
60610 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 12.0 (TID 82) in 4214 ms on 192.168.1.4 (executor 0) (6/8)
60611 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
60643 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 1
60643 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 12.0 (TID 84) in 4246 ms on 192.168.1.4 (executor 0) (7/8)
60643 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
60651 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_12.0, runningTasks: 0
60651 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 12.0 (TID 83) in 4255 ms on 192.168.1.4 (executor 0) (8/8)
60651 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 12.0, whose tasks have all completed, from pool 
60651 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
60651 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 12 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.255 s
60651 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
60651 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
60651 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 13)
60651 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
60651 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 5
60651 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 13)
60651 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
60651 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 13 (MapPartitionsRDD[28] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
60651 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 13)
60653 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
60653 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_17 locally took  1 ms
60653 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_17 without replication took  1 ms
60654 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
60654 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_17_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
60654 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_17_piece0
60654 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_17_piece0
60654 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_17_piece0 locally took  1 ms
60654 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_17_piece0 without replication took  1 ms
60654 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
60655 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[28] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
60655 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 13.0 with 2 tasks
60655 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 13.0: 5
60655 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 13.0: NODE_LOCAL, ANY
60656 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_13.0, runningTasks: 0
60656 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 13.0 (TID 90, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
60656 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 13.0 (TID 91, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
60656 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
60657 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 90 on executor id: 0 hostname: 192.168.1.4.
60657 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 91 on executor id: 0 hostname: 192.168.1.4.
60664 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_17_piece0 as bytes
60664 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_17_piece0 is StorageLevel(disk, memory, 1 replicas)
60666 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_17_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
60669 [dispatcher-event-loop-4] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 3 to 192.168.1.4:49914
60669 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 3 to 192.168.1.4:49914
60669 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 3
60669 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 3
60669 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 3 is 159 bytes
60710 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_13.0, runningTasks: 1
60711 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_13.0, runningTasks: 0
60711 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 13.0 (TID 90) in 55 ms on 192.168.1.4 (executor 0) (1/2)
60711 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 13.0 (TID 91) in 55 ms on 192.168.1.4 (executor 0) (2/2)
60712 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 13.0, whose tasks have all completed, from pool 
60712 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 13 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.057 s
60712 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 11, remaining stages = 2
60712 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 13, remaining stages = 1
60712 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 12, remaining stages = 0
60712 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 8 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.387575 s
60713 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
60715 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
60715 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_18 locally took  0 ms
60715 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_18 without replication took  0 ms
60716 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
60716 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_18_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
60716 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_18_piece0
60716 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_18_piece0
60717 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_18_piece0 locally took  1 ms
60717 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_18_piece0 without replication took  1 ms
60717 [main] INFO org.apache.spark.SparkContext  - Created broadcast 18 from broadcast at SparkDl4jMultiLayer.java:595
60718 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
60718 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_19 locally took  1 ms
60718 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_19 without replication took  1 ms
60719 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
60720 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_19_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
60720 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_19_piece0
60720 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_19_piece0
60720 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_19_piece0 locally took  1 ms
60720 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_19_piece0 without replication took  1 ms
60720 [main] INFO org.apache.spark.SparkContext  - Created broadcast 19 from broadcast at SparkDl4jMultiLayer.java:596
60720 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
60722 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
60722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
60725 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
60728 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
60732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
60732 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
60733 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 5 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
60733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 31 (treeAggregate at SparkDl4jMultiLayer.java:598)
60733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 9 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
60733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 15 (treeAggregate at SparkDl4jMultiLayer.java:598)
60733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 14)
60733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 14)
60733 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 15)
60733 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 14)
60733 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 14)
60733 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
60733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 14 (MapPartitionsRDD[31] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
60733 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 14)
60735 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20 stored as values in memory (estimated size 9.0 KB, free 366.1 MB)
60735 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_20 locally took  1 ms
60735 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_20 without replication took  1 ms
60736 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.1 MB)
60737 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_20_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
60737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_20_piece0
60737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_20_piece0
60737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_20_piece0 locally took  1 ms
60737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_20_piece0 without replication took  1 ms
60737 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
60737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[31] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
60737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 14.0 with 8 tasks
60738 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 14.0: 5
60738 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 14.0: NO_PREF, ANY
60738 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 0
60738 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 14.0 (TID 92, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
60738 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 14.0 (TID 93, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
60739 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 14.0 (TID 94, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
60739 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 14.0 (TID 95, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
60739 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 14.0 (TID 96, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
60740 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 14.0 (TID 97, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
60740 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 14.0 (TID 98, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
60740 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 14.0 (TID 99, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 92 on executor id: 0 hostname: 192.168.1.4.
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 93 on executor id: 0 hostname: 192.168.1.4.
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 94 on executor id: 0 hostname: 192.168.1.4.
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 95 on executor id: 0 hostname: 192.168.1.4.
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 96 on executor id: 0 hostname: 192.168.1.4.
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 97 on executor id: 0 hostname: 192.168.1.4.
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 98 on executor id: 0 hostname: 192.168.1.4.
60741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 99 on executor id: 0 hostname: 192.168.1.4.
60747 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_20_piece0 as bytes
60747 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_20_piece0 is StorageLevel(disk, memory, 1 replicas)
60750 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_20_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
60756 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_19_piece0 as bytes
60756 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_19_piece0 is StorageLevel(disk, memory, 1 replicas)
60758 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_19_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
60777 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_18_piece0 as bytes
60777 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_18_piece0 is StorageLevel(disk, memory, 1 replicas)
60779 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_18_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
61014 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 7
61014 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
61014 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 14.0 (TID 99) in 274 ms on 192.168.1.4 (executor 0) (1/8)
61015 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61311 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 6
61311 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 14.0 (TID 92) in 573 ms on 192.168.1.4 (executor 0) (2/8)
61312 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61368 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 5
61368 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 14.0 (TID 98) in 628 ms on 192.168.1.4 (executor 0) (3/8)
61369 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61377 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 5
61403 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 4
61404 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 14.0 (TID 97) in 664 ms on 192.168.1.4 (executor 0) (4/8)
61404 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61479 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 3
61480 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 14.0 (TID 95) in 741 ms on 192.168.1.4 (executor 0) (5/8)
61480 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61498 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 2
61498 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 14.0 (TID 96) in 759 ms on 192.168.1.4 (executor 0) (6/8)
61498 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61511 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 1
61512 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 14.0 (TID 94) in 774 ms on 192.168.1.4 (executor 0) (7/8)
61512 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61542 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_14.0, runningTasks: 0
61543 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 14.0 (TID 93) in 805 ms on 192.168.1.4 (executor 0) (8/8)
61543 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 14.0, whose tasks have all completed, from pool 
61543 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61543 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 14 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.805 s
61543 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
61543 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
61543 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 15)
61543 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
61543 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 6
61543 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 15)
61543 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
61543 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 15 (MapPartitionsRDD[33] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
61543 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 15)
61545 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
61545 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_21 locally took  1 ms
61545 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_21 without replication took  1 ms
61546 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
61546 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_21_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
61546 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_21_piece0
61546 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_21_piece0
61546 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_21_piece0 locally took  1 ms
61546 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_21_piece0 without replication took  1 ms
61546 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
61547 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
61547 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 15.0 with 2 tasks
61547 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 15.0: 6
61547 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 15.0: NODE_LOCAL, ANY
61547 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_15.0, runningTasks: 0
61548 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 15.0 (TID 100, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
61548 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 15.0 (TID 101, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
61548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
61548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 100 on executor id: 0 hostname: 192.168.1.4.
61548 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 101 on executor id: 0 hostname: 192.168.1.4.
61552 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_21_piece0 as bytes
61552 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_21_piece0 is StorageLevel(disk, memory, 1 replicas)
61553 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_21_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
61556 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 5 to 192.168.1.4:49914
61556 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 5 to 192.168.1.4:49914
61556 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 5
61556 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 5
61556 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 5 is 159 bytes
61561 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_15.0, runningTasks: 1
61561 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_15.0, runningTasks: 0
61561 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 15.0 (TID 100) in 14 ms on 192.168.1.4 (executor 0) (1/2)
61562 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 15.0 (TID 101) in 14 ms on 192.168.1.4 (executor 0) (2/2)
61562 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 15.0, whose tasks have all completed, from pool 
61562 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 15 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.015 s
61562 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 14, remaining stages = 1
61562 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 15, remaining stages = 0
61563 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 9 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.830224 s
61563 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 1: Accuracy = 0.19, F1 = 0.32
61563 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 1
61563 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
61565 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
61566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 10 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
61566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 16 (count at ParameterAveragingTrainingMaster.java:325)
61566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
61566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
61566 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 16)
61566 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
61566 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 16 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
61566 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 16)
61567 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
61567 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_22 locally took  0 ms
61567 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_22 without replication took  0 ms
61576 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(10)
61576 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 10
61576 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 10
61576 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
61576 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 10
61576 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 10
61576 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_10_piece0
61576 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10_piece0 of size 2120 dropped from memory (free 383844793)
61576 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_22_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.3 MB)
61577 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_22_piece0
61577 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_22_piece0
61577 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_22_piece0 locally took  1 ms
61577 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_22_piece0 without replication took  1 ms
61577 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_10_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
61577 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
61577 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_10_piece0
61577 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_10_piece0
61577 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_10
61577 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_10 of size 3656 dropped from memory (free 383848449)
61577 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 10, response is 0
61577 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 16 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
61577 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 16.0 with 8 tasks
61577 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61577 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 16.0: 6
61577 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 16.0: PROCESS_LOCAL, NODE_LOCAL, ANY
61578 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 0
61578 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_10_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
61579 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 16 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
61579 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 16.0 (TID 102, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
61579 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 10
61579 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(18)
61579 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 18
61579 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 18
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 18
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 18
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_18_piece0
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18_piece0 of size 1428 dropped from memory (free 383849877)
61580 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 16.0 (TID 103, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
61580 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_18_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.3 MB)
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_18_piece0
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_18_piece0
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_18
61580 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_18 of size 8224 dropped from memory (free 383858101)
61581 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 18, response is 0
61581 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61581 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 16.0 (TID 104, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
61581 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_18_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.4 MB)
61582 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 16.0 (TID 105, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
61582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 18
61582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(5)
61582 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 5
61583 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 16.0 (TID 106, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
61584 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 16.0 (TID 107, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
61585 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 5
61585 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 16.0 (TID 108, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
61585 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 5, response is true
61585 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
61586 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 5
61586 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(1)
61586 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 1
61586 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 1
61586 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 16.0 (TID 109, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
61586 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 1, response is true
61586 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 1
61586 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(6)
61586 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
61586 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 6
61587 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 6
61587 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 102 on executor id: 0 hostname: 192.168.1.4.
61587 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 103 on executor id: 0 hostname: 192.168.1.4.
61587 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 104 on executor id: 0 hostname: 192.168.1.4.
61587 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 105 on executor id: 0 hostname: 192.168.1.4.
61587 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 6
61587 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 6
61587 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_6
61588 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6 of size 3672 dropped from memory (free 383861773)
61588 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 106 on executor id: 0 hostname: 192.168.1.4.
61588 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_6_piece0
61588 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_6_piece0 of size 2134 dropped from memory (free 383863907)
61588 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 107 on executor id: 0 hostname: 192.168.1.4.
61588 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 108 on executor id: 0 hostname: 192.168.1.4.
61588 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 109 on executor id: 0 hostname: 192.168.1.4.
61589 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_6_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
61589 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_6_piece0
61589 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_6_piece0
61589 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 6, response is 0
61589 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61591 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_6_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
61592 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 6
61592 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(14)
61592 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 14
61592 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 14
61592 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 14
61592 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 14
61592 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_14_piece0
61593 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14_piece0 of size 5326 dropped from memory (free 383869233)
61593 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_14_piece0 on 192.168.1.4:49908 in memory (size: 5.2 KB, free: 366.3 MB)
61593 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_14_piece0
61593 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_14_piece0
61593 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_14
61593 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_14 of size 31656 dropped from memory (free 383900889)
61593 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 14, response is 0
61593 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61594 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_14_piece0 on 192.168.1.4:49916 in memory (size: 5.2 KB, free: 365.4 MB)
61595 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 14
61595 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(3)
61595 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 3
61595 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 3
61595 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 3, response is true
61595 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 3
61595 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(8)
61595 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
61595 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 8
61595 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 8
61596 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_22_piece0 as bytes
61596 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_22_piece0 is StorageLevel(disk, memory, 1 replicas)
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 8
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 8
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_8_piece0
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8_piece0 of size 2531 dropped from memory (free 383903420)
61596 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_8_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_8_piece0
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_8_piece0
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_8
61596 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_8 of size 27528 dropped from memory (free 383930948)
61597 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 8, response is 0
61597 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61598 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_8_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.4 MB)
61598 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_22_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
61601 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 8
61602 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(2)
61602 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 2
61602 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 2
61602 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(13)
61602 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 13
61602 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 13
61602 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 2
61602 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 2, response is true
61602 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 13
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 13
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_13_piece0
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13_piece0 of size 1460 dropped from memory (free 383932408)
61603 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_13_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.3 MB)
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_13_piece0
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_13_piece0
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_13
61603 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_13 of size 2216 dropped from memory (free 383934624)
61604 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 13, response is 0
61604 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61604 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_13_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
61605 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 7
61605 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
61605 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
61605 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 16.0 (TID 109) in 20 ms on 192.168.1.4 (executor 0) (1/8)
61606 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 13
61606 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(3)
61606 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 3
61606 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 3
61606 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 3
61606 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 3
61606 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_3_piece0
61606 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3_piece0 of size 5149 dropped from memory (free 383939773)
61606 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_3_piece0 on 192.168.1.4:49908 in memory (size: 5.0 KB, free: 366.3 MB)
61607 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_3_piece0
61607 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_3_piece0
61607 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_3
61607 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_3 of size 33744 dropped from memory (free 383973517)
61607 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 3, response is 0
61607 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61607 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_3_piece0 on 192.168.1.4:49916 in memory (size: 5.0 KB, free: 365.4 MB)
61608 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 3
61608 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(5)
61608 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 5
61608 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 5
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 5
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 5
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_5
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5 of size 6712 dropped from memory (free 383980229)
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_5_piece0
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_5_piece0 of size 3631 dropped from memory (free 383983860)
61609 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_5_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.3 MB)
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_5_piece0
61609 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_5_piece0
61609 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 5, response is 0
61609 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61610 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_5_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.4 MB)
61611 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 5
61611 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(12)
61611 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 12
61611 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 12
61611 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 12
61611 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 12
61611 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_12
61612 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12 of size 2504 dropped from memory (free 383986364)
61612 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_12_piece0
61612 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_12_piece0 of size 1570 dropped from memory (free 383987934)
61612 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_12_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
61612 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_12_piece0
61612 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_12_piece0
61612 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 12, response is 0
61612 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61615 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 6
61615 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 16.0 (TID 104) in 35 ms on 192.168.1.4 (executor 0) (2/8)
61616 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 5
61616 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 16.0 (TID 108) in 32 ms on 192.168.1.4 (executor 0) (3/8)
61616 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 4
61617 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 16.0 (TID 105) in 35 ms on 192.168.1.4 (executor 0) (4/8)
61619 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 3
61619 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 16.0 (TID 102) in 41 ms on 192.168.1.4 (executor 0) (5/8)
61619 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_12_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.4 MB)
61619 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 2
61620 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 1
61620 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 16.0 (TID 107) in 37 ms on 192.168.1.4 (executor 0) (6/8)
61620 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 16.0 (TID 106) in 38 ms on 192.168.1.4 (executor 0) (7/8)
61620 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 12
61621 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(20)
61621 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 20
61621 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 20
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 20
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 20
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_20
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20 of size 9208 dropped from memory (free 383997142)
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_20_piece0
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_20_piece0 of size 4224 dropped from memory (free 384001366)
61621 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_20_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.3 MB)
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_20_piece0
61621 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_20_piece0
61622 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 20, response is 0
61622 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61622 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_20_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.4 MB)
61623 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 20
61623 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(4)
61623 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 4
61623 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 4
61623 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 4
61623 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 4, response is true
61623 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(7)
61623 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 7
61623 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 7
61623 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 7
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 7
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_7
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7 of size 8224 dropped from memory (free 384009590)
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_7_piece0
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_7_piece0 of size 1428 dropped from memory (free 384011018)
61624 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_7_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.3 MB)
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_7_piece0
61624 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_7_piece0
61624 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 7, response is 0
61624 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61625 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_7_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.4 MB)
61626 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 7
61626 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(9)
61626 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 9
61626 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 9
61626 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 9
61626 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 9
61626 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_9_piece0
61626 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9_piece0 of size 4226 dropped from memory (free 384015244)
61627 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_9_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.3 MB)
61627 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_9_piece0
61627 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_9_piece0
61627 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_9
61627 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_9 of size 9208 dropped from memory (free 384024452)
61627 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 9, response is 0
61627 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61628 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_9_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.4 MB)
61629 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 9
61629 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(4)
61629 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 4
61629 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 4
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 4
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 4
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_4
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4 of size 3600 dropped from memory (free 384028052)
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_4_piece0
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_4_piece0 of size 2195 dropped from memory (free 384030247)
61629 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_4_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_4_piece0
61629 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_4_piece0
61630 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 4, response is 0
61630 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61630 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_4_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
61631 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 4
61631 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(17)
61631 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 17
61631 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 17
61631 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 17
61631 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 17
61631 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_17_piece0
61631 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17_piece0 of size 2135 dropped from memory (free 384032382)
61632 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_17_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
61632 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_17_piece0
61632 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_17_piece0
61632 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_17
61632 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_17 of size 3672 dropped from memory (free 384036054)
61632 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 17, response is 0
61632 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61633 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_17_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
61634 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 17
61634 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(21)
61634 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 21
61634 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 21
61634 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 21
61634 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 21
61634 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_21
61634 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21 of size 3656 dropped from memory (free 384039710)
61634 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_21_piece0
61635 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_21_piece0 of size 2122 dropped from memory (free 384041832)
61635 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_21_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
61635 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_21_piece0
61635 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_21_piece0
61635 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 21, response is 0
61635 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61636 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_21_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
61637 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 21
61637 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(0)
61637 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 0
61637 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 0
61637 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 0
61637 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 0, response is true
61637 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(15)
61637 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 15
61637 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
61637 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 15
61637 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 15
61637 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 15
61637 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_15
61637 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15 of size 3600 dropped from memory (free 384045432)
61637 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_15_piece0
61638 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_15_piece0 of size 2197 dropped from memory (free 384047629)
61638 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_15_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
61638 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_15_piece0
61638 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_15_piece0
61638 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 15, response is 0
61638 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61638 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_15_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.5 MB)
61639 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 15
61639 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(19)
61639 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 19
61639 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 19
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 19
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 19
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_19_piece0
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19_piece0 of size 2531 dropped from memory (free 384050160)
61640 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_19_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_19_piece0
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_19_piece0
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_19
61640 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_19 of size 27976 dropped from memory (free 384078136)
61640 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 19, response is 0
61640 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61641 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_19_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.5 MB)
61641 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_16.0, runningTasks: 0
61641 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 16.0 (TID 103) in 62 ms on 192.168.1.4 (executor 0) (8/8)
61642 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 16.0, whose tasks have all completed, from pool 
61642 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 16 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.064 s
61642 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 16, remaining stages = 0
61642 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 10 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.076596 s
61642 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 19
61642 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(16)
61642 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 16
61642 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 16
61642 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 16
61642 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 16
61642 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_16_piece0
61642 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
61642 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16_piece0 of size 3632 dropped from memory (free 384081768)
61643 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_16_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.3 MB)
61643 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_16_piece0
61643 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_16_piece0
61643 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_16
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61643 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_16 of size 6712 dropped from memory (free 384088480)
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61643 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 16, response is 0
61643 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61643 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61644 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_16_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.5 MB)
61644 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61644 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61644 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
61644 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
61645 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 16
61645 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(11)
61645 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 11
61645 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 11
61645 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 11
61645 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 11
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
61645 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_11
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
61645 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11 of size 1448 dropped from memory (free 384089928)
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61645 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_11_piece0
61645 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_11_piece0 of size 1006 dropped from memory (free 384090934)
61645 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61645 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_11_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
61646 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_11_piece0
61646 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_11_piece0
61646 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 11, response is 0
61646 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
61646 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61646 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61646 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
61646 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_11_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.5 MB)
61646 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
61647 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 11
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353
61647 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61648 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
61648 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
61648 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
61648 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353)
61648 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
61649 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353
61650 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
61650 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
61650 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
61650 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353)
61650 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
61650 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
61650 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
61652 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
61652 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 11 (collect at SparkUtils.java:353) with 8 output partitions
61652 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 17 (collect at SparkUtils.java:353)
61652 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
61652 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
61653 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 17)
61653 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
61653 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 17 (MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
61653 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 17)
61654 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23 stored as values in memory (estimated size 2.4 KB, free 366.3 MB)
61654 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_23 locally took  1 ms
61654 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_23 without replication took  1 ms
61654 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.3 MB)
61655 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_23_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.3 MB)
61655 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_23_piece0
61655 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_23_piece0
61655 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_23_piece0 locally took  1 ms
61655 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_23_piece0 without replication took  1 ms
61655 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
61656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 17 (MapPartitionsRDD[35] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
61656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 17.0 with 8 tasks
61656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 17.0: 6
61656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 17.0: PROCESS_LOCAL, NODE_LOCAL, ANY
61656 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 0
61657 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 17 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
61657 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 17.0 (TID 110, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
61658 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 17.0 (TID 111, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
61659 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 17.0 (TID 112, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
61660 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 17.0 (TID 113, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
61661 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 17.0 (TID 114, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
61661 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 17.0 (TID 115, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
61662 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 17.0 (TID 116, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
61663 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 17.0 (TID 117, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
61664 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 110 on executor id: 0 hostname: 192.168.1.4.
61664 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 111 on executor id: 0 hostname: 192.168.1.4.
61664 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 112 on executor id: 0 hostname: 192.168.1.4.
61664 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 113 on executor id: 0 hostname: 192.168.1.4.
61664 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 114 on executor id: 0 hostname: 192.168.1.4.
61664 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 115 on executor id: 0 hostname: 192.168.1.4.
61665 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 116 on executor id: 0 hostname: 192.168.1.4.
61665 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 117 on executor id: 0 hostname: 192.168.1.4.
61674 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_23_piece0 as bytes
61675 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_23_piece0 is StorageLevel(disk, memory, 1 replicas)
61680 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_23_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.5 MB)
61685 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 7
61686 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
61686 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
61686 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 17.0 (TID 117) in 24 ms on 192.168.1.4 (executor 0) (1/8)
61686 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 6
61687 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 17.0 (TID 113) in 28 ms on 192.168.1.4 (executor 0) (2/8)
61690 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 5
61690 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 17.0 (TID 114) in 30 ms on 192.168.1.4 (executor 0) (3/8)
61691 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 4
61691 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 17.0 (TID 115) in 30 ms on 192.168.1.4 (executor 0) (4/8)
61692 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 3
61692 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 17.0 (TID 111) in 35 ms on 192.168.1.4 (executor 0) (5/8)
61693 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 2
61693 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 17.0 (TID 112) in 35 ms on 192.168.1.4 (executor 0) (6/8)
61693 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 1
61693 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 17.0 (TID 116) in 31 ms on 192.168.1.4 (executor 0) (7/8)
61696 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_17.0, runningTasks: 0
61696 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 17.0 (TID 110) in 40 ms on 192.168.1.4 (executor 0) (8/8)
61696 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 17.0, whose tasks have all completed, from pool 
61697 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 17 (collect at SparkUtils.java:353) finished in 0.041 s
61697 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 17, remaining stages = 0
61697 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 11 finished: collect at SparkUtils.java:353, took 0.045127 s
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61698 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61699 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61700 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
61700 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
61700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 12 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
61700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 18 (zipWithIndex at SparkUtils.java:391)
61700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
61701 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
61701 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 18)
61701 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
61701 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 18 (MapPartitionsRDD[34] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
61701 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 18)
61702 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24 stored as values in memory (estimated size 2.2 KB, free 366.3 MB)
61702 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_24 locally took  0 ms
61702 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_24 without replication took  0 ms
61703 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.3 MB)
61704 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_24_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
61704 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_24_piece0
61704 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_24_piece0
61704 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_24_piece0 locally took  1 ms
61704 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_24_piece0 without replication took  1 ms
61704 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
61704 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 18 (MapPartitionsRDD[34] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
61704 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 18.0 with 7 tasks
61705 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 18.0: 6
61705 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 18.0: PROCESS_LOCAL, NODE_LOCAL, ANY
61705 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 0
61706 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 18 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
61706 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 18.0 (TID 118, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
61707 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 18.0 (TID 119, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
61707 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 18.0 (TID 120, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
61708 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 18.0 (TID 121, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
61709 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 18.0 (TID 122, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
61710 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 18.0 (TID 123, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
61711 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 18.0 (TID 124, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
61711 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
61711 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
61711 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 118 on executor id: 0 hostname: 192.168.1.4.
61712 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 119 on executor id: 0 hostname: 192.168.1.4.
61712 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 120 on executor id: 0 hostname: 192.168.1.4.
61712 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 121 on executor id: 0 hostname: 192.168.1.4.
61712 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 122 on executor id: 0 hostname: 192.168.1.4.
61712 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 123 on executor id: 0 hostname: 192.168.1.4.
61713 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 124 on executor id: 0 hostname: 192.168.1.4.
61720 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_24_piece0 as bytes
61720 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_24_piece0 is StorageLevel(disk, memory, 1 replicas)
61722 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_24_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.5 MB)
61728 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 6
61728 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 18.0 (TID 124) in 18 ms on 192.168.1.4 (executor 0) (1/7)
61731 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 5
61731 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 18.0 (TID 123) in 22 ms on 192.168.1.4 (executor 0) (2/7)
61733 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 4
61733 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 18.0 (TID 118) in 28 ms on 192.168.1.4 (executor 0) (3/7)
61737 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 3
61737 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 18.0 (TID 122) in 29 ms on 192.168.1.4 (executor 0) (4/7)
61738 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 2
61738 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 18.0 (TID 121) in 31 ms on 192.168.1.4 (executor 0) (5/7)
61738 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 1
61739 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 18.0 (TID 120) in 32 ms on 192.168.1.4 (executor 0) (6/7)
61740 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_18.0, runningTasks: 0
61740 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 18.0 (TID 119) in 34 ms on 192.168.1.4 (executor 0) (7/7)
61740 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 18.0, whose tasks have all completed, from pool 
61740 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 18 (zipWithIndex at SparkUtils.java:391) finished in 0.035 s
61740 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 18, remaining stages = 0
61740 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 12 finished: zipWithIndex at SparkUtils.java:391, took 0.040147 s
61740 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61741 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61742 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61743 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61743 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61743 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61743 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
61745 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25 stored as values in memory (estimated size 30.5 KB, free 366.3 MB)
61745 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_25 locally took  2 ms
61745 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_25 without replication took  2 ms
61747 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.3 MB)
61747 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_25_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
61747 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_25_piece0
61747 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_25_piece0
61747 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_25_piece0 locally took  1 ms
61747 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_25_piece0 without replication took  1 ms
61747 [main] INFO org.apache.spark.SparkContext  - Created broadcast 25 from broadcast at ParameterAveragingTrainingMaster.java:259
61747 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61748 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
61749 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61750 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61751 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61751 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61751 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61751 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
61751 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61752 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
61754 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
61755 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
61756 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
61757 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
61758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
61758 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
61758 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 6 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
61758 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 37 (mapToPair at SparkUtils.java:391)
61759 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 42 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
61759 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 13 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
61759 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 21 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
61759 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 20)
61759 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 20)
61759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 21)
61759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 20)
61759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 20)
61759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 19)
61759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 19)
61759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
61759 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 19 (MapPartitionsRDD[37] at mapToPair at SparkUtils.java:391), which has no missing parents
61759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 19)
61761 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26 stored as values in memory (estimated size 3.5 KB, free 366.3 MB)
61761 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_26 locally took  1 ms
61761 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_26 without replication took  1 ms
61761 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
61762 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_26_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
61762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_26_piece0
61762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_26_piece0
61762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_26_piece0 locally took  1 ms
61762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_26_piece0 without replication took  1 ms
61762 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
61763 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[37] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
61763 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 19.0 with 8 tasks
61763 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 19.0: 6
61764 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 19.0: PROCESS_LOCAL, NODE_LOCAL, ANY
61764 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 0
61765 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 19 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
61765 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 19.0 (TID 125, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
61766 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 19.0 (TID 126, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
61767 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 19.0 (TID 127, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
61768 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 19.0 (TID 128, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
61769 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 19.0 (TID 129, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
61770 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 19.0 (TID 130, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
61772 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 19.0 (TID 131, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
61773 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 19.0 (TID 132, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
61773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 125 on executor id: 0 hostname: 192.168.1.4.
61773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 126 on executor id: 0 hostname: 192.168.1.4.
61773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 127 on executor id: 0 hostname: 192.168.1.4.
61774 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 128 on executor id: 0 hostname: 192.168.1.4.
61774 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 129 on executor id: 0 hostname: 192.168.1.4.
61774 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 130 on executor id: 0 hostname: 192.168.1.4.
61774 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 131 on executor id: 0 hostname: 192.168.1.4.
61774 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 132 on executor id: 0 hostname: 192.168.1.4.
61781 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_26_piece0 as bytes
61781 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_26_piece0 is StorageLevel(disk, memory, 1 replicas)
61783 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_26_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.5 MB)
61796 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 7
61796 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
61796 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
61796 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 19.0 (TID 128) in 29 ms on 192.168.1.4 (executor 0) (1/8)
61797 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61799 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 6
61799 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 19.0 (TID 132) in 27 ms on 192.168.1.4 (executor 0) (2/8)
61799 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61801 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 5
61801 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 19.0 (TID 126) in 36 ms on 192.168.1.4 (executor 0) (3/8)
61801 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61803 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 4
61804 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 19.0 (TID 127) in 38 ms on 192.168.1.4 (executor 0) (4/8)
61804 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 3
61804 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61804 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 19.0 (TID 131) in 34 ms on 192.168.1.4 (executor 0) (5/8)
61804 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61804 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 2
61805 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 19.0 (TID 130) in 36 ms on 192.168.1.4 (executor 0) (6/8)
61805 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 19.0 (TID 129) in 37 ms on 192.168.1.4 (executor 0) (7/8)
61805 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61805 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 1
61805 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61809 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_19.0, runningTasks: 0
61809 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 19.0 (TID 125) in 45 ms on 192.168.1.4 (executor 0) (8/8)
61809 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 19.0, whose tasks have all completed, from pool 
61809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
61809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 19 (mapToPair at SparkUtils.java:391) finished in 0.045 s
61809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
61809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
61809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 20, ResultStage 21)
61809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
61809 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 7
61809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 20)
61809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
61809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 20 (MapPartitionsRDD[42] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
61809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 20)
61811 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27 stored as values in memory (estimated size 6.6 KB, free 366.2 MB)
61811 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_27 locally took  0 ms
61811 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_27 without replication took  0 ms
61812 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
61812 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_27_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
61812 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_27_piece0
61812 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_27_piece0
61812 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_27_piece0 locally took  0 ms
61812 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_27_piece0 without replication took  0 ms
61813 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
61813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[42] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
61813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 20.0 with 8 tasks
61813 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 20.0: 7
61813 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 20.0: NODE_LOCAL, ANY
61813 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 0
61813 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 20.0 (TID 133, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
61813 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 20.0 (TID 134, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
61814 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 20.0 (TID 135, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
61814 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 20.0 (TID 136, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
61814 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 20.0 (TID 137, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
61814 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 20.0 (TID 138, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
61814 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 20.0 (TID 139, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
61814 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 20.0 (TID 140, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
61814 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 133 on executor id: 0 hostname: 192.168.1.4.
61814 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 134 on executor id: 0 hostname: 192.168.1.4.
61814 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 135 on executor id: 0 hostname: 192.168.1.4.
61814 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 136 on executor id: 0 hostname: 192.168.1.4.
61814 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 137 on executor id: 0 hostname: 192.168.1.4.
61815 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 138 on executor id: 0 hostname: 192.168.1.4.
61815 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 139 on executor id: 0 hostname: 192.168.1.4.
61815 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 140 on executor id: 0 hostname: 192.168.1.4.
61818 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_27_piece0 as bytes
61818 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_27_piece0 is StorageLevel(disk, memory, 1 replicas)
61820 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_27_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.5 MB)
61822 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 7 to 192.168.1.4:49914
61822 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 7 to 192.168.1.4:49914
61822 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 7
61822 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 7
61823 [map-output-dispatcher-6] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 7 is 186 bytes
61827 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_25_piece0 as bytes
61827 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_25_piece0 is StorageLevel(disk, memory, 1 replicas)
61828 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_25_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
62376 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 8
63376 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 8
63595 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 7
63595 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
63595 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 20.0 (TID 139) in 1781 ms on 192.168.1.4 (executor 0) (1/8)
63595 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
64376 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 7
65376 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 7
65410 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 6
65410 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 20.0 (TID 140) in 3596 ms on 192.168.1.4 (executor 0) (2/8)
65410 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
65434 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 5
65434 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 20.0 (TID 138) in 3620 ms on 192.168.1.4 (executor 0) (3/8)
65434 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
65672 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 4
65673 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 20.0 (TID 137) in 3859 ms on 192.168.1.4 (executor 0) (4/8)
65673 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
65745 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 3
65745 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 20.0 (TID 133) in 3932 ms on 192.168.1.4 (executor 0) (5/8)
65746 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
65747 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 2
65747 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 20.0 (TID 135) in 3933 ms on 192.168.1.4 (executor 0) (6/8)
65747 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
65766 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 1
65766 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 20.0 (TID 134) in 3953 ms on 192.168.1.4 (executor 0) (7/8)
65766 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
65820 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_20.0, runningTasks: 0
65820 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 20.0 (TID 136) in 4006 ms on 192.168.1.4 (executor 0) (8/8)
65820 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 20.0, whose tasks have all completed, from pool 
65820 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
65820 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 20 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.007 s
65820 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
65820 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
65820 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 21)
65820 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
65820 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 8
65820 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 21)
65820 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
65820 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 21 (MapPartitionsRDD[44] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
65820 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 21)
65823 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
65823 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_28 locally took  2 ms
65823 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_28 without replication took  2 ms
65825 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
65825 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_28_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
65825 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_28_piece0
65825 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_28_piece0
65825 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_28_piece0 locally took  0 ms
65825 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_28_piece0 without replication took  0 ms
65826 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 28 from broadcast at DAGScheduler.scala:1006
65826 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[44] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
65826 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 21.0 with 2 tasks
65826 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 21.0: 8
65826 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 21.0: NODE_LOCAL, ANY
65826 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_21.0, runningTasks: 0
65826 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 21.0 (TID 141, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
65826 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 21.0 (TID 142, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
65826 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
65826 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 141 on executor id: 0 hostname: 192.168.1.4.
65827 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 142 on executor id: 0 hostname: 192.168.1.4.
65830 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_28_piece0 as bytes
65831 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_28_piece0 is StorageLevel(disk, memory, 1 replicas)
65833 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_28_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
65835 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 6 to 192.168.1.4:49914
65835 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 6 to 192.168.1.4:49914
65835 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 6
65835 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 6
65836 [map-output-dispatcher-7] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 6 is 159 bytes
65926 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_21.0, runningTasks: 1
65927 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_21.0, runningTasks: 0
65927 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 21.0 (TID 142) in 101 ms on 192.168.1.4 (executor 0) (1/2)
65927 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 21.0 (TID 141) in 101 ms on 192.168.1.4 (executor 0) (2/2)
65927 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 21.0, whose tasks have all completed, from pool 
65928 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 21 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.102 s
65928 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 20, remaining stages = 2
65928 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 19, remaining stages = 1
65928 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 21, remaining stages = 0
65928 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 13 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.170185 s
65929 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
65931 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
65931 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_29 locally took  0 ms
65931 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_29 without replication took  0 ms
65932 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
65932 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_29_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
65932 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_29_piece0
65932 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_29_piece0
65932 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_29_piece0 locally took  0 ms
65932 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_29_piece0 without replication took  0 ms
65932 [main] INFO org.apache.spark.SparkContext  - Created broadcast 29 from broadcast at SparkDl4jMultiLayer.java:595
65934 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
65934 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_30 locally took  2 ms
65934 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_30 without replication took  2 ms
65935 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
65935 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_30_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
65935 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_30_piece0
65935 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_30_piece0
65935 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_30_piece0 locally took  0 ms
65935 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_30_piece0 without replication took  0 ms
65935 [main] INFO org.apache.spark.SparkContext  - Created broadcast 30 from broadcast at SparkDl4jMultiLayer.java:596
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65936 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65937 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65937 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65937 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65938 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65939 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65940 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
65941 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65942 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
65943 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65944 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65945 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65946 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
65947 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
65948 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
65948 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
65948 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
65948 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
65948 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 8 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
65949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 47 (treeAggregate at SparkDl4jMultiLayer.java:598)
65949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 14 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
65949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 23 (treeAggregate at SparkDl4jMultiLayer.java:598)
65949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 22)
65949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 22)
65949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 23)
65949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 22)
65949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 22)
65949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
65949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 22 (MapPartitionsRDD[47] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
65949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 22)
65950 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31 stored as values in memory (estimated size 9.0 KB, free 366.2 MB)
65950 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_31 locally took  0 ms
65951 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_31 without replication took  0 ms
65951 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.2 MB)
65951 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_31_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
65952 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_31_piece0
65952 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_31_piece0
65952 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_31_piece0 locally took  1 ms
65952 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_31_piece0 without replication took  1 ms
65952 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 31 from broadcast at DAGScheduler.scala:1006
65952 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[47] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
65952 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 22.0 with 8 tasks
65952 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 22.0: 8
65952 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 22.0: NO_PREF, ANY
65952 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 0
65953 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 22.0 (TID 143, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
65953 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 22.0 (TID 144, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
65953 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 22.0 (TID 145, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
65954 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 22.0 (TID 146, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
65954 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 22.0 (TID 147, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
65955 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 22.0 (TID 148, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
65955 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 22.0 (TID 149, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
65955 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 22.0 (TID 150, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
65956 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 143 on executor id: 0 hostname: 192.168.1.4.
65956 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 144 on executor id: 0 hostname: 192.168.1.4.
65956 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 145 on executor id: 0 hostname: 192.168.1.4.
65956 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 146 on executor id: 0 hostname: 192.168.1.4.
65956 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 147 on executor id: 0 hostname: 192.168.1.4.
65957 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 148 on executor id: 0 hostname: 192.168.1.4.
65957 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 149 on executor id: 0 hostname: 192.168.1.4.
65957 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 150 on executor id: 0 hostname: 192.168.1.4.
65961 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_31_piece0 as bytes
65961 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_31_piece0 is StorageLevel(disk, memory, 1 replicas)
65963 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_31_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
65968 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_30_piece0 as bytes
65968 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_30_piece0 is StorageLevel(disk, memory, 1 replicas)
65970 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_30_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
66031 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_29_piece0 as bytes
66031 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_29_piece0 is StorageLevel(disk, memory, 1 replicas)
66032 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_29_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
66356 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 7
66357 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
66357 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 22.0 (TID 150) in 402 ms on 192.168.1.4 (executor 0) (1/8)
66357 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66379 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 7
66468 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 6
66468 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 22.0 (TID 143) in 516 ms on 192.168.1.4 (executor 0) (2/8)
66469 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66672 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 5
66672 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 22.0 (TID 149) in 717 ms on 192.168.1.4 (executor 0) (3/8)
66673 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66695 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 4
66695 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 22.0 (TID 148) in 741 ms on 192.168.1.4 (executor 0) (4/8)
66696 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66697 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 3
66697 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 22.0 (TID 145) in 744 ms on 192.168.1.4 (executor 0) (5/8)
66697 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66697 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 2
66697 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 22.0 (TID 146) in 744 ms on 192.168.1.4 (executor 0) (6/8)
66697 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 1
66697 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66697 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 22.0 (TID 147) in 743 ms on 192.168.1.4 (executor 0) (7/8)
66698 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66737 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_22.0, runningTasks: 0
66737 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 22.0 (TID 144) in 784 ms on 192.168.1.4 (executor 0) (8/8)
66737 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 22.0, whose tasks have all completed, from pool 
66737 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 22 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.785 s
66737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
66737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
66737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 23)
66737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
66737 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 9
66738 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 23)
66738 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
66738 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 23 (MapPartitionsRDD[49] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
66738 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 23)
66739 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
66739 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_32 locally took  1 ms
66739 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_32 without replication took  1 ms
66740 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
66740 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_32_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
66740 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_32_piece0
66740 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_32_piece0
66740 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_32_piece0 locally took  0 ms
66740 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_32_piece0 without replication took  0 ms
66740 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 32 from broadcast at DAGScheduler.scala:1006
66741 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[49] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
66741 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 23.0 with 2 tasks
66741 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 23.0: 9
66741 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 23.0: NODE_LOCAL, ANY
66741 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_23.0, runningTasks: 0
66741 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 23.0 (TID 151, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
66741 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 23.0 (TID 152, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
66741 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
66741 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 151 on executor id: 0 hostname: 192.168.1.4.
66742 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 152 on executor id: 0 hostname: 192.168.1.4.
66746 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_32_piece0 as bytes
66746 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_32_piece0 is StorageLevel(disk, memory, 1 replicas)
66748 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_32_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
66750 [dispatcher-event-loop-3] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 8 to 192.168.1.4:49914
66750 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 8 to 192.168.1.4:49914
66750 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 8
66750 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 8
66750 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 8 is 159 bytes
66756 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_23.0, runningTasks: 1
66756 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_23.0, runningTasks: 0
66756 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 23.0 (TID 151) in 15 ms on 192.168.1.4 (executor 0) (1/2)
66756 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 23.0 (TID 152) in 15 ms on 192.168.1.4 (executor 0) (2/2)
66756 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 23.0, whose tasks have all completed, from pool 
66757 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 23 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.016 s
66757 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 23, remaining stages = 1
66757 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 22, remaining stages = 0
66757 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 14 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.809197 s
66758 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 2: Accuracy = 0.19, F1 = 0.32
66758 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 2
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66758 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66759 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66760 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66760 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66760 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
66760 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
66760 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 15 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
66760 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 24 (count at ParameterAveragingTrainingMaster.java:325)
66760 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
66760 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
66760 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 24)
66761 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
66761 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 24 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
66761 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 24)
66761 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
66761 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_33 locally took  0 ms
66761 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_33 without replication took  0 ms
66762 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
66762 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_33_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.3 MB)
66762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_33_piece0
66762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_33_piece0
66762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_33_piece0 locally took  0 ms
66762 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_33_piece0 without replication took  0 ms
66762 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 33 from broadcast at DAGScheduler.scala:1006
66763 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 24 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
66763 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 24.0 with 8 tasks
66763 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 24.0: 9
66763 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 24.0: PROCESS_LOCAL, NODE_LOCAL, ANY
66763 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 0
66764 [dispatcher-event-loop-4] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 24 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
66764 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 24.0 (TID 153, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
66765 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 24.0 (TID 154, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
66766 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 24.0 (TID 155, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
66766 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 24.0 (TID 156, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
66767 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 24.0 (TID 157, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
66768 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 24.0 (TID 158, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
66769 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 24.0 (TID 159, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
66770 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 24.0 (TID 160, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
66770 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 153 on executor id: 0 hostname: 192.168.1.4.
66770 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 154 on executor id: 0 hostname: 192.168.1.4.
66770 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 155 on executor id: 0 hostname: 192.168.1.4.
66771 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 156 on executor id: 0 hostname: 192.168.1.4.
66771 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 157 on executor id: 0 hostname: 192.168.1.4.
66771 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 158 on executor id: 0 hostname: 192.168.1.4.
66771 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 159 on executor id: 0 hostname: 192.168.1.4.
66772 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 160 on executor id: 0 hostname: 192.168.1.4.
66779 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_33_piece0 as bytes
66780 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_33_piece0 is StorageLevel(disk, memory, 1 replicas)
66781 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_33_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
66785 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 7
66786 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
66786 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
66786 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 24.0 (TID 160) in 17 ms on 192.168.1.4 (executor 0) (1/8)
66787 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 6
66787 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 24.0 (TID 155) in 22 ms on 192.168.1.4 (executor 0) (2/8)
66787 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 5
66787 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 24.0 (TID 156) in 21 ms on 192.168.1.4 (executor 0) (3/8)
66789 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 4
66789 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 24.0 (TID 153) in 26 ms on 192.168.1.4 (executor 0) (4/8)
66790 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 3
66790 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 24.0 (TID 158) in 23 ms on 192.168.1.4 (executor 0) (5/8)
66790 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 2
66790 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 24.0 (TID 154) in 26 ms on 192.168.1.4 (executor 0) (6/8)
66791 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 1
66791 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 24.0 (TID 159) in 23 ms on 192.168.1.4 (executor 0) (7/8)
66792 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_24.0, runningTasks: 0
66793 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 24.0 (TID 157) in 27 ms on 192.168.1.4 (executor 0) (8/8)
66793 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 24.0, whose tasks have all completed, from pool 
66793 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 24 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.030 s
66793 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 24, remaining stages = 0
66793 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 15 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.033278 s
66793 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
66795 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66796 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66796 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66796 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66796 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
66796 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353)
66797 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353)
66798 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66799 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
66800 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
66800 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 16 (collect at SparkUtils.java:353) with 8 output partitions
66800 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 25 (collect at SparkUtils.java:353)
66800 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
66800 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
66800 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 25)
66800 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
66800 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 25 (MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
66800 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 25)
66801 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
66801 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_34 locally took  0 ms
66801 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_34 without replication took  0 ms
66802 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
66802 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_34_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.3 MB)
66802 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_34_piece0
66802 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_34_piece0
66802 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_34_piece0 locally took  0 ms
66802 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_34_piece0 without replication took  0 ms
66803 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 34 from broadcast at DAGScheduler.scala:1006
66803 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 25 (MapPartitionsRDD[51] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
66803 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 25.0 with 8 tasks
66803 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 25.0: 9
66803 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 25.0: PROCESS_LOCAL, NODE_LOCAL, ANY
66804 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 0
66804 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 25 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
66804 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 25.0 (TID 161, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
66805 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 25.0 (TID 162, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
66806 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 25.0 (TID 163, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
66807 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 25.0 (TID 164, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
66808 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 25.0 (TID 165, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
66809 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 25.0 (TID 166, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
66810 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 25.0 (TID 167, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
66811 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 25.0 (TID 168, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
66811 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 161 on executor id: 0 hostname: 192.168.1.4.
66811 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 162 on executor id: 0 hostname: 192.168.1.4.
66812 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 163 on executor id: 0 hostname: 192.168.1.4.
66812 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 164 on executor id: 0 hostname: 192.168.1.4.
66812 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 165 on executor id: 0 hostname: 192.168.1.4.
66812 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 166 on executor id: 0 hostname: 192.168.1.4.
66812 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 167 on executor id: 0 hostname: 192.168.1.4.
66812 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 168 on executor id: 0 hostname: 192.168.1.4.
66821 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_34_piece0 as bytes
66821 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_34_piece0 is StorageLevel(disk, memory, 1 replicas)
66824 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_34_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
66829 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 7
66829 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
66829 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
66829 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 25.0 (TID 168) in 19 ms on 192.168.1.4 (executor 0) (1/8)
66830 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 6
66830 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 25.0 (TID 167) in 21 ms on 192.168.1.4 (executor 0) (2/8)
66831 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 5
66831 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 25.0 (TID 166) in 23 ms on 192.168.1.4 (executor 0) (3/8)
66831 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 4
66831 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 25.0 (TID 162) in 27 ms on 192.168.1.4 (executor 0) (4/8)
66831 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 3
66831 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 25.0 (TID 165) in 24 ms on 192.168.1.4 (executor 0) (5/8)
66832 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 2
66832 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 25.0 (TID 164) in 26 ms on 192.168.1.4 (executor 0) (6/8)
66833 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 1
66833 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 25.0 (TID 163) in 28 ms on 192.168.1.4 (executor 0) (7/8)
66833 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_25.0, runningTasks: 0
66833 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 25.0 (TID 161) in 29 ms on 192.168.1.4 (executor 0) (8/8)
66833 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 25.0, whose tasks have all completed, from pool 
66834 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 25 (collect at SparkUtils.java:353) finished in 0.030 s
66834 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 25, remaining stages = 0
66834 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 16 finished: collect at SparkUtils.java:353, took 0.034094 s
66834 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66835 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66836 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66837 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66837 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66837 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66837 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
66837 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
66837 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 17 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
66837 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 26 (zipWithIndex at SparkUtils.java:391)
66837 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
66838 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
66838 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 26)
66838 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
66838 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 26 (MapPartitionsRDD[50] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
66838 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 26)
66839 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
66839 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_35 locally took  0 ms
66839 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_35 without replication took  0 ms
66840 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
66840 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_35_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
66840 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_35_piece0
66840 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_35_piece0
66840 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_35_piece0 locally took  0 ms
66840 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_35_piece0 without replication took  0 ms
66840 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 35 from broadcast at DAGScheduler.scala:1006
66841 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 26 (MapPartitionsRDD[50] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
66841 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 26.0 with 7 tasks
66841 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 26.0: 9
66841 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 26.0: PROCESS_LOCAL, NODE_LOCAL, ANY
66841 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 0
66842 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 26 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
66842 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 26.0 (TID 169, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
66843 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 26.0 (TID 170, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
66844 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 26.0 (TID 171, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
66845 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 26.0 (TID 172, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
66846 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 26.0 (TID 173, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
66847 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 26.0 (TID 174, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
66848 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 26.0 (TID 175, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
66848 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
66848 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
66848 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 169 on executor id: 0 hostname: 192.168.1.4.
66849 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 170 on executor id: 0 hostname: 192.168.1.4.
66849 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 171 on executor id: 0 hostname: 192.168.1.4.
66849 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 172 on executor id: 0 hostname: 192.168.1.4.
66849 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 173 on executor id: 0 hostname: 192.168.1.4.
66849 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 174 on executor id: 0 hostname: 192.168.1.4.
66849 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 175 on executor id: 0 hostname: 192.168.1.4.
66856 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_35_piece0 as bytes
66856 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_35_piece0 is StorageLevel(disk, memory, 1 replicas)
66857 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_35_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.4 MB)
66862 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 6
66863 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 5
66863 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 26.0 (TID 171) in 20 ms on 192.168.1.4 (executor 0) (1/7)
66863 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 26.0 (TID 175) in 16 ms on 192.168.1.4 (executor 0) (2/7)
66864 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 4
66864 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 26.0 (TID 174) in 18 ms on 192.168.1.4 (executor 0) (3/7)
66864 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 3
66864 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 26.0 (TID 173) in 19 ms on 192.168.1.4 (executor 0) (4/7)
66866 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 2
66866 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 26.0 (TID 172) in 22 ms on 192.168.1.4 (executor 0) (5/7)
66867 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 1
66867 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 26.0 (TID 169) in 26 ms on 192.168.1.4 (executor 0) (6/7)
66873 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_26.0, runningTasks: 0
66873 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 26.0 (TID 170) in 31 ms on 192.168.1.4 (executor 0) (7/7)
66873 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 26.0, whose tasks have all completed, from pool 
66873 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 26 (zipWithIndex at SparkUtils.java:391) finished in 0.032 s
66873 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 26, remaining stages = 0
66873 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 17 finished: zipWithIndex at SparkUtils.java:391, took 0.036080 s
66873 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66874 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66875 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66876 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
66877 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36 stored as values in memory (estimated size 30.9 KB, free 366.1 MB)
66877 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_36 locally took  1 ms
66878 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_36 without replication took  2 ms
66879 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
66879 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_36_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
66879 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_36_piece0
66879 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_36_piece0
66879 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_36_piece0 locally took  1 ms
66879 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_36_piece0 without replication took  1 ms
66879 [main] INFO org.apache.spark.SparkContext  - Created broadcast 36 from broadcast at ParameterAveragingTrainingMaster.java:259
66879 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66880 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66881 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66881 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66881 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
66881 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
66882 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66883 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66884 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66885 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66885 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66885 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
66886 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
66887 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66887 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66887 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66888 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66888 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66888 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
66888 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
66889 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66890 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66891 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66892 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66892 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66892 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66892 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66893 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66894 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66894 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66894 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
66894 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66895 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
66896 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
66897 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
66897 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
66897 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
66897 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
66897 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 9 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
66897 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 53 (mapToPair at SparkUtils.java:391)
66898 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 58 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
66898 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 18 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
66898 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 29 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
66898 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 28)
66898 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 28)
66898 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 29)
66898 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 28)
66898 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 28)
66898 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 27)
66898 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 27)
66898 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
66899 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 27 (MapPartitionsRDD[53] at mapToPair at SparkUtils.java:391), which has no missing parents
66899 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 27)
66900 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
66900 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_37 locally took  0 ms
66900 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_37 without replication took  0 ms
66901 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
66901 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_37_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
66901 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_37_piece0
66901 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_37_piece0
66901 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_37_piece0 locally took  0 ms
66901 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_37_piece0 without replication took  0 ms
66902 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 37 from broadcast at DAGScheduler.scala:1006
66902 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[53] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
66902 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 27.0 with 8 tasks
66902 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 27.0: 9
66902 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 27.0: PROCESS_LOCAL, NODE_LOCAL, ANY
66903 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 0
66904 [dispatcher-event-loop-1] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 27 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
66904 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 27.0 (TID 176, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
66905 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 27.0 (TID 177, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
66907 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 27.0 (TID 178, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
66909 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 27.0 (TID 179, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
66911 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 27.0 (TID 180, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
66912 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 27.0 (TID 181, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
66913 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 27.0 (TID 182, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
66915 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 27.0 (TID 183, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
66916 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 176 on executor id: 0 hostname: 192.168.1.4.
66916 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 177 on executor id: 0 hostname: 192.168.1.4.
66916 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 178 on executor id: 0 hostname: 192.168.1.4.
66916 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 179 on executor id: 0 hostname: 192.168.1.4.
66916 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 180 on executor id: 0 hostname: 192.168.1.4.
66917 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 181 on executor id: 0 hostname: 192.168.1.4.
66917 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 182 on executor id: 0 hostname: 192.168.1.4.
66917 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 183 on executor id: 0 hostname: 192.168.1.4.
66927 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_37_piece0 as bytes
66927 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_37_piece0 is StorageLevel(disk, memory, 1 replicas)
66929 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_37_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
66939 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 7
66939 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
66939 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
66939 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 6
66939 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 27.0 (TID 183) in 26 ms on 192.168.1.4 (executor 0) (1/8)
66939 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 27.0 (TID 180) in 30 ms on 192.168.1.4 (executor 0) (2/8)
66940 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 5
66940 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66940 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 27.0 (TID 182) in 28 ms on 192.168.1.4 (executor 0) (3/8)
66940 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 4
66940 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66940 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 27.0 (TID 181) in 29 ms on 192.168.1.4 (executor 0) (4/8)
66940 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66940 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66941 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 3
66941 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 27.0 (TID 179) in 34 ms on 192.168.1.4 (executor 0) (5/8)
66941 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66942 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 2
66942 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 27.0 (TID 178) in 37 ms on 192.168.1.4 (executor 0) (6/8)
66942 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66943 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 1
66943 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 27.0 (TID 177) in 39 ms on 192.168.1.4 (executor 0) (7/8)
66943 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66948 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_27.0, runningTasks: 0
66948 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 27.0 (TID 176) in 45 ms on 192.168.1.4 (executor 0) (8/8)
66948 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 27.0, whose tasks have all completed, from pool 
66949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
66949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 27 (mapToPair at SparkUtils.java:391) finished in 0.047 s
66949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
66949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
66949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 28, ResultStage 29)
66949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
66949 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 10
66949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 28)
66949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
66949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 28 (MapPartitionsRDD[58] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
66949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 28)
66951 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
66951 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_38 locally took  0 ms
66952 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_38 without replication took  1 ms
66952 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
66953 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_38_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
66953 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_38_piece0
66953 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_38_piece0
66953 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_38_piece0 locally took  1 ms
66953 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_38_piece0 without replication took  1 ms
66953 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 38 from broadcast at DAGScheduler.scala:1006
66953 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[58] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
66954 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 28.0 with 8 tasks
66954 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 28.0: 10
66954 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 28.0: NODE_LOCAL, ANY
66954 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 0
66954 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 28.0 (TID 184, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
66954 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 28.0 (TID 185, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
66954 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 28.0 (TID 186, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
66954 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 28.0 (TID 187, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
66954 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 28.0 (TID 188, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
66954 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 28.0 (TID 189, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
66955 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 28.0 (TID 190, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
66955 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 28.0 (TID 191, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 184 on executor id: 0 hostname: 192.168.1.4.
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 185 on executor id: 0 hostname: 192.168.1.4.
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 186 on executor id: 0 hostname: 192.168.1.4.
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 187 on executor id: 0 hostname: 192.168.1.4.
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 188 on executor id: 0 hostname: 192.168.1.4.
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 189 on executor id: 0 hostname: 192.168.1.4.
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 190 on executor id: 0 hostname: 192.168.1.4.
66955 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 191 on executor id: 0 hostname: 192.168.1.4.
66959 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_38_piece0 as bytes
66959 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_38_piece0 is StorageLevel(disk, memory, 1 replicas)
66961 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_38_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.4 MB)
66963 [dispatcher-event-loop-0] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 10 to 192.168.1.4:49914
66963 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 10 to 192.168.1.4:49914
66963 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 10
66963 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 10
66963 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 10 is 186 bytes
66967 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_36_piece0 as bytes
66967 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_36_piece0 is StorageLevel(disk, memory, 1 replicas)
66969 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_36_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
67376 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 8
68376 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 8
68942 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 7
68942 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
68943 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 28.0 (TID 191) in 1988 ms on 192.168.1.4 (executor 0) (1/8)
68943 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
69377 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 7
70377 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 7
70768 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 6
70768 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 28.0 (TID 190) in 3814 ms on 192.168.1.4 (executor 0) (2/8)
70768 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
70799 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 5
70799 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 28.0 (TID 189) in 3845 ms on 192.168.1.4 (executor 0) (3/8)
70799 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71010 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 4
71010 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 28.0 (TID 185) in 4056 ms on 192.168.1.4 (executor 0) (4/8)
71011 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71101 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 3
71101 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 28.0 (TID 186) in 4147 ms on 192.168.1.4 (executor 0) (5/8)
71101 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71143 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 2
71144 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 28.0 (TID 184) in 4189 ms on 192.168.1.4 (executor 0) (6/8)
71144 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71206 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 1
71206 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 28.0 (TID 188) in 4252 ms on 192.168.1.4 (executor 0) (7/8)
71207 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71214 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_28.0, runningTasks: 0
71214 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 28.0 (TID 187) in 4260 ms on 192.168.1.4 (executor 0) (8/8)
71214 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 28.0, whose tasks have all completed, from pool 
71214 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71214 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 28 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.260 s
71214 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
71214 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
71214 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 29)
71214 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
71214 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 11
71214 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 29)
71214 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
71214 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 29 (MapPartitionsRDD[60] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
71214 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 29)
71216 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
71216 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_39 locally took  1 ms
71216 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_39 without replication took  1 ms
71217 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
71217 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_39_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
71217 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_39_piece0
71217 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_39_piece0
71217 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_39_piece0 locally took  0 ms
71217 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_39_piece0 without replication took  0 ms
71217 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 39 from broadcast at DAGScheduler.scala:1006
71218 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 29 (MapPartitionsRDD[60] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
71218 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 29.0 with 2 tasks
71218 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 29.0: 11
71218 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 29.0: NODE_LOCAL, ANY
71218 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_29.0, runningTasks: 0
71218 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 29.0 (TID 192, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
71218 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 29.0 (TID 193, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
71218 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
71218 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 192 on executor id: 0 hostname: 192.168.1.4.
71219 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 193 on executor id: 0 hostname: 192.168.1.4.
71222 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_39_piece0 as bytes
71222 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_39_piece0 is StorageLevel(disk, memory, 1 replicas)
71224 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_39_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
71226 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 9 to 192.168.1.4:49914
71226 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 9 to 192.168.1.4:49914
71226 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 9
71226 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 9
71226 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 9 is 159 bytes
71295 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_29.0, runningTasks: 1
71296 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_29.0, runningTasks: 0
71296 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 29.0 (TID 192) in 78 ms on 192.168.1.4 (executor 0) (1/2)
71296 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 29.0 (TID 193) in 78 ms on 192.168.1.4 (executor 0) (2/2)
71296 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 29.0, whose tasks have all completed, from pool 
71296 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 29 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.078 s
71296 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 29, remaining stages = 2
71296 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 28, remaining stages = 1
71296 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 27, remaining stages = 0
71297 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 18 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.400078 s
71298 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
71299 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
71299 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_40 locally took  0 ms
71299 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_40 without replication took  0 ms
71300 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
71300 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_40_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
71300 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_40_piece0
71300 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_40_piece0
71300 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_40_piece0 locally took  0 ms
71300 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_40_piece0 without replication took  0 ms
71300 [main] INFO org.apache.spark.SparkContext  - Created broadcast 40 from broadcast at SparkDl4jMultiLayer.java:595
71301 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
71301 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_41 locally took  1 ms
71301 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_41 without replication took  1 ms
71302 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
71303 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_41_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
71303 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_41_piece0
71303 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_41_piece0
71303 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_41_piece0 locally took  1 ms
71303 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_41_piece0 without replication took  1 ms
71303 [main] INFO org.apache.spark.SparkContext  - Created broadcast 41 from broadcast at SparkDl4jMultiLayer.java:596
71303 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71304 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71305 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71306 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71307 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71308 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71309 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71310 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
71311 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
71312 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
71313 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
71314 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
71315 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
71316 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
71316 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
71316 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 11 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
71316 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 63 (treeAggregate at SparkDl4jMultiLayer.java:598)
71317 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 19 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
71317 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 31 (treeAggregate at SparkDl4jMultiLayer.java:598)
71317 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 30)
71317 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 30)
71317 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 31)
71317 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 30)
71317 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 30)
71317 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
71317 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 30 (MapPartitionsRDD[63] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
71317 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 30)
71318 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42 stored as values in memory (estimated size 9.0 KB, free 366.1 MB)
71318 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_42 locally took  0 ms
71318 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_42 without replication took  0 ms
71319 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.1 MB)
71319 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_42_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.2 MB)
71320 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_42_piece0
71320 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_42_piece0
71320 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_42_piece0 locally took  1 ms
71320 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_42_piece0 without replication took  1 ms
71320 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 42 from broadcast at DAGScheduler.scala:1006
71320 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[63] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
71320 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 30.0 with 8 tasks
71320 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 30.0: 11
71320 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 30.0: NO_PREF, ANY
71320 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 0
71321 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 30.0 (TID 194, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
71321 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 30.0 (TID 195, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
71321 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 30.0 (TID 196, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
71322 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 30.0 (TID 197, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
71322 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 30.0 (TID 198, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
71322 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 30.0 (TID 199, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
71322 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 30.0 (TID 200, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
71323 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 30.0 (TID 201, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
71323 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 194 on executor id: 0 hostname: 192.168.1.4.
71323 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 195 on executor id: 0 hostname: 192.168.1.4.
71323 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 196 on executor id: 0 hostname: 192.168.1.4.
71323 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 197 on executor id: 0 hostname: 192.168.1.4.
71324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 198 on executor id: 0 hostname: 192.168.1.4.
71324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 199 on executor id: 0 hostname: 192.168.1.4.
71324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 200 on executor id: 0 hostname: 192.168.1.4.
71324 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 201 on executor id: 0 hostname: 192.168.1.4.
71328 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_42_piece0 as bytes
71329 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_42_piece0 is StorageLevel(disk, memory, 1 replicas)
71330 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_42_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
71333 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_41_piece0 as bytes
71333 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_41_piece0 is StorageLevel(disk, memory, 1 replicas)
71334 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_41_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
71377 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_40_piece0 as bytes
71377 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_40_piece0 is StorageLevel(disk, memory, 1 replicas)
71379 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_40_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
71379 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 8
71619 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 7
71619 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
71619 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 30.0 (TID 201) in 297 ms on 192.168.1.4 (executor 0) (1/8)
71619 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71805 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 6
71805 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 30.0 (TID 194) in 485 ms on 192.168.1.4 (executor 0) (2/8)
71806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71940 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 5
71940 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 30.0 (TID 198) in 618 ms on 192.168.1.4 (executor 0) (3/8)
71941 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71963 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 4
71963 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 30.0 (TID 199) in 641 ms on 192.168.1.4 (executor 0) (4/8)
71964 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
71964 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 3
71964 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 30.0 (TID 200) in 642 ms on 192.168.1.4 (executor 0) (5/8)
71964 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72050 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 2
72050 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 1
72050 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 30.0 (TID 197) in 729 ms on 192.168.1.4 (executor 0) (6/8)
72051 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_30.0, runningTasks: 0
72051 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 30.0 (TID 196) in 730 ms on 192.168.1.4 (executor 0) (7/8)
72051 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72051 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 30.0 (TID 195) in 730 ms on 192.168.1.4 (executor 0) (8/8)
72051 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 30.0, whose tasks have all completed, from pool 
72051 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72051 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72051 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 30 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.731 s
72051 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
72051 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
72051 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 31)
72051 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
72051 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 12
72051 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 31)
72051 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72051 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 31 (MapPartitionsRDD[65] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
72051 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 31)
72052 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
72052 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_43 locally took  0 ms
72052 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_43 without replication took  0 ms
72053 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
72053 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_43_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.2 MB)
72053 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_43_piece0
72053 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_43_piece0
72053 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_43_piece0 locally took  0 ms
72053 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_43_piece0 without replication took  0 ms
72054 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 43 from broadcast at DAGScheduler.scala:1006
72054 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[65] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
72054 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 31.0 with 2 tasks
72054 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 31.0: 12
72054 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 31.0: NODE_LOCAL, ANY
72054 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_31.0, runningTasks: 0
72054 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 31.0 (TID 202, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
72054 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 31.0 (TID 203, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
72054 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
72054 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 202 on executor id: 0 hostname: 192.168.1.4.
72054 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 203 on executor id: 0 hostname: 192.168.1.4.
72058 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_43_piece0 as bytes
72058 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_43_piece0 is StorageLevel(disk, memory, 1 replicas)
72059 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_43_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
72061 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 11 to 192.168.1.4:49914
72061 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 11 to 192.168.1.4:49914
72062 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 11
72062 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 11
72062 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 11 is 159 bytes
72068 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_31.0, runningTasks: 1
72069 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_31.0, runningTasks: 0
72069 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 31.0 (TID 203) in 15 ms on 192.168.1.4 (executor 0) (1/2)
72069 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 31.0 (TID 202) in 15 ms on 192.168.1.4 (executor 0) (2/2)
72069 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 31.0, whose tasks have all completed, from pool 
72070 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 31 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.015 s
72070 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 31, remaining stages = 1
72070 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 30, remaining stages = 0
72070 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 19 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.753696 s
72071 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 3: Accuracy = 0.19, F1 = 0.32
72071 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 3
72071 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
72072 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
72073 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
72074 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 20 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
72074 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 32 (count at ParameterAveragingTrainingMaster.java:325)
72074 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
72074 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
72074 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 32)
72074 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72074 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 32 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
72074 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 32)
72075 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
72075 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_44 locally took  0 ms
72075 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_44 without replication took  0 ms
72076 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
72076 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_44_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.2 MB)
72076 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_44_piece0
72076 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_44_piece0
72076 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_44_piece0 locally took  0 ms
72076 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_44_piece0 without replication took  0 ms
72076 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 44 from broadcast at DAGScheduler.scala:1006
72077 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 32 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
72077 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 32.0 with 8 tasks
72077 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 32.0: 12
72077 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 32.0: PROCESS_LOCAL, NODE_LOCAL, ANY
72077 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 0
72078 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 32 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
72078 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 32.0 (TID 204, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
72080 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 32.0 (TID 205, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
72081 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 32.0 (TID 206, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
72082 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 32.0 (TID 207, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
72083 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 32.0 (TID 208, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
72084 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 32.0 (TID 209, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
72085 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 32.0 (TID 210, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
72086 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 32.0 (TID 211, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
72086 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 204 on executor id: 0 hostname: 192.168.1.4.
72086 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 205 on executor id: 0 hostname: 192.168.1.4.
72086 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 206 on executor id: 0 hostname: 192.168.1.4.
72086 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 207 on executor id: 0 hostname: 192.168.1.4.
72087 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 208 on executor id: 0 hostname: 192.168.1.4.
72087 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 209 on executor id: 0 hostname: 192.168.1.4.
72087 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 210 on executor id: 0 hostname: 192.168.1.4.
72087 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 211 on executor id: 0 hostname: 192.168.1.4.
72093 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_44_piece0 as bytes
72093 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_44_piece0 is StorageLevel(disk, memory, 1 replicas)
72095 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_44_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
72100 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 7
72100 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
72100 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
72100 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 32.0 (TID 204) in 23 ms on 192.168.1.4 (executor 0) (1/8)
72101 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 6
72101 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 32.0 (TID 211) in 16 ms on 192.168.1.4 (executor 0) (2/8)
72102 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 5
72102 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 32.0 (TID 207) in 21 ms on 192.168.1.4 (executor 0) (3/8)
72103 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 4
72103 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 32.0 (TID 205) in 25 ms on 192.168.1.4 (executor 0) (4/8)
72103 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 3
72103 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 32.0 (TID 210) in 19 ms on 192.168.1.4 (executor 0) (5/8)
72117 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(35)
72117 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 35
72117 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 35
72117 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 2
72118 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 32.0 (TID 206) in 37 ms on 192.168.1.4 (executor 0) (6/8)
72118 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 1
72118 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_32.0, runningTasks: 0
72118 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 35
72118 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 35
72118 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_35_piece0
72118 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35_piece0 of size 1460 dropped from memory (free 383836283)
72118 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 32.0 (TID 209) in 35 ms on 192.168.1.4 (executor 0) (7/8)
72119 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 32.0 (TID 208) in 37 ms on 192.168.1.4 (executor 0) (8/8)
72119 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 32.0, whose tasks have all completed, from pool 
72119 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_35_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.2 MB)
72119 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_35_piece0
72119 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_35_piece0
72119 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 32 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.042 s
72119 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_35
72119 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_35 of size 2216 dropped from memory (free 383838499)
72119 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 32, remaining stages = 0
72119 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 35, response is 0
72119 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72119 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 20 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.045774 s
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
72120 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_35_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72120 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72121 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72121 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72121 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72121 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
72121 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
72122 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 35
72122 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(9)
72122 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 9
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72122 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72123 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 9
72123 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(25)
72123 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 25
72123 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72123 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 9
72123 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72123 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72123 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
72124 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353
72125 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72123 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 25
72125 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 9, response is true
72125 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
72125 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
72125 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
72125 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
72125 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353)
72125 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
72126 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
72126 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
72126 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 25
72126 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 25
72126 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_25_piece0
72126 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25_piece0 of size 5323 dropped from memory (free 383843822)
72127 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_25_piece0 on 192.168.1.4:49908 in memory (size: 5.2 KB, free: 366.3 MB)
72128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_25_piece0
72128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_25_piece0
72128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_25
72128 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72128 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
72128 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_25 of size 31208 dropped from memory (free 383875030)
72128 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
72128 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72128 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
72128 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
72128 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
72129 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
72129 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
72129 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
72129 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
72129 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 25, response is 0
72129 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353
72129 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
72130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
72130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
72130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353)
72130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
72130 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
72131 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
72131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72131 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72132 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_25_piece0 on 192.168.1.4:49916 in memory (size: 5.2 KB, free: 365.4 MB)
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72132 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
72132 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
72133 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 25
72133 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(23)
72133 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 23
72133 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 23
72133 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 21 (collect at SparkUtils.java:353) with 8 output partitions
72133 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 33 (collect at SparkUtils.java:353)
72133 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
72133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 23
72133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 23
72133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_23
72133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23 of size 2504 dropped from memory (free 383877534)
72133 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
72133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_23_piece0
72133 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 33)
72133 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_23_piece0 of size 1570 dropped from memory (free 383879104)
72133 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72133 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 33 (MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
72133 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 33)
72134 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_23_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
72134 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_23_piece0
72134 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_23_piece0
72134 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 23, response is 0
72135 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72135 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
72135 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_45 locally took  1 ms
72135 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_45 without replication took  1 ms
72136 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_23_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.4 MB)
72137 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.1 MB)
72137 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_45_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.3 MB)
72137 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 23
72137 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(33)
72137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_45_piece0
72137 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 33
72137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_45_piece0
72137 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 33
72137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_45_piece0 locally took  1 ms
72137 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_45_piece0 without replication took  1 ms
72137 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 45 from broadcast at DAGScheduler.scala:1006
72138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 33
72138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 33
72138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_33
72138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33 of size 1448 dropped from memory (free 383876478)
72138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_33_piece0
72138 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_33_piece0 of size 1006 dropped from memory (free 383877484)
72138 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 33 (MapPartitionsRDD[67] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
72138 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 33.0 with 8 tasks
72139 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 33.0: 12
72139 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_33_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
72139 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 33.0: PROCESS_LOCAL, NODE_LOCAL, ANY
72139 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_33_piece0
72139 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_33_piece0
72139 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 33, response is 0
72139 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 0
72139 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72139 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_33_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.4 MB)
72140 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 33
72140 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(11)
72140 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 11
72140 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 33 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
72141 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 33.0 (TID 212, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
72141 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 11
72141 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 11
72141 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(38)
72141 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 38
72141 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 38
72141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 11, response is true
72141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
72141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 38
72141 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 38
72142 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_38_piece0
72142 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38_piece0 of size 3630 dropped from memory (free 383881114)
72142 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 33.0 (TID 213, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
72143 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_38_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.3 MB)
72143 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_38_piece0
72143 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_38_piece0
72143 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_38
72143 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_38 of size 6712 dropped from memory (free 383887826)
72144 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 38, response is 0
72144 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72144 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 33.0 (TID 214, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
72144 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_38_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.4 MB)
72145 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 33.0 (TID 215, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
72145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 38
72145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(10)
72145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 10
72145 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 10
72145 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 10
72145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(43)
72145 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 10, response is true
72145 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 43
72145 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 43
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 43
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 43
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_43_piece0
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43_piece0 of size 2125 dropped from memory (free 383889951)
72146 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_43_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_43_piece0
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_43_piece0
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_43
72146 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_43 of size 3656 dropped from memory (free 383893607)
72146 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 33.0 (TID 216, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
72146 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 43, response is 0
72146 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72147 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_43_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
72147 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 33.0 (TID 217, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
72148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 43
72148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(7)
72148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 7
72148 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 7
72148 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 7
72148 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 7, response is true
72148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(39)
72148 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 39
72148 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
72148 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 39
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 39
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 39
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_39
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39 of size 3672 dropped from memory (free 383897279)
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_39_piece0
72149 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 33.0 (TID 218, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_39_piece0 of size 2135 dropped from memory (free 383899414)
72149 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_39_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_39_piece0
72149 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_39_piece0
72149 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 39, response is 0
72149 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72150 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_39_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
72150 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 33.0 (TID 219, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
72151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 39
72151 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 212 on executor id: 0 hostname: 192.168.1.4.
72151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(29)
72151 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 29
72151 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 29
72151 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 213 on executor id: 0 hostname: 192.168.1.4.
72151 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 214 on executor id: 0 hostname: 192.168.1.4.
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 29
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 29
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_29_piece0
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29_piece0 of size 1428 dropped from memory (free 383900842)
72151 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 215 on executor id: 0 hostname: 192.168.1.4.
72151 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 216 on executor id: 0 hostname: 192.168.1.4.
72151 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_29_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.3 MB)
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_29_piece0
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_29_piece0
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_29
72151 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 217 on executor id: 0 hostname: 192.168.1.4.
72151 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_29 of size 8224 dropped from memory (free 383909066)
72152 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 29, response is 0
72152 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 218 on executor id: 0 hostname: 192.168.1.4.
72152 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72152 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 219 on executor id: 0 hostname: 192.168.1.4.
72153 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_29_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.4 MB)
72155 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 29
72155 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(32)
72155 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 32
72155 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 32
72155 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 32
72155 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 32
72155 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_32
72155 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32 of size 3656 dropped from memory (free 383912722)
72155 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_32_piece0
72155 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_32_piece0 of size 2124 dropped from memory (free 383914846)
72156 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_32_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
72156 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_32_piece0
72156 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_32_piece0
72156 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 32, response is 0
72156 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72157 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_32_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
72157 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 32
72157 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(27)
72157 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 27
72158 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 27
72158 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 27
72158 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 27
72158 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_27_piece0
72158 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27_piece0 of size 3630 dropped from memory (free 383918476)
72158 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_27_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.3 MB)
72158 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_27_piece0
72158 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_27_piece0
72158 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_27
72159 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_27 of size 6712 dropped from memory (free 383925188)
72159 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 27, response is 0
72159 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72159 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_27_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.4 MB)
72160 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 27
72160 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(30)
72160 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 30
72160 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 30
72160 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 30
72160 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 30
72160 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_30
72160 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30 of size 27528 dropped from memory (free 383952716)
72160 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_30_piece0
72160 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_30_piece0 of size 2531 dropped from memory (free 383955247)
72161 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_30_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
72161 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_30_piece0
72161 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_30_piece0
72161 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 30, response is 0
72161 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72162 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_30_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.4 MB)
72163 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 30
72163 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(22)
72163 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 22
72163 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 22
72163 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 22
72163 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 22
72163 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_22_piece0
72163 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22_piece0 of size 1006 dropped from memory (free 383956253)
72164 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_22_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
72164 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_22_piece0
72164 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_22_piece0
72164 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_22
72164 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_22 of size 1448 dropped from memory (free 383957701)
72164 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 22, response is 0
72164 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72166 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_22_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.4 MB)
72167 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 22
72167 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(6)
72167 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 6
72167 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_45_piece0 as bytes
72167 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_45_piece0 is StorageLevel(disk, memory, 1 replicas)
72167 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 6
72167 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 6
72167 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(37)
72168 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 37
72168 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 37
72168 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 6, response is true
72168 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
72168 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 37
72168 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 37
72168 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_37_piece0
72169 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37_piece0 of size 2197 dropped from memory (free 383959898)
72169 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_37_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
72169 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_37_piece0
72169 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_37_piece0
72169 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_37
72169 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_37 of size 3600 dropped from memory (free 383963498)
72170 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_37_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
72170 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 37, response is 0
72170 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72171 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 37
72171 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(8)
72171 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 8
72171 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 8
72171 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 8, response is true
72171 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 8
72171 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(36)
72171 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
72171 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 36
72171 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 36
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 36
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 36
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_36
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36 of size 31656 dropped from memory (free 383995154)
72172 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_45_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_36_piece0
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_36_piece0 of size 5327 dropped from memory (free 384000481)
72172 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_36_piece0 on 192.168.1.4:49908 in memory (size: 5.2 KB, free: 366.3 MB)
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_36_piece0
72172 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_36_piece0
72172 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 36, response is 0
72172 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72174 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_36_piece0 on 192.168.1.4:49916 in memory (size: 5.2 KB, free: 365.4 MB)
72175 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 36
72175 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(24)
72175 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 24
72175 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 24
72176 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 24
72176 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 24
72176 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_24
72176 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24 of size 2216 dropped from memory (free 384002697)
72176 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_24_piece0
72176 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_24_piece0 of size 1460 dropped from memory (free 384004157)
72177 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_24_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.3 MB)
72177 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_24_piece0
72177 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_24_piece0
72177 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 24, response is 0
72177 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72178 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_24_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
72179 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 24
72179 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(28)
72179 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 28
72179 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 28
72179 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 28
72179 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 28
72180 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_28_piece0
72180 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28_piece0 of size 2135 dropped from memory (free 384006292)
72180 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_28_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
72180 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_28_piece0
72180 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_28_piece0
72180 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_28
72180 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_28 of size 3672 dropped from memory (free 384009964)
72180 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 28, response is 0
72180 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72181 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_28_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
72181 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 28
72181 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(26)
72181 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 26
72181 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 26
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 26
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 26
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_26_piece0
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26_piece0 of size 2197 dropped from memory (free 384012161)
72182 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_26_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_26_piece0
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_26_piece0
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_26
72182 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_26 of size 3600 dropped from memory (free 384015761)
72182 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 26, response is 0
72182 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72182 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_26_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
72183 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 26
72183 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(42)
72183 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 42
72183 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 42
72183 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 42
72184 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 42
72184 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_42
72184 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42 of size 9208 dropped from memory (free 384024969)
72184 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_42_piece0
72184 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_42_piece0 of size 4226 dropped from memory (free 384029195)
72184 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_42_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.3 MB)
72184 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_42_piece0
72184 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_42_piece0
72184 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 7
72184 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 42, response is 0
72184 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
72184 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72184 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
72184 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 6
72185 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 33.0 (TID 213) in 43 ms on 192.168.1.4 (executor 0) (1/8)
72185 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_42_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.4 MB)
72185 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 33.0 (TID 216) in 40 ms on 192.168.1.4 (executor 0) (2/8)
72185 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 5
72185 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 33.0 (TID 218) in 38 ms on 192.168.1.4 (executor 0) (3/8)
72185 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 42
72185 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(31)
72185 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 31
72185 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 31
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 31
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 31
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_31_piece0
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31_piece0 of size 4224 dropped from memory (free 384033419)
72186 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_31_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.3 MB)
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_31_piece0
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_31_piece0
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_31
72186 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_31 of size 9208 dropped from memory (free 384042627)
72186 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 31, response is 0
72186 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72187 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_31_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.5 MB)
72187 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 31
72187 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(34)
72187 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 34
72187 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 34
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 34
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 34
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_34_piece0
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34_piece0 of size 1570 dropped from memory (free 384044197)
72188 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_34_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_34_piece0
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_34_piece0
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_34
72188 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_34 of size 2504 dropped from memory (free 384046701)
72188 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 34, response is 0
72188 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72188 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_34_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.5 MB)
72189 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 34
72189 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(40)
72189 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 40
72189 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 40
72189 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 40
72189 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 40
72189 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_40
72190 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40 of size 8224 dropped from memory (free 384054925)
72190 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_40_piece0
72190 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_40_piece0 of size 1428 dropped from memory (free 384056353)
72190 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_40_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.3 MB)
72190 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_40_piece0
72190 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_40_piece0
72190 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 40, response is 0
72190 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72190 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_40_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.5 MB)
72191 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 40
72191 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(41)
72191 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 41
72191 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 41
72191 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 41
72191 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 41
72191 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_41
72191 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41 of size 27976 dropped from memory (free 384084329)
72191 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_41_piece0
72191 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_41_piece0 of size 2531 dropped from memory (free 384086860)
72192 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_41_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
72192 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_41_piece0
72192 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_41_piece0
72192 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 41, response is 0
72192 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
72192 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 4
72192 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 33.0 (TID 212) in 53 ms on 192.168.1.4 (executor 0) (4/8)
72193 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 3
72193 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 33.0 (TID 214) in 51 ms on 192.168.1.4 (executor 0) (5/8)
72193 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_41_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.5 MB)
72194 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 41
72195 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 2
72195 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 33.0 (TID 215) in 51 ms on 192.168.1.4 (executor 0) (6/8)
72197 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 1
72198 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_33.0, runningTasks: 0
72198 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 33.0 (TID 217) in 52 ms on 192.168.1.4 (executor 0) (7/8)
72198 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 33.0 (TID 219) in 49 ms on 192.168.1.4 (executor 0) (8/8)
72198 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 33.0, whose tasks have all completed, from pool 
72198 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 33 (collect at SparkUtils.java:353) finished in 0.059 s
72198 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 33, remaining stages = 0
72198 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 21 finished: collect at SparkUtils.java:353, took 0.065893 s
72199 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72200 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72201 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72202 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
72202 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
72202 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 22 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
72202 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 34 (zipWithIndex at SparkUtils.java:391)
72202 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
72202 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
72202 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 34)
72202 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72203 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 34 (MapPartitionsRDD[66] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
72203 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 34)
72204 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46 stored as values in memory (estimated size 2.2 KB, free 366.3 MB)
72204 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_46 locally took  1 ms
72204 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_46 without replication took  1 ms
72204 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.3 MB)
72204 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_46_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
72205 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_46_piece0
72205 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_46_piece0
72205 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_46_piece0 locally took  1 ms
72205 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_46_piece0 without replication took  1 ms
72205 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 46 from broadcast at DAGScheduler.scala:1006
72205 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 34 (MapPartitionsRDD[66] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
72205 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 34.0 with 7 tasks
72205 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 34.0: 12
72205 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 34.0: PROCESS_LOCAL, NODE_LOCAL, ANY
72205 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 0
72206 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 34 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
72206 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 34.0 (TID 220, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
72207 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 34.0 (TID 221, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
72208 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 34.0 (TID 222, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
72209 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 34.0 (TID 223, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
72210 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 34.0 (TID 224, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
72210 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 34.0 (TID 225, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
72211 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 34.0 (TID 226, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
72211 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
72211 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
72211 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 220 on executor id: 0 hostname: 192.168.1.4.
72212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 221 on executor id: 0 hostname: 192.168.1.4.
72212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 222 on executor id: 0 hostname: 192.168.1.4.
72212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 223 on executor id: 0 hostname: 192.168.1.4.
72212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 224 on executor id: 0 hostname: 192.168.1.4.
72212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 225 on executor id: 0 hostname: 192.168.1.4.
72212 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 226 on executor id: 0 hostname: 192.168.1.4.
72217 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_46_piece0 as bytes
72217 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_46_piece0 is StorageLevel(disk, memory, 1 replicas)
72218 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_46_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.5 MB)
72222 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 6
72223 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 34.0 (TID 223) in 15 ms on 192.168.1.4 (executor 0) (1/7)
72225 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 5
72225 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 34.0 (TID 224) in 16 ms on 192.168.1.4 (executor 0) (2/7)
72228 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 4
72228 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 34.0 (TID 225) in 18 ms on 192.168.1.4 (executor 0) (3/7)
72228 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 3
72228 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 34.0 (TID 226) in 18 ms on 192.168.1.4 (executor 0) (4/7)
72229 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 2
72229 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 34.0 (TID 221) in 23 ms on 192.168.1.4 (executor 0) (5/7)
72230 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 1
72230 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 34.0 (TID 222) in 23 ms on 192.168.1.4 (executor 0) (6/7)
72231 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_34.0, runningTasks: 0
72231 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 34.0 (TID 220) in 26 ms on 192.168.1.4 (executor 0) (7/7)
72231 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 34.0, whose tasks have all completed, from pool 
72231 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 34 (zipWithIndex at SparkUtils.java:391) finished in 0.026 s
72231 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 34, remaining stages = 0
72232 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 22 finished: zipWithIndex at SparkUtils.java:391, took 0.029889 s
72232 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
72232 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72232 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
72232 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
72232 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72232 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72233 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72234 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72235 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72235 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72235 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
72236 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47 stored as values in memory (estimated size 30.5 KB, free 366.3 MB)
72236 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_47 locally took  1 ms
72236 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_47 without replication took  1 ms
72237 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.3 MB)
72237 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_47_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
72237 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_47_piece0
72237 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_47_piece0
72237 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_47_piece0 locally took  0 ms
72237 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_47_piece0 without replication took  0 ms
72238 [main] INFO org.apache.spark.SparkContext  - Created broadcast 47 from broadcast at ParameterAveragingTrainingMaster.java:259
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72238 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72239 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72239 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72239 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72239 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
72239 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72240 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72241 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72242 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72243 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72244 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72244 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72244 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72244 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
72244 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72245 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72246 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72247 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
72248 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
72249 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
72249 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
72249 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 12 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
72249 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 69 (mapToPair at SparkUtils.java:391)
72250 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 74 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
72250 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 23 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
72250 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 37 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
72250 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 36)
72250 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 36)
72250 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 37)
72250 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 36)
72250 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 36)
72250 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 35)
72250 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 35)
72250 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72250 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 35 (MapPartitionsRDD[69] at mapToPair at SparkUtils.java:391), which has no missing parents
72250 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 35)
72251 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48 stored as values in memory (estimated size 3.5 KB, free 366.3 MB)
72251 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_48 locally took  0 ms
72251 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_48 without replication took  0 ms
72252 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
72252 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_48_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
72252 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_48_piece0
72252 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_48_piece0
72252 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_48_piece0 locally took  0 ms
72252 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_48_piece0 without replication took  0 ms
72252 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 48 from broadcast at DAGScheduler.scala:1006
72252 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[69] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
72252 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 35.0 with 8 tasks
72253 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 35.0: 12
72253 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 35.0: PROCESS_LOCAL, NODE_LOCAL, ANY
72253 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 0
72254 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 35 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
72254 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 35.0 (TID 227, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
72254 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 35.0 (TID 228, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
72255 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 35.0 (TID 229, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
72256 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 35.0 (TID 230, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
72257 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 35.0 (TID 231, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
72257 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 35.0 (TID 232, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
72258 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 35.0 (TID 233, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
72259 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 35.0 (TID 234, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
72259 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 227 on executor id: 0 hostname: 192.168.1.4.
72260 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 228 on executor id: 0 hostname: 192.168.1.4.
72260 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 229 on executor id: 0 hostname: 192.168.1.4.
72260 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 230 on executor id: 0 hostname: 192.168.1.4.
72260 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 231 on executor id: 0 hostname: 192.168.1.4.
72260 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 232 on executor id: 0 hostname: 192.168.1.4.
72261 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 233 on executor id: 0 hostname: 192.168.1.4.
72261 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 234 on executor id: 0 hostname: 192.168.1.4.
72266 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_48_piece0 as bytes
72266 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_48_piece0 is StorageLevel(disk, memory, 1 replicas)
72267 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_48_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.5 MB)
72275 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 7
72275 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
72275 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
72275 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 35.0 (TID 231) in 19 ms on 192.168.1.4 (executor 0) (1/8)
72276 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72276 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 6
72276 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 35.0 (TID 229) in 22 ms on 192.168.1.4 (executor 0) (2/8)
72276 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72279 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 5
72279 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 35.0 (TID 233) in 21 ms on 192.168.1.4 (executor 0) (3/8)
72279 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72280 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 4
72280 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 35.0 (TID 227) in 27 ms on 192.168.1.4 (executor 0) (4/8)
72280 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72280 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 3
72281 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 35.0 (TID 228) in 27 ms on 192.168.1.4 (executor 0) (5/8)
72281 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72281 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 2
72281 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 35.0 (TID 232) in 24 ms on 192.168.1.4 (executor 0) (6/8)
72281 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72282 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 1
72282 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 35.0 (TID 234) in 24 ms on 192.168.1.4 (executor 0) (7/8)
72282 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72284 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_35.0, runningTasks: 0
72284 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 35.0 (TID 230) in 29 ms on 192.168.1.4 (executor 0) (8/8)
72284 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 35.0, whose tasks have all completed, from pool 
72284 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
72284 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 35 (mapToPair at SparkUtils.java:391) finished in 0.031 s
72284 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
72284 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
72284 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 37, ShuffleMapStage 36)
72284 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
72284 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 13
72284 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 36)
72284 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
72284 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 36 (MapPartitionsRDD[74] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
72284 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 36)
72285 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49 stored as values in memory (estimated size 6.6 KB, free 366.2 MB)
72285 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_49 locally took  0 ms
72285 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_49 without replication took  0 ms
72286 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
72286 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_49_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
72286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_49_piece0
72286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_49_piece0
72286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_49_piece0 locally took  0 ms
72286 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_49_piece0 without replication took  0 ms
72286 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 49 from broadcast at DAGScheduler.scala:1006
72287 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[74] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
72287 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 36.0 with 8 tasks
72287 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 36.0: 13
72287 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 36.0: NODE_LOCAL, ANY
72287 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 0
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 36.0 (TID 235, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 36.0 (TID 236, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 36.0 (TID 237, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 36.0 (TID 238, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 36.0 (TID 239, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 36.0 (TID 240, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 36.0 (TID 241, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
72287 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 36.0 (TID 242, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 235 on executor id: 0 hostname: 192.168.1.4.
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 236 on executor id: 0 hostname: 192.168.1.4.
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 237 on executor id: 0 hostname: 192.168.1.4.
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 238 on executor id: 0 hostname: 192.168.1.4.
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 239 on executor id: 0 hostname: 192.168.1.4.
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 240 on executor id: 0 hostname: 192.168.1.4.
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 241 on executor id: 0 hostname: 192.168.1.4.
72288 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 242 on executor id: 0 hostname: 192.168.1.4.
72291 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_49_piece0 as bytes
72291 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_49_piece0 is StorageLevel(disk, memory, 1 replicas)
72292 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_49_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.5 MB)
72294 [dispatcher-event-loop-1] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 13 to 192.168.1.4:49914
72294 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 13 to 192.168.1.4:49914
72294 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 13
72294 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 13
72295 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 13 is 186 bytes
72298 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_47_piece0 as bytes
72298 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_47_piece0 is StorageLevel(disk, memory, 1 replicas)
72299 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_47_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
72376 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 8
73375 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 8
74337 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 7
74337 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
74338 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 36.0 (TID 242) in 2050 ms on 192.168.1.4 (executor 0) (1/8)
74338 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
74375 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 7
75379 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 7
75953 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 6
75953 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 36.0 (TID 241) in 3666 ms on 192.168.1.4 (executor 0) (2/8)
75953 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76073 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 5
76073 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 36.0 (TID 240) in 3786 ms on 192.168.1.4 (executor 0) (3/8)
76073 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76378 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 5
76449 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 4
76449 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 36.0 (TID 239) in 4162 ms on 192.168.1.4 (executor 0) (4/8)
76449 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 3
76449 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 2
76449 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76449 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 36.0 (TID 237) in 4162 ms on 192.168.1.4 (executor 0) (5/8)
76449 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 36.0 (TID 238) in 4162 ms on 192.168.1.4 (executor 0) (6/8)
76449 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76449 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 1
76449 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76449 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 36.0 (TID 235) in 4162 ms on 192.168.1.4 (executor 0) (7/8)
76450 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76484 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_36.0, runningTasks: 0
76484 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 36.0 (TID 236) in 4197 ms on 192.168.1.4 (executor 0) (8/8)
76484 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 36.0, whose tasks have all completed, from pool 
76484 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
76484 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 36 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.197 s
76484 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
76484 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
76484 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 37)
76484 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
76484 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 14
76484 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 37)
76484 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
76484 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 37 (MapPartitionsRDD[76] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
76484 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 37)
76485 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
76485 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_50 locally took  0 ms
76485 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_50 without replication took  0 ms
76486 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
76486 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_50_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
76487 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_50_piece0
76487 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_50_piece0
76487 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_50_piece0 locally took  1 ms
76487 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_50_piece0 without replication took  1 ms
76487 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 50 from broadcast at DAGScheduler.scala:1006
76487 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[76] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
76487 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 37.0 with 2 tasks
76487 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 37.0: 14
76487 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 37.0: NODE_LOCAL, ANY
76487 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_37.0, runningTasks: 0
76488 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 37.0 (TID 243, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
76488 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 37.0 (TID 244, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
76488 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
76488 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 243 on executor id: 0 hostname: 192.168.1.4.
76488 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 244 on executor id: 0 hostname: 192.168.1.4.
76492 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_50_piece0 as bytes
76492 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_50_piece0 is StorageLevel(disk, memory, 1 replicas)
76493 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_50_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
76495 [dispatcher-event-loop-2] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 12 to 192.168.1.4:49914
76495 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 12 to 192.168.1.4:49914
76495 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 12
76495 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 12
76495 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 12 is 159 bytes
76614 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_37.0, runningTasks: 1
76615 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 37.0 (TID 244) in 127 ms on 192.168.1.4 (executor 0) (1/2)
76630 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_37.0, runningTasks: 0
76665 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 37.0 (TID 243) in 178 ms on 192.168.1.4 (executor 0) (2/2)
76665 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 37.0, whose tasks have all completed, from pool 
76665 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 37 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.178 s
76665 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 35, remaining stages = 2
76665 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 37, remaining stages = 1
76665 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 36, remaining stages = 0
76666 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 23 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.416690 s
76667 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
76668 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
76668 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_51 locally took  0 ms
76669 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_51 without replication took  1 ms
76670 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
76670 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_51_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
76670 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_51_piece0
76670 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_51_piece0
76670 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_51_piece0 locally took  1 ms
76670 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_51_piece0 without replication took  1 ms
76670 [main] INFO org.apache.spark.SparkContext  - Created broadcast 51 from broadcast at SparkDl4jMultiLayer.java:595
76671 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
76671 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_52 locally took  1 ms
76671 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_52 without replication took  1 ms
76672 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
76672 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_52_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
76672 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_52_piece0
76672 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_52_piece0
76672 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_52_piece0 locally took  0 ms
76672 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_52_piece0 without replication took  0 ms
76672 [main] INFO org.apache.spark.SparkContext  - Created broadcast 52 from broadcast at SparkDl4jMultiLayer.java:596
76672 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
76673 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76673 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
76673 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
76673 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76674 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
76675 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76676 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
76725 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
76731 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
76734 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
76734 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
76734 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 14 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
76735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 79 (treeAggregate at SparkDl4jMultiLayer.java:598)
76735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 24 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
76735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 39 (treeAggregate at SparkDl4jMultiLayer.java:598)
76735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 38)
76735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 38)
76735 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 39)
76735 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 38)
76735 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 38)
76735 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
76735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 38 (MapPartitionsRDD[79] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
76735 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 38)
76736 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53 stored as values in memory (estimated size 9.0 KB, free 366.2 MB)
76736 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_53 locally took  0 ms
76736 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_53 without replication took  0 ms
76737 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.2 MB)
76737 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_53_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
76737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_53_piece0
76737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_53_piece0
76737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_53_piece0 locally took  0 ms
76737 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_53_piece0 without replication took  0 ms
76737 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 53 from broadcast at DAGScheduler.scala:1006
76737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[79] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
76737 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 38.0 with 8 tasks
76737 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 38.0: 14
76738 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 38.0: NO_PREF, ANY
76738 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 0
76738 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 38.0 (TID 245, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
76738 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 38.0 (TID 246, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
76739 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 38.0 (TID 247, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
76739 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 38.0 (TID 248, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
76739 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 38.0 (TID 249, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
76739 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 38.0 (TID 250, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
76740 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 38.0 (TID 251, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
76740 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 38.0 (TID 252, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
76740 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 245 on executor id: 0 hostname: 192.168.1.4.
76740 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 246 on executor id: 0 hostname: 192.168.1.4.
76741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 247 on executor id: 0 hostname: 192.168.1.4.
76741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 248 on executor id: 0 hostname: 192.168.1.4.
76741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 249 on executor id: 0 hostname: 192.168.1.4.
76741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 250 on executor id: 0 hostname: 192.168.1.4.
76741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 251 on executor id: 0 hostname: 192.168.1.4.
76741 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 252 on executor id: 0 hostname: 192.168.1.4.
76745 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_53_piece0 as bytes
76745 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_53_piece0 is StorageLevel(disk, memory, 1 replicas)
76746 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_53_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
76749 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_52_piece0 as bytes
76749 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_52_piece0 is StorageLevel(disk, memory, 1 replicas)
76750 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_52_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
76774 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_51_piece0 as bytes
76774 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_51_piece0 is StorageLevel(disk, memory, 1 replicas)
76776 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_51_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
77090 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 7
77091 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
77091 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 38.0 (TID 252) in 351 ms on 192.168.1.4 (executor 0) (1/8)
77091 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77261 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 6
77261 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 38.0 (TID 245) in 523 ms on 192.168.1.4 (executor 0) (2/8)
77262 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77375 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 6
77390 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 5
77390 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 38.0 (TID 250) in 651 ms on 192.168.1.4 (executor 0) (3/8)
77390 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77398 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 4
77398 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 38.0 (TID 251) in 659 ms on 192.168.1.4 (executor 0) (4/8)
77398 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77448 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 3
77448 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 38.0 (TID 247) in 710 ms on 192.168.1.4 (executor 0) (5/8)
77448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77453 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 2
77453 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 38.0 (TID 246) in 715 ms on 192.168.1.4 (executor 0) (6/8)
77454 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77464 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 1
77464 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_38.0, runningTasks: 0
77464 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 38.0 (TID 249) in 725 ms on 192.168.1.4 (executor 0) (7/8)
77464 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 38.0 (TID 248) in 725 ms on 192.168.1.4 (executor 0) (8/8)
77464 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77464 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 38.0, whose tasks have all completed, from pool 
77464 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77464 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 38 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.726 s
77464 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
77464 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
77464 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 39)
77464 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
77464 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 15
77464 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 39)
77464 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77464 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 39 (MapPartitionsRDD[81] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
77464 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 39)
77465 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
77465 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_54 locally took  0 ms
77465 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_54 without replication took  0 ms
77466 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
77466 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_54_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
77466 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_54_piece0
77466 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_54_piece0
77466 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_54_piece0 locally took  0 ms
77466 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_54_piece0 without replication took  0 ms
77466 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 54 from broadcast at DAGScheduler.scala:1006
77467 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[81] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
77467 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 39.0 with 2 tasks
77467 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 39.0: 15
77467 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 39.0: NODE_LOCAL, ANY
77468 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_39.0, runningTasks: 0
77468 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 39.0 (TID 253, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
77468 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 39.0 (TID 254, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
77468 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77468 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 253 on executor id: 0 hostname: 192.168.1.4.
77468 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 254 on executor id: 0 hostname: 192.168.1.4.
77470 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_54_piece0 as bytes
77471 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_54_piece0 is StorageLevel(disk, memory, 1 replicas)
77472 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_54_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
77474 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 14 to 192.168.1.4:49914
77474 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 14 to 192.168.1.4:49914
77474 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 14
77474 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 14
77474 [map-output-dispatcher-6] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 14 is 159 bytes
77479 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_39.0, runningTasks: 1
77479 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_39.0, runningTasks: 0
77479 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 39.0 (TID 254) in 11 ms on 192.168.1.4 (executor 0) (1/2)
77479 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 39.0 (TID 253) in 11 ms on 192.168.1.4 (executor 0) (2/2)
77479 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 39.0, whose tasks have all completed, from pool 
77479 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 39 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.012 s
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 38, remaining stages = 1
77479 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 39, remaining stages = 0
77480 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 24 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.745217 s
77480 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 4: Accuracy = 0.19, F1 = 0.32
77480 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 4
77480 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
77481 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77482 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
77482 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
77482 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 25 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
77482 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 40 (count at ParameterAveragingTrainingMaster.java:325)
77482 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
77482 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
77483 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 40)
77483 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77483 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 40 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
77483 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 40)
77483 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
77483 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_55 locally took  0 ms
77483 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_55 without replication took  0 ms
77484 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
77484 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_55_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.3 MB)
77484 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_55_piece0
77484 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_55_piece0
77484 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_55_piece0 locally took  0 ms
77484 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_55_piece0 without replication took  0 ms
77484 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 55 from broadcast at DAGScheduler.scala:1006
77485 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 40 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77485 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 40.0 with 8 tasks
77485 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 40.0: 15
77485 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 40.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77485 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 0
77486 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 40 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77486 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 40.0 (TID 255, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
77487 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 40.0 (TID 256, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
77487 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 40.0 (TID 257, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
77488 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 40.0 (TID 258, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
77489 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 40.0 (TID 259, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
77490 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 40.0 (TID 260, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
77491 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 40.0 (TID 261, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
77491 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 40.0 (TID 262, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
77492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 255 on executor id: 0 hostname: 192.168.1.4.
77492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 256 on executor id: 0 hostname: 192.168.1.4.
77492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 257 on executor id: 0 hostname: 192.168.1.4.
77492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 258 on executor id: 0 hostname: 192.168.1.4.
77492 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 259 on executor id: 0 hostname: 192.168.1.4.
77493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 260 on executor id: 0 hostname: 192.168.1.4.
77493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 261 on executor id: 0 hostname: 192.168.1.4.
77493 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 262 on executor id: 0 hostname: 192.168.1.4.
77498 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_55_piece0 as bytes
77498 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_55_piece0 is StorageLevel(disk, memory, 1 replicas)
77499 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_55_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
77503 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 7
77503 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77503 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77503 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 40.0 (TID 260) in 14 ms on 192.168.1.4 (executor 0) (1/8)
77503 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 6
77503 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 5
77503 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 40.0 (TID 255) in 18 ms on 192.168.1.4 (executor 0) (2/8)
77503 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 40.0 (TID 262) in 12 ms on 192.168.1.4 (executor 0) (3/8)
77504 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 4
77504 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 40.0 (TID 257) in 17 ms on 192.168.1.4 (executor 0) (4/8)
77504 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 3
77504 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 40.0 (TID 259) in 16 ms on 192.168.1.4 (executor 0) (5/8)
77504 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 2
77505 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 40.0 (TID 261) in 15 ms on 192.168.1.4 (executor 0) (6/8)
77505 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 1
77505 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 40.0 (TID 258) in 18 ms on 192.168.1.4 (executor 0) (7/8)
77505 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_40.0, runningTasks: 0
77505 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 40.0 (TID 256) in 19 ms on 192.168.1.4 (executor 0) (8/8)
77505 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 40.0, whose tasks have all completed, from pool 
77505 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 40 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.020 s
77505 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 40, remaining stages = 0
77506 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 25 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.023519 s
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77506 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
77507 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77507 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
77508 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353)
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
77509 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353)
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77510 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77511 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77511 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77511 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77511 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
77511 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
77511 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 26 (collect at SparkUtils.java:353) with 8 output partitions
77511 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 41 (collect at SparkUtils.java:353)
77511 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
77511 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
77511 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 41)
77512 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77512 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 41 (MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
77512 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 41)
77512 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
77512 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_56 locally took  0 ms
77512 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_56 without replication took  0 ms
77513 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
77513 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_56_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.3 MB)
77513 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_56_piece0
77513 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_56_piece0
77513 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_56_piece0 locally took  0 ms
77513 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_56_piece0 without replication took  0 ms
77513 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 56 from broadcast at DAGScheduler.scala:1006
77514 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 41 (MapPartitionsRDD[83] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77514 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 41.0 with 8 tasks
77514 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 41.0: 15
77514 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 41.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77514 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 0
77515 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 41 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77515 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 41.0 (TID 263, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
77516 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 41.0 (TID 264, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
77516 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 41.0 (TID 265, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
77517 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 41.0 (TID 266, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
77518 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 41.0 (TID 267, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
77519 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 41.0 (TID 268, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
77519 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 41.0 (TID 269, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
77520 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 41.0 (TID 270, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
77521 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 263 on executor id: 0 hostname: 192.168.1.4.
77521 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 264 on executor id: 0 hostname: 192.168.1.4.
77521 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 265 on executor id: 0 hostname: 192.168.1.4.
77521 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 266 on executor id: 0 hostname: 192.168.1.4.
77521 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 267 on executor id: 0 hostname: 192.168.1.4.
77521 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 268 on executor id: 0 hostname: 192.168.1.4.
77522 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 269 on executor id: 0 hostname: 192.168.1.4.
77522 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 270 on executor id: 0 hostname: 192.168.1.4.
77527 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_56_piece0 as bytes
77527 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_56_piece0 is StorageLevel(disk, memory, 1 replicas)
77528 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_56_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
77532 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 7
77532 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77532 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77532 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 41.0 (TID 265) in 16 ms on 192.168.1.4 (executor 0) (1/8)
77533 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 6
77533 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 41.0 (TID 263) in 19 ms on 192.168.1.4 (executor 0) (2/8)
77533 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 5
77533 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 4
77533 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 41.0 (TID 270) in 14 ms on 192.168.1.4 (executor 0) (3/8)
77533 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 41.0 (TID 267) in 16 ms on 192.168.1.4 (executor 0) (4/8)
77533 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 3
77534 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 41.0 (TID 268) in 16 ms on 192.168.1.4 (executor 0) (5/8)
77534 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 2
77534 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 41.0 (TID 264) in 19 ms on 192.168.1.4 (executor 0) (6/8)
77534 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 1
77534 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 41.0 (TID 269) in 15 ms on 192.168.1.4 (executor 0) (7/8)
77535 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_41.0, runningTasks: 0
77535 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 41.0 (TID 266) in 19 ms on 192.168.1.4 (executor 0) (8/8)
77535 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 41.0, whose tasks have all completed, from pool 
77535 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 41 (collect at SparkUtils.java:353) finished in 0.021 s
77535 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 41, remaining stages = 0
77535 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 26 finished: collect at SparkUtils.java:353, took 0.024144 s
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77536 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77537 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
77537 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
77537 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 27 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
77537 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 42 (zipWithIndex at SparkUtils.java:391)
77537 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
77538 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
77538 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 42)
77538 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77538 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 42 (MapPartitionsRDD[82] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
77538 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 42)
77538 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
77538 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_57 locally took  0 ms
77538 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_57 without replication took  0 ms
77539 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
77539 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_57_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
77539 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_57_piece0
77539 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_57_piece0
77539 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_57_piece0 locally took  0 ms
77539 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_57_piece0 without replication took  0 ms
77539 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 57 from broadcast at DAGScheduler.scala:1006
77540 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 42 (MapPartitionsRDD[82] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
77540 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 42.0 with 7 tasks
77540 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 42.0: 15
77540 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 42.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77540 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 0
77541 [dispatcher-event-loop-6] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 42 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77541 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 42.0 (TID 271, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
77542 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 42.0 (TID 272, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
77542 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 42.0 (TID 273, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
77543 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 42.0 (TID 274, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
77544 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 42.0 (TID 275, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
77545 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 42.0 (TID 276, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
77545 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 42.0 (TID 277, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
77545 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77545 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77546 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 271 on executor id: 0 hostname: 192.168.1.4.
77546 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 272 on executor id: 0 hostname: 192.168.1.4.
77546 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 273 on executor id: 0 hostname: 192.168.1.4.
77546 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 274 on executor id: 0 hostname: 192.168.1.4.
77547 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 275 on executor id: 0 hostname: 192.168.1.4.
77547 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 276 on executor id: 0 hostname: 192.168.1.4.
77547 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 277 on executor id: 0 hostname: 192.168.1.4.
77551 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_57_piece0 as bytes
77551 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_57_piece0 is StorageLevel(disk, memory, 1 replicas)
77552 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_57_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.4 MB)
77555 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 6
77555 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 42.0 (TID 271) in 15 ms on 192.168.1.4 (executor 0) (1/7)
77555 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 5
77555 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 42.0 (TID 276) in 11 ms on 192.168.1.4 (executor 0) (2/7)
77556 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 4
77556 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 3
77556 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 42.0 (TID 274) in 14 ms on 192.168.1.4 (executor 0) (3/7)
77556 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 42.0 (TID 272) in 15 ms on 192.168.1.4 (executor 0) (4/7)
77556 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 2
77556 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 1
77556 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_42.0, runningTasks: 0
77556 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 42.0 (TID 275) in 13 ms on 192.168.1.4 (executor 0) (5/7)
77556 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 42.0 (TID 273) in 14 ms on 192.168.1.4 (executor 0) (6/7)
77556 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 42.0 (TID 277) in 11 ms on 192.168.1.4 (executor 0) (7/7)
77556 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 42.0, whose tasks have all completed, from pool 
77557 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 42 (zipWithIndex at SparkUtils.java:391) finished in 0.016 s
77557 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 42, remaining stages = 0
77557 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 27 finished: zipWithIndex at SparkUtils.java:391, took 0.019497 s
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77557 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77558 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77559 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77559 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77559 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77559 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
77560 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58 stored as values in memory (estimated size 30.9 KB, free 366.1 MB)
77560 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_58 locally took  1 ms
77560 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_58 without replication took  1 ms
77560 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
77561 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_58_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
77561 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_58_piece0
77561 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_58_piece0
77561 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_58_piece0 locally took  1 ms
77561 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_58_piece0 without replication took  1 ms
77561 [main] INFO org.apache.spark.SparkContext  - Created broadcast 58 from broadcast at ParameterAveragingTrainingMaster.java:259
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77561 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77562 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77563 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77564 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
77565 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
77565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
77565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
77565 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77566 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
77567 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77568 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77569 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77570 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
77571 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
77571 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
77572 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 15 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
77572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 85 (mapToPair at SparkUtils.java:391)
77572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 90 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
77572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 28 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
77572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 45 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
77572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 44)
77572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 44)
77572 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 45)
77572 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 44)
77572 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 44)
77572 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 43)
77572 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 43)
77573 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77573 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 43 (MapPartitionsRDD[85] at mapToPair at SparkUtils.java:391), which has no missing parents
77573 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 43)
77574 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
77574 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_59 locally took  1 ms
77574 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_59 without replication took  1 ms
77574 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
77574 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_59_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
77574 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_59_piece0
77575 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_59_piece0
77575 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_59_piece0 locally took  1 ms
77575 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_59_piece0 without replication took  1 ms
77575 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 59 from broadcast at DAGScheduler.scala:1006
77575 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[85] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77575 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 43.0 with 8 tasks
77575 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 43.0: 15
77575 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 43.0: PROCESS_LOCAL, NODE_LOCAL, ANY
77575 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 0
77576 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 43 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
77576 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 43.0 (TID 278, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
77577 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 43.0 (TID 279, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
77577 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 43.0 (TID 280, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
77578 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 43.0 (TID 281, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
77579 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 43.0 (TID 282, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
77580 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 43.0 (TID 283, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
77581 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 43.0 (TID 284, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
77582 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 43.0 (TID 285, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
77582 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 278 on executor id: 0 hostname: 192.168.1.4.
77582 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 279 on executor id: 0 hostname: 192.168.1.4.
77582 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 280 on executor id: 0 hostname: 192.168.1.4.
77582 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 281 on executor id: 0 hostname: 192.168.1.4.
77582 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 282 on executor id: 0 hostname: 192.168.1.4.
77583 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 283 on executor id: 0 hostname: 192.168.1.4.
77583 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 284 on executor id: 0 hostname: 192.168.1.4.
77583 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 285 on executor id: 0 hostname: 192.168.1.4.
77588 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_59_piece0 as bytes
77588 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_59_piece0 is StorageLevel(disk, memory, 1 replicas)
77589 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_59_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
77598 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 7
77598 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
77598 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
77598 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 43.0 (TID 278) in 23 ms on 192.168.1.4 (executor 0) (1/8)
77598 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77599 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 6
77599 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 43.0 (TID 285) in 18 ms on 192.168.1.4 (executor 0) (2/8)
77599 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77600 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 5
77600 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 43.0 (TID 283) in 21 ms on 192.168.1.4 (executor 0) (3/8)
77600 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77601 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 4
77601 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 43.0 (TID 280) in 24 ms on 192.168.1.4 (executor 0) (4/8)
77601 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77604 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 3
77604 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 43.0 (TID 279) in 28 ms on 192.168.1.4 (executor 0) (5/8)
77605 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77606 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 2
77606 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 43.0 (TID 284) in 26 ms on 192.168.1.4 (executor 0) (6/8)
77607 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77607 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 1
77607 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 43.0 (TID 281) in 30 ms on 192.168.1.4 (executor 0) (7/8)
77608 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77610 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_43.0, runningTasks: 0
77611 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 43.0 (TID 282) in 33 ms on 192.168.1.4 (executor 0) (8/8)
77611 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 43.0, whose tasks have all completed, from pool 
77611 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
77612 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 43 (mapToPair at SparkUtils.java:391) finished in 0.036 s
77612 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
77612 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
77612 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 45, ShuffleMapStage 44)
77612 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
77612 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 16
77612 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 44)
77612 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
77612 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 44 (MapPartitionsRDD[90] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
77612 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 44)
77615 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
77615 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_60 locally took  0 ms
77615 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_60 without replication took  0 ms
77616 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
77616 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_60_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
77617 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_60_piece0
77617 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_60_piece0
77617 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_60_piece0 locally took  1 ms
77617 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_60_piece0 without replication took  1 ms
77617 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 60 from broadcast at DAGScheduler.scala:1006
77617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[90] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
77617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 44.0 with 8 tasks
77617 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 44.0: 16
77617 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 44.0: NODE_LOCAL, ANY
77618 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 0
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 44.0 (TID 286, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 44.0 (TID 287, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 44.0 (TID 288, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 44.0 (TID 289, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 44.0 (TID 290, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 44.0 (TID 291, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 44.0 (TID 292, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 44.0 (TID 293, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
77618 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 286 on executor id: 0 hostname: 192.168.1.4.
77618 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 287 on executor id: 0 hostname: 192.168.1.4.
77618 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 288 on executor id: 0 hostname: 192.168.1.4.
77619 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 289 on executor id: 0 hostname: 192.168.1.4.
77619 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 290 on executor id: 0 hostname: 192.168.1.4.
77619 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 291 on executor id: 0 hostname: 192.168.1.4.
77619 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 292 on executor id: 0 hostname: 192.168.1.4.
77619 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 293 on executor id: 0 hostname: 192.168.1.4.
77623 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_60_piece0 as bytes
77623 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_60_piece0 is StorageLevel(disk, memory, 1 replicas)
77624 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_60_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.4 MB)
77629 [dispatcher-event-loop-3] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 16 to 192.168.1.4:49914
77629 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 16 to 192.168.1.4:49914
77629 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 16
77629 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 16
77629 [map-output-dispatcher-7] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 16 is 186 bytes
77632 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_58_piece0 as bytes
77632 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_58_piece0 is StorageLevel(disk, memory, 1 replicas)
77633 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_58_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
78375 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 8
79376 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 8
79515 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 7
79515 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
79515 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 44.0 (TID 291) in 1897 ms on 192.168.1.4 (executor 0) (1/8)
79515 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
80376 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 7
81103 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 6
81103 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 44.0 (TID 292) in 3485 ms on 192.168.1.4 (executor 0) (2/8)
81103 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81321 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 5
81321 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 44.0 (TID 293) in 3703 ms on 192.168.1.4 (executor 0) (3/8)
81321 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81379 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 5
81600 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 4
81600 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 44.0 (TID 288) in 3982 ms on 192.168.1.4 (executor 0) (4/8)
81601 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81655 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 3
81655 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 44.0 (TID 290) in 4037 ms on 192.168.1.4 (executor 0) (5/8)
81655 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81674 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 2
81674 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 44.0 (TID 287) in 4056 ms on 192.168.1.4 (executor 0) (6/8)
81674 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81683 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 1
81683 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 44.0 (TID 286) in 4065 ms on 192.168.1.4 (executor 0) (7/8)
81683 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_44.0, runningTasks: 0
81683 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81683 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 44.0 (TID 289) in 4065 ms on 192.168.1.4 (executor 0) (8/8)
81683 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 44.0, whose tasks have all completed, from pool 
81684 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
81684 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 44 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.067 s
81684 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
81684 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
81684 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 45)
81684 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
81684 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 17
81684 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 45)
81684 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
81684 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 45 (MapPartitionsRDD[92] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
81684 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 45)
81685 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
81685 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_61 locally took  1 ms
81685 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_61 without replication took  1 ms
81685 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
81686 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_61_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
81686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_61_piece0
81686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_61_piece0
81686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_61_piece0 locally took  1 ms
81686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_61_piece0 without replication took  1 ms
81686 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 61 from broadcast at DAGScheduler.scala:1006
81686 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[92] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
81686 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 45.0 with 2 tasks
81686 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 45.0: 17
81686 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 45.0: NODE_LOCAL, ANY
81686 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_45.0, runningTasks: 0
81687 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 45.0 (TID 294, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
81687 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 45.0 (TID 295, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
81687 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
81687 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 294 on executor id: 0 hostname: 192.168.1.4.
81687 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 295 on executor id: 0 hostname: 192.168.1.4.
81689 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_61_piece0 as bytes
81689 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_61_piece0 is StorageLevel(disk, memory, 1 replicas)
81690 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_61_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
81692 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 15 to 192.168.1.4:49914
81692 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 15 to 192.168.1.4:49914
81692 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 15
81692 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 15
81692 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 15 is 159 bytes
81757 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_45.0, runningTasks: 1
81757 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_45.0, runningTasks: 0
81757 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 45.0 (TID 294) in 70 ms on 192.168.1.4 (executor 0) (1/2)
81757 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 45.0 (TID 295) in 70 ms on 192.168.1.4 (executor 0) (2/2)
81757 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 45.0, whose tasks have all completed, from pool 
81757 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 45 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.071 s
81758 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 44, remaining stages = 2
81758 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 43, remaining stages = 1
81758 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 45, remaining stages = 0
81758 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 28 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.186867 s
81760 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
81762 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
81762 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_62 locally took  1 ms
81762 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_62 without replication took  1 ms
81763 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
81763 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_62_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
81763 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_62_piece0
81763 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_62_piece0
81763 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_62_piece0 locally took  1 ms
81763 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_62_piece0 without replication took  1 ms
81763 [main] INFO org.apache.spark.SparkContext  - Created broadcast 62 from broadcast at SparkDl4jMultiLayer.java:595
81764 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
81764 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_63 locally took  1 ms
81764 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_63 without replication took  1 ms
81765 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
81765 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_63_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
81765 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_63_piece0
81765 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_63_piece0
81765 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_63_piece0 locally took  0 ms
81766 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_63_piece0 without replication took  0 ms
81766 [main] INFO org.apache.spark.SparkContext  - Created broadcast 63 from broadcast at SparkDl4jMultiLayer.java:596
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
81768 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81769 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
81772 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
81773 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
81774 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
81776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
81777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
81777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
81777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
81777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
81777 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
81777 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 17 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
81778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 95 (treeAggregate at SparkDl4jMultiLayer.java:598)
81778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 29 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
81778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 47 (treeAggregate at SparkDl4jMultiLayer.java:598)
81778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 46)
81778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 46)
81778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 47)
81778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 46)
81778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 46)
81778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
81778 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 46 (MapPartitionsRDD[95] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
81778 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 46)
81779 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64 stored as values in memory (estimated size 9.0 KB, free 366.1 MB)
81779 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_64 locally took  0 ms
81779 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_64 without replication took  0 ms
81780 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.1 MB)
81780 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_64_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.2 MB)
81781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_64_piece0
81781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_64_piece0
81781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_64_piece0 locally took  1 ms
81781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_64_piece0 without replication took  1 ms
81781 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 64 from broadcast at DAGScheduler.scala:1006
81781 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[95] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
81781 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 46.0 with 8 tasks
81781 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 46.0: 17
81781 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 46.0: NO_PREF, ANY
81781 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 0
81782 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 46.0 (TID 296, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
81782 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 46.0 (TID 297, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
81782 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 46.0 (TID 298, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
81783 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 46.0 (TID 299, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
81783 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 46.0 (TID 300, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
81783 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 46.0 (TID 301, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
81784 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 46.0 (TID 302, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
81784 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 46.0 (TID 303, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
81784 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 296 on executor id: 0 hostname: 192.168.1.4.
81784 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 297 on executor id: 0 hostname: 192.168.1.4.
81784 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 298 on executor id: 0 hostname: 192.168.1.4.
81784 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 299 on executor id: 0 hostname: 192.168.1.4.
81784 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 300 on executor id: 0 hostname: 192.168.1.4.
81785 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 301 on executor id: 0 hostname: 192.168.1.4.
81785 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 302 on executor id: 0 hostname: 192.168.1.4.
81785 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 303 on executor id: 0 hostname: 192.168.1.4.
81789 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_64_piece0 as bytes
81789 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_64_piece0 is StorageLevel(disk, memory, 1 replicas)
81790 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_64_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
81796 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_63_piece0 as bytes
81796 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_63_piece0 is StorageLevel(disk, memory, 1 replicas)
81797 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_63_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
81837 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_62_piece0 as bytes
81837 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_62_piece0 is StorageLevel(disk, memory, 1 replicas)
81838 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_62_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
82177 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 7
82178 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
82178 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 46.0 (TID 303) in 394 ms on 192.168.1.4 (executor 0) (1/8)
82178 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82354 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 6
82354 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 46.0 (TID 296) in 573 ms on 192.168.1.4 (executor 0) (2/8)
82355 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82378 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 6
82414 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 5
82415 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 46.0 (TID 301) in 632 ms on 192.168.1.4 (executor 0) (3/8)
82415 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82470 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 4
82470 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 46.0 (TID 302) in 687 ms on 192.168.1.4 (executor 0) (4/8)
82470 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82532 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 3
82532 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 46.0 (TID 300) in 749 ms on 192.168.1.4 (executor 0) (5/8)
82532 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82532 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 2
82532 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 46.0 (TID 299) in 750 ms on 192.168.1.4 (executor 0) (6/8)
82533 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82571 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 1
82571 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 46.0 (TID 298) in 789 ms on 192.168.1.4 (executor 0) (7/8)
82571 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82572 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_46.0, runningTasks: 0
82572 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 46.0 (TID 297) in 790 ms on 192.168.1.4 (executor 0) (8/8)
82572 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 46.0, whose tasks have all completed, from pool 
82572 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 46 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.791 s
82572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
82572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
82572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 47)
82572 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
82573 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 18
82573 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 47)
82573 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82573 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 47 (MapPartitionsRDD[97] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
82573 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 47)
82573 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
82573 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_65 locally took  0 ms
82573 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_65 without replication took  0 ms
82574 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
82574 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_65_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.2 MB)
82575 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_65_piece0
82575 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_65_piece0
82575 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_65_piece0 locally took  1 ms
82575 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_65_piece0 without replication took  1 ms
82575 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 65 from broadcast at DAGScheduler.scala:1006
82576 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[97] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
82576 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 47.0 with 2 tasks
82577 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 47.0: 18
82577 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 47.0: NODE_LOCAL, ANY
82577 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_47.0, runningTasks: 0
82578 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 47.0 (TID 304, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
82578 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 47.0 (TID 305, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
82578 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82578 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 304 on executor id: 0 hostname: 192.168.1.4.
82579 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 305 on executor id: 0 hostname: 192.168.1.4.
82583 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_65_piece0 as bytes
82583 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_65_piece0 is StorageLevel(disk, memory, 1 replicas)
82584 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_65_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
82586 [dispatcher-event-loop-2] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 17 to 192.168.1.4:49914
82586 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 17 to 192.168.1.4:49914
82586 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 17
82586 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 17
82586 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 17 is 159 bytes
82589 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_47.0, runningTasks: 1
82590 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_47.0, runningTasks: 0
82590 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 47.0 (TID 305) in 12 ms on 192.168.1.4 (executor 0) (1/2)
82590 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 47.0 (TID 304) in 13 ms on 192.168.1.4 (executor 0) (2/2)
82590 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 47.0, whose tasks have all completed, from pool 
82590 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 47 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.013 s
82590 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 47, remaining stages = 1
82590 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 46, remaining stages = 0
82591 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 29 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.813695 s
82591 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 5: Accuracy = 0.19, F1 = 0.32
82591 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 5
82591 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82593 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82594 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82594 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82594 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
82594 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82595 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82596 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82596 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82596 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
82596 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
82596 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 30 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
82596 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 48 (count at ParameterAveragingTrainingMaster.java:325)
82596 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
82596 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
82596 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 48)
82596 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82597 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 48 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
82597 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 48)
82597 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
82597 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_66 locally took  0 ms
82597 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_66 without replication took  0 ms
82598 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
82599 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_66_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.2 MB)
82599 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_66_piece0
82599 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_66_piece0
82599 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_66_piece0 locally took  1 ms
82599 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_66_piece0 without replication took  1 ms
82599 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 66 from broadcast at DAGScheduler.scala:1006
82599 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 48 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82599 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 48.0 with 8 tasks
82599 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 48.0: 18
82599 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 48.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82599 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 0
82600 [dispatcher-event-loop-1] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 48 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82600 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 48.0 (TID 306, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
82601 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 48.0 (TID 307, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
82602 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 48.0 (TID 308, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
82603 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 48.0 (TID 309, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
82604 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 48.0 (TID 310, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
82604 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 48.0 (TID 311, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
82605 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 48.0 (TID 312, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
82606 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 48.0 (TID 313, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
82606 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 306 on executor id: 0 hostname: 192.168.1.4.
82607 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 307 on executor id: 0 hostname: 192.168.1.4.
82607 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 308 on executor id: 0 hostname: 192.168.1.4.
82607 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 309 on executor id: 0 hostname: 192.168.1.4.
82607 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 310 on executor id: 0 hostname: 192.168.1.4.
82608 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 311 on executor id: 0 hostname: 192.168.1.4.
82609 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 312 on executor id: 0 hostname: 192.168.1.4.
82609 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 313 on executor id: 0 hostname: 192.168.1.4.
82616 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_66_piece0 as bytes
82616 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_66_piece0 is StorageLevel(disk, memory, 1 replicas)
82618 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_66_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
82622 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 7
82622 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82622 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82622 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 6
82622 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 48.0 (TID 310) in 19 ms on 192.168.1.4 (executor 0) (1/8)
82622 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 5
82622 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 48.0 (TID 311) in 18 ms on 192.168.1.4 (executor 0) (2/8)
82622 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 4
82622 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 48.0 (TID 306) in 23 ms on 192.168.1.4 (executor 0) (3/8)
82622 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 48.0 (TID 308) in 21 ms on 192.168.1.4 (executor 0) (4/8)
82623 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 3
82623 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 2
82623 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 48.0 (TID 313) in 18 ms on 192.168.1.4 (executor 0) (5/8)
82623 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 1
82623 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_48.0, runningTasks: 0
82623 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 48.0 (TID 309) in 21 ms on 192.168.1.4 (executor 0) (6/8)
82623 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 48.0 (TID 312) in 19 ms on 192.168.1.4 (executor 0) (7/8)
82623 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 48.0 (TID 307) in 23 ms on 192.168.1.4 (executor 0) (8/8)
82623 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 48.0, whose tasks have all completed, from pool 
82623 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 48 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.024 s
82623 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 48, remaining stages = 0
82623 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 30 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.027622 s
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82624 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82625 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
82625 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
82626 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82627 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
82628 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353)
82629 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
82630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353)
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82632 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82632 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82632 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
82632 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
82632 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 31 (collect at SparkUtils.java:353) with 8 output partitions
82632 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 49 (collect at SparkUtils.java:353)
82632 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
82632 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
82632 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 49)
82632 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82632 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 49 (MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
82632 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 49)
82633 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
82633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_67 locally took  0 ms
82633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_67 without replication took  0 ms
82634 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.0 MB)
82634 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_67_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.2 MB)
82634 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_67_piece0
82634 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_67_piece0
82634 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_67_piece0 locally took  0 ms
82634 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_67_piece0 without replication took  0 ms
82634 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 67 from broadcast at DAGScheduler.scala:1006
82635 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 49 (MapPartitionsRDD[99] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82635 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 49.0 with 8 tasks
82635 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 49.0: 18
82635 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 49.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82635 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 0
82636 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 49 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82636 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 49.0 (TID 314, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
82637 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 49.0 (TID 315, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
82638 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 49.0 (TID 316, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
82638 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 49.0 (TID 317, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
82639 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 49.0 (TID 318, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
82640 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 49.0 (TID 319, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
82641 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 49.0 (TID 320, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
82642 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 49.0 (TID 321, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
82642 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 314 on executor id: 0 hostname: 192.168.1.4.
82642 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 315 on executor id: 0 hostname: 192.168.1.4.
82642 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 316 on executor id: 0 hostname: 192.168.1.4.
82642 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 317 on executor id: 0 hostname: 192.168.1.4.
82643 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 318 on executor id: 0 hostname: 192.168.1.4.
82643 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 319 on executor id: 0 hostname: 192.168.1.4.
82643 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 320 on executor id: 0 hostname: 192.168.1.4.
82643 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 321 on executor id: 0 hostname: 192.168.1.4.
82650 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_67_piece0 as bytes
82651 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_67_piece0 is StorageLevel(disk, memory, 1 replicas)
82652 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_67_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
82656 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 7
82656 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82657 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82657 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 49.0 (TID 316) in 20 ms on 192.168.1.4 (executor 0) (1/8)
82658 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 6
82658 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 49.0 (TID 315) in 22 ms on 192.168.1.4 (executor 0) (2/8)
82659 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 5
82659 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 49.0 (TID 320) in 19 ms on 192.168.1.4 (executor 0) (3/8)
82661 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 4
82661 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 3
82661 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 49.0 (TID 314) in 26 ms on 192.168.1.4 (executor 0) (4/8)
82661 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 49.0 (TID 318) in 23 ms on 192.168.1.4 (executor 0) (5/8)
82661 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 2
82661 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 49.0 (TID 321) in 20 ms on 192.168.1.4 (executor 0) (6/8)
82664 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 1
82664 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_49.0, runningTasks: 0
82664 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 49.0 (TID 317) in 26 ms on 192.168.1.4 (executor 0) (7/8)
82664 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 49.0 (TID 319) in 25 ms on 192.168.1.4 (executor 0) (8/8)
82665 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 49.0, whose tasks have all completed, from pool 
82665 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 49 (collect at SparkUtils.java:353) finished in 0.030 s
82665 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 49, remaining stages = 0
82665 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 31 finished: collect at SparkUtils.java:353, took 0.033199 s
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82666 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82667 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82668 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82668 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82668 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
82668 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
82668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 32 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
82668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 50 (zipWithIndex at SparkUtils.java:391)
82668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
82668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
82668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 50)
82668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 50 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
82668 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 50)
82669 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68 stored as values in memory (estimated size 2.2 KB, free 366.0 MB)
82669 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_68 locally took  0 ms
82669 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_68 without replication took  0 ms
82684 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(49)
82684 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 49
82684 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 49
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 49
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 49
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_49_piece0
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49_piece0 of size 3630 dropped from memory (free 383830701)
82685 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.0 MB)
82685 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_49_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.2 MB)
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_49_piece0
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_49_piece0
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_49
82685 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_49 of size 6712 dropped from memory (free 383837413)
82685 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_68_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.2 MB)
82686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_68_piece0
82686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_68_piece0
82686 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 49, response is 0
82686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_68_piece0 locally took  1 ms
82686 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82686 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_68_piece0 without replication took  1 ms
82686 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 68 from broadcast at DAGScheduler.scala:1006
82686 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 50 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
82686 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_49_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.4 MB)
82686 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 50.0 with 7 tasks
82686 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 50.0: 18
82686 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 50.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82687 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 0
82687 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 49
82687 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(17)
82687 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 17
82687 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 17
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 17, response is true
82688 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 17
82688 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(62)
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
82688 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 62
82688 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 62
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 62
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 62
82688 [dispatcher-event-loop-1] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 50 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_62
82688 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 50.0 (TID 322, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62 of size 8224 dropped from memory (free 383845637)
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_62_piece0
82688 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_62_piece0 of size 1428 dropped from memory (free 383847065)
82689 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_62_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.2 MB)
82689 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_62_piece0
82689 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_62_piece0
82689 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 62, response is 0
82689 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82689 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_62_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.4 MB)
82689 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 50.0 (TID 323, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
82690 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 62
82690 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(48)
82690 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 48
82690 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 48
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 48
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 48
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_48_piece0
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48_piece0 of size 2197 dropped from memory (free 383849262)
82691 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 50.0 (TID 324, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
82691 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_48_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_48_piece0
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_48_piece0
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_48
82691 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_48 of size 3600 dropped from memory (free 383852862)
82691 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 48, response is 0
82691 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82692 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_48_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
82693 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 50.0 (TID 325, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
82694 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 48
82694 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(46)
82694 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 46
82694 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 46
82695 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 50.0 (TID 326, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
82695 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 46
82695 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 46
82695 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_46_piece0
82695 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46_piece0 of size 1460 dropped from memory (free 383854322)
82696 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_46_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.3 MB)
82696 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_46_piece0
82696 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_46_piece0
82696 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_46
82696 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_46 of size 2216 dropped from memory (free 383856538)
82696 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 46, response is 0
82697 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82697 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 50.0 (TID 327, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
82698 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_46_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
82698 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 50.0 (TID 328, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
82698 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82698 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82699 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 322 on executor id: 0 hostname: 192.168.1.4.
82699 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 323 on executor id: 0 hostname: 192.168.1.4.
82699 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 324 on executor id: 0 hostname: 192.168.1.4.
82699 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 325 on executor id: 0 hostname: 192.168.1.4.
82699 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 46
82699 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(67)
82699 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 67
82700 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 67
82700 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 326 on executor id: 0 hostname: 192.168.1.4.
82700 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 327 on executor id: 0 hostname: 192.168.1.4.
82700 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 67
82700 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 328 on executor id: 0 hostname: 192.168.1.4.
82700 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 67
82700 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_67_piece0
82700 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67_piece0 of size 1570 dropped from memory (free 383858108)
82701 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_67_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
82701 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_67_piece0
82701 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_67_piece0
82701 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_67
82701 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_67 of size 2504 dropped from memory (free 383860612)
82701 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 67, response is 0
82701 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82703 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_67_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.4 MB)
82704 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 67
82704 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(55)
82704 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 55
82704 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 55
82704 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 55
82704 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 55
82705 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_55_piece0
82705 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55_piece0 of size 1006 dropped from memory (free 383861618)
82705 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_55_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
82705 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_55_piece0
82705 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_55_piece0
82705 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_55
82705 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_55 of size 1448 dropped from memory (free 383863066)
82705 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 55, response is 0
82705 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82706 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_55_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.4 MB)
82707 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 55
82707 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(15)
82707 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 15
82707 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_68_piece0 as bytes
82707 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_68_piece0 is StorageLevel(disk, memory, 1 replicas)
82707 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 15
82707 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 15, response is true
82707 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
82707 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 15
82707 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(57)
82707 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 57
82707 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 57
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 57
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 57
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_57
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57 of size 2216 dropped from memory (free 383865282)
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_57_piece0
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_57_piece0 of size 1460 dropped from memory (free 383866742)
82708 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_57_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.3 MB)
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_57_piece0
82708 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_57_piece0
82708 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 57, response is 0
82708 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82708 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_68_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.4 MB)
82711 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_57_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
82713 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 57
82713 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(54)
82713 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 54
82713 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 54
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 54
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 54
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_54
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54 of size 3656 dropped from memory (free 383870398)
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_54_piece0
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_54_piece0 of size 2126 dropped from memory (free 383872524)
82714 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_54_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_54_piece0
82714 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_54_piece0
82714 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 54, response is 0
82715 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82715 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_54_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
82716 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 54
82716 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(53)
82716 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 53
82716 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 53
82716 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 53
82716 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 53
82716 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_53
82716 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53 of size 9208 dropped from memory (free 383881732)
82716 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_53_piece0
82717 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_53_piece0 of size 4225 dropped from memory (free 383885957)
82717 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_53_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.3 MB)
82717 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_53_piece0
82717 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_53_piece0
82717 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 53, response is 0
82717 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82717 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_53_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.4 MB)
82718 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 53
82718 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(47)
82718 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 47
82718 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 47
82718 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 47
82718 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 47
82719 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_47_piece0
82719 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47_piece0 of size 5327 dropped from memory (free 383891284)
82719 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_47_piece0 on 192.168.1.4:49908 in memory (size: 5.2 KB, free: 366.3 MB)
82719 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_47_piece0
82719 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_47_piece0
82719 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_47
82719 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_47 of size 31208 dropped from memory (free 383922492)
82719 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 6
82719 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 47, response is 0
82719 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82719 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 50.0 (TID 326) in 26 ms on 192.168.1.4 (executor 0) (1/7)
82720 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_47_piece0 on 192.168.1.4:49916 in memory (size: 5.2 KB, free: 365.4 MB)
82722 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 47
82722 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(50)
82722 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 50
82722 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 50
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 50
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 50
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_50
82722 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 5
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50 of size 3672 dropped from memory (free 383926164)
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_50_piece0
82722 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 50.0 (TID 324) in 32 ms on 192.168.1.4 (executor 0) (2/7)
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_50_piece0 of size 2135 dropped from memory (free 383928299)
82722 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_50_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_50_piece0
82722 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_50_piece0
82723 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 50, response is 0
82723 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82723 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_50_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
82724 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 50
82724 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(64)
82724 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 64
82724 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 64
82724 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 64
82724 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 64
82724 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_64_piece0
82724 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64_piece0 of size 4224 dropped from memory (free 383932523)
82725 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_64_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.3 MB)
82725 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_64_piece0
82725 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_64_piece0
82725 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_64
82725 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_64 of size 9208 dropped from memory (free 383941731)
82725 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 64, response is 0
82725 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82728 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_64_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.4 MB)
82729 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 4
82729 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 50.0 (TID 322) in 42 ms on 192.168.1.4 (executor 0) (3/7)
82729 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 64
82729 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(60)
82730 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 60
82730 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 60
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 60
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 60
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_60
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60 of size 6712 dropped from memory (free 383948443)
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_60_piece0
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_60_piece0 of size 3629 dropped from memory (free 383952072)
82730 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_60_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.3 MB)
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_60_piece0
82730 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_60_piece0
82730 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 60, response is 0
82730 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82731 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_60_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.4 MB)
82732 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 60
82732 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(61)
82732 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 61
82732 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 61
82732 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 61
82732 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 61
82732 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_61
82732 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61 of size 3672 dropped from memory (free 383955744)
82732 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_61_piece0
82732 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_61_piece0 of size 2133 dropped from memory (free 383957877)
82732 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_61_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
82733 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_61_piece0
82733 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_61_piece0
82733 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 61, response is 0
82733 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82733 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_61_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
82734 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 61
82734 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(65)
82734 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 65
82734 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 65
82734 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 65
82734 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 65
82734 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_65
82734 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65 of size 3656 dropped from memory (free 383961533)
82734 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_65_piece0
82734 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_65_piece0 of size 2125 dropped from memory (free 383963658)
82734 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_65_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
82735 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_65_piece0
82735 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_65_piece0
82735 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 65, response is 0
82735 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82735 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_65_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
82736 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 65
82736 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(14)
82736 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 14
82736 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 14
82736 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 14
82736 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 14, response is true
82736 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(66)
82736 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
82736 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 66
82736 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 66
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 66
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 66
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_66_piece0
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66_piece0 of size 1006 dropped from memory (free 383964664)
82737 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_66_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_66_piece0
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_66_piece0
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_66
82737 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_66 of size 1448 dropped from memory (free 383966112)
82737 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 66, response is 0
82737 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82737 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_66_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.4 MB)
82738 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 3
82739 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 66
82739 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(59)
82739 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 59
82739 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 50.0 (TID 325) in 48 ms on 192.168.1.4 (executor 0) (4/7)
82739 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 59
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 59
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 59
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_59
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59 of size 3600 dropped from memory (free 383969712)
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_59_piece0
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_59_piece0 of size 2197 dropped from memory (free 383971909)
82739 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_59_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_59_piece0
82739 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_59_piece0
82739 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 59, response is 0
82739 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82740 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_59_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
82741 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 59
82741 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(12)
82741 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 12
82741 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 2
82741 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 50.0 (TID 328) in 44 ms on 192.168.1.4 (executor 0) (5/7)
82741 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 12
82741 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 12
82741 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(51)
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 12, response is true
82741 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 51
82741 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 51
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 51
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 51
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_51
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51 of size 8224 dropped from memory (free 383980133)
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_51_piece0
82741 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_51_piece0 of size 1428 dropped from memory (free 383981561)
82742 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_51_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.3 MB)
82742 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_51_piece0
82742 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_51_piece0
82742 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 51, response is 0
82742 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82745 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_51_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.4 MB)
82746 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 51
82746 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(16)
82746 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 16
82746 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 16
82746 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 16
82746 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(45)
82746 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 45
82746 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 45
82746 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 16, response is true
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 45
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 45
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_45
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45 of size 2504 dropped from memory (free 383984065)
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_45_piece0
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_45_piece0 of size 1570 dropped from memory (free 383985635)
82747 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_45_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_45_piece0
82747 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_45_piece0
82747 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 45, response is 0
82747 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82747 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 1
82747 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 50.0 (TID 323) in 59 ms on 192.168.1.4 (executor 0) (6/7)
82748 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_45_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.4 MB)
82748 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 45
82748 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(56)
82748 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 56
82748 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 56
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 56
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 56
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_56_piece0
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56_piece0 of size 1570 dropped from memory (free 383987205)
82749 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_56_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_56_piece0
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_56_piece0
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_56
82749 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_56 of size 2504 dropped from memory (free 383989709)
82749 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 56, response is 0
82749 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82750 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_56_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.4 MB)
82750 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 56
82750 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(63)
82750 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 63
82750 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 63
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 63
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 63
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_63
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63 of size 27976 dropped from memory (free 384017685)
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_63_piece0
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_63_piece0 of size 2531 dropped from memory (free 384020216)
82751 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_63_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_63_piece0
82751 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_63_piece0
82751 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 63, response is 0
82751 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82751 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_50.0, runningTasks: 0
82751 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 50.0 (TID 327) in 56 ms on 192.168.1.4 (executor 0) (7/7)
82751 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 50.0, whose tasks have all completed, from pool 
82752 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_63_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.4 MB)
82752 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 50 (zipWithIndex at SparkUtils.java:391) finished in 0.065 s
82752 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 50, remaining stages = 0
82752 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 32 finished: zipWithIndex at SparkUtils.java:391, took 0.084169 s
82752 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 63
82752 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(13)
82752 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 13
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
82753 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 13
82753 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 13
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 13, response is true
82753 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(52)
82753 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 52
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
82753 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 52
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 52
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 52
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_52_piece0
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52_piece0 of size 2531 dropped from memory (free 384022747)
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82753 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_52_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
82753 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_52_piece0
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_52_piece0
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_52
82753 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_52 of size 27528 dropped from memory (free 384050275)
82753 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 52, response is 0
82753 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82754 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_52_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.5 MB)
82754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82754 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
82755 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 52
82755 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(58)
82755 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 58
82755 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 58
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
82755 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 58
82755 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 58
82755 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_58
82755 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58 of size 31656 dropped from memory (free 384081931)
82755 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_58_piece0
82755 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_58_piece0 of size 5327 dropped from memory (free 384087258)
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82755 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82756 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_58_piece0 on 192.168.1.4:49908 in memory (size: 5.2 KB, free: 366.3 MB)
82756 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_58_piece0
82756 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_58_piece0
82756 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 58, response is 0
82756 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82756 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_58_piece0 on 192.168.1.4:49916 in memory (size: 5.2 KB, free: 365.5 MB)
82756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82756 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
82757 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 58
82758 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69 stored as values in memory (estimated size 30.5 KB, free 366.3 MB)
82758 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(44)
82758 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 44
82758 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 44
82758 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_69 locally took  1 ms
82758 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_69 without replication took  1 ms
82758 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 44
82758 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 44
82758 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_44
82758 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44 of size 1448 dropped from memory (free 384057498)
82759 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_44_piece0
82759 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_44_piece0 of size 1006 dropped from memory (free 384058504)
82759 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_44_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
82759 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_44_piece0
82760 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_44_piece0
82760 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 44, response is 0
82760 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
82762 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_44_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.5 MB)
82762 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.3 MB)
82762 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_69_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
82762 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_69_piece0
82762 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_69_piece0
82762 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_69_piece0 locally took  0 ms
82763 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_69_piece0 without replication took  1 ms
82763 [main] INFO org.apache.spark.SparkContext  - Created broadcast 69 from broadcast at ParameterAveragingTrainingMaster.java:259
82763 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 44
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82765 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82766 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82767 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82768 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
82769 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82770 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82771 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82772 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82773 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82774 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82775 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82776 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82777 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
82778 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
82779 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
82779 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
82779 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
82779 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
82779 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
82779 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 18 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
82779 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 101 (mapToPair at SparkUtils.java:391)
82780 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 106 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
82780 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 33 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
82780 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 53 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
82780 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 52)
82780 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 52)
82780 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 53)
82780 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 52)
82780 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 52)
82780 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 51)
82780 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 51)
82780 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82780 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 51 (MapPartitionsRDD[101] at mapToPair at SparkUtils.java:391), which has no missing parents
82780 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 51)
82781 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70 stored as values in memory (estimated size 3.5 KB, free 366.3 MB)
82781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_70 locally took  0 ms
82781 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_70 without replication took  0 ms
82782 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.3 MB)
82782 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_70_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
82782 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_70_piece0
82782 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_70_piece0
82782 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_70_piece0 locally took  0 ms
82782 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_70_piece0 without replication took  0 ms
82782 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 70 from broadcast at DAGScheduler.scala:1006
82782 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[101] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82782 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 51.0 with 8 tasks
82782 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 51.0: 18
82783 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 51.0: PROCESS_LOCAL, NODE_LOCAL, ANY
82783 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 0
82783 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 51 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
82784 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 51.0 (TID 329, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
82785 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 51.0 (TID 330, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
82785 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 51.0 (TID 331, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
82786 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 51.0 (TID 332, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
82787 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 51.0 (TID 333, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
82788 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 51.0 (TID 334, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
82788 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 51.0 (TID 335, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
82789 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 51.0 (TID 336, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
82790 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 329 on executor id: 0 hostname: 192.168.1.4.
82790 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 330 on executor id: 0 hostname: 192.168.1.4.
82790 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 331 on executor id: 0 hostname: 192.168.1.4.
82790 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 332 on executor id: 0 hostname: 192.168.1.4.
82790 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 333 on executor id: 0 hostname: 192.168.1.4.
82790 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 334 on executor id: 0 hostname: 192.168.1.4.
82791 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 335 on executor id: 0 hostname: 192.168.1.4.
82791 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 336 on executor id: 0 hostname: 192.168.1.4.
82798 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_70_piece0 as bytes
82799 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_70_piece0 is StorageLevel(disk, memory, 1 replicas)
82800 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_70_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.5 MB)
82808 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 7
82808 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
82808 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
82808 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 6
82808 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 51.0 (TID 334) in 21 ms on 192.168.1.4 (executor 0) (1/8)
82808 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 51.0 (TID 335) in 20 ms on 192.168.1.4 (executor 0) (2/8)
82809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82809 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 5
82809 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 51.0 (TID 333) in 23 ms on 192.168.1.4 (executor 0) (3/8)
82809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82810 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 4
82810 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 51.0 (TID 336) in 22 ms on 192.168.1.4 (executor 0) (4/8)
82811 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82813 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 3
82813 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 2
82813 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 51.0 (TID 330) in 29 ms on 192.168.1.4 (executor 0) (5/8)
82813 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 51.0 (TID 332) in 28 ms on 192.168.1.4 (executor 0) (6/8)
82814 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82814 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82814 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 1
82814 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 51.0 (TID 329) in 31 ms on 192.168.1.4 (executor 0) (7/8)
82814 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82814 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_51.0, runningTasks: 0
82815 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 51.0 (TID 331) in 30 ms on 192.168.1.4 (executor 0) (8/8)
82815 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 51.0, whose tasks have all completed, from pool 
82815 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
82815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 51 (mapToPair at SparkUtils.java:391) finished in 0.032 s
82815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
82815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
82815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 52, ResultStage 53)
82815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
82815 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 19
82815 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 52)
82815 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
82815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 52 (MapPartitionsRDD[106] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
82815 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 52)
82817 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71 stored as values in memory (estimated size 6.6 KB, free 366.2 MB)
82817 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_71 locally took  1 ms
82817 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_71 without replication took  1 ms
82818 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
82818 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_71_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
82818 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_71_piece0
82819 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_71_piece0
82819 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_71_piece0 locally took  1 ms
82819 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_71_piece0 without replication took  1 ms
82819 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 71 from broadcast at DAGScheduler.scala:1006
82819 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[106] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
82819 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 52.0 with 8 tasks
82819 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 52.0: 19
82819 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 52.0: NODE_LOCAL, ANY
82819 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 0
82819 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 52.0 (TID 337, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
82819 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 52.0 (TID 338, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
82819 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 52.0 (TID 339, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
82819 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 52.0 (TID 340, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
82820 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 52.0 (TID 341, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
82820 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 52.0 (TID 342, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
82820 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 52.0 (TID 343, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
82820 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 52.0 (TID 344, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 337 on executor id: 0 hostname: 192.168.1.4.
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 338 on executor id: 0 hostname: 192.168.1.4.
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 339 on executor id: 0 hostname: 192.168.1.4.
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 340 on executor id: 0 hostname: 192.168.1.4.
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 341 on executor id: 0 hostname: 192.168.1.4.
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 342 on executor id: 0 hostname: 192.168.1.4.
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 343 on executor id: 0 hostname: 192.168.1.4.
82820 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 344 on executor id: 0 hostname: 192.168.1.4.
82823 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_71_piece0 as bytes
82823 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_71_piece0 is StorageLevel(disk, memory, 1 replicas)
82824 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_71_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.5 MB)
82828 [dispatcher-event-loop-4] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 19 to 192.168.1.4:49914
82829 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 19 to 192.168.1.4:49914
82829 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 19
82829 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 19
82829 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 19 is 186 bytes
82833 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_69_piece0 as bytes
82833 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_69_piece0 is StorageLevel(disk, memory, 1 replicas)
82834 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_69_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
83376 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 8
84375 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 8
84895 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 7
84895 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
84895 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 52.0 (TID 343) in 2075 ms on 192.168.1.4 (executor 0) (1/8)
84895 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
85378 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 7
86375 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 7
86404 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 6
86405 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 52.0 (TID 344) in 3585 ms on 192.168.1.4 (executor 0) (2/8)
86405 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86501 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 5
86501 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 52.0 (TID 342) in 3681 ms on 192.168.1.4 (executor 0) (3/8)
86502 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86907 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 4
86907 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 52.0 (TID 341) in 4088 ms on 192.168.1.4 (executor 0) (4/8)
86907 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86917 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 3
86917 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 52.0 (TID 339) in 4098 ms on 192.168.1.4 (executor 0) (5/8)
86917 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86919 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 2
86919 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 52.0 (TID 337) in 4100 ms on 192.168.1.4 (executor 0) (6/8)
86919 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86931 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 1
86931 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 52.0 (TID 340) in 4112 ms on 192.168.1.4 (executor 0) (7/8)
86931 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86941 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_52.0, runningTasks: 0
86941 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 52.0 (TID 338) in 4122 ms on 192.168.1.4 (executor 0) (8/8)
86941 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 52.0, whose tasks have all completed, from pool 
86941 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
86941 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 52 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 4.122 s
86941 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
86941 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
86941 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 53)
86941 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
86941 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 20
86941 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 53)
86941 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
86941 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 53 (MapPartitionsRDD[108] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
86941 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 53)
86942 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
86942 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_72 locally took  0 ms
86942 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_72 without replication took  0 ms
86943 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
86943 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_72_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
86943 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_72_piece0
86943 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_72_piece0
86943 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_72_piece0 locally took  0 ms
86943 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_72_piece0 without replication took  0 ms
86943 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 72 from broadcast at DAGScheduler.scala:1006
86944 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[108] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
86944 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 53.0 with 2 tasks
86944 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 53.0: 20
86944 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 53.0: NODE_LOCAL, ANY
86944 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_53.0, runningTasks: 0
86944 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 53.0 (TID 345, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
86944 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 53.0 (TID 346, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
86944 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
86944 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 345 on executor id: 0 hostname: 192.168.1.4.
86944 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 346 on executor id: 0 hostname: 192.168.1.4.
86947 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_72_piece0 as bytes
86947 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_72_piece0 is StorageLevel(disk, memory, 1 replicas)
86948 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_72_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
86949 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 18 to 192.168.1.4:49914
86949 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 18 to 192.168.1.4:49914
86949 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 18
86949 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 18
86949 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 18 is 159 bytes
87060 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_53.0, runningTasks: 1
87060 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_53.0, runningTasks: 0
87060 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 53.0 (TID 346) in 116 ms on 192.168.1.4 (executor 0) (1/2)
87061 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 53.0 (TID 345) in 117 ms on 192.168.1.4 (executor 0) (2/2)
87061 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 53.0, whose tasks have all completed, from pool 
87061 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 53 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.117 s
87061 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 53, remaining stages = 2
87061 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 52, remaining stages = 1
87061 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 51, remaining stages = 0
87061 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 33 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.282437 s
87062 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
87063 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
87063 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_73 locally took  0 ms
87063 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_73 without replication took  0 ms
87064 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
87064 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_73_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
87064 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_73_piece0
87064 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_73_piece0
87064 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_73_piece0 locally took  0 ms
87064 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_73_piece0 without replication took  0 ms
87065 [main] INFO org.apache.spark.SparkContext  - Created broadcast 73 from broadcast at SparkDl4jMultiLayer.java:595
87065 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
87065 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_74 locally took  0 ms
87065 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_74 without replication took  0 ms
87066 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
87066 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_74_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
87066 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_74_piece0
87066 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_74_piece0
87066 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_74_piece0 locally took  0 ms
87066 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_74_piece0 without replication took  0 ms
87066 [main] INFO org.apache.spark.SparkContext  - Created broadcast 74 from broadcast at SparkDl4jMultiLayer.java:596
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87067 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87068 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87069 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87070 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
87070 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
87071 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87072 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87073 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87074 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87075 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
87075 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
87076 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 20 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
87076 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 111 (treeAggregate at SparkDl4jMultiLayer.java:598)
87076 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 34 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
87076 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 55 (treeAggregate at SparkDl4jMultiLayer.java:598)
87076 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 54)
87076 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 54)
87076 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 55)
87076 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 54)
87076 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 54)
87076 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87076 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 54 (MapPartitionsRDD[111] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
87076 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 54)
87077 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75 stored as values in memory (estimated size 9.0 KB, free 366.2 MB)
87077 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_75 locally took  0 ms
87077 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_75 without replication took  0 ms
87078 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.2 MB)
87078 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_75_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
87078 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_75_piece0
87078 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_75_piece0
87078 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_75_piece0 locally took  0 ms
87078 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_75_piece0 without replication took  0 ms
87078 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 75 from broadcast at DAGScheduler.scala:1006
87078 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[111] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87078 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 54.0 with 8 tasks
87078 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 54.0: 20
87078 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 54.0: NO_PREF, ANY
87079 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 0
87079 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 54.0 (TID 347, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
87079 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 54.0 (TID 348, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
87079 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 54.0 (TID 349, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
87080 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 54.0 (TID 350, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
87080 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 54.0 (TID 351, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
87080 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 54.0 (TID 352, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
87081 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 54.0 (TID 353, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
87081 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 54.0 (TID 354, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
87081 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 347 on executor id: 0 hostname: 192.168.1.4.
87081 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 348 on executor id: 0 hostname: 192.168.1.4.
87081 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 349 on executor id: 0 hostname: 192.168.1.4.
87082 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 350 on executor id: 0 hostname: 192.168.1.4.
87082 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 351 on executor id: 0 hostname: 192.168.1.4.
87082 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 352 on executor id: 0 hostname: 192.168.1.4.
87082 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 353 on executor id: 0 hostname: 192.168.1.4.
87082 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 354 on executor id: 0 hostname: 192.168.1.4.
87086 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_75_piece0 as bytes
87086 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_75_piece0 is StorageLevel(disk, memory, 1 replicas)
87087 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_75_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
87089 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_74_piece0 as bytes
87089 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_74_piece0 is StorageLevel(disk, memory, 1 replicas)
87090 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_74_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
87157 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_73_piece0 as bytes
87157 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_73_piece0 is StorageLevel(disk, memory, 1 replicas)
87158 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_73_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
87375 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 8
87401 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 7
87401 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
87401 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 54.0 (TID 354) in 320 ms on 192.168.1.4 (executor 0) (1/8)
87401 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87620 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 6
87620 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 54.0 (TID 347) in 541 ms on 192.168.1.4 (executor 0) (2/8)
87620 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87684 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 5
87685 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 54.0 (TID 353) in 605 ms on 192.168.1.4 (executor 0) (3/8)
87685 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87732 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 4
87733 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 54.0 (TID 352) in 652 ms on 192.168.1.4 (executor 0) (4/8)
87733 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87781 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 3
87781 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 54.0 (TID 349) in 702 ms on 192.168.1.4 (executor 0) (5/8)
87782 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87784 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 2
87784 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 54.0 (TID 350) in 705 ms on 192.168.1.4 (executor 0) (6/8)
87784 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87796 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 1
87796 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 54.0 (TID 351) in 716 ms on 192.168.1.4 (executor 0) (7/8)
87796 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87812 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_54.0, runningTasks: 0
87813 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 54.0 (TID 348) in 733 ms on 192.168.1.4 (executor 0) (8/8)
87813 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 54.0, whose tasks have all completed, from pool 
87813 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 54 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.735 s
87813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
87813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
87813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 55)
87813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
87813 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 21
87813 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 55)
87813 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87813 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 55 (MapPartitionsRDD[113] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
87813 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 55)
87814 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
87814 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_76 locally took  1 ms
87814 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_76 without replication took  1 ms
87814 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
87815 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_76_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
87815 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_76_piece0
87815 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_76_piece0
87815 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_76_piece0 locally took  1 ms
87815 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_76_piece0 without replication took  1 ms
87815 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 76 from broadcast at DAGScheduler.scala:1006
87815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[113] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
87815 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 55.0 with 2 tasks
87815 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 55.0: 21
87815 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 55.0: NODE_LOCAL, ANY
87815 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_55.0, runningTasks: 0
87815 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 55.0 (TID 355, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
87815 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 55.0 (TID 356, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
87815 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87816 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 355 on executor id: 0 hostname: 192.168.1.4.
87816 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 356 on executor id: 0 hostname: 192.168.1.4.
87818 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_76_piece0 as bytes
87818 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_76_piece0 is StorageLevel(disk, memory, 1 replicas)
87819 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_76_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
87820 [dispatcher-event-loop-0] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 20 to 192.168.1.4:49914
87821 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 20 to 192.168.1.4:49914
87821 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 20
87821 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 20
87821 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 20 is 159 bytes
87824 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_55.0, runningTasks: 1
87824 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_55.0, runningTasks: 0
87825 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 55.0 (TID 355) in 10 ms on 192.168.1.4 (executor 0) (1/2)
87825 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 55.0 (TID 356) in 10 ms on 192.168.1.4 (executor 0) (2/2)
87825 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 55.0, whose tasks have all completed, from pool 
87825 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 55 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.010 s
87825 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 55, remaining stages = 1
87825 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 54, remaining stages = 0
87825 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 34 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.749508 s
87826 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 6: Accuracy = 0.19, F1 = 0.32
87826 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 6
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87826 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87827 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
87827 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
87827 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 35 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
87827 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 56 (count at ParameterAveragingTrainingMaster.java:325)
87827 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
87828 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
87828 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 56)
87828 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87828 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 56 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
87828 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 56)
87828 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
87828 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_77 locally took  0 ms
87828 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_77 without replication took  0 ms
87829 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
87829 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_77_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.3 MB)
87829 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_77_piece0
87829 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_77_piece0
87829 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_77_piece0 locally took  0 ms
87829 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_77_piece0 without replication took  0 ms
87829 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 77 from broadcast at DAGScheduler.scala:1006
87829 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 56 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87830 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 56.0 with 8 tasks
87830 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 56.0: 21
87830 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 56.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87830 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 0
87831 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 56 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87831 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 56.0 (TID 357, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
87831 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 56.0 (TID 358, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
87832 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 56.0 (TID 359, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
87833 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 56.0 (TID 360, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
87834 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 56.0 (TID 361, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
87834 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 56.0 (TID 362, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
87835 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 56.0 (TID 363, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
87836 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 56.0 (TID 364, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
87836 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 357 on executor id: 0 hostname: 192.168.1.4.
87836 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 358 on executor id: 0 hostname: 192.168.1.4.
87837 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 359 on executor id: 0 hostname: 192.168.1.4.
87837 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 360 on executor id: 0 hostname: 192.168.1.4.
87837 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 361 on executor id: 0 hostname: 192.168.1.4.
87837 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 362 on executor id: 0 hostname: 192.168.1.4.
87837 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 363 on executor id: 0 hostname: 192.168.1.4.
87837 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 364 on executor id: 0 hostname: 192.168.1.4.
87842 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_77_piece0 as bytes
87842 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_77_piece0 is StorageLevel(disk, memory, 1 replicas)
87843 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_77_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
87846 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 7
87846 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87846 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87846 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 56.0 (TID 357) in 16 ms on 192.168.1.4 (executor 0) (1/8)
87846 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 6
87846 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 56.0 (TID 362) in 12 ms on 192.168.1.4 (executor 0) (2/8)
87846 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 5
87846 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 56.0 (TID 361) in 13 ms on 192.168.1.4 (executor 0) (3/8)
87846 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 4
87846 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 56.0 (TID 360) in 14 ms on 192.168.1.4 (executor 0) (4/8)
87847 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 3
87847 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 56.0 (TID 364) in 12 ms on 192.168.1.4 (executor 0) (5/8)
87847 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 2
87847 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 1
87847 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 56.0 (TID 363) in 13 ms on 192.168.1.4 (executor 0) (6/8)
87847 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 56.0 (TID 359) in 16 ms on 192.168.1.4 (executor 0) (7/8)
87848 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_56.0, runningTasks: 0
87848 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 56.0 (TID 358) in 17 ms on 192.168.1.4 (executor 0) (8/8)
87848 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 56.0, whose tasks have all completed, from pool 
87849 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 56 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.019 s
87849 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 56, remaining stages = 0
87849 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 35 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.021661 s
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87849 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
87850 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
87850 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
87851 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353)
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
87852 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353)
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87853 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87854 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87854 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87854 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87854 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
87854 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
87854 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 36 (collect at SparkUtils.java:353) with 8 output partitions
87854 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 57 (collect at SparkUtils.java:353)
87854 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
87854 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
87855 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 57)
87855 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87855 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 57 (MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
87855 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 57)
87855 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
87855 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_78 locally took  0 ms
87855 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_78 without replication took  0 ms
87856 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
87856 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_78_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.3 MB)
87856 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_78_piece0
87856 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_78_piece0
87856 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_78_piece0 locally took  0 ms
87856 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_78_piece0 without replication took  0 ms
87856 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 78 from broadcast at DAGScheduler.scala:1006
87856 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 57 (MapPartitionsRDD[115] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87856 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 57.0 with 8 tasks
87857 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 57.0: 21
87857 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 57.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87857 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 0
87857 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 57 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87857 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 57.0 (TID 365, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
87858 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 57.0 (TID 366, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
87859 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 57.0 (TID 367, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
87860 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 57.0 (TID 368, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
87861 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 57.0 (TID 369, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
87861 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 57.0 (TID 370, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
87862 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 57.0 (TID 371, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
87863 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 57.0 (TID 372, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
87863 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 365 on executor id: 0 hostname: 192.168.1.4.
87863 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 366 on executor id: 0 hostname: 192.168.1.4.
87864 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 367 on executor id: 0 hostname: 192.168.1.4.
87864 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 368 on executor id: 0 hostname: 192.168.1.4.
87864 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 369 on executor id: 0 hostname: 192.168.1.4.
87864 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 370 on executor id: 0 hostname: 192.168.1.4.
87864 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 371 on executor id: 0 hostname: 192.168.1.4.
87865 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 372 on executor id: 0 hostname: 192.168.1.4.
87868 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_78_piece0 as bytes
87868 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_78_piece0 is StorageLevel(disk, memory, 1 replicas)
87869 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_78_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
87873 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 7
87873 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87873 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87873 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 6
87873 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 57.0 (TID 365) in 16 ms on 192.168.1.4 (executor 0) (1/8)
87873 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 57.0 (TID 369) in 13 ms on 192.168.1.4 (executor 0) (2/8)
87874 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 5
87874 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 57.0 (TID 368) in 15 ms on 192.168.1.4 (executor 0) (3/8)
87874 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 4
87874 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 57.0 (TID 370) in 13 ms on 192.168.1.4 (executor 0) (4/8)
87874 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 3
87874 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 57.0 (TID 371) in 13 ms on 192.168.1.4 (executor 0) (5/8)
87875 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 2
87875 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 57.0 (TID 372) in 13 ms on 192.168.1.4 (executor 0) (6/8)
87875 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 1
87875 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_57.0, runningTasks: 0
87875 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 57.0 (TID 366) in 18 ms on 192.168.1.4 (executor 0) (7/8)
87875 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 57.0 (TID 367) in 17 ms on 192.168.1.4 (executor 0) (8/8)
87875 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 57.0, whose tasks have all completed, from pool 
87876 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 57 (collect at SparkUtils.java:353) finished in 0.018 s
87876 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 57, remaining stages = 0
87876 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 36 finished: collect at SparkUtils.java:353, took 0.021719 s
87876 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87877 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87878 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
87878 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
87878 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 37 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
87878 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 58 (zipWithIndex at SparkUtils.java:391)
87878 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
87878 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
87878 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 58)
87879 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87879 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 58 (MapPartitionsRDD[114] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
87879 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 58)
87879 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
87879 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_79 locally took  0 ms
87879 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_79 without replication took  0 ms
87880 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
87880 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_79_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
87880 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_79_piece0
87880 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_79_piece0
87880 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_79_piece0 locally took  0 ms
87880 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_79_piece0 without replication took  0 ms
87880 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 79 from broadcast at DAGScheduler.scala:1006
87880 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 58 (MapPartitionsRDD[114] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
87880 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 58.0 with 7 tasks
87881 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 58.0: 21
87881 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 58.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87881 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 0
87881 [dispatcher-event-loop-7] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 58 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87881 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 58.0 (TID 373, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
87882 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 58.0 (TID 374, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
87883 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 58.0 (TID 375, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
87884 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 58.0 (TID 376, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
87885 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 58.0 (TID 377, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
87885 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 58.0 (TID 378, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
87886 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 58.0 (TID 379, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
87886 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87886 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87887 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 373 on executor id: 0 hostname: 192.168.1.4.
87887 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 374 on executor id: 0 hostname: 192.168.1.4.
87887 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 375 on executor id: 0 hostname: 192.168.1.4.
87887 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 376 on executor id: 0 hostname: 192.168.1.4.
87887 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 377 on executor id: 0 hostname: 192.168.1.4.
87888 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 378 on executor id: 0 hostname: 192.168.1.4.
87888 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 379 on executor id: 0 hostname: 192.168.1.4.
87892 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_79_piece0 as bytes
87892 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_79_piece0 is StorageLevel(disk, memory, 1 replicas)
87893 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_79_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.4 MB)
87897 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 6
87897 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 5
87898 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 58.0 (TID 375) in 15 ms on 192.168.1.4 (executor 0) (1/7)
87898 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 58.0 (TID 378) in 13 ms on 192.168.1.4 (executor 0) (2/7)
87898 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 4
87898 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 58.0 (TID 373) in 17 ms on 192.168.1.4 (executor 0) (3/7)
87898 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 3
87898 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 58.0 (TID 374) in 16 ms on 192.168.1.4 (executor 0) (4/7)
87898 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 2
87898 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 1
87898 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 58.0 (TID 377) in 14 ms on 192.168.1.4 (executor 0) (5/7)
87898 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 58.0 (TID 376) in 15 ms on 192.168.1.4 (executor 0) (6/7)
87899 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_58.0, runningTasks: 0
87899 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 58.0 (TID 379) in 14 ms on 192.168.1.4 (executor 0) (7/7)
87899 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 58.0, whose tasks have all completed, from pool 
87899 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 58 (zipWithIndex at SparkUtils.java:391) finished in 0.018 s
87899 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 58, remaining stages = 0
87899 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 37 finished: zipWithIndex at SparkUtils.java:391, took 0.021404 s
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87900 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87901 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87902 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
87903 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80 stored as values in memory (estimated size 30.9 KB, free 366.1 MB)
87903 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_80 locally took  1 ms
87903 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_80 without replication took  1 ms
87903 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
87904 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_80_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
87904 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_80_piece0
87904 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_80_piece0
87904 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_80_piece0 locally took  1 ms
87904 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_80_piece0 without replication took  1 ms
87904 [main] INFO org.apache.spark.SparkContext  - Created broadcast 80 from broadcast at ParameterAveragingTrainingMaster.java:259
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87904 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87905 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87906 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
87907 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87908 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87909 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87910 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87911 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
87912 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
87913 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
87913 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
87913 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 21 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
87913 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 117 (mapToPair at SparkUtils.java:391)
87913 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 122 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
87913 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 38 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
87913 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 61 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
87913 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 60)
87914 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 60)
87914 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 61)
87914 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 60)
87914 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 60)
87914 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 59)
87914 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 59)
87914 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87914 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 59 (MapPartitionsRDD[117] at mapToPair at SparkUtils.java:391), which has no missing parents
87914 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 59)
87915 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
87915 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_81 locally took  1 ms
87915 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_81 without replication took  1 ms
87915 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
87916 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_81_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
87916 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_81_piece0
87916 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_81_piece0
87916 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_81_piece0 locally took  1 ms
87916 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_81_piece0 without replication took  1 ms
87916 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 81 from broadcast at DAGScheduler.scala:1006
87916 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[117] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87916 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 59.0 with 8 tasks
87916 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 59.0: 21
87916 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 59.0: PROCESS_LOCAL, NODE_LOCAL, ANY
87916 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 0
87917 [dispatcher-event-loop-6] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 59 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
87917 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 59.0 (TID 380, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
87918 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 59.0 (TID 381, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
87919 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 59.0 (TID 382, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
87920 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 59.0 (TID 383, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
87920 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 59.0 (TID 384, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
87921 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 59.0 (TID 385, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
87922 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 59.0 (TID 386, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
87923 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 59.0 (TID 387, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
87923 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 380 on executor id: 0 hostname: 192.168.1.4.
87923 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 381 on executor id: 0 hostname: 192.168.1.4.
87923 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 382 on executor id: 0 hostname: 192.168.1.4.
87923 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 383 on executor id: 0 hostname: 192.168.1.4.
87923 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 384 on executor id: 0 hostname: 192.168.1.4.
87924 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 385 on executor id: 0 hostname: 192.168.1.4.
87924 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 386 on executor id: 0 hostname: 192.168.1.4.
87924 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 387 on executor id: 0 hostname: 192.168.1.4.
87928 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_81_piece0 as bytes
87928 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_81_piece0 is StorageLevel(disk, memory, 1 replicas)
87929 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_81_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
87938 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 7
87938 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
87938 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
87938 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 59.0 (TID 385) in 18 ms on 192.168.1.4 (executor 0) (1/8)
87938 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87940 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 6
87940 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 59.0 (TID 384) in 20 ms on 192.168.1.4 (executor 0) (2/8)
87940 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87942 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 5
87942 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 59.0 (TID 381) in 25 ms on 192.168.1.4 (executor 0) (3/8)
87942 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 59.0 (TID 386) in 21 ms on 192.168.1.4 (executor 0) (4/8)
87942 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87942 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87942 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 4
87943 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 3
87943 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 59.0 (TID 382) in 25 ms on 192.168.1.4 (executor 0) (5/8)
87943 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 2
87943 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87943 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 59.0 (TID 383) in 24 ms on 192.168.1.4 (executor 0) (6/8)
87943 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87946 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 1
87946 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 59.0 (TID 387) in 24 ms on 192.168.1.4 (executor 0) (7/8)
87946 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_59.0, runningTasks: 0
87946 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87946 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 59.0 (TID 380) in 30 ms on 192.168.1.4 (executor 0) (8/8)
87946 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 59.0, whose tasks have all completed, from pool 
87946 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
87947 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 59 (mapToPair at SparkUtils.java:391) finished in 0.030 s
87947 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
87947 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
87947 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 60, ResultStage 61)
87947 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
87947 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 22
87947 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 60)
87947 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
87947 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 60 (MapPartitionsRDD[122] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
87947 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 60)
87948 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
87948 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_82 locally took  0 ms
87948 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_82 without replication took  0 ms
87949 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
87949 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_82_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
87949 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_82_piece0
87949 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_82_piece0
87949 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_82_piece0 locally took  1 ms
87949 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_82_piece0 without replication took  1 ms
87949 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 82 from broadcast at DAGScheduler.scala:1006
87949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[122] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
87949 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 60.0 with 8 tasks
87949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 60.0: 22
87949 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 60.0: NODE_LOCAL, ANY
87949 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 0
87949 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 60.0 (TID 388, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 60.0 (TID 389, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 60.0 (TID 390, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 60.0 (TID 391, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 60.0 (TID 392, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 60.0 (TID 393, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 60.0 (TID 394, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 60.0 (TID 395, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
87950 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 388 on executor id: 0 hostname: 192.168.1.4.
87951 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 389 on executor id: 0 hostname: 192.168.1.4.
87951 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 390 on executor id: 0 hostname: 192.168.1.4.
87951 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 391 on executor id: 0 hostname: 192.168.1.4.
87951 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 392 on executor id: 0 hostname: 192.168.1.4.
87951 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 393 on executor id: 0 hostname: 192.168.1.4.
87951 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 394 on executor id: 0 hostname: 192.168.1.4.
87951 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 395 on executor id: 0 hostname: 192.168.1.4.
87954 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_82_piece0 as bytes
87954 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_82_piece0 is StorageLevel(disk, memory, 1 replicas)
87955 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_82_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.4 MB)
87957 [dispatcher-event-loop-5] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 22 to 192.168.1.4:49914
87957 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 22 to 192.168.1.4:49914
87957 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 22
87957 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 22
87957 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 22 is 186 bytes
87960 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_80_piece0 as bytes
87960 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_80_piece0 is StorageLevel(disk, memory, 1 replicas)
87961 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_80_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
88378 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 8
89376 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 8
89803 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 7
89803 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
89804 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 60.0 (TID 395) in 1854 ms on 192.168.1.4 (executor 0) (1/8)
89804 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
90375 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 7
91379 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 7
91500 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 6
91501 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 60.0 (TID 393) in 3551 ms on 192.168.1.4 (executor 0) (2/8)
91501 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91516 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 5
91516 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 60.0 (TID 394) in 3566 ms on 192.168.1.4 (executor 0) (3/8)
91516 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91933 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 4
91933 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 3
91933 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 60.0 (TID 392) in 3983 ms on 192.168.1.4 (executor 0) (4/8)
91933 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 60.0 (TID 391) in 3983 ms on 192.168.1.4 (executor 0) (5/8)
91933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91934 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 2
91934 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 60.0 (TID 389) in 3984 ms on 192.168.1.4 (executor 0) (6/8)
91934 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91935 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 1
91935 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 60.0 (TID 388) in 3986 ms on 192.168.1.4 (executor 0) (7/8)
91935 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91942 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_60.0, runningTasks: 0
91942 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 60.0 (TID 390) in 3992 ms on 192.168.1.4 (executor 0) (8/8)
91942 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 60.0, whose tasks have all completed, from pool 
91942 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
91942 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 60 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.993 s
91942 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
91942 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
91942 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 61)
91942 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
91942 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 23
91942 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 61)
91943 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
91943 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 61 (MapPartitionsRDD[124] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
91943 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 61)
91943 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
91943 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_83 locally took  0 ms
91943 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_83 without replication took  0 ms
91944 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
91944 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_83_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
91944 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_83_piece0
91944 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_83_piece0
91944 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_83_piece0 locally took  0 ms
91944 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_83_piece0 without replication took  0 ms
91944 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 83 from broadcast at DAGScheduler.scala:1006
91944 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[124] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
91944 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 61.0 with 2 tasks
91945 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 61.0: 23
91945 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 61.0: NODE_LOCAL, ANY
91945 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_61.0, runningTasks: 0
91945 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 61.0 (TID 396, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
91945 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 61.0 (TID 397, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
91945 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
91945 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 396 on executor id: 0 hostname: 192.168.1.4.
91945 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 397 on executor id: 0 hostname: 192.168.1.4.
91948 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_83_piece0 as bytes
91948 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_83_piece0 is StorageLevel(disk, memory, 1 replicas)
91949 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_83_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
91950 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 21 to 192.168.1.4:49914
91950 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 21 to 192.168.1.4:49914
91950 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 21
91950 [map-output-dispatcher-6] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 21
91950 [map-output-dispatcher-6] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 21 is 159 bytes
91994 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_61.0, runningTasks: 1
91995 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_61.0, runningTasks: 0
91995 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 61.0 (TID 396) in 50 ms on 192.168.1.4 (executor 0) (1/2)
91995 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 61.0 (TID 397) in 50 ms on 192.168.1.4 (executor 0) (2/2)
91995 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 61.0, whose tasks have all completed, from pool 
91995 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 61 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.050 s
91995 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 59, remaining stages = 2
91995 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 61, remaining stages = 1
91995 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 60, remaining stages = 0
91996 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 38 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.082704 s
91996 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
92004 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
92004 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_84 locally took  0 ms
92004 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_84 without replication took  0 ms
92005 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
92005 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_84_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
92005 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_84_piece0
92005 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_84_piece0
92005 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_84_piece0 locally took  0 ms
92005 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_84_piece0 without replication took  0 ms
92005 [main] INFO org.apache.spark.SparkContext  - Created broadcast 84 from broadcast at SparkDl4jMultiLayer.java:595
92006 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
92006 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_85 locally took  1 ms
92006 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_85 without replication took  1 ms
92006 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
92007 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_85_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
92007 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_85_piece0
92007 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_85_piece0
92007 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_85_piece0 locally took  1 ms
92007 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_85_piece0 without replication took  1 ms
92007 [main] INFO org.apache.spark.SparkContext  - Created broadcast 85 from broadcast at SparkDl4jMultiLayer.java:596
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92007 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92008 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92008 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92008 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92008 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
92008 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92008 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92008 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92009 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92010 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92011 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92012 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92013 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92014 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92015 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92016 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
92016 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
92017 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 23 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
92017 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 127 (treeAggregate at SparkDl4jMultiLayer.java:598)
92017 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 39 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
92017 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 63 (treeAggregate at SparkDl4jMultiLayer.java:598)
92017 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 62)
92017 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 62)
92017 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 63)
92017 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 62)
92017 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 62)
92017 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
92017 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 62 (MapPartitionsRDD[127] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
92017 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 62)
92018 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86 stored as values in memory (estimated size 9.0 KB, free 366.1 MB)
92018 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_86 locally took  0 ms
92018 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_86 without replication took  0 ms
92019 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.1 MB)
92019 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_86_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
92019 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_86_piece0
92019 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_86_piece0
92019 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_86_piece0 locally took  0 ms
92019 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_86_piece0 without replication took  0 ms
92019 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 86 from broadcast at DAGScheduler.scala:1006
92019 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[127] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
92019 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 62.0 with 8 tasks
92019 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 62.0: 23
92019 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 62.0: NO_PREF, ANY
92019 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 0
92020 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 62.0 (TID 398, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
92020 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 62.0 (TID 399, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
92020 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 62.0 (TID 400, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
92021 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 62.0 (TID 401, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
92021 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 62.0 (TID 402, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
92021 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 62.0 (TID 403, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
92021 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 62.0 (TID 404, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
92022 [dispatcher-event-loop-4] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 62.0 (TID 405, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 398 on executor id: 0 hostname: 192.168.1.4.
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 399 on executor id: 0 hostname: 192.168.1.4.
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 400 on executor id: 0 hostname: 192.168.1.4.
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 401 on executor id: 0 hostname: 192.168.1.4.
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 402 on executor id: 0 hostname: 192.168.1.4.
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 403 on executor id: 0 hostname: 192.168.1.4.
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 404 on executor id: 0 hostname: 192.168.1.4.
92022 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 405 on executor id: 0 hostname: 192.168.1.4.
92027 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_86_piece0 as bytes
92027 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_86_piece0 is StorageLevel(disk, memory, 1 replicas)
92028 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_86_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
92031 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_85_piece0 as bytes
92031 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_85_piece0 is StorageLevel(disk, memory, 1 replicas)
92032 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_85_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
92058 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_84_piece0 as bytes
92059 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_84_piece0 is StorageLevel(disk, memory, 1 replicas)
92060 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_84_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
92310 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 7
92310 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
92310 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 62.0 (TID 405) in 289 ms on 192.168.1.4 (executor 0) (1/8)
92310 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92377 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 7
92441 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 6
92442 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 62.0 (TID 398) in 422 ms on 192.168.1.4 (executor 0) (2/8)
92442 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92604 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 5
92604 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 62.0 (TID 404) in 583 ms on 192.168.1.4 (executor 0) (3/8)
92604 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92642 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 4
92642 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 62.0 (TID 403) in 621 ms on 192.168.1.4 (executor 0) (4/8)
92643 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92685 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 3
92685 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 62.0 (TID 399) in 665 ms on 192.168.1.4 (executor 0) (5/8)
92685 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92687 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 2
92687 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 62.0 (TID 400) in 667 ms on 192.168.1.4 (executor 0) (6/8)
92687 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92697 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 1
92697 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 62.0 (TID 401) in 677 ms on 192.168.1.4 (executor 0) (7/8)
92697 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92700 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_62.0, runningTasks: 0
92700 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 62.0 (TID 402) in 679 ms on 192.168.1.4 (executor 0) (8/8)
92700 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 62.0, whose tasks have all completed, from pool 
92700 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 62 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.681 s
92700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
92700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
92700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 63)
92700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
92700 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 24
92700 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 63)
92700 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
92700 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 63 (MapPartitionsRDD[129] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
92700 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 63)
92701 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
92701 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_87 locally took  0 ms
92701 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_87 without replication took  0 ms
92702 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
92702 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_87_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.2 MB)
92702 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_87_piece0
92702 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_87_piece0
92702 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_87_piece0 locally took  1 ms
92702 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_87_piece0 without replication took  1 ms
92702 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 87 from broadcast at DAGScheduler.scala:1006
92702 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 63 (MapPartitionsRDD[129] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
92702 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 63.0 with 2 tasks
92702 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 63.0: 24
92702 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 63.0: NODE_LOCAL, ANY
92703 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_63.0, runningTasks: 0
92703 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 63.0 (TID 406, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
92703 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 63.0 (TID 407, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
92703 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
92703 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 406 on executor id: 0 hostname: 192.168.1.4.
92703 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 407 on executor id: 0 hostname: 192.168.1.4.
92705 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_87_piece0 as bytes
92705 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_87_piece0 is StorageLevel(disk, memory, 1 replicas)
92706 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_87_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
92708 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 23 to 192.168.1.4:49914
92708 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 23 to 192.168.1.4:49914
92708 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 23
92708 [map-output-dispatcher-7] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 23
92708 [map-output-dispatcher-7] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 23 is 159 bytes
92711 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_63.0, runningTasks: 1
92711 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_63.0, runningTasks: 0
92712 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 63.0 (TID 407) in 9 ms on 192.168.1.4 (executor 0) (1/2)
92712 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 63.0 (TID 406) in 9 ms on 192.168.1.4 (executor 0) (2/2)
92712 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 63.0, whose tasks have all completed, from pool 
92712 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 63 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.010 s
92712 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 62, remaining stages = 1
92712 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 63, remaining stages = 0
92712 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 39 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.695695 s
92713 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 7: Accuracy = 0.19, F1 = 0.32
92713 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 7
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92713 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
92715 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
92715 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 40 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
92715 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 64 (count at ParameterAveragingTrainingMaster.java:325)
92715 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
92715 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
92715 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 64)
92715 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
92715 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 64 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
92715 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 64)
92716 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88 stored as values in memory (estimated size 1448.0 B, free 366.1 MB)
92716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_88 locally took  0 ms
92716 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_88 without replication took  0 ms
92717 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.1 MB)
92717 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_88_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.2 MB)
92717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_88_piece0
92717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_88_piece0
92717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_88_piece0 locally took  1 ms
92717 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_88_piece0 without replication took  1 ms
92717 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 88 from broadcast at DAGScheduler.scala:1006
92717 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 64 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
92717 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 64.0 with 8 tasks
92717 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 64.0: 24
92717 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 64.0: PROCESS_LOCAL, NODE_LOCAL, ANY
92717 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 0
92718 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 64 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
92718 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 64.0 (TID 408, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
92719 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 64.0 (TID 409, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
92719 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 64.0 (TID 410, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
92720 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 64.0 (TID 411, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
92721 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 64.0 (TID 412, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
92722 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 64.0 (TID 413, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
92722 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 64.0 (TID 414, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
92723 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 64.0 (TID 415, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
92723 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 408 on executor id: 0 hostname: 192.168.1.4.
92723 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 409 on executor id: 0 hostname: 192.168.1.4.
92724 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 410 on executor id: 0 hostname: 192.168.1.4.
92724 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 411 on executor id: 0 hostname: 192.168.1.4.
92724 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 412 on executor id: 0 hostname: 192.168.1.4.
92724 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 413 on executor id: 0 hostname: 192.168.1.4.
92724 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 414 on executor id: 0 hostname: 192.168.1.4.
92724 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 415 on executor id: 0 hostname: 192.168.1.4.
92728 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_88_piece0 as bytes
92729 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_88_piece0 is StorageLevel(disk, memory, 1 replicas)
92729 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_88_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
92733 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 7
92733 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
92733 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
92733 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 6
92733 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 64.0 (TID 408) in 16 ms on 192.168.1.4 (executor 0) (1/8)
92734 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 5
92734 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 64.0 (TID 415) in 12 ms on 192.168.1.4 (executor 0) (2/8)
92734 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 64.0 (TID 413) in 13 ms on 192.168.1.4 (executor 0) (3/8)
92734 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 4
92734 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 3
92734 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 64.0 (TID 414) in 12 ms on 192.168.1.4 (executor 0) (4/8)
92734 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 64.0 (TID 412) in 14 ms on 192.168.1.4 (executor 0) (5/8)
92734 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 2
92734 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 64.0 (TID 410) in 15 ms on 192.168.1.4 (executor 0) (6/8)
92734 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 1
92734 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 64.0 (TID 411) in 15 ms on 192.168.1.4 (executor 0) (7/8)
92734 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_64.0, runningTasks: 0
92734 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 64.0 (TID 409) in 16 ms on 192.168.1.4 (executor 0) (8/8)
92734 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 64.0, whose tasks have all completed, from pool 
92735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 64 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.017 s
92735 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 64, remaining stages = 0
92735 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 40 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.019922 s
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92735 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
92736 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92736 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
92737 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353)
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
92738 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353)
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
92739 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92740 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
92740 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
92740 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 41 (collect at SparkUtils.java:353) with 8 output partitions
92740 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 65 (collect at SparkUtils.java:353)
92740 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
92740 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
92741 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 65)
92741 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
92741 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 65 (MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
92741 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 65)
92741 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89 stored as values in memory (estimated size 2.4 KB, free 366.1 MB)
92741 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_89 locally took  0 ms
92741 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_89 without replication took  0 ms
92742 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.1 MB)
92742 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_89_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.2 MB)
92742 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_89_piece0
92742 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_89_piece0
92742 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_89_piece0 locally took  0 ms
92742 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_89_piece0 without replication took  0 ms
92742 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 89 from broadcast at DAGScheduler.scala:1006
92742 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 65 (MapPartitionsRDD[131] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
92742 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 65.0 with 8 tasks
92742 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 65.0: 24
92743 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 65.0: PROCESS_LOCAL, NODE_LOCAL, ANY
92743 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 0
92743 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 65 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
92743 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 65.0 (TID 416, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
92744 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 65.0 (TID 417, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
92745 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 65.0 (TID 418, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
92746 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 65.0 (TID 419, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
92747 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 65.0 (TID 420, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
92747 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 65.0 (TID 421, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
92748 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 65.0 (TID 422, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
92749 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 65.0 (TID 423, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 416 on executor id: 0 hostname: 192.168.1.4.
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 417 on executor id: 0 hostname: 192.168.1.4.
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 418 on executor id: 0 hostname: 192.168.1.4.
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 419 on executor id: 0 hostname: 192.168.1.4.
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 420 on executor id: 0 hostname: 192.168.1.4.
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 421 on executor id: 0 hostname: 192.168.1.4.
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 422 on executor id: 0 hostname: 192.168.1.4.
92749 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 423 on executor id: 0 hostname: 192.168.1.4.
92754 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_89_piece0 as bytes
92754 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_89_piece0 is StorageLevel(disk, memory, 1 replicas)
92755 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_89_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
92759 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 7
92759 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
92759 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
92759 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 65.0 (TID 418) in 15 ms on 192.168.1.4 (executor 0) (1/8)
92759 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 6
92759 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 65.0 (TID 421) in 12 ms on 192.168.1.4 (executor 0) (2/8)
92760 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 5
92760 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 65.0 (TID 417) in 17 ms on 192.168.1.4 (executor 0) (3/8)
92760 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 4
92760 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 65.0 (TID 420) in 14 ms on 192.168.1.4 (executor 0) (4/8)
92760 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 3
92760 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 65.0 (TID 423) in 12 ms on 192.168.1.4 (executor 0) (5/8)
92761 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 2
92761 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 1
92761 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 65.0 (TID 422) in 14 ms on 192.168.1.4 (executor 0) (6/8)
92761 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 65.0 (TID 416) in 18 ms on 192.168.1.4 (executor 0) (7/8)
92762 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_65.0, runningTasks: 0
92762 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 65.0 (TID 419) in 17 ms on 192.168.1.4 (executor 0) (8/8)
92762 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 65.0, whose tasks have all completed, from pool 
92762 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 65 (collect at SparkUtils.java:353) finished in 0.019 s
92762 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 65, remaining stages = 0
92762 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 41 finished: collect at SparkUtils.java:353, took 0.022049 s
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92763 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92764 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
92764 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
92765 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 42 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
92765 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 66 (zipWithIndex at SparkUtils.java:391)
92765 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
92765 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
92765 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 66)
92765 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
92765 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 66 (MapPartitionsRDD[130] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
92765 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 66)
92766 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90 stored as values in memory (estimated size 2.2 KB, free 366.1 MB)
92766 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_90 locally took  1 ms
92766 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_90 without replication took  1 ms
92766 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.1 MB)
92767 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_90_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.2 MB)
92767 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_90_piece0
92767 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_90_piece0
92767 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_90_piece0 locally took  1 ms
92767 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_90_piece0 without replication took  1 ms
92767 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 90 from broadcast at DAGScheduler.scala:1006
92767 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 66 (MapPartitionsRDD[130] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
92767 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 66.0 with 7 tasks
92767 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 66.0: 24
92767 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 66.0: PROCESS_LOCAL, NODE_LOCAL, ANY
92767 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 0
92768 [dispatcher-event-loop-5] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 66 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
92768 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 66.0 (TID 424, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
92769 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 66.0 (TID 425, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
92769 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 66.0 (TID 426, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
92770 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 66.0 (TID 427, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
92771 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 66.0 (TID 428, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
92772 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 66.0 (TID 429, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
92772 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 66.0 (TID 430, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
92772 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 424 on executor id: 0 hostname: 192.168.1.4.
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 425 on executor id: 0 hostname: 192.168.1.4.
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 426 on executor id: 0 hostname: 192.168.1.4.
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 427 on executor id: 0 hostname: 192.168.1.4.
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 428 on executor id: 0 hostname: 192.168.1.4.
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 429 on executor id: 0 hostname: 192.168.1.4.
92773 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 430 on executor id: 0 hostname: 192.168.1.4.
92777 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_90_piece0 as bytes
92777 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_90_piece0 is StorageLevel(disk, memory, 1 replicas)
92778 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_90_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.4 MB)
92781 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 6
92781 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 66.0 (TID 426) in 12 ms on 192.168.1.4 (executor 0) (1/7)
92782 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 5
92782 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 66.0 (TID 427) in 13 ms on 192.168.1.4 (executor 0) (2/7)
92782 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 4
92782 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 66.0 (TID 428) in 12 ms on 192.168.1.4 (executor 0) (3/7)
92782 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 3
92782 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 66.0 (TID 425) in 14 ms on 192.168.1.4 (executor 0) (4/7)
92782 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 2
92782 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 66.0 (TID 424) in 15 ms on 192.168.1.4 (executor 0) (5/7)
92782 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 1
92782 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 66.0 (TID 430) in 10 ms on 192.168.1.4 (executor 0) (6/7)
92783 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_66.0, runningTasks: 0
92783 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 66.0 (TID 429) in 12 ms on 192.168.1.4 (executor 0) (7/7)
92783 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 66.0, whose tasks have all completed, from pool 
92783 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 66 (zipWithIndex at SparkUtils.java:391) finished in 0.016 s
92783 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 66, remaining stages = 0
92783 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 42 finished: zipWithIndex at SparkUtils.java:391, took 0.018473 s
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92783 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92784 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92784 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92784 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92784 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
92784 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92785 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
92786 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_91 stored as values in memory (estimated size 31.4 KB, free 366.0 MB)
92786 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_91 locally took  1 ms
92786 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_91 without replication took  1 ms
92787 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_91_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.0 MB)
92787 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_91_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.2 MB)
92787 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_91_piece0
92787 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_91_piece0
92787 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_91_piece0 locally took  0 ms
92787 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_91_piece0 without replication took  0 ms
92787 [main] INFO org.apache.spark.SparkContext  - Created broadcast 91 from broadcast at ParameterAveragingTrainingMaster.java:259
92787 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
92788 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92789 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92790 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92791 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
92792 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92793 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92794 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92795 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92804 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(77)
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92804 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 77
92804 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 77
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 77
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 77
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_77_piece0
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77_piece0 of size 1006 dropped from memory (free 383797172)
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
92804 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_77_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.2 MB)
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_77_piece0
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_77_piece0
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_77
92804 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_77 of size 1448 dropped from memory (free 383798620)
92804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 77, response is 0
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
92804 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
92804 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
92805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
92805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
92805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
92805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
92805 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_77_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.4 MB)
92805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
92805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
92805 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
92805 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
92805 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 24 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
92805 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 133 (mapToPair at SparkUtils.java:391)
92806 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 138 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
92806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 77
92806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(84)
92806 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 84
92806 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 84
92806 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 43 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
92806 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 69 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
92806 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 68)
92806 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 68)
92806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 69)
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 84
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 84
92806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 68)
92806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 68)
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_84_piece0
92806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 67)
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84_piece0 of size 1428 dropped from memory (free 383800048)
92806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 67)
92806 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_84_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.2 MB)
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_84_piece0
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_84_piece0
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_84
92806 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_84 of size 8224 dropped from memory (free 383808272)
92806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
92806 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 67 (MapPartitionsRDD[133] at mapToPair at SparkUtils.java:391), which has no missing parents
92806 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 67)
92806 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 84, response is 0
92806 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92807 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_84_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.4 MB)
92807 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_92 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
92807 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_92 locally took  0 ms
92807 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 84
92807 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_92 without replication took  0 ms
92807 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(18)
92807 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 18
92808 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 18
92808 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 18
92808 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(73)
92808 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 73
92808 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 73
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 18, response is true
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 73
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 73
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_73_piece0
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73_piece0 of size 1428 dropped from memory (free 383806100)
92808 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_73_piece0 on 192.168.1.4:49908 in memory (size: 1428.0 B, free: 366.2 MB)
92808 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_92_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_73_piece0
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_73_piece0
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_73
92808 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_73 of size 8224 dropped from memory (free 383812127)
92808 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 73, response is 0
92808 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92808 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_92_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.2 MB)
92808 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_92_piece0
92808 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_92_piece0
92808 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_92_piece0 locally took  0 ms
92808 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_92_piece0 without replication took  0 ms
92809 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_73_piece0 on 192.168.1.4:49916 in memory (size: 1428.0 B, free: 365.4 MB)
92809 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 92 from broadcast at DAGScheduler.scala:1006
92809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[133] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
92809 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 67.0 with 8 tasks
92809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 67.0: 24
92809 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 67.0: PROCESS_LOCAL, NODE_LOCAL, ANY
92809 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 73
92809 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(75)
92809 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 75
92809 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 75
92809 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 0
92809 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 75
92809 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 75
92809 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_75
92809 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75 of size 9208 dropped from memory (free 383821335)
92810 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_75_piece0
92810 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_75_piece0 of size 4225 dropped from memory (free 383825560)
92810 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_75_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.2 MB)
92810 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_75_piece0
92810 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_75_piece0
92810 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 75, response is 0
92810 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92810 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_75_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.4 MB)
92810 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 67 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
92810 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 67.0 (TID 431, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
92811 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 75
92811 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(23)
92811 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 23
92811 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 23
92811 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 23
92811 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(79)
92811 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 79
92811 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 79
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 23, response is true
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
92811 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 67.0 (TID 432, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 79
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 79
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_79
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79 of size 2216 dropped from memory (free 383827776)
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_79_piece0
92811 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_79_piece0 of size 1460 dropped from memory (free 383829236)
92811 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_79_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.2 MB)
92812 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_79_piece0
92812 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_79_piece0
92812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 79, response is 0
92812 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92812 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_79_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
92812 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 67.0 (TID 433, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
92812 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 79
92812 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(76)
92812 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 76
92812 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 76
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 76
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 76
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_76_piece0
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76_piece0 of size 2127 dropped from memory (free 383831363)
92813 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_76_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.2 MB)
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_76_piece0
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_76_piece0
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_76
92813 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_76 of size 3656 dropped from memory (free 383835019)
92813 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 76, response is 0
92813 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92813 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_76_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
92813 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 67.0 (TID 434, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
92814 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 76
92814 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(72)
92814 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 72
92814 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 72
92814 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 72
92814 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 72
92814 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_72_piece0
92814 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 67.0 (TID 435, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
92814 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72_piece0 of size 2135 dropped from memory (free 383837154)
92815 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_72_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
92815 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_72_piece0
92815 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_72_piece0
92815 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_72
92815 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_72 of size 3672 dropped from memory (free 383840826)
92815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 72, response is 0
92815 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92815 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_72_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
92815 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 67.0 (TID 436, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
92816 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 72
92816 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(20)
92816 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 20
92816 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 20
92816 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 20
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 20, response is true
92816 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(80)
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
92816 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 80
92816 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 80
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 80
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 80
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_80
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80 of size 31656 dropped from memory (free 383872482)
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_80_piece0
92816 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_80_piece0 of size 5325 dropped from memory (free 383877807)
92816 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 67.0 (TID 437, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
92816 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_80_piece0 on 192.168.1.4:49908 in memory (size: 5.2 KB, free: 366.3 MB)
92817 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_80_piece0
92817 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_80_piece0
92817 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 80, response is 0
92817 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92817 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_80_piece0 on 192.168.1.4:49916 in memory (size: 5.2 KB, free: 365.4 MB)
92817 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 80
92817 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(68)
92817 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 68
92817 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 68
92818 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 67.0 (TID 438, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
92818 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 431 on executor id: 0 hostname: 192.168.1.4.
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 68
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 68
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_68_piece0
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68_piece0 of size 1460 dropped from memory (free 383879267)
92818 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 432 on executor id: 0 hostname: 192.168.1.4.
92818 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_68_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.3 MB)
92818 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 433 on executor id: 0 hostname: 192.168.1.4.
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_68_piece0
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_68_piece0
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_68
92818 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_68 of size 2216 dropped from memory (free 383881483)
92818 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 434 on executor id: 0 hostname: 192.168.1.4.
92818 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 68, response is 0
92818 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92818 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 435 on executor id: 0 hostname: 192.168.1.4.
92819 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 436 on executor id: 0 hostname: 192.168.1.4.
92819 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_68_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
92819 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 437 on executor id: 0 hostname: 192.168.1.4.
92819 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 438 on executor id: 0 hostname: 192.168.1.4.
92821 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 68
92821 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(22)
92821 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 22
92822 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 22
92822 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 22
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 22, response is true
92822 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(71)
92822 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 71
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
92822 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 71
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 71
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 71
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_71
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71 of size 6712 dropped from memory (free 383888195)
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_71_piece0
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_71_piece0 of size 3634 dropped from memory (free 383891829)
92822 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_71_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.3 MB)
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_71_piece0
92822 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_71_piece0
92822 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 71, response is 0
92822 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92823 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_71_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.4 MB)
92823 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 71
92823 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(69)
92823 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 69
92823 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 69
92823 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 69
92823 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 69
92824 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_69
92824 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69 of size 31208 dropped from memory (free 383923037)
92824 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_92_piece0 as bytes
92824 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_92_piece0 is StorageLevel(disk, memory, 1 replicas)
92824 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_69_piece0
92824 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_69_piece0 of size 5323 dropped from memory (free 383928360)
92824 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_69_piece0 on 192.168.1.4:49908 in memory (size: 5.2 KB, free: 366.3 MB)
92824 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_69_piece0
92824 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_69_piece0
92824 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 69, response is 0
92824 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92824 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_69_piece0 on 192.168.1.4:49916 in memory (size: 5.2 KB, free: 365.4 MB)
92825 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_92_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
92825 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 69
92825 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(86)
92825 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 86
92825 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 86
92825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 86
92825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 86
92825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_86
92825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86 of size 9208 dropped from memory (free 383937568)
92825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_86_piece0
92825 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_86_piece0 of size 4226 dropped from memory (free 383941794)
92825 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_86_piece0 on 192.168.1.4:49908 in memory (size: 4.1 KB, free: 366.3 MB)
92826 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_86_piece0
92826 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_86_piece0
92826 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 86, response is 0
92826 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92826 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_86_piece0 on 192.168.1.4:49916 in memory (size: 4.1 KB, free: 365.4 MB)
92826 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 86
92826 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(85)
92826 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 85
92826 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 85
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 85
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 85
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_85_piece0
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85_piece0 of size 2531 dropped from memory (free 383944325)
92827 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_85_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_85_piece0
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_85_piece0
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_85
92827 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_85 of size 27976 dropped from memory (free 383972301)
92827 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 85, response is 0
92827 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92827 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_85_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.4 MB)
92828 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 85
92828 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(82)
92828 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 82
92828 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 82
92828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 82
92828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 82
92828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_82
92828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82 of size 6712 dropped from memory (free 383979013)
92828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_82_piece0
92828 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_82_piece0 of size 3628 dropped from memory (free 383982641)
92829 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_82_piece0 on 192.168.1.4:49908 in memory (size: 3.5 KB, free: 366.3 MB)
92829 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_82_piece0
92829 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_82_piece0
92829 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 82, response is 0
92829 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_82_piece0 on 192.168.1.4:49916 in memory (size: 3.5 KB, free: 365.4 MB)
92829 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92830 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 82
92830 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(83)
92830 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 83
92830 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 83
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 83
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 83
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_83
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83 of size 3672 dropped from memory (free 383986313)
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_83_piece0
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_83_piece0 of size 2135 dropped from memory (free 383988448)
92830 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_83_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_83_piece0
92830 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_83_piece0
92830 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 83, response is 0
92831 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92831 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_83_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.4 MB)
92831 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 83
92831 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(74)
92831 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 74
92831 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 74
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 74
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 74
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_74
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74 of size 27528 dropped from memory (free 384015976)
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_74_piece0
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_74_piece0 of size 2531 dropped from memory (free 384018507)
92832 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_74_piece0 on 192.168.1.4:49908 in memory (size: 2.5 KB, free: 366.3 MB)
92832 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 7
92832 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
92832 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_74_piece0
92832 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_74_piece0
92832 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 74, response is 0
92832 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92832 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 67.0 (TID 436) in 18 ms on 192.168.1.4 (executor 0) (1/8)
92832 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92833 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_74_piece0 on 192.168.1.4:49916 in memory (size: 2.5 KB, free: 365.4 MB)
92833 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 74
92833 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(19)
92833 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 19
92833 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 19
92833 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(78)
92834 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 78
92834 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 78
92833 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 19
92834 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 19, response is true
92834 [block-manager-slave-async-thread-pool-0] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 78
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 78
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_78
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78 of size 2504 dropped from memory (free 384021011)
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_78_piece0
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_78_piece0 of size 1570 dropped from memory (free 384022581)
92834 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_78_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_78_piece0
92834 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_78_piece0
92834 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 78, response is 0
92834 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92835 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_78_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.4 MB)
92836 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 78
92836 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(90)
92836 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 90
92836 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 90
92836 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 90
92836 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 90
92836 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_90_piece0
92836 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90_piece0 of size 1460 dropped from memory (free 384024041)
92837 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_90_piece0 on 192.168.1.4:49908 in memory (size: 1460.0 B, free: 366.3 MB)
92837 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_90_piece0
92837 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_90_piece0
92837 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_90
92837 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_90 of size 2216 dropped from memory (free 384026257)
92837 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 90, response is 0
92837 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92837 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 6
92837 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 67.0 (TID 435) in 24 ms on 192.168.1.4 (executor 0) (2/8)
92837 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_90_piece0 on 192.168.1.4:49916 in memory (size: 1460.0 B, free: 365.4 MB)
92837 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92838 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 90
92838 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(70)
92838 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 70
92838 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 70
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 70
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 70
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_70
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70 of size 3600 dropped from memory (free 384029857)
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_70_piece0
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_70_piece0 of size 2197 dropped from memory (free 384032054)
92838 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_70_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_70_piece0
92838 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_70_piece0
92838 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 70, response is 0
92839 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92839 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_70_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.5 MB)
92840 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 70
92840 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(81)
92840 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 81
92840 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 81
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 81
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 81
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_81
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81 of size 3600 dropped from memory (free 384035654)
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_81_piece0
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_81_piece0 of size 2197 dropped from memory (free 384037851)
92840 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_81_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_81_piece0
92840 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_81_piece0
92841 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 81, response is 0
92841 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92841 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_81_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.5 MB)
92842 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 81
92842 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(88)
92842 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 88
92842 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 88
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 88
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 88
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_88_piece0
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88_piece0 of size 1006 dropped from memory (free 384038857)
92842 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_88_piece0 on 192.168.1.4:49908 in memory (size: 1006.0 B, free: 366.3 MB)
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_88_piece0
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_88_piece0
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_88
92842 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_88 of size 1448 dropped from memory (free 384040305)
92842 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 88, response is 0
92842 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92843 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_88_piece0 on 192.168.1.4:49916 in memory (size: 1006.0 B, free: 365.5 MB)
92844 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 88
92844 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(87)
92844 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 87
92844 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 87
92844 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 87
92844 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 87
92844 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_87_piece0
92845 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87_piece0 of size 2125 dropped from memory (free 384042430)
92845 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_87_piece0 on 192.168.1.4:49908 in memory (size: 2.1 KB, free: 366.3 MB)
92845 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_87_piece0
92845 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_87_piece0
92845 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_87
92845 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_87 of size 3656 dropped from memory (free 384046086)
92845 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 87, response is 0
92845 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92845 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_87_piece0 on 192.168.1.4:49916 in memory (size: 2.1 KB, free: 365.5 MB)
92846 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 87
92846 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanBroadcast(89)
92846 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning broadcast 89
92846 [Spark Context Cleaner] DEBUG org.apache.spark.broadcast.TorrentBroadcast  - Unpersisting TorrentBroadcast 89
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing broadcast 89
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing broadcast 89
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_89
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89 of size 2504 dropped from memory (free 384048590)
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Removing block broadcast_89_piece0
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.memory.MemoryStore  - Block broadcast_89_piece0 of size 1570 dropped from memory (free 384050160)
92847 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 5
92847 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_89_piece0 on 192.168.1.4:49908 in memory (size: 1570.0 B, free: 366.3 MB)
92847 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 67.0 (TID 432) in 37 ms on 192.168.1.4 (executor 0) (3/8)
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_89_piece0
92847 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_89_piece0
92847 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing broadcast 89, response is 0
92847 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
92847 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92848 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Removed broadcast_89_piece0 on 192.168.1.4:49916 in memory (size: 1570.0 B, free: 365.5 MB)
92848 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaned broadcast 89
92848 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanShuffle(21)
92848 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning shuffle 21
92849 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing shuffle 21
92849 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned shuffle 21
92849 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing shuffle 21, response is true
92849 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: true to 192.168.1.4:49902
92851 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 4
92852 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 67.0 (TID 434) in 40 ms on 192.168.1.4 (executor 0) (4/8)
92852 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 3
92852 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92852 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 67.0 (TID 431) in 43 ms on 192.168.1.4 (executor 0) (5/8)
92852 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92853 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 2
92853 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 67.0 (TID 433) in 42 ms on 192.168.1.4 (executor 0) (6/8)
92853 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92857 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 1
92857 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 67.0 (TID 437) in 42 ms on 192.168.1.4 (executor 0) (7/8)
92857 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92858 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_67.0, runningTasks: 0
92858 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 67.0 (TID 438) in 42 ms on 192.168.1.4 (executor 0) (8/8)
92858 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 67.0, whose tasks have all completed, from pool 
92858 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
92858 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 67 (mapToPair at SparkUtils.java:391) finished in 0.049 s
92858 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
92858 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
92858 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 68, ResultStage 69)
92858 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
92858 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 25
92859 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 68)
92859 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
92859 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 68 (MapPartitionsRDD[138] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
92859 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 68)
92860 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_93 stored as values in memory (estimated size 6.6 KB, free 366.3 MB)
92860 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_93 locally took  0 ms
92860 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_93 without replication took  0 ms
92861 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_93_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.2 MB)
92861 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_93_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
92861 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_93_piece0
92861 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_93_piece0
92861 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_93_piece0 locally took  1 ms
92861 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_93_piece0 without replication took  1 ms
92861 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 93 from broadcast at DAGScheduler.scala:1006
92861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[138] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
92861 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 68.0 with 8 tasks
92861 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 68.0: 25
92861 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 68.0: NODE_LOCAL, ANY
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 0
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 68.0 (TID 439, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 68.0 (TID 440, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 68.0 (TID 441, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 68.0 (TID 442, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 68.0 (TID 443, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 68.0 (TID 444, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 68.0 (TID 445, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 68.0 (TID 446, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 439 on executor id: 0 hostname: 192.168.1.4.
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 440 on executor id: 0 hostname: 192.168.1.4.
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 441 on executor id: 0 hostname: 192.168.1.4.
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 442 on executor id: 0 hostname: 192.168.1.4.
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 443 on executor id: 0 hostname: 192.168.1.4.
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 444 on executor id: 0 hostname: 192.168.1.4.
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 445 on executor id: 0 hostname: 192.168.1.4.
92862 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 446 on executor id: 0 hostname: 192.168.1.4.
92866 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_93_piece0 as bytes
92866 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_93_piece0 is StorageLevel(disk, memory, 1 replicas)
92867 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_93_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.5 MB)
92869 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 25 to 192.168.1.4:49914
92869 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 25 to 192.168.1.4:49914
92869 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 25
92869 [map-output-dispatcher-0] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 25
92869 [map-output-dispatcher-0] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 25 is 186 bytes
92872 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_91_piece0 as bytes
92872 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_91_piece0 is StorageLevel(disk, memory, 1 replicas)
92873 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_91_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
93375 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 8
94374 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 8
94907 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 7
94908 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
94908 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 68.0 (TID 446) in 2046 ms on 192.168.1.4 (executor 0) (1/8)
94908 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
95377 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 7
96208 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 6
96209 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 68.0 (TID 445) in 3347 ms on 192.168.1.4 (executor 0) (2/8)
96209 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96374 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 6
96378 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 5
96378 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 68.0 (TID 444) in 3516 ms on 192.168.1.4 (executor 0) (3/8)
96378 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96671 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 4
96671 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 68.0 (TID 439) in 3809 ms on 192.168.1.4 (executor 0) (4/8)
96671 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96746 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 3
96746 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 68.0 (TID 443) in 3884 ms on 192.168.1.4 (executor 0) (5/8)
96746 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96824 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 2
96824 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 68.0 (TID 442) in 3962 ms on 192.168.1.4 (executor 0) (6/8)
96824 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96827 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 1
96827 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 68.0 (TID 441) in 3965 ms on 192.168.1.4 (executor 0) (7/8)
96828 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96851 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_68.0, runningTasks: 0
96852 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 68.0 (TID 440) in 3990 ms on 192.168.1.4 (executor 0) (8/8)
96852 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 68.0, whose tasks have all completed, from pool 
96852 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
96852 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 68 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.991 s
96852 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
96852 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
96852 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 69)
96852 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
96852 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 26
96852 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 69)
96852 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
96852 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 69 (MapPartitionsRDD[140] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
96852 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 69)
96853 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_94 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
96853 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_94 locally took  0 ms
96853 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_94 without replication took  0 ms
96854 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_94_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
96854 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_94_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
96854 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_94_piece0
96854 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_94_piece0
96854 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_94_piece0 locally took  1 ms
96854 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_94_piece0 without replication took  1 ms
96854 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 94 from broadcast at DAGScheduler.scala:1006
96854 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 69 (MapPartitionsRDD[140] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
96854 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 69.0 with 2 tasks
96854 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 69.0: 26
96854 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 69.0: NODE_LOCAL, ANY
96855 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_69.0, runningTasks: 0
96855 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 69.0 (TID 447, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
96855 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 69.0 (TID 448, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
96855 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
96855 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 447 on executor id: 0 hostname: 192.168.1.4.
96855 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 448 on executor id: 0 hostname: 192.168.1.4.
96857 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_94_piece0 as bytes
96857 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_94_piece0 is StorageLevel(disk, memory, 1 replicas)
96858 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_94_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
96860 [dispatcher-event-loop-0] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 24 to 192.168.1.4:49914
96860 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 24 to 192.168.1.4:49914
96860 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 24
96860 [map-output-dispatcher-1] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 24
96860 [map-output-dispatcher-1] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 24 is 159 bytes
96917 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_69.0, runningTasks: 1
96917 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_69.0, runningTasks: 0
96918 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 69.0 (TID 448) in 63 ms on 192.168.1.4 (executor 0) (1/2)
96918 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 69.0 (TID 447) in 63 ms on 192.168.1.4 (executor 0) (2/2)
96918 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 69.0, whose tasks have all completed, from pool 
96918 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 69 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.064 s
96918 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 68, remaining stages = 2
96918 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 67, remaining stages = 1
96918 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 69, remaining stages = 0
96918 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 43 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 4.113613 s
96919 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
96920 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_95 stored as values in memory (estimated size 8.0 KB, free 366.2 MB)
96920 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_95 locally took  0 ms
96920 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_95 without replication took  0 ms
96921 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_95_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.2 MB)
96921 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_95_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
96921 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_95_piece0
96921 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_95_piece0
96921 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_95_piece0 locally took  0 ms
96921 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_95_piece0 without replication took  0 ms
96921 [main] INFO org.apache.spark.SparkContext  - Created broadcast 95 from broadcast at SparkDl4jMultiLayer.java:595
96922 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_96 stored as values in memory (estimated size 26.9 KB, free 366.2 MB)
96922 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_96 locally took  1 ms
96922 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_96 without replication took  1 ms
96922 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_96_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.2 MB)
96923 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_96_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
96923 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_96_piece0
96923 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_96_piece0
96923 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_96_piece0 locally took  1 ms
96923 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_96_piece0 without replication took  1 ms
96923 [main] INFO org.apache.spark.SparkContext  - Created broadcast 96 from broadcast at SparkDl4jMultiLayer.java:596
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96923 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96924 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96924 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96924 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96924 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
96924 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96925 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96926 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96927 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96928 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96929 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96930 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96931 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
96932 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
96932 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
96932 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 26 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
96933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 143 (treeAggregate at SparkDl4jMultiLayer.java:598)
96933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 44 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
96933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 71 (treeAggregate at SparkDl4jMultiLayer.java:598)
96933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 70)
96933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 70)
96933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 71)
96933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 70)
96933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 70)
96933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
96933 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 70 (MapPartitionsRDD[143] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
96933 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 70)
96934 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_97 stored as values in memory (estimated size 9.0 KB, free 366.2 MB)
96934 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_97 locally took  1 ms
96934 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_97 without replication took  1 ms
96934 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_97_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.2 MB)
96934 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_97_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
96935 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_97_piece0
96935 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_97_piece0
96935 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_97_piece0 locally took  1 ms
96935 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_97_piece0 without replication took  1 ms
96935 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 97 from broadcast at DAGScheduler.scala:1006
96935 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[143] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
96935 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 70.0 with 8 tasks
96935 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 70.0: 26
96935 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 70.0: NO_PREF, ANY
96935 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 0
96935 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 70.0 (TID 449, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
96936 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 70.0 (TID 450, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
96936 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 70.0 (TID 451, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
96936 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 70.0 (TID 452, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
96937 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 70.0 (TID 453, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
96937 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 70.0 (TID 454, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
96937 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 70.0 (TID 455, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
96938 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 70.0 (TID 456, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 449 on executor id: 0 hostname: 192.168.1.4.
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 450 on executor id: 0 hostname: 192.168.1.4.
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 451 on executor id: 0 hostname: 192.168.1.4.
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 452 on executor id: 0 hostname: 192.168.1.4.
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 453 on executor id: 0 hostname: 192.168.1.4.
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 454 on executor id: 0 hostname: 192.168.1.4.
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 455 on executor id: 0 hostname: 192.168.1.4.
96938 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 456 on executor id: 0 hostname: 192.168.1.4.
96942 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_97_piece0 as bytes
96942 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_97_piece0 is StorageLevel(disk, memory, 1 replicas)
96943 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_97_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
96946 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_96_piece0 as bytes
96946 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_96_piece0 is StorageLevel(disk, memory, 1 replicas)
96947 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_96_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
96976 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_95_piece0 as bytes
96976 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_95_piece0 is StorageLevel(disk, memory, 1 replicas)
96977 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_95_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
97301 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 7
97301 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
97301 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 70.0 (TID 456) in 364 ms on 192.168.1.4 (executor 0) (1/8)
97301 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97369 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 6
97369 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 70.0 (TID 449) in 434 ms on 192.168.1.4 (executor 0) (2/8)
97369 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97374 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 6
97607 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 5
97607 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 70.0 (TID 455) in 670 ms on 192.168.1.4 (executor 0) (3/8)
97608 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97609 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 4
97609 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 70.0 (TID 453) in 673 ms on 192.168.1.4 (executor 0) (4/8)
97610 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97612 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 3
97612 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 70.0 (TID 450) in 677 ms on 192.168.1.4 (executor 0) (5/8)
97613 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97615 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 2
97615 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 70.0 (TID 454) in 678 ms on 192.168.1.4 (executor 0) (6/8)
97615 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97616 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 1
97617 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 70.0 (TID 451) in 681 ms on 192.168.1.4 (executor 0) (7/8)
97617 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_70.0, runningTasks: 0
97617 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97617 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 70.0 (TID 452) in 681 ms on 192.168.1.4 (executor 0) (8/8)
97617 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 70.0, whose tasks have all completed, from pool 
97617 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 70 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.682 s
97617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
97617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
97617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 71)
97617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
97617 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 27
97617 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 71)
97617 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
97617 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 71 (MapPartitionsRDD[145] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
97617 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 71)
97618 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_98 stored as values in memory (estimated size 3.6 KB, free 366.2 MB)
97618 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_98 locally took  0 ms
97618 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_98 without replication took  0 ms
97618 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_98_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.2 MB)
97619 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_98_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
97619 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_98_piece0
97619 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_98_piece0
97619 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_98_piece0 locally took  1 ms
97619 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_98_piece0 without replication took  1 ms
97619 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 98 from broadcast at DAGScheduler.scala:1006
97619 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 71 (MapPartitionsRDD[145] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
97619 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 71.0 with 2 tasks
97619 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 71.0: 27
97619 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 71.0: NODE_LOCAL, ANY
97619 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_71.0, runningTasks: 0
97619 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 71.0 (TID 457, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
97620 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 71.0 (TID 458, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
97620 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
97620 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 457 on executor id: 0 hostname: 192.168.1.4.
97620 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 458 on executor id: 0 hostname: 192.168.1.4.
97622 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_98_piece0 as bytes
97622 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_98_piece0 is StorageLevel(disk, memory, 1 replicas)
97623 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_98_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
97624 [dispatcher-event-loop-7] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 26 to 192.168.1.4:49914
97624 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 26 to 192.168.1.4:49914
97624 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 26
97625 [map-output-dispatcher-2] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 26
97625 [map-output-dispatcher-2] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 26 is 159 bytes
97628 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_71.0, runningTasks: 1
97628 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_71.0, runningTasks: 0
97628 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 71.0 (TID 458) in 9 ms on 192.168.1.4 (executor 0) (1/2)
97628 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 71.0 (TID 457) in 9 ms on 192.168.1.4 (executor 0) (2/2)
97628 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 71.0, whose tasks have all completed, from pool 
97628 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 71 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.009 s
97628 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 71, remaining stages = 1
97628 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 70, remaining stages = 0
97629 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 44 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.696378 s
97629 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 8: Accuracy = 0.19, F1 = 0.32
97629 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 8
97629 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) +++
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$count$1.serialVersionUID
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$count$1.apply(java.lang.Object)
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.RDD$$anonfun$count$1.apply(scala.collection.Iterator)
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$count$1) is now cleaned +++
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97630 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97631 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
97631 [main] INFO org.apache.spark.SparkContext  - Starting job: count at ParameterAveragingTrainingMaster.java:325
97631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 45 (count at ParameterAveragingTrainingMaster.java:325) with 8 output partitions
97631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 72 (count at ParameterAveragingTrainingMaster.java:325)
97631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
97631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
97631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 72)
97631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
97631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 72 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173), which has no missing parents
97631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 72)
97632 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_99 stored as values in memory (estimated size 1448.0 B, free 366.2 MB)
97632 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_99 locally took  0 ms
97632 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_99 without replication took  0 ms
97632 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_99_piece0 stored as bytes in memory (estimated size 1006.0 B, free 366.2 MB)
97633 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_99_piece0 in memory on 192.168.1.4:49908 (size: 1006.0 B, free: 366.3 MB)
97633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_99_piece0
97633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_99_piece0
97633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_99_piece0 locally took  1 ms
97633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_99_piece0 without replication took  1 ms
97633 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 99 from broadcast at DAGScheduler.scala:1006
97633 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 72 (ParallelCollectionRDD[0] at parallelize at UCISequenceClassificationSpark2.java:173) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
97633 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 72.0 with 8 tasks
97633 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 72.0: 27
97633 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 72.0: PROCESS_LOCAL, NODE_LOCAL, ANY
97633 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 0
97634 [dispatcher-event-loop-2] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 72 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
97634 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 72.0 (TID 459, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
97635 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 72.0 (TID 460, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
97635 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 72.0 (TID 461, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
97636 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 72.0 (TID 462, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
97637 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 72.0 (TID 463, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
97638 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 72.0 (TID 464, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
97639 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 72.0 (TID 465, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
97639 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 72.0 (TID 466, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
97639 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 459 on executor id: 0 hostname: 192.168.1.4.
97640 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 460 on executor id: 0 hostname: 192.168.1.4.
97640 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 461 on executor id: 0 hostname: 192.168.1.4.
97640 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 462 on executor id: 0 hostname: 192.168.1.4.
97640 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 463 on executor id: 0 hostname: 192.168.1.4.
97640 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 464 on executor id: 0 hostname: 192.168.1.4.
97640 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 465 on executor id: 0 hostname: 192.168.1.4.
97640 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 466 on executor id: 0 hostname: 192.168.1.4.
97644 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_99_piece0 as bytes
97644 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_99_piece0 is StorageLevel(disk, memory, 1 replicas)
97645 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_99_piece0 in memory on 192.168.1.4:49916 (size: 1006.0 B, free: 365.4 MB)
97648 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 7
97648 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
97648 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
97648 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 72.0 (TID 459) in 15 ms on 192.168.1.4 (executor 0) (1/8)
97649 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 6
97649 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 72.0 (TID 461) in 14 ms on 192.168.1.4 (executor 0) (2/8)
97649 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 5
97649 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 4
97649 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 72.0 (TID 463) in 13 ms on 192.168.1.4 (executor 0) (3/8)
97649 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 3
97649 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 72.0 (TID 462) in 14 ms on 192.168.1.4 (executor 0) (4/8)
97649 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 2
97649 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 72.0 (TID 460) in 15 ms on 192.168.1.4 (executor 0) (5/8)
97649 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 1
97649 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 72.0 (TID 464) in 12 ms on 192.168.1.4 (executor 0) (6/8)
97650 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_72.0, runningTasks: 0
97650 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 72.0 (TID 465) in 12 ms on 192.168.1.4 (executor 0) (7/8)
97650 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 72.0 (TID 466) in 11 ms on 192.168.1.4 (executor 0) (8/8)
97650 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 72.0, whose tasks have all completed, from pool 
97650 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 72 (count at ParameterAveragingTrainingMaster.java:325) finished in 0.017 s
97650 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 72, remaining stages = 0
97650 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 45 finished: count at ParameterAveragingTrainingMaster.java:325, took 0.019132 s
97650 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
97651 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Starting training of split 1 of 1. workerMiniBatchSize=16, averagingFreq=5, Configured for 8 workers
97651 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) +++
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.serialVersionUID
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.f$1
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(java.lang.Object,java.lang.Object)
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1.apply(int,scala.collection.Iterator)
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1) is now cleaned +++
97652 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) +++
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.serialVersionUID
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.$outer
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(java.lang.Object)
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(scala.collection.Iterator)
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 2
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 2
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      <function0>
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
97653 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353)
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 1
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 1
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 2
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
97654 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353)
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13) is now cleaned +++
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97655 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
97655 [main] INFO org.apache.spark.SparkContext  - Starting job: collect at SparkUtils.java:353
97656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 46 (collect at SparkUtils.java:353) with 8 output partitions
97656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 73 (collect at SparkUtils.java:353)
97656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
97656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
97656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 73)
97656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
97656 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 73 (MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353), which has no missing parents
97656 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 73)
97657 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_100 stored as values in memory (estimated size 2.4 KB, free 366.2 MB)
97657 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_100 locally took  0 ms
97657 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_100 without replication took  0 ms
97658 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_100_piece0 stored as bytes in memory (estimated size 1570.0 B, free 366.2 MB)
97658 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_100_piece0 in memory on 192.168.1.4:49908 (size: 1570.0 B, free: 366.3 MB)
97658 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_100_piece0
97658 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_100_piece0
97658 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_100_piece0 locally took  0 ms
97658 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_100_piece0 without replication took  0 ms
97658 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 100 from broadcast at DAGScheduler.scala:1006
97658 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ResultStage 73 (MapPartitionsRDD[147] at mapPartitionsWithIndex at SparkUtils.java:353) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
97658 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 73.0 with 8 tasks
97658 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 73.0: 27
97658 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 73.0: PROCESS_LOCAL, NODE_LOCAL, ANY
97659 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 0
97659 [dispatcher-event-loop-3] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 73 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
97659 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 73.0 (TID 467, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
97660 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 73.0 (TID 468, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
97661 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 73.0 (TID 469, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
97662 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 73.0 (TID 470, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
97663 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 73.0 (TID 471, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
97664 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 73.0 (TID 472, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
97664 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 73.0 (TID 473, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
97666 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 73.0 (TID 474, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122288 bytes)
97666 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 467 on executor id: 0 hostname: 192.168.1.4.
97667 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 468 on executor id: 0 hostname: 192.168.1.4.
97668 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 469 on executor id: 0 hostname: 192.168.1.4.
97668 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 470 on executor id: 0 hostname: 192.168.1.4.
97668 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 471 on executor id: 0 hostname: 192.168.1.4.
97668 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 472 on executor id: 0 hostname: 192.168.1.4.
97668 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 473 on executor id: 0 hostname: 192.168.1.4.
97668 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 474 on executor id: 0 hostname: 192.168.1.4.
97673 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_100_piece0 as bytes
97673 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_100_piece0 is StorageLevel(disk, memory, 1 replicas)
97674 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_100_piece0 in memory on 192.168.1.4:49916 (size: 1570.0 B, free: 365.4 MB)
97679 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 7
97679 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
97679 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
97679 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 6
97679 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 73.0 (TID 472) in 16 ms on 192.168.1.4 (executor 0) (1/8)
97679 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 73.0 (TID 474) in 15 ms on 192.168.1.4 (executor 0) (2/8)
97679 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 5
97679 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 73.0 (TID 470) in 18 ms on 192.168.1.4 (executor 0) (3/8)
97680 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 4
97680 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 73.0 (TID 473) in 16 ms on 192.168.1.4 (executor 0) (4/8)
97681 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 3
97681 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 73.0 (TID 468) in 22 ms on 192.168.1.4 (executor 0) (5/8)
97681 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 2
97681 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 73.0 (TID 467) in 22 ms on 192.168.1.4 (executor 0) (6/8)
97686 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 1
97686 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 73.0 (TID 471) in 24 ms on 192.168.1.4 (executor 0) (7/8)
97686 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_73.0, runningTasks: 0
97686 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 73.0 (TID 469) in 26 ms on 192.168.1.4 (executor 0) (8/8)
97686 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 73.0, whose tasks have all completed, from pool 
97686 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 73 (collect at SparkUtils.java:353) finished in 0.027 s
97687 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 73, remaining stages = 0
97687 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 46 finished: collect at SparkUtils.java:353, took 0.031190 s
97687 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) +++
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.serialVersionUID
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(java.lang.Object)
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final long org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2.apply(scala.collection.Iterator)
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2) is now cleaned +++
97688 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97689 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
97689 [main] INFO org.apache.spark.SparkContext  - Starting job: zipWithIndex at SparkUtils.java:391
97689 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 47 (zipWithIndex at SparkUtils.java:391) with 7 output partitions
97689 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 74 (zipWithIndex at SparkUtils.java:391)
97689 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List()
97689 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List()
97689 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 74)
97690 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
97690 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 74 (MapPartitionsRDD[146] at mapPartitionsWithIndex at SparkUtils.java:434), which has no missing parents
97690 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 74)
97690 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_101 stored as values in memory (estimated size 2.2 KB, free 366.2 MB)
97690 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_101 locally took  0 ms
97690 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_101 without replication took  0 ms
97691 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_101_piece0 stored as bytes in memory (estimated size 1460.0 B, free 366.2 MB)
97691 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_101_piece0 in memory on 192.168.1.4:49908 (size: 1460.0 B, free: 366.3 MB)
97691 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_101_piece0
97691 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_101_piece0
97691 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_101_piece0 locally took  0 ms
97691 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_101_piece0 without replication took  0 ms
97692 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 101 from broadcast at DAGScheduler.scala:1006
97692 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 7 missing tasks from ResultStage 74 (MapPartitionsRDD[146] at mapPartitionsWithIndex at SparkUtils.java:434) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
97692 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 74.0 with 7 tasks
97692 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 74.0: 27
97692 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 74.0: PROCESS_LOCAL, NODE_LOCAL, ANY
97692 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 0
97693 [dispatcher-event-loop-0] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 74 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
97693 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 74.0 (TID 475, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102771 bytes)
97694 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 74.0 (TID 476, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122288 bytes)
97694 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 74.0 (TID 477, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102771 bytes)
97695 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 74.0 (TID 478, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122288 bytes)
97696 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 74.0 (TID 479, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122288 bytes)
97697 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 74.0 (TID 480, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102771 bytes)
97697 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 74.0 (TID 481, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122288 bytes)
97697 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
97697 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
97697 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 475 on executor id: 0 hostname: 192.168.1.4.
97698 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 476 on executor id: 0 hostname: 192.168.1.4.
97698 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 477 on executor id: 0 hostname: 192.168.1.4.
97698 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 478 on executor id: 0 hostname: 192.168.1.4.
97698 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 479 on executor id: 0 hostname: 192.168.1.4.
97698 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 480 on executor id: 0 hostname: 192.168.1.4.
97698 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 481 on executor id: 0 hostname: 192.168.1.4.
97702 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_101_piece0 as bytes
97702 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_101_piece0 is StorageLevel(disk, memory, 1 replicas)
97703 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_101_piece0 in memory on 192.168.1.4:49916 (size: 1460.0 B, free: 365.4 MB)
97707 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 6
97707 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 5
97708 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 74.0 (TID 480) in 12 ms on 192.168.1.4 (executor 0) (1/7)
97708 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 74.0 (TID 479) in 13 ms on 192.168.1.4 (executor 0) (2/7)
97708 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 4
97708 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 74.0 (TID 481) in 11 ms on 192.168.1.4 (executor 0) (3/7)
97708 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 3
97708 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 74.0 (TID 478) in 14 ms on 192.168.1.4 (executor 0) (4/7)
97708 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 2
97708 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 74.0 (TID 477) in 14 ms on 192.168.1.4 (executor 0) (5/7)
97708 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 1
97708 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 74.0 (TID 476) in 15 ms on 192.168.1.4 (executor 0) (6/7)
97709 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_74.0, runningTasks: 0
97709 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 74.0 (TID 475) in 17 ms on 192.168.1.4 (executor 0) (7/7)
97709 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 74.0, whose tasks have all completed, from pool 
97709 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 74 (zipWithIndex at SparkUtils.java:391) finished in 0.017 s
97709 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 74, remaining stages = 0
97709 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 47 finished: zipWithIndex at SparkUtils.java:391, took 0.020116 s
97709 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) +++
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.serialVersionUID
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.PairFunction org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.x$334
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.Tuple2 org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(java.lang.Object)
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97710 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1) is now cleaned +++
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) +++
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.serialVersionUID
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(java.lang.Object)
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1.apply(scala.Tuple2)
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97711 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1) is now cleaned +++
97712 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_102 stored as values in memory (estimated size 30.9 KB, free 366.1 MB)
97712 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_102 locally took  0 ms
97712 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_102 without replication took  0 ms
97713 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_102_piece0 stored as bytes in memory (estimated size 5.2 KB, free 366.1 MB)
97713 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_102_piece0 in memory on 192.168.1.4:49908 (size: 5.2 KB, free: 366.3 MB)
97713 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_102_piece0
97713 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_102_piece0
97713 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_102_piece0 locally took  0 ms
97713 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_102_piece0 without replication took  0 ms
97713 [main] INFO org.apache.spark.SparkContext  - Created broadcast 102 from broadcast at ParameterAveragingTrainingMaster.java:259
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97714 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
97715 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97716 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97717 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
97717 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
97718 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97719 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97720 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
97721 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
97722 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
97723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
97723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
97723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
97723 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
97723 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at ParameterAveragingTrainingMaster.java:801
97723 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 27 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
97723 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 149 (mapToPair at SparkUtils.java:391)
97723 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 154 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
97723 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 48 (treeAggregate at ParameterAveragingTrainingMaster.java:801) with 2 output partitions
97723 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 77 (treeAggregate at ParameterAveragingTrainingMaster.java:801)
97723 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 76)
97723 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 76)
97723 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 77)
97723 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 76)
97723 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 76)
97723 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 75)
97723 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 75)
97724 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
97724 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 75 (MapPartitionsRDD[149] at mapToPair at SparkUtils.java:391), which has no missing parents
97724 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 75)
97724 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_103 stored as values in memory (estimated size 3.5 KB, free 366.1 MB)
97724 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_103 locally took  0 ms
97724 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_103 without replication took  0 ms
97725 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_103_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
97725 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_103_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
97725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_103_piece0
97725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_103_piece0
97725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_103_piece0 locally took  0 ms
97725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_103_piece0 without replication took  0 ms
97725 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 103 from broadcast at DAGScheduler.scala:1006
97725 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[149] at mapToPair at SparkUtils.java:391) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
97725 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 75.0 with 8 tasks
97726 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 75.0: 27
97726 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 75.0: PROCESS_LOCAL, NODE_LOCAL, ANY
97726 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 0
97726 [dispatcher-event-loop-6] WARN org.apache.spark.scheduler.TaskSetManager  - Stage 75 contains a task of very large size (100 KB). The maximum recommended task size is 100 KB.
97726 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 75.0 (TID 482, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 102870 bytes)
97727 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 75.0 (TID 483, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 122387 bytes)
97728 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 75.0 (TID 484, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 102870 bytes)
97729 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 75.0 (TID 485, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 122387 bytes)
97729 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 75.0 (TID 486, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 122387 bytes)
97730 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 75.0 (TID 487, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 102870 bytes)
97731 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 75.0 (TID 488, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 122387 bytes)
97732 [dispatcher-event-loop-6] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 75.0 (TID 489, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 122387 bytes)
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 482 on executor id: 0 hostname: 192.168.1.4.
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 483 on executor id: 0 hostname: 192.168.1.4.
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 484 on executor id: 0 hostname: 192.168.1.4.
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 485 on executor id: 0 hostname: 192.168.1.4.
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 486 on executor id: 0 hostname: 192.168.1.4.
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 487 on executor id: 0 hostname: 192.168.1.4.
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 488 on executor id: 0 hostname: 192.168.1.4.
97732 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 489 on executor id: 0 hostname: 192.168.1.4.
97736 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_103_piece0 as bytes
97736 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_103_piece0 is StorageLevel(disk, memory, 1 replicas)
97737 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_103_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
97745 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 7
97745 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
97745 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
97745 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 75.0 (TID 487) in 16 ms on 192.168.1.4 (executor 0) (1/8)
97745 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 6
97746 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97746 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 75.0 (TID 488) in 16 ms on 192.168.1.4 (executor 0) (2/8)
97746 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 5
97746 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97746 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 75.0 (TID 485) in 18 ms on 192.168.1.4 (executor 0) (3/8)
97746 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97747 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 4
97747 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 75.0 (TID 489) in 16 ms on 192.168.1.4 (executor 0) (4/8)
97747 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 3
97748 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97748 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 75.0 (TID 484) in 21 ms on 192.168.1.4 (executor 0) (5/8)
97748 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97749 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 2
97749 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 75.0 (TID 486) in 20 ms on 192.168.1.4 (executor 0) (6/8)
97749 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97750 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 1
97750 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 75.0 (TID 482) in 24 ms on 192.168.1.4 (executor 0) (7/8)
97750 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_75.0, runningTasks: 0
97750 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97750 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 75.0 (TID 483) in 24 ms on 192.168.1.4 (executor 0) (8/8)
97750 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 75.0, whose tasks have all completed, from pool 
97750 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
97750 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 75 (mapToPair at SparkUtils.java:391) finished in 0.024 s
97750 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
97750 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
97750 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ShuffleMapStage 76, ResultStage 77)
97750 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
97750 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 28
97750 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 76)
97750 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
97750 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 76 (MapPartitionsRDD[154] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
97750 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 76)
97751 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_104 stored as values in memory (estimated size 6.6 KB, free 366.1 MB)
97751 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_104 locally took  0 ms
97752 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_104 without replication took  1 ms
97752 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_104_piece0 stored as bytes in memory (estimated size 3.5 KB, free 366.1 MB)
97752 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_104_piece0 in memory on 192.168.1.4:49908 (size: 3.5 KB, free: 366.3 MB)
97752 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_104_piece0
97752 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_104_piece0
97752 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_104_piece0 locally took  0 ms
97752 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_104_piece0 without replication took  0 ms
97753 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 104 from broadcast at DAGScheduler.scala:1006
97753 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[154] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
97753 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 76.0 with 8 tasks
97753 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 76.0: 28
97753 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 76.0: NODE_LOCAL, ANY
97753 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 0
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 76.0 (TID 490, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 76.0 (TID 491, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 76.0 (TID 492, 192.168.1.4, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 76.0 (TID 493, 192.168.1.4, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 76.0 (TID 494, 192.168.1.4, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 76.0 (TID 495, 192.168.1.4, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 76.0 (TID 496, 192.168.1.4, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 76.0 (TID 497, 192.168.1.4, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
97753 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 490 on executor id: 0 hostname: 192.168.1.4.
97753 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 491 on executor id: 0 hostname: 192.168.1.4.
97753 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 492 on executor id: 0 hostname: 192.168.1.4.
97753 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 493 on executor id: 0 hostname: 192.168.1.4.
97753 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 494 on executor id: 0 hostname: 192.168.1.4.
97753 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 495 on executor id: 0 hostname: 192.168.1.4.
97754 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 496 on executor id: 0 hostname: 192.168.1.4.
97754 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 497 on executor id: 0 hostname: 192.168.1.4.
97756 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_104_piece0 as bytes
97756 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_104_piece0 is StorageLevel(disk, memory, 1 replicas)
97757 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_104_piece0 in memory on 192.168.1.4:49916 (size: 3.5 KB, free: 365.4 MB)
97758 [dispatcher-event-loop-3] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 28 to 192.168.1.4:49914
97759 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 28 to 192.168.1.4:49914
97759 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 28
97759 [map-output-dispatcher-3] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 28
97759 [map-output-dispatcher-3] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 28 is 186 bytes
97761 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_102_piece0 as bytes
97761 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_102_piece0 is StorageLevel(disk, memory, 1 replicas)
97762 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_102_piece0 in memory on 192.168.1.4:49916 (size: 5.2 KB, free: 365.4 MB)
98374 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 8
99376 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 8
99559 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 7
99559 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
99559 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 76.0 (TID 495) in 1806 ms on 192.168.1.4 (executor 0) (1/8)
99559 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
100377 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 7
101268 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 6
101268 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 76.0 (TID 497) in 3515 ms on 192.168.1.4 (executor 0) (2/8)
101268 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
101287 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 5
101287 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 76.0 (TID 496) in 3534 ms on 192.168.1.4 (executor 0) (3/8)
101287 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
101374 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 5
101546 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 4
101546 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 76.0 (TID 494) in 3793 ms on 192.168.1.4 (executor 0) (4/8)
101546 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
101577 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 3
101578 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 76.0 (TID 491) in 3825 ms on 192.168.1.4 (executor 0) (5/8)
101578 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
101588 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 2
101588 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 76.0 (TID 492) in 3835 ms on 192.168.1.4 (executor 0) (6/8)
101588 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
101631 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 1
101631 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_76.0, runningTasks: 0
101631 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 76.0 (TID 490) in 3878 ms on 192.168.1.4 (executor 0) (7/8)
101631 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 76.0 (TID 493) in 3878 ms on 192.168.1.4 (executor 0) (8/8)
101631 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 76.0, whose tasks have all completed, from pool 
101631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
101631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
101631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 76 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 3.878 s
101631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
101631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
101631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 77)
101631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
101631 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 29
101631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 77)
101631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
101631 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 77 (MapPartitionsRDD[156] at treeAggregate at ParameterAveragingTrainingMaster.java:801), which has no missing parents
101631 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 77)
101632 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_105 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
101632 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_105 locally took  0 ms
101632 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_105 without replication took  0 ms
101633 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_105_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
101633 [dispatcher-event-loop-7] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_105_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
101633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_105_piece0
101633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_105_piece0
101633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_105_piece0 locally took  0 ms
101633 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_105_piece0 without replication took  0 ms
101633 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 105 from broadcast at DAGScheduler.scala:1006
101633 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 77 (MapPartitionsRDD[156] at treeAggregate at ParameterAveragingTrainingMaster.java:801) (first 15 tasks are for partitions Vector(0, 1))
101633 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 77.0 with 2 tasks
101633 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 77.0: 29
101633 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 77.0: NODE_LOCAL, ANY
101634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_77.0, runningTasks: 0
101634 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 77.0 (TID 498, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
101634 [dispatcher-event-loop-3] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 77.0 (TID 499, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
101634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
101634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 498 on executor id: 0 hostname: 192.168.1.4.
101634 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 499 on executor id: 0 hostname: 192.168.1.4.
101636 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_105_piece0 as bytes
101636 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_105_piece0 is StorageLevel(disk, memory, 1 replicas)
101637 [dispatcher-event-loop-1] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_105_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
101638 [dispatcher-event-loop-4] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 27 to 192.168.1.4:49914
101638 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 27 to 192.168.1.4:49914
101638 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 27
101638 [map-output-dispatcher-4] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 27
101638 [map-output-dispatcher-4] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 27 is 159 bytes
101719 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_77.0, runningTasks: 1
101719 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_77.0, runningTasks: 0
101719 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 77.0 (TID 498) in 85 ms on 192.168.1.4 (executor 0) (1/2)
101719 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 77.0 (TID 499) in 85 ms on 192.168.1.4 (executor 0) (2/2)
101719 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 77.0, whose tasks have all completed, from pool 
101719 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 77 (treeAggregate at ParameterAveragingTrainingMaster.java:801) finished in 0.086 s
101720 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 77, remaining stages = 2
101720 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 76, remaining stages = 1
101720 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 75, remaining stages = 0
101720 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 48 finished: treeAggregate at ParameterAveragingTrainingMaster.java:801, took 3.997210 s
101720 [main] INFO org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster  - Completed training of split 1 of 1
101721 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_106 stored as values in memory (estimated size 8.0 KB, free 366.1 MB)
101721 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_106 locally took  0 ms
101721 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_106 without replication took  0 ms
101722 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_106_piece0 stored as bytes in memory (estimated size 1428.0 B, free 366.1 MB)
101722 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_106_piece0 in memory on 192.168.1.4:49908 (size: 1428.0 B, free: 366.3 MB)
101722 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_106_piece0
101722 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_106_piece0
101722 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_106_piece0 locally took  0 ms
101722 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_106_piece0 without replication took  0 ms
101722 [main] INFO org.apache.spark.SparkContext  - Created broadcast 106 from broadcast at SparkDl4jMultiLayer.java:595
101723 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_107 stored as values in memory (estimated size 27.3 KB, free 366.1 MB)
101723 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_107 locally took  1 ms
101723 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_107 without replication took  1 ms
101724 [main] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_107_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.1 MB)
101724 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_107_piece0 in memory on 192.168.1.4:49908 (size: 2.5 KB, free: 366.3 MB)
101724 [main] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_107_piece0
101724 [main] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_107_piece0
101724 [main] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_107_piece0 locally took  0 ms
101724 [main] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_107_piece0 without replication took  0 ms
101724 [main] INFO org.apache.spark.SparkContext  - Created broadcast 107 from broadcast at SparkDl4jMultiLayer.java:596
101724 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) +++
101724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101724 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.serialVersionUID
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.FlatMapFunction org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.f$6
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(java.lang.Object)
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(scala.collection.Iterator)
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1) is now cleaned +++
101725 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101726 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) +++
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.serialVersionUID
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.aggregatePartition$1
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(java.lang.Object)
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(scala.collection.Iterator)
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101727 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25) is now cleaned +++
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) +++
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.serialVersionUID
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final int org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.curNumPartitions$1
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(java.lang.Object,java.lang.Object)
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(int,scala.collection.Iterator)
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 1
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26$$anonfun$apply$42
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101728 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26) is now cleaned +++
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) +++
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.serialVersionUID
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13.apply(java.lang.Object)
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101729 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$13) is now cleaned +++
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101730 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) +++
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 1
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.serialVersionUID
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(java.lang.Object)
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1.apply(scala.Tuple2)
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101731 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1) is now cleaned +++
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) +++
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.serialVersionUID
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final org.apache.spark.api.java.function.Function2 org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.fun$2
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 1
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(java.lang.Object,java.lang.Object)
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1) is now cleaned +++
101732 [main] DEBUG org.apache.spark.util.ClosureCleaner  - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$33) +++
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared fields: 2
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public static final long org.apache.spark.SparkContext$$anonfun$33.serialVersionUID
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$33.processPartition$1
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + declared methods: 2
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(java.lang.Object,java.lang.Object)
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$33.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + inner classes: 0
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer classes: 0
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + outer objects: 0
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + populating accessed fields because this is the starting closure
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + fields accessed by starting closure: 0
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  + there are no enclosing objects!
101733 [main] DEBUG org.apache.spark.util.ClosureCleaner  -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$33) is now cleaned +++
101733 [main] INFO org.apache.spark.SparkContext  - Starting job: treeAggregate at SparkDl4jMultiLayer.java:598
101733 [dag-scheduler-event-loop] DEBUG org.apache.spark.shuffle.sort.SortShuffleManager  - Can't use serialized shuffle for shuffle 29 because the serializer, org.apache.spark.serializer.JavaSerializer, does not support object relocation
101733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Registering RDD 159 (treeAggregate at SparkDl4jMultiLayer.java:598)
101733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Got job 49 (treeAggregate at SparkDl4jMultiLayer.java:598) with 2 output partitions
101733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Final stage: ResultStage 79 (treeAggregate at SparkDl4jMultiLayer.java:598)
101733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Parents of final stage: List(ShuffleMapStage 78)
101733 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Missing parents: List(ShuffleMapStage 78)
101733 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 79)
101734 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List(ShuffleMapStage 78)
101734 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ShuffleMapStage 78)
101734 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
101734 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ShuffleMapStage 78 (MapPartitionsRDD[159] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
101734 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ShuffleMapStage 78)
101734 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_108 stored as values in memory (estimated size 9.0 KB, free 366.1 MB)
101734 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_108 locally took  0 ms
101734 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_108 without replication took  0 ms
101735 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_108_piece0 stored as bytes in memory (estimated size 4.1 KB, free 366.1 MB)
101735 [dispatcher-event-loop-5] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_108_piece0 in memory on 192.168.1.4:49908 (size: 4.1 KB, free: 366.3 MB)
101735 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_108_piece0
101735 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_108_piece0
101735 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_108_piece0 locally took  0 ms
101735 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_108_piece0 without replication took  0 ms
101735 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 108 from broadcast at DAGScheduler.scala:1006
101735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 8 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[159] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
101735 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 78.0 with 8 tasks
101736 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 78.0: 29
101736 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 78.0: NO_PREF, ANY
101736 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 0
101736 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 78.0 (TID 500, 192.168.1.4, executor 0, partition 0, PROCESS_LOCAL, 24692 bytes)
101736 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 78.0 (TID 501, 192.168.1.4, executor 0, partition 1, PROCESS_LOCAL, 44209 bytes)
101737 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 2.0 in stage 78.0 (TID 502, 192.168.1.4, executor 0, partition 2, PROCESS_LOCAL, 44209 bytes)
101737 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 3.0 in stage 78.0 (TID 503, 192.168.1.4, executor 0, partition 3, PROCESS_LOCAL, 44209 bytes)
101737 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 4.0 in stage 78.0 (TID 504, 192.168.1.4, executor 0, partition 4, PROCESS_LOCAL, 44209 bytes)
101738 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 5.0 in stage 78.0 (TID 505, 192.168.1.4, executor 0, partition 5, PROCESS_LOCAL, 44209 bytes)
101738 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 6.0 in stage 78.0 (TID 506, 192.168.1.4, executor 0, partition 6, PROCESS_LOCAL, 44209 bytes)
101738 [dispatcher-event-loop-2] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 7.0 in stage 78.0 (TID 507, 192.168.1.4, executor 0, partition 7, PROCESS_LOCAL, 44209 bytes)
101738 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 500 on executor id: 0 hostname: 192.168.1.4.
101738 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 501 on executor id: 0 hostname: 192.168.1.4.
101738 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 502 on executor id: 0 hostname: 192.168.1.4.
101739 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 503 on executor id: 0 hostname: 192.168.1.4.
101739 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 504 on executor id: 0 hostname: 192.168.1.4.
101739 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 505 on executor id: 0 hostname: 192.168.1.4.
101739 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 506 on executor id: 0 hostname: 192.168.1.4.
101739 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 507 on executor id: 0 hostname: 192.168.1.4.
101742 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_108_piece0 as bytes
101742 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_108_piece0 is StorageLevel(disk, memory, 1 replicas)
101743 [dispatcher-event-loop-4] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_108_piece0 in memory on 192.168.1.4:49916 (size: 4.1 KB, free: 365.4 MB)
101746 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_107_piece0 as bytes
101746 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_107_piece0 is StorageLevel(disk, memory, 1 replicas)
101747 [dispatcher-event-loop-0] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_107_piece0 in memory on 192.168.1.4:49916 (size: 2.5 KB, free: 365.4 MB)
101784 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_106_piece0 as bytes
101784 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_106_piece0 is StorageLevel(disk, memory, 1 replicas)
101784 [dispatcher-event-loop-6] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_106_piece0 in memory on 192.168.1.4:49916 (size: 1428.0 B, free: 365.4 MB)
102030 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 7
102030 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NO_PREF, so moving to locality level ANY
102030 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 7.0 in stage 78.0 (TID 507) in 292 ms on 192.168.1.4 (executor 0) (1/8)
102030 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102226 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 6
102226 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 78.0 (TID 500) in 490 ms on 192.168.1.4 (executor 0) (2/8)
102226 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102323 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 5
102323 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 6.0 in stage 78.0 (TID 506) in 585 ms on 192.168.1.4 (executor 0) (3/8)
102323 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102338 [dispatcher-event-loop-4] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 4
102339 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 5.0 in stage 78.0 (TID 505) in 601 ms on 192.168.1.4 (executor 0) (4/8)
102339 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102375 [dispatcher-event-loop-7] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 4
102429 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 3
102429 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 4.0 in stage 78.0 (TID 504) in 692 ms on 192.168.1.4 (executor 0) (5/8)
102429 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102433 [dispatcher-event-loop-3] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 2
102434 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 3.0 in stage 78.0 (TID 503) in 697 ms on 192.168.1.4 (executor 0) (6/8)
102434 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102439 [dispatcher-event-loop-6] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 1
102439 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 78.0 (TID 501) in 703 ms on 192.168.1.4 (executor 0) (7/8)
102439 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102445 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_78.0, runningTasks: 0
102446 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 2.0 in stage 78.0 (TID 502) in 710 ms on 192.168.1.4 (executor 0) (8/8)
102446 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 78.0, whose tasks have all completed, from pool 
102446 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - ShuffleMapTask finished on 0
102446 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ShuffleMapStage 78 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.710 s
102446 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - looking for newly runnable stages
102446 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - running: Set()
102446 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - waiting: Set(ResultStage 79)
102446 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - failed: Set()
102446 [dag-scheduler-event-loop] DEBUG org.apache.spark.MapOutputTrackerMaster  - Increasing epoch to 30
102446 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitStage(ResultStage 79)
102446 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - missing: List()
102446 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting ResultStage 79 (MapPartitionsRDD[161] at treeAggregate at SparkDl4jMultiLayer.java:598), which has no missing parents
102446 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - submitMissingTasks(ResultStage 79)
102447 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_109 stored as values in memory (estimated size 3.6 KB, free 366.1 MB)
102447 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_109 locally took  1 ms
102447 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_109 without replication took  1 ms
102447 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore  - Block broadcast_109_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.1 MB)
102448 [dispatcher-event-loop-2] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_109_piece0 in memory on 192.168.1.4:49908 (size: 2.1 KB, free: 366.3 MB)
102448 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster  - Updated info of block broadcast_109_piece0
102448 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Told master about block broadcast_109_piece0
102448 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Put block broadcast_109_piece0 locally took  1 ms
102448 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager  - Putting block broadcast_109_piece0 without replication took  1 ms
102448 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext  - Created broadcast 109 from broadcast at DAGScheduler.scala:1006
102448 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - Submitting 2 missing tasks from ResultStage 79 (MapPartitionsRDD[161] at treeAggregate at SparkDl4jMultiLayer.java:598) (first 15 tasks are for partitions Vector(0, 1))
102448 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Adding task set 79.0 with 2 tasks
102448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Epoch for TaskSet 79.0: 30
102448 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager  - Valid locality levels for TaskSet 79.0: NODE_LOCAL, ANY
102448 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_79.0, runningTasks: 0
102448 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 0.0 in stage 79.0 (TID 508, 192.168.1.4, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
102449 [dispatcher-event-loop-1] INFO org.apache.spark.scheduler.TaskSetManager  - Starting task 1.0 in stage 79.0 (TID 509, 192.168.1.4, executor 0, partition 1, NODE_LOCAL, 4625 bytes)
102449 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSetManager  - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
102449 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 508 on executor id: 0 hostname: 192.168.1.4.
102449 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Launching task 509 on executor id: 0 hostname: 192.168.1.4.
102451 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Getting local block broadcast_109_piece0 as bytes
102451 [shuffle-server-5-2] DEBUG org.apache.spark.storage.BlockManager  - Level for block broadcast_109_piece0 is StorageLevel(disk, memory, 1 replicas)
102452 [dispatcher-event-loop-3] INFO org.apache.spark.storage.BlockManagerInfo  - Added broadcast_109_piece0 in memory on 192.168.1.4:49916 (size: 2.1 KB, free: 365.4 MB)
102453 [dispatcher-event-loop-6] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - Asked to send map output locations for shuffle 29 to 192.168.1.4:49914
102453 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - Handling request to send map output locations for shuffle 29 to 192.168.1.4:49914
102453 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 29
102453 [map-output-dispatcher-5] DEBUG org.apache.spark.MapOutputTrackerMaster  - cached status not found for : 29
102453 [map-output-dispatcher-5] INFO org.apache.spark.MapOutputTrackerMaster  - Size of output statuses for shuffle 29 is 159 bytes
102457 [dispatcher-event-loop-5] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_79.0, runningTasks: 1
102457 [dispatcher-event-loop-2] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl  - parentName: , name: TaskSet_79.0, runningTasks: 0
102457 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 0.0 in stage 79.0 (TID 508) in 9 ms on 192.168.1.4 (executor 0) (1/2)
102457 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager  - Finished task 1.0 in stage 79.0 (TID 509) in 9 ms on 192.168.1.4 (executor 0) (2/2)
102457 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl  - Removed TaskSet 79.0, whose tasks have all completed, from pool 
102458 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler  - ResultStage 79 (treeAggregate at SparkDl4jMultiLayer.java:598) finished in 0.010 s
102458 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 79, remaining stages = 1
102458 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler  - After removal of stage 78, remaining stages = 0
102458 [main] INFO org.apache.spark.scheduler.DAGScheduler  - Job 49 finished: treeAggregate at SparkDl4jMultiLayer.java:598, took 0.724763 s
102459 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Test set evaluation at epoch 9: Accuracy = 0.19, F1 = 0.32
102459 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - Completed Epoch 9
102459 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - ##############EVALUTAION##########
##############DONE############
102459 [main] INFO skymind.dsx.UCISequenceClassificationSpark2  - ----- Example Complete -----
102553 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Got cleaning task CleanRDD(0)
102553 [Spark Context Cleaner] DEBUG org.apache.spark.ContextCleaner  - Cleaning RDD 0
102561 [Thread-1] INFO org.apache.spark.SparkContext  - Invoking stop() from shutdown hook
102563 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.Server@7d373bcf
102563 [Thread-1] DEBUG org.spark_project.jetty.server.Server  - doStop org.spark_project.jetty.server.Server@7d373bcf
102563 [SparkUI-49] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran SparkUI-49-acceptor-0@52eacb4b-ServerConnector@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
102564 [block-manager-slave-async-thread-pool-2] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - removing RDD 0
102565 [Thread-1] DEBUG org.spark_project.jetty.server.Server  - Graceful shutdown org.spark_project.jetty.server.Server@7d373bcf by 
102565 [block-manager-slave-async-thread-pool-2] INFO org.apache.spark.storage.BlockManager  - Removing RDD 0
102565 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping Spark@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
102565 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42
102565 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
102565 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
102566 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1d8df246 on org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
102566 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102567 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1d8df246
102567 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
102567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Done removing RDD 0, response is 0
102567 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
102567 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
102567 [block-manager-slave-async-thread-pool-1] DEBUG org.apache.spark.storage.BlockManagerSlaveEndpoint  - Sent response: 0 to 192.168.1.4:49902
102567 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@63543a03 on org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=0 selected=0
102567 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102567 [SparkUI-48] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@63543a03
102568 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@19e9d793 produced null
102568 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@19e9d793 produce exit
102568 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=-1 selected=-1
102568 [SparkUI-48] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=-1 selected=-1
102568 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@c41709a id=3 keys=-1 selected=-1
102568 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
102568 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
102568 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1139fbed on org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
102568 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102568 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1139fbed
102568 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
102568 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
102568 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
102568 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@6cdb283b on org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=0 selected=0
102568 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102568 [SparkUI-47] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@6cdb283b
102568 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@223853fc produced null
102568 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@223853fc produce exit
102568 [SparkUI-47] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=-1 selected=-1
102568 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=-1 selected=-1
102568 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@70eecdc2 id=2 keys=-1 selected=-1
102568 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
102568 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
102568 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@57ea34f1 on org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
102569 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102569 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@57ea34f1
102569 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
102569 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
102569 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
102569 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@152c882d on org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=0 selected=0
102569 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102569 [SparkUI-46] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@152c882d
102569 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6ab3e57 produced null
102569 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=-1 selected=-1
102569 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6ab3e57 produce exit
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=-1 selected=-1
102569 [SparkUI-46] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@20312893 id=1 keys=-1 selected=-1
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
102569 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopping org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
102569 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4b94eff6 on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
102569 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102569 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4b94eff6
102569 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
102569 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
102569 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop waiting on select
102569 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@7e3b9c4f on org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=0 selected=0
102569 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Selector loop woken up from select, 0/0 selected
102569 [SparkUI-45] DEBUG org.spark_project.jetty.io.ManagedSelector  - Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@7e3b9c4f
102569 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 produced null
102569 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume  - EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3e9c8c97 produce exit
102569 [Thread-1] DEBUG org.spark_project.jetty.io.ManagedSelector  - Stopped org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=-1 selected=-1
102569 [SparkUI-45] DEBUG org.spark_project.jetty.util.thread.QueuedThreadPool  - ran org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=-1 selected=-1
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.io.ManagedSelector@2a7b6f69 id=0 keys=-1 selected=-1
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@443dbe42
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping HttpConnectionFactory@6c4f9535[HTTP/1.1]
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED HttpConnectionFactory@6c4f9535[HTTP/1.1]
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@1e11bc55
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@1e11bc55
102569 [Thread-1] INFO org.spark_project.jetty.server.AbstractConnector  - Stopped Spark@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED Spark@63fd4873{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
102569 [Thread-1] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - stopping org.spark_project.jetty.server.Server@7d373bcf
102569 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100, org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec, org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617, o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,SHUTDOWN,@Spark}]
102570 [Thread-1] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100, org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec, org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617, o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,SHUTDOWN,@Spark}]
102570 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@5a021cb9[org.spark_project.jetty.server.handler.gzip.GzipHandler@581d969c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c291aad, org.spark_project.jetty.server.handler.gzip.GzipHandler@1cfd1875, org.spark_project.jetty.server.handler.gzip.GzipHandler@68ed96ca, org.spark_project.jetty.server.handler.gzip.GzipHandler@51c929ae, org.spark_project.jetty.server.handler.gzip.GzipHandler@512d92b, org.spark_project.jetty.server.handler.gzip.GzipHandler@475b7792, org.spark_project.jetty.server.handler.gzip.GzipHandler@3153ddfc, org.spark_project.jetty.server.handler.gzip.GzipHandler@33a2499c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abd581e, org.spark_project.jetty.server.handler.gzip.GzipHandler@12f3afb5, org.spark_project.jetty.server.handler.gzip.GzipHandler@6831d8fd, org.spark_project.jetty.server.handler.gzip.GzipHandler@5a2f016d, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bb9efbc, org.spark_project.jetty.server.handler.gzip.GzipHandler@6ca320ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@619bd14c, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b52d3e, org.spark_project.jetty.server.handler.gzip.GzipHandler@36dce7ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@32c0915e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c282004, org.spark_project.jetty.server.handler.gzip.GzipHandler@3c1e3314, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a71c100, org.spark_project.jetty.server.handler.gzip.GzipHandler@7e8e8651, org.spark_project.jetty.server.handler.gzip.GzipHandler@3fc08eec, org.spark_project.jetty.server.handler.gzip.GzipHandler@4201a617, o.s.j.s.ServletContextHandler@4cbf4f53{/metrics/json,null,SHUTDOWN,@Spark}]
102570 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping org.spark_project.jetty.server.handler.ErrorHandler@10027fc9
102570 [Thread-1] DEBUG org.spark_project.jetty.server.handler.AbstractHandler  - stopping org.spark_project.jetty.server.handler.ErrorHandler@10027fc9
102570 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.handler.ErrorHandler@10027fc9
102570 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
102571 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
102571 [Thread-1] DEBUG org.spark_project.jetty.util.component.AbstractLifeCycle  - STOPPED org.spark_project.jetty.server.Server@7d373bcf
102571 [Thread-1] INFO org.apache.spark.ui.SparkUI  - Stopped Spark web UI at http://192.168.1.4:4040
102579 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner  - Cleaned RDD 0
102582 [Thread-1] INFO org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend  - Shutting down all executors
102582 [dispatcher-event-loop-7] INFO org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint  - Asking each executor to shut down
102588 [dispatcher-event-loop-1] INFO org.apache.spark.MapOutputTrackerMasterEndpoint  - MapOutputTrackerMasterEndpoint stopped!
102601 [Thread-1] INFO org.apache.spark.storage.memory.MemoryStore  - MemoryStore cleared
102601 [Thread-1] INFO org.apache.spark.storage.BlockManager  - BlockManager stopped
102602 [Thread-1] INFO org.apache.spark.storage.BlockManagerMaster  - BlockManagerMaster stopped
102605 [dispatcher-event-loop-5] INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint  - OutputCommitCoordinator stopped!
102606 [rpc-server-3-2] DEBUG io.netty.buffer.PoolThreadCache  - Freed 3 thread-local buffer(s) from thread: rpc-server-3-2
102607 [Thread-1] INFO org.apache.spark.SparkContext  - Successfully stopped SparkContext
102607 [Thread-1] INFO org.apache.spark.util.ShutdownHookManager  - Shutdown hook called
102608 [Thread-1] INFO org.apache.spark.util.ShutdownHookManager  - Deleting directory /private/var/folders/p6/22lhx4414k55sf3nrsgqw0_80000gn/T/spark-3119c848-bdd7-430c-b867-32e535f8e122
